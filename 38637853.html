<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1702544459156" as="style"/><link rel="stylesheet" href="styles.css?v=1702544459156"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://github.com/microsoft/windows-ai-studio">Windows AI Studio Preview</a> <span class="domain">(<a href="https://github.com">github.com</a>)</span></div><div class="subtext"><span>Jayakumark</span> | <span>26 comments</span></div><br/><div><div id="38637924" class="c"><input type="checkbox" id="c-38637924" checked=""/><div class="controls bullet"><span class="by">blackoil</span><span>|</span><a href="#38637890">next</a><span>|</span><label class="collapse" for="c-38637924">[-]</label><label class="expand" for="c-38637924">[17 more]</label></div><br/><div class="children"><div class="content">Windows AI Studio is in real a Linux AI Studio as it needs WSL to run. Little funny</div><br/><div id="38638984" class="c"><input type="checkbox" id="c-38638984" checked=""/><div class="controls bullet"><span class="by">severino</span><span>|</span><a href="#38637924">parent</a><span>|</span><a href="#38637993">next</a><span>|</span><label class="collapse" for="c-38638984">[-]</label><label class="expand" for="c-38638984">[3 more]</label></div><br/><div class="children"><div class="content">But can you get this to run in Linux? From the article I can see it&#x27;s a VSCode extension or something like that but the name kind of implies it&#x27;s Windows only.</div><br/><div id="38639033" class="c"><input type="checkbox" id="c-38639033" checked=""/><div class="controls bullet"><span class="by">diffeomorphism</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38638984">parent</a><span>|</span><a href="#38637993">next</a><span>|</span><label class="collapse" for="c-38639033">[-]</label><label class="expand" for="c-38639033">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <a href="https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;windows-ai-studio&#x2F;blob&#x2F;main&#x2F;QA.md">https:&#x2F;&#x2F;github.com&#x2F;microsoft&#x2F;windows-ai-studio&#x2F;blob&#x2F;main&#x2F;QA....</a><p>For now, but seems to be planned in the future.</div><br/><div id="38639178" class="c"><input type="checkbox" id="c-38639178" checked=""/><div class="controls bullet"><span class="by">severino</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38639033">parent</a><span>|</span><a href="#38637993">next</a><span>|</span><label class="collapse" for="c-38639178">[-]</label><label class="expand" for="c-38639178">[1 more]</label></div><br/><div class="children"><div class="content">Yep, didn&#x27;t read that. In the meantime, kudos to Canonical (and other parties) who helped Microsoft with WSL. Now they can also use Linux to produce Windows-only software! :D</div><br/></div></div></div></div></div></div><div id="38637993" class="c"><input type="checkbox" id="c-38637993" checked=""/><div class="controls bullet"><span class="by">mmis1000</span><span>|</span><a href="#38637924">parent</a><span>|</span><a href="#38638984">prev</a><span>|</span><a href="#38638979">next</a><span>|</span><label class="collapse" for="c-38637993">[-]</label><label class="expand" for="c-38637993">[12 more]</label></div><br/><div class="children"><div class="content">that probably explain why nvidia only. Amd don&#x27;t really have rocm for linux on latest consumer cards.</div><br/><div id="38638257" class="c"><input type="checkbox" id="c-38638257" checked=""/><div class="controls bullet"><span class="by">Cu3PO42</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38637993">parent</a><span>|</span><a href="#38638091">next</a><span>|</span><label class="collapse" for="c-38638257">[-]</label><label class="expand" for="c-38638257">[2 more]</label></div><br/><div class="children"><div class="content">Support is not nearly as ubiquitous as for CUDA, but it&#x27;s there for some current and last Gen cards.</div><br/><div id="38638602" class="c"><input type="checkbox" id="c-38638602" checked=""/><div class="controls bullet"><span class="by">mmis1000</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38638257">parent</a><span>|</span><a href="#38638091">next</a><span>|</span><label class="collapse" for="c-38638602">[-]</label><label class="expand" for="c-38638602">[1 more]</label></div><br/><div class="children"><div class="content">They did add support for the whole rdna2&#x2F;3 series to windows. But only support for 7900xt&#x2F;xtx were added to linux for some reason. And softwere in title seems actually ran on linux.<p>Besides that, I don&#x27;t think I ever heard that they supports container at all.</div><br/></div></div></div></div><div id="38638091" class="c"><input type="checkbox" id="c-38638091" checked=""/><div class="controls bullet"><span class="by">iotku</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38637993">parent</a><span>|</span><a href="#38638257">prev</a><span>|</span><a href="#38638676">next</a><span>|</span><label class="collapse" for="c-38638091">[-]</label><label class="expand" for="c-38638091">[8 more]</label></div><br/><div class="children"><div class="content">The Nvidia container toolkit works pretty much out of the box on WSL these days as well.<p>Funny that some cuda stuff works better through Windows virtualizing Linux than Windows natively, but if we&#x27;re being honest even as a native Linux user, WSL probably provides a better user experience (vs having to use Nvidia drivers on Linux anyways)</div><br/><div id="38638111" class="c"><input type="checkbox" id="c-38638111" checked=""/><div class="controls bullet"><span class="by">theturtle32</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38638091">parent</a><span>|</span><a href="#38638530">next</a><span>|</span><label class="collapse" for="c-38638111">[-]</label><label class="expand" for="c-38638111">[2 more]</label></div><br/><div class="children"><div class="content">Having had the displeasure of trying to get CUDA running under WSL2, I can tell you it is most definitely not a better user experience :-P</div><br/><div id="38638207" class="c"><input type="checkbox" id="c-38638207" checked=""/><div class="controls bullet"><span class="by">freeone3000</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38638111">parent</a><span>|</span><a href="#38638530">next</a><span>|</span><label class="collapse" for="c-38638207">[-]</label><label class="expand" for="c-38638207">[1 more]</label></div><br/><div class="children"><div class="content">Is it a better user experience than trying to get CUDA natively? :P</div><br/></div></div></div></div><div id="38638530" class="c"><input type="checkbox" id="c-38638530" checked=""/><div class="controls bullet"><span class="by">vunderba</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38638091">parent</a><span>|</span><a href="#38638111">prev</a><span>|</span><a href="#38638645">next</a><span>|</span><label class="collapse" for="c-38638530">[-]</label><label class="expand" for="c-38638530">[3 more]</label></div><br/><div class="children"><div class="content">Is the container toolkit even necessary anymore in WSL2? I did a fresh install of windows 10 LTSC a few weeks ago and installed WSL2 and docker with WSL2 integration and I was able to use my nvidia rtx card (checked through nvidia-smi) without any issues.</div><br/><div id="38638808" class="c"><input type="checkbox" id="c-38638808" checked=""/><div class="controls bullet"><span class="by">anvuong</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38638530">parent</a><span>|</span><a href="#38638645">next</a><span>|</span><label class="collapse" for="c-38638808">[-]</label><label class="expand" for="c-38638808">[2 more]</label></div><br/><div class="children"><div class="content">It registered the card, as in you can query the device id using nvidia-smi. But CUDA&#x2F;cuDNN requires further work.</div><br/><div id="38638884" class="c"><input type="checkbox" id="c-38638884" checked=""/><div class="controls bullet"><span class="by">holoduke</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38638808">parent</a><span>|</span><a href="#38638645">next</a><span>|</span><label class="collapse" for="c-38638884">[-]</label><label class="expand" for="c-38638884">[1 more]</label></div><br/><div class="children"><div class="content">What? No latest windows drivers give full cuda support in wsl out of the box. I am running all kinds of models without any issues at all.</div><br/></div></div></div></div></div></div><div id="38638645" class="c"><input type="checkbox" id="c-38638645" checked=""/><div class="controls bullet"><span class="by">ekianjo</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38638091">parent</a><span>|</span><a href="#38638530">prev</a><span>|</span><a href="#38638676">next</a><span>|</span><label class="collapse" for="c-38638645">[-]</label><label class="expand" for="c-38638645">[2 more]</label></div><br/><div class="children"><div class="content">Nvidia drivers work just fine on Linux... unless you are clueless at following instructions</div><br/><div id="38638800" class="c"><input type="checkbox" id="c-38638800" checked=""/><div class="controls bullet"><span class="by">iotku</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38638645">parent</a><span>|</span><a href="#38638676">next</a><span>|</span><label class="collapse" for="c-38638800">[-]</label><label class="expand" for="c-38638800">[1 more]</label></div><br/><div class="children"><div class="content">Counterpoint:<p><a href="https:&#x2F;&#x2F;forums.developer.nvidia.com&#x2F;t&#x2F;545-drivers-have-bad-flickering-and-black-screen-issues-when-vrr-is-enabled&#x2F;269801" rel="nofollow noreferrer">https:&#x2F;&#x2F;forums.developer.nvidia.com&#x2F;t&#x2F;545-drivers-have-bad-f...</a><p><a href="https:&#x2F;&#x2F;forums.developer.nvidia.com&#x2F;t&#x2F;wayland-native-wayland-apps-vulkan-apps-have-graphical-glitches-similar-to-xwayland-glamor&#x2F;260288" rel="nofollow noreferrer">https:&#x2F;&#x2F;forums.developer.nvidia.com&#x2F;t&#x2F;wayland-native-wayland...</a><p><a href="https:&#x2F;&#x2F;gitlab.freedesktop.org&#x2F;xorg&#x2F;xserver&#x2F;-&#x2F;issues&#x2F;1317" rel="nofollow noreferrer">https:&#x2F;&#x2F;gitlab.freedesktop.org&#x2F;xorg&#x2F;xserver&#x2F;-&#x2F;issues&#x2F;1317</a><p>and literally me being a Linux Nvidia 1080ti user for years and having plenty of issues<p><a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;lwHDZoq.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;i.imgur.com&#x2F;lwHDZoq.png</a></div><br/></div></div></div></div></div></div><div id="38638676" class="c"><input type="checkbox" id="c-38638676" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#38637924">root</a><span>|</span><a href="#38637993">parent</a><span>|</span><a href="#38638091">prev</a><span>|</span><a href="#38638979">next</a><span>|</span><label class="collapse" for="c-38638676">[-]</label><label class="expand" for="c-38638676">[1 more]</label></div><br/><div class="children"><div class="content">ROCM support for windows is also just a few months old.</div><br/></div></div></div></div><div id="38638979" class="c"><input type="checkbox" id="c-38638979" checked=""/><div class="controls bullet"><span class="by">troupo</span><span>|</span><a href="#38637924">parent</a><span>|</span><a href="#38637993">prev</a><span>|</span><a href="#38637890">next</a><span>|</span><label class="collapse" for="c-38638979">[-]</label><label class="expand" for="c-38638979">[1 more]</label></div><br/><div class="children"><div class="content">Obligatory &quot;is <i>this</i> the year of Linux in desktop&quot; joke</div><br/></div></div></div></div><div id="38637890" class="c"><input type="checkbox" id="c-38637890" checked=""/><div class="controls bullet"><span class="by">Jayakumark</span><span>|</span><a href="#38637924">prev</a><span>|</span><a href="#38639268">next</a><span>|</span><label class="collapse" for="c-38637890">[-]</label><label class="expand" for="c-38637890">[1 more]</label></div><br/><div class="children"><div class="content">Adding link to VScode extension:<p><a href="https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=ms-windows-ai-studio.windows-ai-studio&amp;ssr=false#overview" rel="nofollow noreferrer">https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=ms-windo...</a></div><br/></div></div><div id="38639268" class="c"><input type="checkbox" id="c-38639268" checked=""/><div class="controls bullet"><span class="by">franzb</span><span>|</span><a href="#38637890">prev</a><span>|</span><a href="#38638989">next</a><span>|</span><label class="collapse" for="c-38639268">[-]</label><label class="expand" for="c-38639268">[1 more]</label></div><br/><div class="children"><div class="content">Why is this on GitHub?</div><br/></div></div><div id="38638989" class="c"><input type="checkbox" id="c-38638989" checked=""/><div class="controls bullet"><span class="by">Const-me</span><span>|</span><a href="#38639268">prev</a><span>|</span><a href="#38638024">next</a><span>|</span><label class="collapse" for="c-38638989">[-]</label><label class="expand" for="c-38638989">[1 more]</label></div><br/><div class="children"><div class="content">&gt; will run only on NVIDIA GPUs for the preview<p>I wonder why Microsoft helps nVidia, instead of using their own technology?<p>Here’s an example: <a href="https:&#x2F;&#x2F;github.com&#x2F;Const-me&#x2F;Cgml">https:&#x2F;&#x2F;github.com&#x2F;Const-me&#x2F;Cgml</a></div><br/></div></div><div id="38638024" class="c"><input type="checkbox" id="c-38638024" checked=""/><div class="controls bullet"><span class="by">andruby</span><span>|</span><a href="#38638989">prev</a><span>|</span><label class="collapse" for="c-38638024">[-]</label><label class="expand" for="c-38638024">[5 more]</label></div><br/><div class="children"><div class="content">Apple has good uniform hardware to enable this, but they are a product company and an “AI studio” would not fit their usual definition of a product.<p>I do hope they are considering going in that direction though.</div><br/><div id="38638674" class="c"><input type="checkbox" id="c-38638674" checked=""/><div class="controls bullet"><span class="by">TheRoque</span><span>|</span><a href="#38638024">parent</a><span>|</span><a href="#38638092">next</a><span>|</span><label class="collapse" for="c-38638674">[-]</label><label class="expand" for="c-38638674">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s the weird thing. They seem to have the best hardware for the price, for individuals to develop and use local LLMs, but so far they have been pretty quiet on all this.</div><br/><div id="38639084" class="c"><input type="checkbox" id="c-38639084" checked=""/><div class="controls bullet"><span class="by">diffeomorphism</span><span>|</span><a href="#38638024">root</a><span>|</span><a href="#38638674">parent</a><span>|</span><a href="#38638092">next</a><span>|</span><label class="collapse" for="c-38639084">[-]</label><label class="expand" for="c-38639084">[1 more]</label></div><br/><div class="children"><div class="content">Highly depends on the price. Currently 1600€ gets you a laptop with 8gb shared memory, which surely is a nice device for other use cases but for <i>developing</i> local LLMs that seems awfully limiting.<p>With upgraded ram (for just 230€ for each 8GB) and storage (just over 1000€ for 2tb; a samsung 990 pro is like 170€) that might be another story, but &quot;check your specs before downloading this app&quot; seems very un-appley. Also, no cuda support etc. 
Maybe if they make it exclusive to the mac studio?</div><br/></div></div></div></div><div id="38638092" class="c"><input type="checkbox" id="c-38638092" checked=""/><div class="controls bullet"><span class="by">paradite</span><span>|</span><a href="#38638024">parent</a><span>|</span><a href="#38638674">prev</a><span>|</span><a href="#38638039">next</a><span>|</span><label class="collapse" for="c-38638092">[-]</label><label class="expand" for="c-38638092">[1 more]</label></div><br/><div class="children"><div class="content">Apple has it: <a href="https:&#x2F;&#x2F;github.com&#x2F;ml-explore&#x2F;mlx">https:&#x2F;&#x2F;github.com&#x2F;ml-explore&#x2F;mlx</a></div><br/></div></div><div id="38638039" class="c"><input type="checkbox" id="c-38638039" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#38638024">parent</a><span>|</span><a href="#38638092">prev</a><span>|</span><label class="collapse" for="c-38638039">[-]</label><label class="expand" for="c-38638039">[1 more]</label></div><br/><div class="children"><div class="content">They do have such tools for developers like CreateML to train your own models, pretty sure they will have one for LLM.</div><br/></div></div></div></div></div></div></div></div></div></body></html>