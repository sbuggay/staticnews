<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1684227658934" as="style"/><link rel="stylesheet" href="styles.css?v=1684227658934"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2305.06161">StarCoder and StarCoderBase: 15.5B parameter models with 8K context length</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>belter</span> | <span>104 comments</span></div><br/><div><div id="35955317" class="c"><input type="checkbox" id="c-35955317" checked=""/><div class="controls bullet"><span class="by">simonw</span><span>|</span><a href="#35956090">next</a><span>|</span><label class="collapse" for="c-35955317">[-]</label><label class="expand" for="c-35955317">[53 more]</label></div><br/><div class="children"><div class="content">This is trained on The Stack, which is available here: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;bigcode&#x2F;the-stack&#x2F;" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;bigcode&#x2F;the-stack&#x2F;</a><p>Interesting to note that The Stack is 6TB - the whole of the RedPajama LLM training set (a lot more than just code) is only 2.6TB.<p>To get an idea what that training data looks like, I grabbed the first 300MB SQL file from <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;bigcode&#x2F;the-stack&#x2F;tree&#x2F;main&#x2F;data&#x2F;sql" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;bigcode&#x2F;the-stack&#x2F;tree&#x2F;main&#x2F;...</a> and then dumped the first 1,000 rows from that into JSON and loaded it into Datasette Lite:<p><a href="https:&#x2F;&#x2F;lite.datasette.io&#x2F;?json=https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;acc4e6973d38aa18c445e7279023dab5#&#x2F;data&#x2F;raw?_facet_array=max_stars_repo_licenses&amp;_facet=ext" rel="nofollow">https:&#x2F;&#x2F;lite.datasette.io&#x2F;?json=https:&#x2F;&#x2F;gist.github.com&#x2F;simo...</a><p>Here&#x27;s a query that shows a random row - hit the blue &quot;Run SQL&quot; button to see another one: <a href="https:&#x2F;&#x2F;lite.datasette.io&#x2F;?json=https:&#x2F;&#x2F;gist.github.com&#x2F;simonw&#x2F;acc4e6973d38aa18c445e7279023dab5#&#x2F;data?sql=select+max_stars_repo_path%2C+content+from+raw+order+by+random%28%29+limit+1" rel="nofollow">https:&#x2F;&#x2F;lite.datasette.io&#x2F;?json=https:&#x2F;&#x2F;gist.github.com&#x2F;simo...</a></div><br/><div id="35955585" class="c"><input type="checkbox" id="c-35955585" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#35955317">parent</a><span>|</span><a href="#35956717">next</a><span>|</span><label class="collapse" for="c-35955585">[-]</label><label class="expand" for="c-35955585">[51 more]</label></div><br/><div class="children"><div class="content">Something tells me that I haven&#x27;t trained on 6 TB of code and can meaningfully outperform any AI. That tells me that there&#x27;s something still structurally missing about the training efficiency. I wonder if this replicates to things like chess&#x2F;go - for a computer trained on the same number of games that a human is, is the computer still able to outperform a human?</div><br/><div id="35958541" class="c"><input type="checkbox" id="c-35958541" checked=""/><div class="controls bullet"><span class="by">tveita</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35955843">next</a><span>|</span><label class="collapse" for="c-35958541">[-]</label><label class="expand" for="c-35958541">[2 more]</label></div><br/><div class="children"><div class="content">If you read that much code you could code in your sleep. So far that seems to be a good intuition for models based on LLMs - how well can you code without most of your higher reasoning facilities, just glancing at the previous text and typing whatever your gut feeling tells you?<p>The programs that beat humans at chess and go have added structure to be able to <i>plan ahead</i>; they use a Monte Carlo search to play out the moves that &quot;intuitively&quot; look better, with another &quot;intuition&quot; check to see how good the position looks in the end. Similarly, AlphaCode [1] generates a large set of potential solutions and uses additional logic to verify that the code compiles, runs, and passes tests.<p>[1] <a href="https:&#x2F;&#x2F;www.deepmind.com&#x2F;blog&#x2F;competitive-programming-with-alphacode" rel="nofollow">https:&#x2F;&#x2F;www.deepmind.com&#x2F;blog&#x2F;competitive-programming-with-a...</a></div><br/><div id="35958970" class="c"><input type="checkbox" id="c-35958970" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35958541">parent</a><span>|</span><a href="#35955843">next</a><span>|</span><label class="collapse" for="c-35958970">[-]</label><label class="expand" for="c-35958970">[1 more]</label></div><br/><div class="children"><div class="content">Exactly this. I too find this to be the best intuition for LLMs right now: they&#x27;re not comparable to an entire combined human mind - they&#x27;re comparable to <i>subconscious</i>, or <i>inner voice</i> (as in, the part of your subconscious that interfaces with your conscious using language - aka. &quot;the voice in your head&quot;, if you have one).<p>So, as you say, if we had as much training as those LLMs, we&#x27;d be similarly good at coding by gut feel, with barely a conscious thought - and that&#x27;s across pretty much any domain and technology that existed today. Compare with generic LLMs: a typical adult will be quite adept at saying somewhat coherent things on autopilot when prompted (!), which is reasonable given nearly two decades of constant exposure to natural language as written and spoken - but that same adult will be <i>nowhere as good at this as GPT-4</i>, and definitely not across so many different domains.</div><br/></div></div></div></div><div id="35955843" class="c"><input type="checkbox" id="c-35955843" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35958541">prev</a><span>|</span><a href="#35957421">next</a><span>|</span><label class="collapse" for="c-35955843">[-]</label><label class="expand" for="c-35955843">[17 more]</label></div><br/><div class="children"><div class="content">Look i&#x27;m not going to say the transformer is as efficient as the brain but you are not starting from Zero.<p>any Code LLM will be learning language and code and everything else, with absolutely no predisposition to either.<p>Your brain is baked with millions of years of evolution with specific areas already predisposed to certain types of processing before you ever utter a word.</div><br/><div id="35957657" class="c"><input type="checkbox" id="c-35957657" checked=""/><div class="controls bullet"><span class="by">hannasm</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955843">parent</a><span>|</span><a href="#35956163">next</a><span>|</span><label class="collapse" for="c-35957657">[-]</label><label class="expand" for="c-35957657">[2 more]</label></div><br/><div class="children"><div class="content">The training process is finding local minimums based around an initialization vector of random numbers. 1000s of years of evolution probably mean you were initialized better than a baby AI using a pseudo random number generator.</div><br/><div id="35958611" class="c"><input type="checkbox" id="c-35958611" checked=""/><div class="controls bullet"><span class="by">ddalex</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35957657">parent</a><span>|</span><a href="#35956163">next</a><span>|</span><label class="collapse" for="c-35958611">[-]</label><label class="expand" for="c-35958611">[1 more]</label></div><br/><div class="children"><div class="content">Watching my kid learn to speak made it clear to me that we are pre-wired for the acquisition of language - we&#x27;re not building the structures from scratch, we are learning to put words into the empty spaces. Probably natural evolution at best - no speech, lower chance of gene propagation</div><br/></div></div></div></div><div id="35956163" class="c"><input type="checkbox" id="c-35956163" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955843">parent</a><span>|</span><a href="#35957657">prev</a><span>|</span><a href="#35956468">next</a><span>|</span><label class="collapse" for="c-35956163">[-]</label><label class="expand" for="c-35956163">[13 more]</label></div><br/><div class="children"><div class="content">&gt;<i>Look i&#x27;m not going to say the transformer is as efficient as the brain but you are not starting from Zero.</i><p>Still, we can rewrite the parent&#x27;s argument as:<p>If we train an AI on the amount of non-code-related dataset (writing read&#x2F;speech heard) I&#x27;ve consumed, and then add to it all the amount of code-related writing&#x2F;speech (coding book, coding lessons taken, code and manual pages read, man pages, etc.) I&#x27;ve consumed, would it even remotely as good as coding as me? Or even as good as itself is now?<p>I&#x27;d guess no. It&#x27;s less effiecient, and thus needs way more coding dataset to get the point of coding than a human. Which brings us to:<p>&gt;<i>Your brain is baked with millions of years of evolution with specific areas already predisposed to certain types of processing before you ever utter a word.</i><p>Isn&#x27;t that the whole point the parent is making?<p>That our advantage isn&#x27;t about dataset-volume, but architecture.</div><br/><div id="35956261" class="c"><input type="checkbox" id="c-35956261" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956163">parent</a><span>|</span><a href="#35957659">next</a><span>|</span><label class="collapse" for="c-35956261">[-]</label><label class="expand" for="c-35956261">[11 more]</label></div><br/><div class="children"><div class="content">The closest biological equivalent to a parameter in an ann is a synapse. Well humans have about 100 trillion synapses. We already know that the higher the parameter count, the lower the training data required. a 50 billion parameter model will far outperform a 5 billion one trained on the same data. and a 500b one would far outperform that 50 billion one.<p>Current LLMs are actually nowhere near the scale of the human brain, either in parameters&#x2F;neurons or training data (all the text we&#x27;ve ever trained an LLM on would be dwarfed by all the sense data humans perceive), as well as not having the headstart the human brain has.<p>It&#x27;s a bogus comparison when you really think about it.
You could easily make the case that LLMs are far more efficient.</div><br/><div id="35956414" class="c"><input type="checkbox" id="c-35956414" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956261">parent</a><span>|</span><a href="#35957652">next</a><span>|</span><label class="collapse" for="c-35956414">[-]</label><label class="expand" for="c-35956414">[4 more]</label></div><br/><div class="children"><div class="content">It is a bogus comparison, because typical language models used already have textual representations, and output textual representations; which is a very small fraction of &#x27;the brain&#x27;.  An astounding portion of the brain&#x27;s neurons really go towards proprioception, smell, taste, motor function, etc. Which are not at all even slightly part of most models today.
Wernicke&#x27;s area, a small sliver of frontal cortex, and a dash of dopaminergic circuitry is maybe the best &#x27;coverage&#x27; made in these models if you want to be exceedingly facile&#x2F;ham-handed about the analogies here.  That&#x27;s a very small portion of cortex, and much closer than what you may think in terms of capability&#x2F; TEPS and unit count.</div><br/><div id="35957388" class="c"><input type="checkbox" id="c-35957388" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956414">parent</a><span>|</span><a href="#35956539">next</a><span>|</span><label class="collapse" for="c-35957388">[-]</label><label class="expand" for="c-35957388">[1 more]</label></div><br/><div class="children"><div class="content">&gt; An astounding portion of the brain&#x27;s neurons really go towards proprioception, smell, taste, motor function, etc<p>Object recognition leads to abstraction.  Motion perception to causality.  I wouldn’t be surprised if proprioception is key to human self-awareness.<p>These are key logical concepts that are used in language, they are not isolated.</div><br/></div></div><div id="35956539" class="c"><input type="checkbox" id="c-35956539" checked=""/><div class="controls bullet"><span class="by">reaperman</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956414">parent</a><span>|</span><a href="#35957388">prev</a><span>|</span><a href="#35957652">next</a><span>|</span><label class="collapse" for="c-35956539">[-]</label><label class="expand" for="c-35956539">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not clear how many classical calculations a single human neuron is equivalent to. There&#x27;s a strong analog component in multiple domains (strength, frequency, timing) and each neuron can connect to up to 15,000 other neurons. Assuming the brain&#x27;s neurons are (probably unrealistically) fairly &#x27;digital&#x27; we get an estimation of the human brain being equivalent to 1 exaflop (this is the currently accepted lower bound, and rather disputed as being too low). Current TPUv4 pods currently provide approximately 9 exaflops. I don&#x27;t think we&#x27;re currently reaching human-level learning rates. There’s currently no accepted “upper bound” on estimates of FLOP equivalency to a human brain.<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HB5TrK7A4pI">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HB5TrK7A4pI</a> is a recently posted video to HN Frontpage which was summarized as such:<p>&gt; Though we have been building and programming computing machines for about 60 years and have learned a great deal about composition and abstraction, we have just begun to scratch the surface.<p>&gt; A mammalian neuron takes about ten milliseconds to respond to a stimulus. A driver can respond to a visual stimulus in a few hundred milliseconds, and decide an action, such as making a turn. So the computational depth of this behavior is only a few tens of steps. We don&#x27;t know how to make such a machine, and we wouldn&#x27;t know how to program it.<p>&gt; The human genome -- the information required to build a human from a single, undifferentiated eukariotic cell -- is about 1GB. The instructions to build a mammal are written in very dense code, and the program is extremely flexible. Only small patches to the human genome are required to build a cow or a dog rather than a human. Bigger patches result in a frog or a snake. We don&#x27;t have any idea how to make a description of such a complex machine that is both dense and flexible.<p>&gt; New design principles and new linguistic support are needed. I will address this issue and show some ideas that can perhaps get us to the next phase of engineering design.<p>&gt; Gerald Sussman Massachusetts Institute of Technology</div><br/><div id="35957082" class="c"><input type="checkbox" id="c-35957082" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956539">parent</a><span>|</span><a href="#35957652">next</a><span>|</span><label class="collapse" for="c-35957082">[-]</label><label class="expand" for="c-35957082">[1 more]</label></div><br/><div class="children"><div class="content">My understanding is that TEPS were used to determine computing for these types operations, rather than FLOPS, as they were more useful specifically for that comparison.  There metrics put them in the same order of magnitude; however, as stated before, these miss the point by quite a bit, since much of the &#x27;computations&#x27; humans do are quite irrelevant (taste, smell, etc) to producing language or solving algorithmic problems, etc.<p>For example, the cerebellum is 50-80% of what people keep quoting here (Number of neurons in the brain) and is not activated much in language processing.<p>Wernicke&#x27;s area spans just a few percent of the cortical neurons.
The amount of pre processing we do by providing text is actually quite enormous, so that already removes a remarkable amount of complexity from the model.  So, despite the differences between biology and ANNs, it&#x27;s not unreasonable what were seeing right now.</div><br/></div></div></div></div></div></div><div id="35957652" class="c"><input type="checkbox" id="c-35957652" checked=""/><div class="controls bullet"><span class="by">somenameforme</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956261">parent</a><span>|</span><a href="#35956414">prev</a><span>|</span><a href="#35956667">next</a><span>|</span><label class="collapse" for="c-35957652">[-]</label><label class="expand" for="c-35957652">[2 more]</label></div><br/><div class="children"><div class="content">You run into the typical neural net problem with this logic. OpenAI (or at least Sam Altman) have already publicly acknowledged that the diminishing returns they&#x27;re seeing in terms of model size are sufficient to effectively declare that &#x27;the age of giant models is already over.&#x27; [1] It seems many people were unaware of his comments on this topic.<p>Neural networks in literally every other field always repeat the exact same pattern. You can get from 0-80 without breaking a sweat. 80-90 is dramatically harder but you finally get there. So everybody imagines getting from 90-100 will be little more than a matter of a bit more compute and a bit more massaging of the model. But it turns out that each fraction of a percent progress you make starts becoming exponentially more difficult - and you eventually run into an asymptote that&#x27;s nowhere near what you are aiming for.<p>A prediction based on the typical history of neural nets would be that OpenAI will be able to continue to make progress on extremely specific metrics, like scoring well on some test or another, largely by hardcoding case-specific workarounds and tweaks. But in terms of general model usage, we&#x27;re unlikely to see any real revolutionary leaps in the foreseeable future.<p>If we see model accuracy increase I&#x27;d expect it to be thanks not to model improvement, but instead by doing something like adding a second layer where the software cross references the generated output against a &#x27;fact database&#x27; and regenerates its answer when some correlation factor is insufficiently high. Of course that&#x27;d completely cripple the model&#x27;s ability to ever move &#x27;beyond&#x27; its training. It&#x27;d be like if mankind was forced to double check that any response on astronomy we made confirmed that the Earth is indeed the center of the universe, with no ability to ever change that ourselves.<p>[1] - <a href="https:&#x2F;&#x2F;www.wired.com&#x2F;story&#x2F;openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over&#x2F;" rel="nofollow">https:&#x2F;&#x2F;www.wired.com&#x2F;story&#x2F;openai-ceo-sam-altman-the-age-of...</a></div><br/><div id="35958030" class="c"><input type="checkbox" id="c-35958030" checked=""/><div class="controls bullet"><span class="by">oezi</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35957652">parent</a><span>|</span><a href="#35956667">next</a><span>|</span><label class="collapse" for="c-35958030">[-]</label><label class="expand" for="c-35958030">[1 more]</label></div><br/><div class="children"><div class="content">There is an argument that Altman&#x27;s statement is just trying to distract competitors from outspending OpenAI. Prior to GPT-4 there was no indications that there are diminishing returns (at least on a log scale).<p>The tremendous progress over the last year makes me vary of your statement that progress will stop coming from model size improvements.</div><br/></div></div></div></div><div id="35956667" class="c"><input type="checkbox" id="c-35956667" checked=""/><div class="controls bullet"><span class="by">coldtea</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956261">parent</a><span>|</span><a href="#35957652">prev</a><span>|</span><a href="#35958467">next</a><span>|</span><label class="collapse" for="c-35956667">[-]</label><label class="expand" for="c-35956667">[3 more]</label></div><br/><div class="children"><div class="content">&gt;<i>a 50 billion parameter model will far outperform a 5 billion one trained on the same data. and a 500b one would far outperform that 50 billion one.</i><p>I&#x27;m not so sure. I&#x27;m pretty sure there are diminishing returns at play after some point.<p>Plus haven&#x27;t we already seen models with much less billions of parameters perform the same or very close to ChatGPT with had a much higher count (Llama and its siblings)?</div><br/><div id="35956827" class="c"><input type="checkbox" id="c-35956827" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956667">parent</a><span>|</span><a href="#35958331">next</a><span>|</span><label class="collapse" for="c-35956827">[-]</label><label class="expand" for="c-35956827">[1 more]</label></div><br/><div class="children"><div class="content">&gt;a 50 billion parameter model will far outperform a 5 billion one trained on the same data. and a 500b one would far outperform that 50 billion one.
I&#x27;m not so sure. I&#x27;m pretty sure there are diminishing returns at play after some point.<p>We can speculate about just how far this scaling can go or how far is even necessary but all i&#x27;ve said there is true. We have models trained and evaluated on all those sizes.<p>&gt;Plus haven&#x27;t we already seen models with much less billions of parameters perform the same or very close to ChatGPT with had a much higher count (Llama and its siblings)?<p>Only by training on far more data. Llama 13b has to be trained on over 3x more data just to reach the original GPT-3 model from 2020 (not 3.5).</div><br/></div></div><div id="35958331" class="c"><input type="checkbox" id="c-35958331" checked=""/><div class="controls bullet"><span class="by">mdekkers</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956667">parent</a><span>|</span><a href="#35956827">prev</a><span>|</span><a href="#35958467">next</a><span>|</span><label class="collapse" for="c-35958331">[-]</label><label class="expand" for="c-35958331">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  I&#x27;m not so sure. I&#x27;m pretty sure there are diminishing returns at play after some point.<p>..because? Do you have some data to support your assertion?</div><br/></div></div></div></div><div id="35958467" class="c"><input type="checkbox" id="c-35958467" checked=""/><div class="controls bullet"><span class="by">littlestymaar</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956261">parent</a><span>|</span><a href="#35956667">prev</a><span>|</span><a href="#35957659">next</a><span>|</span><label class="collapse" for="c-35958467">[-]</label><label class="expand" for="c-35958467">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Well humans have about 100 trillion synapses. We already know that the higher the parameter count, the lower the training data required.<p>Do you have any reference to back this claim, because it sounds is very curious to me. My understanding was pretty much the opposite, that current LLM technology require a bigger training set as you increase the parameter count. I&#x27;m no NN expert in any way though.</div><br/></div></div></div></div><div id="35957659" class="c"><input type="checkbox" id="c-35957659" checked=""/><div class="controls bullet"><span class="by">dwallin</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956163">parent</a><span>|</span><a href="#35956261">prev</a><span>|</span><a href="#35956468">next</a><span>|</span><label class="collapse" for="c-35957659">[-]</label><label class="expand" for="c-35957659">[1 more]</label></div><br/><div class="children"><div class="content">That’s an arbitrary line to make though. The human brain starts with a general architecture that has been gone through billions and trillions of generations of evolutionary training, before being fine tuned in a single individual over decades, and then you did a little bit of fine tuning and few shot at the end and claim that is comparable to the entire training of a LLM from scratch? Not to mention the many more orders of magnitude of neurons that a human brain has. I could equally argue that an LLM takes zero training, since we have ALREADY trained models and I can just copy the model and run it and get a new “brain” performing a task, instead of taking decades of training to get there.<p>Even your statement about programming skills is debatable, it depends on how you measure programming skill. They certainly are faster at it, and they know more computer languages than most people have even heard of. In fact, human programming strength seems to be more about general logic and planning skills over programming-specific skills, both things where the bulk of training happened evolutionarily and more generally over the course of a life.<p>The truth is, the two are not directly comparable. They are completely different architectures, at completely different scales, with entirely different strengths and weaknesses.</div><br/></div></div></div></div><div id="35956468" class="c"><input type="checkbox" id="c-35956468" checked=""/><div class="controls bullet"><span class="by">aledalgrande</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955843">parent</a><span>|</span><a href="#35956163">prev</a><span>|</span><a href="#35957421">next</a><span>|</span><label class="collapse" for="c-35956468">[-]</label><label class="expand" for="c-35956468">[1 more]</label></div><br/><div class="children"><div class="content">Also multi modal &#x2F; multi topic learning benefits the brain too. Range by David Epstein is an interesting read</div><br/></div></div></div></div><div id="35957421" class="c"><input type="checkbox" id="c-35957421" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35955843">prev</a><span>|</span><a href="#35955845">next</a><span>|</span><label class="collapse" for="c-35957421">[-]</label><label class="expand" for="c-35957421">[2 more]</label></div><br/><div class="children"><div class="content">You get a lot more context though. The training set is just &quot;here&#x27;s lots of code and some comments and docs&quot;. You trained on your own experience with interface, your process expectations as a human in real world, on the whole chains of &quot;we need to achieve this, so we&#x27;re splitting it into those tasks&quot;, and many other related contexts.<p>In RPG terms, the models put everything into intelligence and no points into wisdom.</div><br/><div id="35957465" class="c"><input type="checkbox" id="c-35957465" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35957421">parent</a><span>|</span><a href="#35955845">next</a><span>|</span><label class="collapse" for="c-35957465">[-]</label><label class="expand" for="c-35957465">[1 more]</label></div><br/><div class="children"><div class="content">I suspect that the reason that people find declarative and functional programming more difficult is that they have to ‘unlearn’ a lot of procedural thinking that we get from real world experience.</div><br/></div></div></div></div><div id="35955845" class="c"><input type="checkbox" id="c-35955845" checked=""/><div class="controls bullet"><span class="by">mtlmtlmtlmtl</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35957421">prev</a><span>|</span><a href="#35957383">next</a><span>|</span><label class="collapse" for="c-35955845">[-]</label><label class="expand" for="c-35955845">[2 more]</label></div><br/><div class="children"><div class="content">Responding to your chess question. Starting with random weights? No, not even close. For a talented(i.e having some innate ability to learn the game) child, it&#x27;s actually hard for me to describe how fast they can improve even over the course of a single game. I&#x27;ve seen it happen in real time several times.<p>It&#x27;s very hard for me to ignore the intuition that there&#x27;s some higher level cognitive process going on that can pick out abstract concepts and use them to control and focus the lower level &quot;training&quot; that might look more similar to what we&#x27;re doing in ML these days.</div><br/><div id="35958819" class="c"><input type="checkbox" id="c-35958819" checked=""/><div class="controls bullet"><span class="by">toxik</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955845">parent</a><span>|</span><a href="#35957383">next</a><span>|</span><label class="collapse" for="c-35958819">[-]</label><label class="expand" for="c-35958819">[1 more]</label></div><br/><div class="children"><div class="content">How do you know that isn’t emergent given enough embodied experience of the world? This is the big thing with LLMs for me, showing that yes, if you scale up, all sorts of emergent abilities pop up. And LLMs aren’t even embodied, it’s still a very primitive approach and we’re already seeing this level of competence. Truly makes me wonder if I’m not just a stochastic parrot underneath it all.</div><br/></div></div></div></div><div id="35957383" class="c"><input type="checkbox" id="c-35957383" checked=""/><div class="controls bullet"><span class="by">abeppu</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35955845">prev</a><span>|</span><a href="#35957492">next</a><span>|</span><label class="collapse" for="c-35957383">[-]</label><label class="expand" for="c-35957383">[1 more]</label></div><br/><div class="children"><div class="content">&gt; That tells me that there&#x27;s something still structurally missing about the training efficiency.<p>Imagine Alice is abducted by aliens and given reams and reams of unfamiliar symbols and trained to predict which one came next given a long long prefix. Alice held in a cell alone with just symbol sequences for 15 years, and by the end of that period she&#x27;s gotten pretty good at predicting which symbol comes next. Bob&#x27;s experience is exactly the same. Neither has any way to understand what any of the symbols mean. Finally, Alice and Bob are let out of their cells for a break, and meet Krang. Krang explains that Alice has been doing a sometimes acceptable job of producing computer code for a kind of computer she&#x27;s never been able to directly interact with! She might have gotten really good by the end of year 1 if anyone had explained that she was writing programs, or given her access to a REPL, or a debugger, or a manual. But she&#x27;s been trained with exactly the same procedure as Bob, who has been pumping out advertising copy.<p>Current code LLMs are only doing next token prediction, and critically they don&#x27;t have access to a model of formal semantics for each language, an interpreter or debugger or compiler, etc. This is a shame, because program generation is arguably one of relatively few areas in which we could give our models a &quot;complete&quot; view of the domain. An appropriately structured model could generate the program, predict and observe the AST, predict and observe the IR graph, predict and observe generated bytecode, predict and observe program traces from execution, etc, etc. But it doesn&#x27;t do any of that. It doesn&#x27;t have an explicit model of what the program will do during execution. It doesn&#x27;t have an ability to check that an invariant is maintained at each iteration of a loop. It doesn&#x27;t get to check that what it wrote behaves as intended.<p>Yesterday, one of the chat models which also can generate code gave me a Kotlin example which used a language feature that Kotlin doesn&#x27;t actually have (basically scala-style pattern matching), and of course was totally unaware that the generated code was not even valid Kotlin because it never attempted to call any part of the toolchain.</div><br/></div></div><div id="35957492" class="c"><input type="checkbox" id="c-35957492" checked=""/><div class="controls bullet"><span class="by">Groxx</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35957383">prev</a><span>|</span><a href="#35955655">next</a><span>|</span><label class="collapse" for="c-35957492">[-]</label><label class="expand" for="c-35957492">[1 more]</label></div><br/><div class="children"><div class="content">Given how much data years worth of high resolution, 3D video and audio takes up, arguably you&#x27;ve trained on several orders of magnitude more data.</div><br/></div></div><div id="35955655" class="c"><input type="checkbox" id="c-35955655" checked=""/><div class="controls bullet"><span class="by">RangerScience</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35957492">prev</a><span>|</span><a href="#35958065">next</a><span>|</span><label class="collapse" for="c-35955655">[-]</label><label class="expand" for="c-35955655">[12 more]</label></div><br/><div class="children"><div class="content">Is this training just to understand code, or is training to understand code <i>and</i> language?<p>(If we&#x27;re comparing you to the model, is the model starting at &quot;baby&quot; or &quot;teenager&quot;?)</div><br/><div id="35955855" class="c"><input type="checkbox" id="c-35955855" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955655">parent</a><span>|</span><a href="#35956050">next</a><span>|</span><label class="collapse" for="c-35955855">[-]</label><label class="expand" for="c-35955855">[10 more]</label></div><br/><div class="children"><div class="content">a baby is still predisposed to learning language (amongst many other things essential for human living&#x2F;survival) thanks to the brain and evolution. No human is really starting from scratch in any meaningful way.</div><br/><div id="35956611" class="c"><input type="checkbox" id="c-35956611" checked=""/><div class="controls bullet"><span class="by">stephc_int13</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955855">parent</a><span>|</span><a href="#35956027">next</a><span>|</span><label class="collapse" for="c-35956611">[-]</label><label class="expand" for="c-35956611">[2 more]</label></div><br/><div class="children"><div class="content">If you look at Chess, Poker or writing Python, I am not sure that natural evolution is giving us a huge head start.<p>And still, human experts in those fields don’t need as much data, even with our slow brains, the convergence rate is astounding, compared to machine learning.</div><br/><div id="35957503" class="c"><input type="checkbox" id="c-35957503" checked=""/><div class="controls bullet"><span class="by">mr_toad</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956611">parent</a><span>|</span><a href="#35956027">next</a><span>|</span><label class="collapse" for="c-35957503">[-]</label><label class="expand" for="c-35957503">[1 more]</label></div><br/><div class="children"><div class="content">I’d say that an understanding of causality helps people learn chess.  Maths, from counting through algebra helps people learn to program.  I’d imagine it would be hard to understand the concept of a loop if you couldn’t count.</div><br/></div></div></div></div><div id="35956027" class="c"><input type="checkbox" id="c-35956027" checked=""/><div class="controls bullet"><span class="by">mtlmtlmtlmtl</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955855">parent</a><span>|</span><a href="#35956611">prev</a><span>|</span><a href="#35957498">next</a><span>|</span><label class="collapse" for="c-35956027">[-]</label><label class="expand" for="c-35956027">[6 more]</label></div><br/><div class="children"><div class="content">I think you&#x27;re missing the forest for the trees here. First of all it&#x27;s not well understood how infants are so able to learn languages, and the extent to which language ability is innate is fairly controversial in linguistics.<p>Leaving the details aside, the fact that a human is not starting from scratch is not in dispute. But the whole point of the discussion it seems to me is the question of exactly <i>how</i> humans are not starting from scratch, i.e why do we learn so much faster, and how could we apply the answer to current techniques in machine learning?<p>Those are still interesting questions whether or not humans and randomly wired neural nets are both starting from scratch.</div><br/><div id="35956212" class="c"><input type="checkbox" id="c-35956212" checked=""/><div class="controls bullet"><span class="by">chmod775</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956027">parent</a><span>|</span><a href="#35956203">next</a><span>|</span><label class="collapse" for="c-35956212">[-]</label><label class="expand" for="c-35956212">[3 more]</label></div><br/><div class="children"><div class="content">&gt; i.e why do we learn so much faster<p>A pretty obvious difference is that these models are still nowhere near as large or complex as a human brain. This network has 15 billion parameters, whereas a human brain is estimated to have 60 <i>trillion</i> neuronal connections. Additionally each neuron, of which a human brain has around 90 billion, can fulfill many more roles than a &quot;neuron&quot; in a language model.<p>Apples to oranges, but there&#x27;s a pretty obvious complexity gap.</div><br/><div id="35956364" class="c"><input type="checkbox" id="c-35956364" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956212">parent</a><span>|</span><a href="#35956536">next</a><span>|</span><label class="collapse" for="c-35956364">[-]</label><label class="expand" for="c-35956364">[1 more]</label></div><br/><div class="children"><div class="content">The neurons in Wernicke&#x27;s area however is a very small subset of this, so since these models aren&#x27;t doing anything related to taste or smell, etc that number isn&#x27;t as relevant as you may think it is.  The number of neurons more dedicated towards proprioception for example is quite vast, and often almost completely undiscussed by the AI community.
So you&#x27;re not making quite the argument that you think you are; although the general idea that there&#x27;s still a difference is obviously true (birds v planes, yada yada).</div><br/></div></div><div id="35956536" class="c"><input type="checkbox" id="c-35956536" checked=""/><div class="controls bullet"><span class="by">mtlmtlmtlmtl</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956212">parent</a><span>|</span><a href="#35956364">prev</a><span>|</span><a href="#35956203">next</a><span>|</span><label class="collapse" for="c-35956536">[-]</label><label class="expand" for="c-35956536">[1 more]</label></div><br/><div class="children"><div class="content">Yep. Also of note is the fact that human learning is  fundamentally a more flexible process in that it can lay down new neuronal connections and in fact new neurons too.<p>I&#x27;m sure there are (evolutionary?) NN models that try to do things like this but I have no idea how successful they&#x27;ve been.</div><br/></div></div></div></div><div id="35956203" class="c"><input type="checkbox" id="c-35956203" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956027">parent</a><span>|</span><a href="#35956212">prev</a><span>|</span><a href="#35957498">next</a><span>|</span><label class="collapse" for="c-35956203">[-]</label><label class="expand" for="c-35956203">[2 more]</label></div><br/><div class="children"><div class="content">&gt;First of all it&#x27;s not well understood how infants are so able to learn languages<p>It&#x27;s not well understood sure but the brain is evidently playing a crucial process. Children learn to speak languages at about the same time with the same milestones occurring at roughly the same ages. Not to mention the fact that despite wildly different cultures and situations (some cultures don&#x27;t attempt correct their children ever, some cultures don&#x27;t speak to babies), children learn language just fine. Controversy on exactly how much aside, we&#x27;re obviously predisposed to it.<p>&gt;But the whole point of the discussion it seems to me is the question of exactly how humans are not starting from scratch, i.e why do we learn so much faster, and how could we apply the answer to current techniques in machine learning?<p>The closest biological equivalent to a parameter in an ann is a synapse. Well humans have about 100 trillion synapses. We already know that the higher the parameter count, the lower the training data required. a 50 billion parameter model will far outperform a 5 billion one trained on the same data. and a 500b one would far outperform that 50 billion one.<p>Economics limits how far we can go and i&#x27;m not making any declarative statements but who&#x27;s to say that&#x27;s not the issue ?<p>ann and whatever the brain does diverged in details a long time ago. It&#x27;s cool to speculate and all but any special insight on the brain would have little implications on the future of deep learning. That&#x27;s just not what drives architectural advances.<p>we could have expert level machines in a couple years but any approach trying to copy the brain is decades if not centuries away. That&#x27;s how little we understand. and how little impact that actually has on the DL of today.<p>Current LLMS are actually nowhere near the scale of the human brain, either in parameters&#x2F;neurons or training data (all the text we&#x27;ve ever trained an LLM on would be dwarfed by all the data humans perceive). as well as not having the headstart the human brain has. It&#x27;s kind of a bogus comparison when you think about. You could easily make the case that LLMs are far more effective.</div><br/><div id="35957567" class="c"><input type="checkbox" id="c-35957567" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956203">parent</a><span>|</span><a href="#35957498">next</a><span>|</span><label class="collapse" for="c-35957567">[-]</label><label class="expand" for="c-35957567">[1 more]</label></div><br/><div class="children"><div class="content">Is my understanding of your argument that the near 24&#x2F;7 auditory&#x2F;visualize constant input + the brain having way more neurons helps or converge faster? I can buy that. The challenge of course is someone like Hellen Keller who had very little input in terms of quantity and yet still managed to develop into an intelligent adult once we figured out how to communicate with someone like that.<p>The weak spot of my argument is that it took me 20 years of on and off training, maybe 4-12 hours per day most days to get to this state. By comparison AI gets to maybe my experience level after a few years or so in months. So maybe it doesn’t actually take that much time comparatively (despite having a much lower ceiling).<p>The part that I’m not quite sold on though is the comparison on number of neurons. We don’t actually have a good handle on how many neurons are equivalent and a non-trivial amount of a brain’s neural net is responsible for real time signals processing of high fidelity audio and video, propiecption, motor controls etc, running your body, filtering and converting inputs into long term storage + combining it all with higher order executive functions and thought that can override a good chunk of it. It doesn’t feel like the strongest argument to make to say all that complexity is needed to create human-level intelligence in terms of comparing neurons (there may be reasons those are things are needed, but creating an LLM with the same number of neurons probably won’t work).<p>The compelling part for me is to continue the analogy of the brain which motivated this line of AI research. We know that the brain has all sorts of different structures and they map pretty closely to different functions and it’s not just one giant language center. Wouldn’t it make sense that we’d need different kinds of AI models to build a fully functional AI? Not least of which because specialization can be computationally more efficient (eg various computational imagery tasks are doing extraordinary things and they’re not just throwing large and larger LLMs at the problem)</div><br/></div></div></div></div></div></div><div id="35957498" class="c"><input type="checkbox" id="c-35957498" checked=""/><div class="controls bullet"><span class="by">stygiansonic</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955855">parent</a><span>|</span><a href="#35956027">prev</a><span>|</span><a href="#35956050">next</a><span>|</span><label class="collapse" for="c-35957498">[-]</label><label class="expand" for="c-35957498">[1 more]</label></div><br/><div class="children"><div class="content">For more background for those interested, this is known as Universal Grammar: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Universal_grammar" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Universal_grammar</a></div><br/></div></div></div></div><div id="35956050" class="c"><input type="checkbox" id="c-35956050" checked=""/><div class="controls bullet"><span class="by">saurik</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955655">parent</a><span>|</span><a href="#35955855">prev</a><span>|</span><a href="#35958065">next</a><span>|</span><label class="collapse" for="c-35956050">[-]</label><label class="expand" for="c-35956050">[1 more]</label></div><br/><div class="children"><div class="content">Are you implying that a human--maybe you--might somehow have experienced 6 <i>TB</i> of English if you just go back to when they are a baby?</div><br/></div></div></div></div><div id="35958065" class="c"><input type="checkbox" id="c-35958065" checked=""/><div class="controls bullet"><span class="by">jjallen</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35955655">prev</a><span>|</span><a href="#35957256">next</a><span>|</span><label class="collapse" for="c-35958065">[-]</label><label class="expand" for="c-35958065">[3 more]</label></div><br/><div class="children"><div class="content">You can answer with 90% accuracy how to do every beginner to intermediate coding action in every programming language in a few seconds?</div><br/><div id="35958097" class="c"><input type="checkbox" id="c-35958097" checked=""/><div class="controls bullet"><span class="by">fhd2</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35958065">parent</a><span>|</span><a href="#35957256">next</a><span>|</span><label class="collapse" for="c-35958097">[-]</label><label class="expand" for="c-35958097">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re going into the unique advantage computers have over humans: They scale, a human doesn&#x27;t. If you take away the &quot;in a few seconds&quot; part, it&#x27;s not difficult at all to beat.</div><br/><div id="35958345" class="c"><input type="checkbox" id="c-35958345" checked=""/><div class="controls bullet"><span class="by">jjallen</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35958097">parent</a><span>|</span><a href="#35957256">next</a><span>|</span><label class="collapse" for="c-35958345">[-]</label><label class="expand" for="c-35958345">[1 more]</label></div><br/><div class="children"><div class="content">The OP didn&#x27;t mention which dimensions of inteligence&#x2F;ability they could beat a computer. Surely scale&#x2F;breadth of knowledge is one that matters.</div><br/></div></div></div></div></div></div><div id="35957256" class="c"><input type="checkbox" id="c-35957256" checked=""/><div class="controls bullet"><span class="by">opportune</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35958065">prev</a><span>|</span><a href="#35958287">next</a><span>|</span><label class="collapse" for="c-35957256">[-]</label><label class="expand" for="c-35957256">[1 more]</label></div><br/><div class="children"><div class="content">And yet you have been alive longer than deep learning has existed, with more capable hardware than anything yet implemented in silico. Much of that time spent alive has trained things like planning, pattern matching, theory of mind, etc which all transfer to a lot of other tasks you do<p>IMO it’s a meaningless comparison</div><br/></div></div><div id="35958339" class="c"><input type="checkbox" id="c-35958339" checked=""/><div class="controls bullet"><span class="by">alfor</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35958287">prev</a><span>|</span><a href="#35956457">next</a><span>|</span><label class="collapse" for="c-35958339">[-]</label><label class="expand" for="c-35958339">[1 more]</label></div><br/><div class="children"><div class="content">Yes, still huge low hanging fruits in the training&#x2F;architecture.<p>- multimodal<p>- feedforward<p>- proximal zone of developpement (you don’t start reading with shakespeare)</div><br/></div></div><div id="35956457" class="c"><input type="checkbox" id="c-35956457" checked=""/><div class="controls bullet"><span class="by">pedrosorio</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35958339">prev</a><span>|</span><a href="#35955643">next</a><span>|</span><label class="collapse" for="c-35956457">[-]</label><label class="expand" for="c-35956457">[2 more]</label></div><br/><div class="children"><div class="content">&gt; I wonder if this replicates to things like chess&#x2F;go - for a computer trained on the same number of games that a human is, is the computer still able to outperform a human?<p>The first computers to beat (and completely surpass) the best human beings at chess were not trained on anything. Just efficient search techniques and human feedback through heuristics&#x2F;opening books.</div><br/><div id="35956583" class="c"><input type="checkbox" id="c-35956583" checked=""/><div class="controls bullet"><span class="by">stephc_int13</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35956457">parent</a><span>|</span><a href="#35955643">next</a><span>|</span><label class="collapse" for="c-35956583">[-]</label><label class="expand" for="c-35956583">[1 more]</label></div><br/><div class="children"><div class="content">red black and minmax algorithms were not really useful, and heuristics are a kind of laborious encoding of experts human knowledge into code, so they were still trained, in an hardcodes manner.<p>But overall, yes, the current state of machine learning relies on huge brute force compared to animal learning.<p>Experts Chess players need to play many games to acquire sufficient intuitive knowledge, but they converge orders of magnitude faster than current algorithms.<p>This weakness might be relevant later, for very dynamic and adaptable systems.</div><br/></div></div></div></div><div id="35955643" class="c"><input type="checkbox" id="c-35955643" checked=""/><div class="controls bullet"><span class="by">mysterydip</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35956457">prev</a><span>|</span><a href="#35955887">next</a><span>|</span><label class="collapse" for="c-35955643">[-]</label><label class="expand" for="c-35955643">[1 more]</label></div><br/><div class="children"><div class="content">I wonder how curated the input data is. Just on the surface of it, there&#x27;s a lot of spaghetti code out there that people may have shared. I once saw a codebase that used three different implementations of a date&#x2F;time structure and overloaded operators to convert between them. Or people rolling their own crypto, sort, or random functions, reimplementing data structures, etc.</div><br/></div></div><div id="35955887" class="c"><input type="checkbox" id="c-35955887" checked=""/><div class="controls bullet"><span class="by">burkaman</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35955643">prev</a><span>|</span><a href="#35956185">next</a><span>|</span><label class="collapse" for="c-35955887">[-]</label><label class="expand" for="c-35955887">[1 more]</label></div><br/><div class="children"><div class="content">The computer was trained to respond to a text prompt with code, without looking anything up or running the code. You would not outperform it at that task, but that has very little to do with your actual job, so you would outperform it at more realistic tasks.<p>Board games are many orders of magnitude simpler than real life, so it should be a lot easier for a computer to outperform a human with equivalent experience.</div><br/></div></div><div id="35956185" class="c"><input type="checkbox" id="c-35956185" checked=""/><div class="controls bullet"><span class="by">cyanydeez</span><span>|</span><a href="#35955317">root</a><span>|</span><a href="#35955585">parent</a><span>|</span><a href="#35955887">prev</a><span>|</span><a href="#35957716">next</a><span>|</span><label class="collapse" for="c-35956185">[-]</label><label class="expand" for="c-35956185">[1 more]</label></div><br/><div class="children"><div class="content">You are narrow minded.  They&#x27;re a wide swath that&#x27;s shallow.</div><br/></div></div></div></div><div id="35956717" class="c"><input type="checkbox" id="c-35956717" checked=""/><div class="controls bullet"><span class="by">ed</span><span>|</span><a href="#35955317">parent</a><span>|</span><a href="#35955585">prev</a><span>|</span><a href="#35956090">next</a><span>|</span><label class="collapse" for="c-35956717">[-]</label><label class="expand" for="c-35956717">[1 more]</label></div><br/><div class="children"><div class="content">Nit, but the 6TB version includes a lot of forks and duplicated code so I assume StarCoder was trained on the deduped version, which is 2.9TB.</div><br/></div></div></div></div><div id="35956090" class="c"><input type="checkbox" id="c-35956090" checked=""/><div class="controls bullet"><span class="by">Imnimo</span><span>|</span><a href="#35955317">prev</a><span>|</span><a href="#35958971">next</a><span>|</span><label class="collapse" for="c-35956090">[-]</label><label class="expand" for="c-35956090">[2 more]</label></div><br/><div class="children"><div class="content">&gt;We inspected StarCoder-generated programs on these benchmarks and found that there were several cases where the model produces what are effectively empty solutions, e.g., pass or a comment Insert code here. We also observed this kind of failure in every model we evaluated.<p>I&#x27;m not sure whether the AI learning that it can just write &quot;#TODO&quot; is a sign our jobs are safe or a sign our jobs are truly in danger.</div><br/><div id="35958634" class="c"><input type="checkbox" id="c-35958634" checked=""/><div class="controls bullet"><span class="by">fleischhauf</span><span>|</span><a href="#35956090">parent</a><span>|</span><a href="#35958971">next</a><span>|</span><label class="collapse" for="c-35958634">[-]</label><label class="expand" for="c-35958634">[1 more]</label></div><br/><div class="children"><div class="content">sounds more like lazyness, I think we might be ok actually.</div><br/></div></div></div></div><div id="35958971" class="c"><input type="checkbox" id="c-35958971" checked=""/><div class="controls bullet"><span class="by">veselin</span><span>|</span><a href="#35956090">prev</a><span>|</span><a href="#35955324">next</a><span>|</span><label class="collapse" for="c-35958971">[-]</label><label class="expand" for="c-35958971">[1 more]</label></div><br/><div class="children"><div class="content">What speed should we expect from the model on consumer hardware? I tried a 8 bit quantized version on 4090 and got it to generate 100 tokens for 13 second, which seems a bit slow to me.</div><br/></div></div><div id="35955324" class="c"><input type="checkbox" id="c-35955324" checked=""/><div class="controls bullet"><span class="by">bootloop</span><span>|</span><a href="#35958971">prev</a><span>|</span><a href="#35954824">next</a><span>|</span><label class="collapse" for="c-35955324">[-]</label><label class="expand" for="c-35955324">[5 more]</label></div><br/><div class="children"><div class="content">The biggest interest I have in this, is that I would like to have the ability to ask questions about large code-bases. I think being able to generate small functions or explain single code sections is nice, but being able to ask bigger architectural questions would be really helpful for all kind of engineers (in particular in a large company).<p>I have seen approaches with merging context across multiple levels. But that can only do so much. Is it viable to fine-train a model to a specific code-base so it has knowledge across all files? Does anyone have more info on this kind of problem space?</div><br/><div id="35956537" class="c"><input type="checkbox" id="c-35956537" checked=""/><div class="controls bullet"><span class="by">zellyn</span><span>|</span><a href="#35955324">parent</a><span>|</span><a href="#35956292">next</a><span>|</span><label class="collapse" for="c-35956537">[-]</label><label class="expand" for="c-35956537">[2 more]</label></div><br/><div class="children"><div class="content">Steve Yegge&#x27;s recent blog posts claim that SourceGraph are getting a pretty good result by using embeddings created from their knowledge graph of the code structure. That&#x27;s still the usual [create embeddings, search against embedding of query, retrieve results and use them as prompt] schlep, so yeah, it isn&#x27;t really understanding architecture well yet.<p>I too have a job where almost every question is about structural understanding and improvement of a large existing codebase. I&#x27;d love to have AI help, but I think it&#x27;s going to take another iteration or three of model architecture to get there.</div><br/><div id="35957731" class="c"><input type="checkbox" id="c-35957731" checked=""/><div class="controls bullet"><span class="by">Mockapapella</span><span>|</span><a href="#35955324">root</a><span>|</span><a href="#35956537">parent</a><span>|</span><a href="#35956292">next</a><span>|</span><label class="collapse" for="c-35957731">[-]</label><label class="expand" for="c-35957731">[1 more]</label></div><br/><div class="children"><div class="content">So like, next week then?</div><br/></div></div></div></div><div id="35956292" class="c"><input type="checkbox" id="c-35956292" checked=""/><div class="controls bullet"><span class="by">heliophobicdude</span><span>|</span><a href="#35955324">parent</a><span>|</span><a href="#35956537">prev</a><span>|</span><a href="#35955744">next</a><span>|</span><label class="collapse" for="c-35956292">[-]</label><label class="expand" for="c-35956292">[1 more]</label></div><br/><div class="children"><div class="content">Refined training is usually updating the weights of usually what&#x27;s called a foundational model with well structured and numerous data. It&#x27;s can be expensive but most importantly disturb the usefulness of having all the generalizations baked in from training data [1].
While LLMs can generate code based on a wide range of inputs, they&#x27;re not designed to retrieve specific pieces of information in the same way that a database or a search engine would. It&#x27;s just very lossy. Perhaps it wouldn&#x27;t be the best use for single code base fine tuning right now.<p>Can you please share more about the merging context across levels? This sounds interesting!<p>1: &quot;Language Models are Few-Shot Learners&quot; Brown et al. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2005.14165.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2005.14165.pdf</a></div><br/></div></div><div id="35955744" class="c"><input type="checkbox" id="c-35955744" checked=""/><div class="controls bullet"><span class="by">bradleyjg</span><span>|</span><a href="#35955324">parent</a><span>|</span><a href="#35956292">prev</a><span>|</span><a href="#35954824">next</a><span>|</span><label class="collapse" for="c-35955744">[-]</label><label class="expand" for="c-35955744">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. I’d love to be able to ask where and how would I go about adding some new feature to a code base.</div><br/></div></div></div></div><div id="35954824" class="c"><input type="checkbox" id="c-35954824" checked=""/><div class="controls bullet"><span class="by">freeqaz</span><span>|</span><a href="#35955324">prev</a><span>|</span><a href="#35955199">next</a><span>|</span><label class="collapse" for="c-35954824">[-]</label><label class="expand" for="c-35954824">[4 more]</label></div><br/><div class="children"><div class="content">Looks like the model is on HuggingFace here, for anybody that is curious to play with it. <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;bigcode&#x2F;starcoder" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;bigcode&#x2F;starcoder</a></div><br/><div id="35958296" class="c"><input type="checkbox" id="c-35958296" checked=""/><div class="controls bullet"><span class="by">CodeCompost</span><span>|</span><a href="#35954824">parent</a><span>|</span><a href="#35955199">next</a><span>|</span><label class="collapse" for="c-35958296">[-]</label><label class="expand" for="c-35958296">[3 more]</label></div><br/><div class="children"><div class="content">Sorry I&#x27;m a bit new to this. How does this work? Trying to read the site but have a hard time understanding this.</div><br/><div id="35958446" class="c"><input type="checkbox" id="c-35958446" checked=""/><div class="controls bullet"><span class="by">chillbill</span><span>|</span><a href="#35954824">root</a><span>|</span><a href="#35958296">parent</a><span>|</span><a href="#35955199">next</a><span>|</span><label class="collapse" for="c-35958446">[-]</label><label class="expand" for="c-35958446">[2 more]</label></div><br/><div class="children"><div class="content">Welcome to the crappy ml world, where everything is clunky and barely works one time on one machine if you don’t touch anything on the computer, where software loses its meaning and saving Jupiter notebooks as py files is the norm, where the majority of “data scientist” means glorified labeling machines.</div><br/><div id="35958534" class="c"><input type="checkbox" id="c-35958534" checked=""/><div class="controls bullet"><span class="by">pbmonster</span><span>|</span><a href="#35954824">root</a><span>|</span><a href="#35958446">parent</a><span>|</span><a href="#35955199">next</a><span>|</span><label class="collapse" for="c-35958534">[-]</label><label class="expand" for="c-35958534">[1 more]</label></div><br/><div class="children"><div class="content">In their defense, stuff is moving forward at half the speed of light, so everybody has better things to do right now.<p>Also, investing serious time here on cleaner processes and better documentation of their specific implementation seems like a waste of time. I don&#x27;t think much of any of this will still be in use next year, everybody will have moved on to more advanced projects.<p>But I agree, once things stabilize, the most popular models should invest in clean up a fair bit.</div><br/></div></div></div></div></div></div></div></div><div id="35955199" class="c"><input type="checkbox" id="c-35955199" checked=""/><div class="controls bullet"><span class="by">nr2x</span><span>|</span><a href="#35954824">prev</a><span>|</span><a href="#35954791">next</a><span>|</span><label class="collapse" for="c-35955199">[-]</label><label class="expand" for="c-35955199">[2 more]</label></div><br/><div class="children"><div class="content">Given some of my own open source code is no doubt in GPT and Bard, which feels wrong given the fees and limitations, I’m VERY VERY excited for this!</div><br/><div id="35957708" class="c"><input type="checkbox" id="c-35957708" checked=""/><div class="controls bullet"><span class="by">speedgoose</span><span>|</span><a href="#35955199">parent</a><span>|</span><a href="#35954791">next</a><span>|</span><label class="collapse" for="c-35957708">[-]</label><label class="expand" for="c-35957708">[1 more]</label></div><br/><div class="children"><div class="content">It’s perhaps in the training dataset but unless your code is extremely common and duplicated, it’s probably not in the final models. They aren’t that big.</div><br/></div></div></div></div><div id="35954791" class="c"><input type="checkbox" id="c-35954791" checked=""/><div class="controls bullet"><span class="by">cs702</span><span>|</span><a href="#35955199">prev</a><span>|</span><a href="#35955272">next</a><span>|</span><label class="collapse" for="c-35954791">[-]</label><label class="expand" for="c-35954791">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s great to see this!<p>A big THANK YOU to everyone who made it possible.<p>I&#x27;m looking forward to playing with it -- and also, eventually, inevitably, running a quantized, super-efficient version on my laptop.</div><br/></div></div><div id="35955272" class="c"><input type="checkbox" id="c-35955272" checked=""/><div class="controls bullet"><span class="by">jimlongton</span><span>|</span><a href="#35954791">prev</a><span>|</span><a href="#35956363">next</a><span>|</span><label class="collapse" for="c-35955272">[-]</label><label class="expand" for="c-35955272">[2 more]</label></div><br/><div class="children"><div class="content">(Possibly naive question) This is marketed as open source. Does that mean I can download the model and run it locally? If so, what kind of GPU would I need?</div><br/><div id="35955410" class="c"><input type="checkbox" id="c-35955410" checked=""/><div class="controls bullet"><span class="by">pyrophane</span><span>|</span><a href="#35955272">parent</a><span>|</span><a href="#35956363">next</a><span>|</span><label class="collapse" for="c-35955410">[-]</label><label class="expand" for="c-35955410">[1 more]</label></div><br/><div class="children"><div class="content">Here is a good reference:<p><a href="https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;transformers&#x2F;perf_train_gpu_one" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;transformers&#x2F;perf_train_gpu_one</a></div><br/></div></div></div></div><div id="35956363" class="c"><input type="checkbox" id="c-35956363" checked=""/><div class="controls bullet"><span class="by">heliophobicdude</span><span>|</span><a href="#35955272">prev</a><span>|</span><a href="#35958337">next</a><span>|</span><label class="collapse" for="c-35956363">[-]</label><label class="expand" for="c-35956363">[2 more]</label></div><br/><div class="children"><div class="content">I think we need a different strategy to instruction tuning for coding LLMs.<p>I don&#x27;t think StarCoderBase is instruction-tuned off the bat but would serve as a good starting point for a new technique.<p>RLHF is fine for things that are hard to measure and evaluate, but code is runnable and testable.<p>I propose we try Reinforcement Learning Machine Feedback or RLMF.<p>Prompts and responses are evaluated by how accurate the response evaluated to. We can then train a reward model to help refine StarCoder.</div><br/><div id="35958347" class="c"><input type="checkbox" id="c-35958347" checked=""/><div class="controls bullet"><span class="by">grandmczeb</span><span>|</span><a href="#35956363">parent</a><span>|</span><a href="#35958337">next</a><span>|</span><label class="collapse" for="c-35958347">[-]</label><label class="expand" for="c-35958347">[1 more]</label></div><br/><div class="children"><div class="content">Good idea, but pretty sure this is already widely done. For example, Alex Gravely (architect behind copilot) mentioned on No Priors[1] they would generate the implementations for tests in random github projects and check if they passed as feedback.<p>[1] <a href="https:&#x2F;&#x2F;open.spotify.com&#x2F;episode&#x2F;2a8Rtm4mhjzennOoAByFKx" rel="nofollow">https:&#x2F;&#x2F;open.spotify.com&#x2F;episode&#x2F;2a8Rtm4mhjzennOoAByFKx</a> around 15:10</div><br/></div></div></div></div><div id="35958337" class="c"><input type="checkbox" id="c-35958337" checked=""/><div class="controls bullet"><span class="by">ipsum2</span><span>|</span><a href="#35956363">prev</a><span>|</span><a href="#35957151">next</a><span>|</span><label class="collapse" for="c-35958337">[-]</label><label class="expand" for="c-35958337">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been playing with StarCoder for the last week. It performs great once fine-tuned. Highly recommend people use it as a base model for anything, not just coding.</div><br/></div></div><div id="35957151" class="c"><input type="checkbox" id="c-35957151" checked=""/><div class="controls bullet"><span class="by">ofermend</span><span>|</span><a href="#35958337">prev</a><span>|</span><a href="#35956052">next</a><span>|</span><label class="collapse" for="c-35957151">[-]</label><label class="expand" for="c-35957151">[4 more]</label></div><br/><div class="children"><div class="content">All the code generation tools, StarCoder included, still have hallucinations. In this context code that looks good, but doesn&#x27;t work or has a subtle bug. How do we address that?</div><br/><div id="35957433" class="c"><input type="checkbox" id="c-35957433" checked=""/><div class="controls bullet"><span class="by">theaiquestion</span><span>|</span><a href="#35957151">parent</a><span>|</span><a href="#35957161">next</a><span>|</span><label class="collapse" for="c-35957433">[-]</label><label class="expand" for="c-35957433">[1 more]</label></div><br/><div class="children"><div class="content">&gt; All the code generation tools, StarCoder included, still have hallucinations.<p>This also includes humans. We &quot;hallucinate&quot; in very similar ways. For example mistaking localhost:8080 for localhost:8008 in a large config file. Attempting to use methods that were deprecated and no longer exist, etc.<p>IMO there&#x27;s two ways to prevent this is - one is to make better performing models (architecture&#x2F;training data&#x2F;training amount&#x2F;etc)<p>The other is the exact same as humans. Compile time tools that let it know immediately if it hallucinated, types, linting, tests, etc.<p>You just do it as a loop the exact same as a human. You write code, the compiler tells you that method doesn&#x27;t exist, you adjust your code&#x2F;consult the documents (also doable with agents).</div><br/></div></div><div id="35957161" class="c"><input type="checkbox" id="c-35957161" checked=""/><div class="controls bullet"><span class="by">arthurcolle</span><span>|</span><a href="#35957151">parent</a><span>|</span><a href="#35957433">prev</a><span>|</span><a href="#35956052">next</a><span>|</span><label class="collapse" for="c-35957161">[-]</label><label class="expand" for="c-35957161">[2 more]</label></div><br/><div class="children"><div class="content">Verification systems that then feed back into the models and correct hallucinations. It is slow but I think that&#x27;s the only real way forward</div><br/><div id="35957387" class="c"><input type="checkbox" id="c-35957387" checked=""/><div class="controls bullet"><span class="by">DavidKarlas</span><span>|</span><a href="#35957151">root</a><span>|</span><a href="#35957161">parent</a><span>|</span><a href="#35956052">next</a><span>|</span><label class="collapse" for="c-35957387">[-]</label><label class="expand" for="c-35957387">[1 more]</label></div><br/><div class="children"><div class="content">Sounds same as when I started codding, hallucinated some code, compiler told me it is non-sense, and eventually I understood most of the rules... I still mess it up...</div><br/></div></div></div></div></div></div><div id="35956052" class="c"><input type="checkbox" id="c-35956052" checked=""/><div class="controls bullet"><span class="by">daneel_w</span><span>|</span><a href="#35957151">prev</a><span>|</span><a href="#35958760">next</a><span>|</span><label class="collapse" for="c-35956052">[-]</label><label class="expand" for="c-35956052">[4 more]</label></div><br/><div class="children"><div class="content"><i>&gt;&quot;The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process.&quot;</i><p><i>&gt;&quot;The Stack is a collection of source code from repositories with various licenses. Any use of all or part of the code gathered in The Stack must abide by the terms of the original licenses, including attribution clauses when relevant.&quot;</i><p>Does it have a view of what licenses can mix, or is it simply disallowed from crossing that boundary and only offer answers sourced entirely within the confines of this or that specific license? The latter poses some interesting scenarios and questions.</div><br/><div id="35958437" class="c"><input type="checkbox" id="c-35958437" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#35956052">parent</a><span>|</span><a href="#35956164">next</a><span>|</span><label class="collapse" for="c-35958437">[-]</label><label class="expand" for="c-35958437">[1 more]</label></div><br/><div class="children"><div class="content">Details are here: <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;bigcode&#x2F;the-stack" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;datasets&#x2F;bigcode&#x2F;the-stack</a><p>There are 193 licenses in total. v1.0 of The Stack included MPL&#x2F;EPL&#x2F;LGPL whereas v1.1+ doesn&#x27;t include them.</div><br/></div></div><div id="35956164" class="c"><input type="checkbox" id="c-35956164" checked=""/><div class="controls bullet"><span class="by">freeqaz</span><span>|</span><a href="#35956052">parent</a><span>|</span><a href="#35958437">prev</a><span>|</span><a href="#35958760">next</a><span>|</span><label class="collapse" for="c-35956164">[-]</label><label class="expand" for="c-35956164">[2 more]</label></div><br/><div class="children"><div class="content">Permissively licensed would imply non-copyleft to me. That means only licenses like Apache or MIT would be allowed to be train on, but not licenses like GPL.</div><br/><div id="35956435" class="c"><input type="checkbox" id="c-35956435" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#35956052">root</a><span>|</span><a href="#35956164">parent</a><span>|</span><a href="#35958760">next</a><span>|</span><label class="collapse" for="c-35956435">[-]</label><label class="expand" for="c-35956435">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s my understanding that GPLv3 is perfectly fine to make businesses on, you just have to make your code open source.  There isn&#x27;t anything wrong with that, and in today&#x27;s age, I would actually suggest that&#x27;s an enormous <i>positive</i> for a business, as it allows people to trust the company much more.</div><br/></div></div></div></div></div></div><div id="35958760" class="c"><input type="checkbox" id="c-35958760" checked=""/><div class="controls bullet"><span class="by">buraksarica</span><span>|</span><a href="#35956052">prev</a><span>|</span><a href="#35957104">next</a><span>|</span><label class="collapse" for="c-35958760">[-]</label><label class="expand" for="c-35958760">[1 more]</label></div><br/><div class="children"><div class="content">Is Danish Contractor a real person? :D</div><br/></div></div><div id="35957104" class="c"><input type="checkbox" id="c-35957104" checked=""/><div class="controls bullet"><span class="by">superkuh</span><span>|</span><a href="#35958760">prev</a><span>|</span><a href="#35957877">next</a><span>|</span><label class="collapse" for="c-35957104">[-]</label><label class="expand" for="c-35957104">[2 more]</label></div><br/><div class="children"><div class="content">This didn&#x27;t generate anything like actual perl code but the paper did say it wasn&#x27;t good at perl (relatively) and in their defense my code it was completing was full of regex. What I did enjoy was how it picked up on my style of extremely long variable and subroutine names without spaces. It even named them with swear words like I do.</div><br/><div id="35958636" class="c"><input type="checkbox" id="c-35958636" checked=""/><div class="controls bullet"><span class="by">DanielShir</span><span>|</span><a href="#35957104">parent</a><span>|</span><a href="#35957877">next</a><span>|</span><label class="collapse" for="c-35958636">[-]</label><label class="expand" for="c-35958636">[1 more]</label></div><br/><div class="children"><div class="content">Now I really want to read your code... Anything public? :)</div><br/></div></div></div></div><div id="35957877" class="c"><input type="checkbox" id="c-35957877" checked=""/><div class="controls bullet"><span class="by">pabs3</span><span>|</span><a href="#35957104">prev</a><span>|</span><a href="#35957836">next</a><span>|</span><label class="collapse" for="c-35957877">[-]</label><label class="expand" for="c-35957877">[1 more]</label></div><br/><div class="children"><div class="content">Permissive licenses usually have attribution requirements, does using this mean you have to attribute all the projects from The Stack?</div><br/></div></div><div id="35957836" class="c"><input type="checkbox" id="c-35957836" checked=""/><div class="controls bullet"><span class="by">VadimPR</span><span>|</span><a href="#35957877">prev</a><span>|</span><a href="#35955266">next</a><span>|</span><label class="collapse" for="c-35957836">[-]</label><label class="expand" for="c-35957836">[1 more]</label></div><br/><div class="children"><div class="content">This is great - we needed a model where we&#x27;re sure it won&#x27;t reproduce someone&#x27;s code with an incompatible license.</div><br/></div></div><div id="35955266" class="c"><input type="checkbox" id="c-35955266" checked=""/><div class="controls bullet"><span class="by">fbodz</span><span>|</span><a href="#35957836">prev</a><span>|</span><a href="#35957952">next</a><span>|</span><label class="collapse" for="c-35955266">[-]</label><label class="expand" for="c-35955266">[8 more]</label></div><br/><div class="children"><div class="content">Has anyone figured out a way to fine tune this with 24gb of vram? I have tried with deepspeed etc but no luck. Seems to be just out of reach for fine tuning requiring 26gb.</div><br/><div id="35958142" class="c"><input type="checkbox" id="c-35958142" checked=""/><div class="controls bullet"><span class="by">mirekrusin</span><span>|</span><a href="#35955266">parent</a><span>|</span><a href="#35955625">next</a><span>|</span><label class="collapse" for="c-35958142">[-]</label><label class="expand" for="c-35958142">[1 more]</label></div><br/><div class="children"><div class="content">People should be training model sizes that fit-and-fill consumer GPUs, ie:<p>2x 24G - for dual GPU ~ 28B model<p>1x 24G ~ 14B model<p>etc.</div><br/></div></div><div id="35955625" class="c"><input type="checkbox" id="c-35955625" checked=""/><div class="controls bullet"><span class="by">csdvrx</span><span>|</span><a href="#35955266">parent</a><span>|</span><a href="#35958142">prev</a><span>|</span><a href="#35957952">next</a><span>|</span><label class="collapse" for="c-35955625">[-]</label><label class="expand" for="c-35955625">[6 more]</label></div><br/><div class="children"><div class="content">Have you tried quantization? It&#x27;s often a cheap and simple way to reduce the VRAM requirements.<p>What hardware are you using? (CPU,RAM,GPU,VRAM)<p>Have you considered using llama.cpp for a mixed CPU+GPU use (if you have enough RAM)</div><br/><div id="35958456" class="c"><input type="checkbox" id="c-35958456" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#35955266">root</a><span>|</span><a href="#35955625">parent</a><span>|</span><a href="#35955796">next</a><span>|</span><label class="collapse" for="c-35958456">[-]</label><label class="expand" for="c-35958456">[1 more]</label></div><br/><div class="children"><div class="content">You probably don&#x27;t want to fine-tune a quantized model. They are fine for inference but not great for training.</div><br/></div></div><div id="35955796" class="c"><input type="checkbox" id="c-35955796" checked=""/><div class="controls bullet"><span class="by">fbodz</span><span>|</span><a href="#35955266">root</a><span>|</span><a href="#35955625">parent</a><span>|</span><a href="#35958456">prev</a><span>|</span><a href="#35957952">next</a><span>|</span><label class="collapse" for="c-35955796">[-]</label><label class="expand" for="c-35955796">[4 more]</label></div><br/><div class="children"><div class="content">Yeah I am using the default training script with int8 quantisation. It uses peft with lora but this still requires 26gb</div><br/><div id="35956761" class="c"><input type="checkbox" id="c-35956761" checked=""/><div class="controls bullet"><span class="by">int_19h</span><span>|</span><a href="#35955266">root</a><span>|</span><a href="#35955796">parent</a><span>|</span><a href="#35956170">next</a><span>|</span><label class="collapse" for="c-35956761">[-]</label><label class="expand" for="c-35956761">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure about this model specifically, but training with 4-bit quantization has been a thing with LLaMA for a while now, although the setup involves manual hacks of various libraries.</div><br/></div></div><div id="35956170" class="c"><input type="checkbox" id="c-35956170" checked=""/><div class="controls bullet"><span class="by">freeqaz</span><span>|</span><a href="#35955266">root</a><span>|</span><a href="#35955796">parent</a><span>|</span><a href="#35956761">prev</a><span>|</span><a href="#35957952">next</a><span>|</span><label class="collapse" for="c-35956170">[-]</label><label class="expand" for="c-35956170">[2 more]</label></div><br/><div class="children"><div class="content">Is it possible to offload some layers to CPU and still train in a reasonable amount of time?</div><br/><div id="35956297" class="c"><input type="checkbox" id="c-35956297" checked=""/><div class="controls bullet"><span class="by">generalizations</span><span>|</span><a href="#35955266">root</a><span>|</span><a href="#35956170">parent</a><span>|</span><a href="#35957952">next</a><span>|</span><label class="collapse" for="c-35956297">[-]</label><label class="expand" for="c-35956297">[1 more]</label></div><br/><div class="children"><div class="content">There’s also that pruning tool that was on hn in the last couple weeks. It seemed to work really well on the larger models, and could reduce size by 30-50%</div><br/></div></div></div></div></div></div></div></div></div></div><div id="35957952" class="c"><input type="checkbox" id="c-35957952" checked=""/><div class="controls bullet"><span class="by">pplanel</span><span>|</span><a href="#35955266">prev</a><span>|</span><a href="#35955596">next</a><span>|</span><label class="collapse" for="c-35957952">[-]</label><label class="expand" for="c-35957952">[1 more]</label></div><br/><div class="children"><div class="content">It sucks at Rust<p><pre><code>  fn convert_ogg_to_w  av(input: Path) -&gt; Result&lt;</code></pre></div><br/></div></div><div id="35955596" class="c"><input type="checkbox" id="c-35955596" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#35957952">prev</a><span>|</span><a href="#35955190">next</a><span>|</span><label class="collapse" for="c-35955596">[-]</label><label class="expand" for="c-35955596">[4 more]</label></div><br/><div class="children"><div class="content">Do I need to make an account on huggingface to get the model? I would prefer not to do it, and just download a zip like you can on github.</div><br/><div id="35956267" class="c"><input type="checkbox" id="c-35956267" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#35955596">parent</a><span>|</span><a href="#35955190">next</a><span>|</span><label class="collapse" for="c-35956267">[-]</label><label class="expand" for="c-35956267">[3 more]</label></div><br/><div class="children"><div class="content">I thought you didn&#x27;t need an account to download from HF anymore. You can just do git lfs pull, at least for the stuff I&#x27;ve downloaded.<p>Personally I&#x27;m concerned about how model hosting has been concentrated in one company, and was previously very unhappy that they required accounts, but I think that&#x27;s past. Let me know if it&#x27;s still the case for some things.</div><br/><div id="35956320" class="c"><input type="checkbox" id="c-35956320" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#35955596">root</a><span>|</span><a href="#35956267">parent</a><span>|</span><a href="#35955190">next</a><span>|</span><label class="collapse" for="c-35956320">[-]</label><label class="expand" for="c-35956320">[2 more]</label></div><br/><div class="children"><div class="content">It is suggesting that I have to make an account.<p>When I go to <a href="https:&#x2F;&#x2F;huggingface.co&#x2F;bigcode&#x2F;starcoder" rel="nofollow">https:&#x2F;&#x2F;huggingface.co&#x2F;bigcode&#x2F;starcoder</a> it says &quot;You need to agree to share your contact informations to access this model&quot; and &quot;[Log in] or [Sign Up] to review the conditions and access this model content.&quot;</div><br/><div id="35956375" class="c"><input type="checkbox" id="c-35956375" checked=""/><div class="controls bullet"><span class="by">version_five</span><span>|</span><a href="#35955596">root</a><span>|</span><a href="#35956320">parent</a><span>|</span><a href="#35955190">next</a><span>|</span><label class="collapse" for="c-35956375">[-]</label><label class="expand" for="c-35956375">[1 more]</label></div><br/><div class="children"><div class="content">Yeah you&#x27;re right, that&#x27;s super lame. It used to be like that with stable diffusion but they took the HF login requirement off at some point.<p>It&#x27;s enough of a deal breaker for me to not bother using the model. Especially when it&#x27;s developed by a company that (I assume) wants to harvest your contact info - unless there&#x27;s some other explanation for the login requirement.<p>(I tried git lfs clone and got asked for hf login credentials)</div><br/></div></div></div></div></div></div></div></div><div id="35955169" class="c"><input type="checkbox" id="c-35955169" checked=""/><div class="controls bullet"><span class="by">meghan_rain</span><span>|</span><a href="#35955190">prev</a><span>|</span><a href="#35957210">next</a><span>|</span><label class="collapse" for="c-35955169">[-]</label><label class="expand" for="c-35955169">[2 more]</label></div><br/><div class="children"><div class="content">tldr how does it compare to codepilot&#x2F;gpt4?</div><br/><div id="35955431" class="c"><input type="checkbox" id="c-35955431" checked=""/><div class="controls bullet"><span class="by">bavell</span><span>|</span><a href="#35955169">parent</a><span>|</span><a href="#35957210">next</a><span>|</span><label class="collapse" for="c-35955431">[-]</label><label class="expand" for="c-35955431">[1 more]</label></div><br/><div class="children"><div class="content">From the summary:<p>&quot;We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model.&quot;<p>So I&#x27;d assume not up to par with gpt4 or copilot. Can&#x27;t wait to see it evolve from here!</div><br/></div></div></div></div></div></div></div></div></div></body></html>