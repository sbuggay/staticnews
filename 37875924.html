<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1697446867915" as="style"/><link rel="stylesheet" href="styles.css?v=1697446867915"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://gonzoml.substack.com/p/building-machines-that-learn-and">&quot;Building Machines That Learn and Think Like People&quot;, 7 Years Later</a> <span class="domain">(<a href="https://gonzoml.substack.com">gonzoml.substack.com</a>)</span></div><div class="subtext"><span>che_shr_cat</span> | <span>36 comments</span></div><br/><div><div id="37897270" class="c"><input type="checkbox" id="c-37897270" checked=""/><div class="controls bullet"><span class="by">scotty79</span><span>|</span><a href="#37893525">next</a><span>|</span><label class="collapse" for="c-37897270">[-]</label><label class="expand" for="c-37897270">[1 more]</label></div><br/><div class="children"><div class="content">I was terrible at this task as a kid. When asked to describe an image I usually volunteered single piece of information about it and I had to be prompted multiple times and asked leading questions to observe and describe more of it. GPT-4V beats me even now. There were a lot of information in the descriptions I wouldn&#x27;t notice or include without being specifically asked about them.</div><br/></div></div><div id="37893525" class="c"><input type="checkbox" id="c-37893525" checked=""/><div class="controls bullet"><span class="by">M4v3R</span><span>|</span><a href="#37897270">prev</a><span>|</span><a href="#37893785">next</a><span>|</span><label class="collapse" for="c-37893525">[-]</label><label class="expand" for="c-37893525">[11 more]</label></div><br/><div class="children"><div class="content">GPT-4V is mind blowing, it surprising to me that it gets so little attention here on HN, because after playing around with it I get the same sense of excitement I got when I tried the original ChatGPT. The level of understanding of what is going on in an image is leagues ahead of what we had until this point, ahead of Bard and basically everything else I already saw.<p>I tested it with a bunch of photos I made and images it could not have seen in its training data, and most of the time it nailed them perfectly. Its OCR capabilities are top notch, but this is combined with a spatial understanding of how text relates to other parts of the image. It can take a photo of a wall monthly calendar with hand scribbles on it and give you a list of events for each day. It can guess where a specific photo was taken just by analysing the elements present on the photo like the foliage, architecture, car license plates, etc (without being specifically prompted to do so). It can correctly identify multiple plants from a same photo. Gave it a photo of a Montessori set for teaching math (some wooden blocks with numbers and dots on them, no branding on them) and it guessed exactly what it was. And all of that just from two days of testing.<p>Here are just few examples:<p>[1] <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;cV3dVOf.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;i.imgur.com&#x2F;cV3dVOf.png</a> - Gave it a screenshot from Final Fantasy VII from a boss battle. It correctly identified the party members, and their stats even though the text and labels are a bit all over the place.<p>[2] <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;WeXhP7V.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;i.imgur.com&#x2F;WeXhP7V.png</a> - A photo I shot on my vacation, that didn&#x27;t really contain any major landmarks, and yet it still somehow figured out from the architecture (and house colors) the exact location of it. I tried this game with several photos and it is very good at it, far better than I could ever be if I saw these photos for the first time.<p>[3] <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;HgwYv6q.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;i.imgur.com&#x2F;HgwYv6q.png</a> - A screenshot of a worksheet from the Human Shader Project. I just asked it to solve it for given X&#x2F;Y values and it did, its answer was 100% correct (here&#x27;s the second part of its answer: <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;RZF2r7v.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;i.imgur.com&#x2F;RZF2r7v.png</a>)<p>[4] <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;12xg4qU.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;i.imgur.com&#x2F;12xg4qU.png</a> - A photo of a highly reflective microwave inside a shopping mall. This was given to my by a friend who shot this personally and to be honest I didn&#x27;t catch at first that this is a microwave, and yet GPT-4V figured that out.<p>[5] <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;qSifni5.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;i.imgur.com&#x2F;qSifni5.png</a> - a good old fashioned &quot;find the path connecting one object to the other&quot; puzzle. Correctly identified the right path (this one was taken from the internet so there is a slight chance it saw it in the training data and somehow got the solution for it from the accompanying text, although I couldn&#x27;t find any instance of it).<p>Edit: To confirm that [5] was not a fluke I hand drew my own version of this puzzle, took a picture and uploaded it, GPT-4V nailed this one too: <a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;8NgWhzw.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;i.imgur.com&#x2F;8NgWhzw.png</a></div><br/><div id="37895016" class="c"><input type="checkbox" id="c-37895016" checked=""/><div class="controls bullet"><span class="by">psbp</span><span>|</span><a href="#37893525">parent</a><span>|</span><a href="#37897115">next</a><span>|</span><label class="collapse" for="c-37895016">[-]</label><label class="expand" for="c-37895016">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been using pictures of artifacts from random museum visits through the years to test the recent vision models. GPT-V is the first that has gotten anywhere close to identifying them accurately.<p>It&#x27;s usually able to identify 1) The materials the artifact is made out of 2) The country&#x2F;region it came from 3) the significance&#x2F;use of the item 4) roughly when it was created.<p>The images that I&#x27;m sharing are my own, so it&#x27;s not pulling the images directly from the internet, and for some of the artifacts it&#x27;s actually difficult to find similar images online.<p>I think it&#x27;s fairly safe to say that it&#x27;s truly able to perform advanced image analysis with images that aren&#x27;t directly in its dataset.</div><br/></div></div><div id="37897115" class="c"><input type="checkbox" id="c-37897115" checked=""/><div class="controls bullet"><span class="by">Sakos</span><span>|</span><a href="#37893525">parent</a><span>|</span><a href="#37895016">prev</a><span>|</span><a href="#37894820">next</a><span>|</span><label class="collapse" for="c-37897115">[-]</label><label class="expand" for="c-37897115">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll be impressed when ChatGPT recognizes that the &quot;Attack while its tail up&quot; message is erroneous and the opposite is true. GPT and everything else like GPT is useless until it can differentiate fact and fiction and understand the difference.</div><br/></div></div><div id="37894820" class="c"><input type="checkbox" id="c-37894820" checked=""/><div class="controls bullet"><span class="by">usaar333</span><span>|</span><a href="#37893525">parent</a><span>|</span><a href="#37897115">prev</a><span>|</span><a href="#37893808">next</a><span>|</span><label class="collapse" for="c-37894820">[-]</label><label class="expand" for="c-37894820">[1 more]</label></div><br/><div class="children"><div class="content">FWIW, I couldn&#x27;t get your custom path puzzle reliably working zero shot.<p>Prompt: &quot;This image shows various lines. The line connecting to the box labeled &quot;exit&quot; connects to what point?&quot;<p>Gpt:  &quot;The line connecting to the box labeled &quot;EXIT&quot; connects to point &quot;C&quot;.&quot;<p>A cropped version of the puzzle with the characters also failed 1-shot after presenting your drawing and the correct answer.</div><br/></div></div><div id="37893808" class="c"><input type="checkbox" id="c-37893808" checked=""/><div class="controls bullet"><span class="by">adroitboss</span><span>|</span><a href="#37893525">parent</a><span>|</span><a href="#37894820">prev</a><span>|</span><a href="#37893920">next</a><span>|</span><label class="collapse" for="c-37893808">[-]</label><label class="expand" for="c-37893808">[2 more]</label></div><br/><div class="children"><div class="content">I just think the tech has been out for so long it&#x27;s not as big of a deal. Mini-Gpt4 has been out for 6 months! Of course the descriptions aren&#x27;t exactly gpt-4 grade, but with mistral 7b being used as the language model instead of llama 7b, the reasoning ability will improve noticeably.<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;Vision-CAIR&#x2F;MiniGPT-4">https:&#x2F;&#x2F;github.com&#x2F;Vision-CAIR&#x2F;MiniGPT-4</a></div><br/><div id="37893825" class="c"><input type="checkbox" id="c-37893825" checked=""/><div class="controls bullet"><span class="by">M4v3R</span><span>|</span><a href="#37893525">root</a><span>|</span><a href="#37893808">parent</a><span>|</span><a href="#37893920">next</a><span>|</span><label class="collapse" for="c-37893825">[-]</label><label class="expand" for="c-37893825">[1 more]</label></div><br/><div class="children"><div class="content">Sure, the tech was out there for quite some time but never before the quality of the output was <i>so</i> good, it&#x27;s almost (not 100%, there still are mistakes and hallucinations ocassionally) on par with a human, which to me is really stunning.<p>I&#x27;ve tried these kind of queries with other models (including Mini-GPT4) and never got any meaningful results until now. It’s the same thing with GPT 3.5&#x2F;4 - sure, transformer models existed for few years already but ChatGPT crossed some kind of threshold in the quality of its output where finally people took notice.</div><br/></div></div></div></div><div id="37893920" class="c"><input type="checkbox" id="c-37893920" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#37893525">parent</a><span>|</span><a href="#37893808">prev</a><span>|</span><a href="#37893589">next</a><span>|</span><label class="collapse" for="c-37893920">[-]</label><label class="expand" for="c-37893920">[2 more]</label></div><br/><div class="children"><div class="content">It gets funnier: <a href="https:&#x2F;&#x2F;www.reddit.com&#x2F;media?url=https%3A%2F%2Fi.redd.it%2Fv78o1ggc3ztb1.png" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.reddit.com&#x2F;media?url=https%3A%2F%2Fi.redd.it%2Fv...</a></div><br/><div id="37893989" class="c"><input type="checkbox" id="c-37893989" checked=""/><div class="controls bullet"><span class="by">M4v3R</span><span>|</span><a href="#37893525">root</a><span>|</span><a href="#37893920">parent</a><span>|</span><a href="#37893589">next</a><span>|</span><label class="collapse" for="c-37893989">[-]</label><label class="expand" for="c-37893989">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I saw that, and that&#x27;s a classic jailbreak to which all GPT models are vulnerable to some extent. Although in this specific case apparently just telling the model to not treat the image as instructions helps: <a href="https:&#x2F;&#x2F;preview.redd.it&#x2F;ro31uq3ifztb1.png?width=730&amp;format=png&amp;auto=webp&amp;s=0e1a1cfbadd7107cb3507974bf2af8495e34efca" rel="nofollow noreferrer">https:&#x2F;&#x2F;preview.redd.it&#x2F;ro31uq3ifztb1.png?width=730&amp;format=p...</a></div><br/></div></div></div></div><div id="37893589" class="c"><input type="checkbox" id="c-37893589" checked=""/><div class="controls bullet"><span class="by">meowkit</span><span>|</span><a href="#37893525">parent</a><span>|</span><a href="#37893920">prev</a><span>|</span><a href="#37893785">next</a><span>|</span><label class="collapse" for="c-37893589">[-]</label><label class="expand" for="c-37893589">[3 more]</label></div><br/><div class="children"><div class="content">For [2] there could be meta data in the photo (depending on what device you took it on) that GPTV is extracting which would help dramatically with identifying the location.</div><br/><div id="37893755" class="c"><input type="checkbox" id="c-37893755" checked=""/><div class="controls bullet"><span class="by">M4v3R</span><span>|</span><a href="#37893525">root</a><span>|</span><a href="#37893589">parent</a><span>|</span><a href="#37893732">next</a><span>|</span><label class="collapse" for="c-37893755">[-]</label><label class="expand" for="c-37893755">[1 more]</label></div><br/><div class="children"><div class="content">Good call, but I did make sure to strip any metadata from the photos before I uploaded them :)</div><br/></div></div><div id="37893732" class="c"><input type="checkbox" id="c-37893732" checked=""/><div class="controls bullet"><span class="by">gear54rus</span><span>|</span><a href="#37893525">root</a><span>|</span><a href="#37893589">parent</a><span>|</span><a href="#37893755">prev</a><span>|</span><a href="#37893785">next</a><span>|</span><label class="collapse" for="c-37893732">[-]</label><label class="expand" for="c-37893732">[1 more]</label></div><br/><div class="children"><div class="content">I just did a screenshot of that and tested on my account. It still figured things out.</div><br/></div></div></div></div></div></div><div id="37893785" class="c"><input type="checkbox" id="c-37893785" checked=""/><div class="controls bullet"><span class="by">two_in_one</span><span>|</span><a href="#37893525">prev</a><span>|</span><a href="#37893019">next</a><span>|</span><label class="collapse" for="c-37893785">[-]</label><label class="expand" for="c-37893785">[3 more]</label></div><br/><div class="children"><div class="content">I played with it, a cool thing:<p>It can write a poem from image.<p>It can read text from image and &#x27;understand&#x27; it.<p>Or even specific part of the text. You can say &quot;look at the bottom line&quot;.<p>It can recognize and list songs from album cover.<p>It recognizes famous paintings. Even if only a fragment is given.<p>It can be used to create image-text datasets for generative and recognition tasks. Not sure how much this would cost.</div><br/><div id="37895104" class="c"><input type="checkbox" id="c-37895104" checked=""/><div class="controls bullet"><span class="by">golergka</span><span>|</span><a href="#37893785">parent</a><span>|</span><a href="#37893019">next</a><span>|</span><label class="collapse" for="c-37895104">[-]</label><label class="expand" for="c-37895104">[2 more]</label></div><br/><div class="children"><div class="content">I was at a restoraunt today and was curious what the sauce was made of. I took a photo of the dish and given the city I was in, gpt4 identified the name of the dish and all ingredients correctly, as I verified with the waiter afterwards.<p>Felt like magic.</div><br/><div id="37896069" class="c"><input type="checkbox" id="c-37896069" checked=""/><div class="controls bullet"><span class="by">endofreach</span><span>|</span><a href="#37893785">root</a><span>|</span><a href="#37895104">parent</a><span>|</span><a href="#37893019">next</a><span>|</span><label class="collapse" for="c-37896069">[-]</label><label class="expand" for="c-37896069">[1 more]</label></div><br/><div class="children"><div class="content">Did you strip the exif or disabled gps locations on photos?</div><br/></div></div></div></div></div></div><div id="37893019" class="c"><input type="checkbox" id="c-37893019" checked=""/><div class="controls bullet"><span class="by">mustafa_pasi</span><span>|</span><a href="#37893785">prev</a><span>|</span><a href="#37893082">next</a><span>|</span><label class="collapse" for="c-37893019">[-]</label><label class="expand" for="c-37893019">[11 more]</label></div><br/><div class="children"><div class="content">Could GPT-4V be used for robotic applications? I am a bit confused here. It produces a text from an image, but how much actual understanding does it have? Can the output somehow be used to do image segmentation and object detection and tracking?</div><br/><div id="37893161" class="c"><input type="checkbox" id="c-37893161" checked=""/><div class="controls bullet"><span class="by">voxic11</span><span>|</span><a href="#37893019">parent</a><span>|</span><a href="#37893109">next</a><span>|</span><label class="collapse" for="c-37893161">[-]</label><label class="expand" for="c-37893161">[1 more]</label></div><br/><div class="children"><div class="content">There is a lot happening with multimodal models and robotics right now. PaLM-E is similar to GPT-4V in that its a LLM that has been trained on additional visual and robotics &quot;sense&quot; data.<p><a href="https:&#x2F;&#x2F;blog.research.google&#x2F;2023&#x2F;03&#x2F;palm-e-embodied-multimodal-language.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;blog.research.google&#x2F;2023&#x2F;03&#x2F;palm-e-embodied-multimo...</a></div><br/></div></div><div id="37893109" class="c"><input type="checkbox" id="c-37893109" checked=""/><div class="controls bullet"><span class="by">kjander79</span><span>|</span><a href="#37893019">parent</a><span>|</span><a href="#37893161">prev</a><span>|</span><a href="#37893127">next</a><span>|</span><label class="collapse" for="c-37893109">[-]</label><label class="expand" for="c-37893109">[1 more]</label></div><br/><div class="children"><div class="content">&gt; but how much actual understanding does it have?<p>That&#x27;s always the question, isn&#x27;t it? The article does a pretty convincing job of showing that at least in the given examples, it has pretty good &quot;understanding&quot;  of what&#x27;s taking place in the scenes and what makes them remarkable to people, and 7 years for comparison is going back a long ways, just the last 2 or 3 years has been where much of the most interesting progress has revealed itself.<p>Image segmentation, object detection and tracking, are all on display already here.</div><br/></div></div><div id="37893127" class="c"><input type="checkbox" id="c-37893127" checked=""/><div class="controls bullet"><span class="by">tonmoy</span><span>|</span><a href="#37893019">parent</a><span>|</span><a href="#37893109">prev</a><span>|</span><a href="#37893935">next</a><span>|</span><label class="collapse" for="c-37893127">[-]</label><label class="expand" for="c-37893127">[4 more]</label></div><br/><div class="children"><div class="content">You can ask GPT-4 for bounding box of each object in json format and it’ll give it to you. Don’t know if there is understanding, but it is definitely useful</div><br/><div id="37893316" class="c"><input type="checkbox" id="c-37893316" checked=""/><div class="controls bullet"><span class="by">KRAKRISMOTT</span><span>|</span><a href="#37893019">root</a><span>|</span><a href="#37893127">parent</a><span>|</span><a href="#37893935">next</a><span>|</span><label class="collapse" for="c-37893316">[-]</label><label class="expand" for="c-37893316">[3 more]</label></div><br/><div class="children"><div class="content">How does it work? Does the encoder specifically pass the bounding box coordinates to the rest of the network as part of the embeddings?</div><br/><div id="37893349" class="c"><input type="checkbox" id="c-37893349" checked=""/><div class="controls bullet"><span class="by">Hidios</span><span>|</span><a href="#37893019">root</a><span>|</span><a href="#37893316">parent</a><span>|</span><a href="#37893928">next</a><span>|</span><label class="collapse" for="c-37893349">[-]</label><label class="expand" for="c-37893349">[1 more]</label></div><br/><div class="children"><div class="content">We don&#x27;t understand how they work. We know how to make them, but much like the human brain, the very low level workings are beyond our understanding.<p>Broadly it can be said that LLMs work by reducing uncertainty. Interestingly, human consciousness is also theorized by some to work the same way, react to the input in ways to reduce uncertainty.</div><br/></div></div><div id="37893928" class="c"><input type="checkbox" id="c-37893928" checked=""/><div class="controls bullet"><span class="by">tonmoy</span><span>|</span><a href="#37893019">root</a><span>|</span><a href="#37893316">parent</a><span>|</span><a href="#37893349">prev</a><span>|</span><a href="#37893935">next</a><span>|</span><label class="collapse" for="c-37893928">[-]</label><label class="expand" for="c-37893928">[1 more]</label></div><br/><div class="children"><div class="content">Internally that is probably something similar that is happening, but as far as I can tell it was never designed to specifically do that. Here is an example of the things GPT-4V is capable of: <a href="https:&#x2F;&#x2F;blog.roboflow.com&#x2F;gpt-4-vision&#x2F;amp&#x2F;">https:&#x2F;&#x2F;blog.roboflow.com&#x2F;gpt-4-vision&#x2F;amp&#x2F;</a></div><br/></div></div></div></div></div></div><div id="37893935" class="c"><input type="checkbox" id="c-37893935" checked=""/><div class="controls bullet"><span class="by">moffkalast</span><span>|</span><a href="#37893019">parent</a><span>|</span><a href="#37893127">prev</a><span>|</span><a href="#37894259">next</a><span>|</span><label class="collapse" for="c-37893935">[-]</label><label class="expand" for="c-37893935">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a bit slow for now, but yes end-to-end LMM systems will surely replace all classic general purpose robotic approaches eventually.</div><br/></div></div><div id="37894259" class="c"><input type="checkbox" id="c-37894259" checked=""/><div class="controls bullet"><span class="by">polygamous_bat</span><span>|</span><a href="#37893019">parent</a><span>|</span><a href="#37893935">prev</a><span>|</span><a href="#37893082">next</a><span>|</span><label class="collapse" for="c-37894259">[-]</label><label class="expand" for="c-37894259">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Could GPT-4V be used for robotic applications?<p>I have a quote I like in this context, “Could you learn gymnastics just from watching videos?” However intelligent an internet trained model may be, I strongly believe you have to have some interaction with the real world to learn more complicated actions. So far, Pick and place, is all that’s been shown with the bigger models, so my hypothesis seems to be holding for now.</div><br/><div id="37894724" class="c"><input type="checkbox" id="c-37894724" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#37893019">root</a><span>|</span><a href="#37894259">parent</a><span>|</span><a href="#37894746">next</a><span>|</span><label class="collapse" for="c-37894724">[-]</label><label class="expand" for="c-37894724">[1 more]</label></div><br/><div class="children"><div class="content">Pick and place isn&#x27;t all you can do by any stretch.<p><a href="https:&#x2F;&#x2F;general-pattern-machines.github.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;general-pattern-machines.github.io&#x2F;</a><p><a href="https:&#x2F;&#x2F;wayve.ai&#x2F;thinking&#x2F;lingo-natural-language-autonomous-driving&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;wayve.ai&#x2F;thinking&#x2F;lingo-natural-language-autonomous-...</a><p>It&#x27;s just the straightforward application.<p>&gt;I have a quote I like in this context, “Could you learn gymnastics just from watching videos?”<p>It&#x27;s not like language models learn by some sort of magic osmosis. They&#x27;re not just &quot;reading&quot; text or &quot;watching&quot; images. They learn by predicting, failing and adjusting neurons based on the data. Text is their world and they <i>are</i> interacting with it.</div><br/></div></div></div></div></div></div><div id="37893082" class="c"><input type="checkbox" id="c-37893082" checked=""/><div class="controls bullet"><span class="by">sgt101</span><span>|</span><a href="#37893019">prev</a><span>|</span><a href="#37895179">next</a><span>|</span><label class="collapse" for="c-37893082">[-]</label><label class="expand" for="c-37893082">[3 more]</label></div><br/><div class="children"><div class="content">Do you think that these images were in the GPT4 training set?<p>maybe...</div><br/><div id="37893117" class="c"><input type="checkbox" id="c-37893117" checked=""/><div class="controls bullet"><span class="by">kjander79</span><span>|</span><a href="#37893082">parent</a><span>|</span><a href="#37893093">next</a><span>|</span><label class="collapse" for="c-37893117">[-]</label><label class="expand" for="c-37893117">[1 more]</label></div><br/><div class="children"><div class="content">Actually that&#x27;s an interesting point, since the images are already in use in the article this one is responding to. It seems likely.</div><br/></div></div><div id="37893093" class="c"><input type="checkbox" id="c-37893093" checked=""/><div class="controls bullet"><span class="by">sgt101</span><span>|</span><a href="#37893082">parent</a><span>|</span><a href="#37893117">prev</a><span>|</span><a href="#37895179">next</a><span>|</span><label class="collapse" for="c-37893093">[-]</label><label class="expand" for="c-37893093">[1 more]</label></div><br/><div class="children"><div class="content">honestly, what sort of internal model of ML and AI do people who write blogs lik e this have?</div><br/></div></div></div></div><div id="37895179" class="c"><input type="checkbox" id="c-37895179" checked=""/><div class="controls bullet"><span class="by">jccalhoun</span><span>|</span><a href="#37893082">prev</a><span>|</span><a href="#37893320">next</a><span>|</span><label class="collapse" for="c-37895179">[-]</label><label class="expand" for="c-37895179">[2 more]</label></div><br/><div class="children"><div class="content">As a college professor the descriptions from ChatGPT remind me a lot of freshmen writing: they are often flailing around on extraneous details and have difficulty determining what is and isn&#x27;t important.<p>It will be interesting to see how it improves.</div><br/><div id="37895457" class="c"><input type="checkbox" id="c-37895457" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#37895179">parent</a><span>|</span><a href="#37893320">next</a><span>|</span><label class="collapse" for="c-37895457">[-]</label><label class="expand" for="c-37895457">[1 more]</label></div><br/><div class="children"><div class="content">GPT-4 in the web UI defaults to trying to describe the image very tentatively and in general, and it seems intentional: doing that improves performance if you&#x27;re expecting follow up questions similarly to chain of thought.<p>I expect the API with low temperature will be much more decisive in describing images</div><br/></div></div></div></div><div id="37893320" class="c"><input type="checkbox" id="c-37893320" checked=""/><div class="controls bullet"><span class="by">Animats</span><span>|</span><a href="#37895179">prev</a><span>|</span><a href="#37894423">next</a><span>|</span><label class="collapse" for="c-37893320">[-]</label><label class="expand" for="c-37893320">[3 more]</label></div><br/><div class="children"><div class="content">Indeed, there has been much progress.<p>The next big fundamental problem is &quot;hallucination&quot;, or being totally wrong without detecting it.</div><br/><div id="37893527" class="c"><input type="checkbox" id="c-37893527" checked=""/><div class="controls bullet"><span class="by">greatpostman</span><span>|</span><a href="#37893320">parent</a><span>|</span><a href="#37893372">next</a><span>|</span><label class="collapse" for="c-37893527">[-]</label><label class="expand" for="c-37893527">[1 more]</label></div><br/><div class="children"><div class="content">The hallucinations are what allow for the intelligence. It’s a feature not a bug</div><br/></div></div><div id="37893372" class="c"><input type="checkbox" id="c-37893372" checked=""/><div class="controls bullet"><span class="by">konschubert</span><span>|</span><a href="#37893320">parent</a><span>|</span><a href="#37893527">prev</a><span>|</span><a href="#37894423">next</a><span>|</span><label class="collapse" for="c-37893372">[-]</label><label class="expand" for="c-37893372">[1 more]</label></div><br/><div class="children"><div class="content">Same problem with human brains.</div><br/></div></div></div></div><div id="37894423" class="c"><input type="checkbox" id="c-37894423" checked=""/><div class="controls bullet"><span class="by">drewcoo</span><span>|</span><a href="#37893320">prev</a><span>|</span><label class="collapse" for="c-37894423">[-]</label><label class="expand" for="c-37894423">[1 more]</label></div><br/><div class="children"><div class="content">So it draws pictures like a grade school boy, a human whose &quot;training set&quot; involves TV and movies.<p>For seven years that doesn&#x27;t seem unreasonable.</div><br/></div></div></div></div></div></div></div></body></html>