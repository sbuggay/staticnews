<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700989258610" as="style"/><link rel="stylesheet" href="styles.css?v=1700989258610"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://economicsfromthetopdown.com/2022/04/08/the-dunning-kruger-effect-is-autocorrelation/">The Dunning-Kruger effect is autocorrelation</a> <span class="domain">(<a href="https://economicsfromthetopdown.com">economicsfromthetopdown.com</a>)</span></div><div class="subtext"><span>ljosifov</span> | <span>120 comments</span></div><br/><div><div id="38416100" class="c"><input type="checkbox" id="c-38416100" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#38416412">next</a><span>|</span><label class="collapse" for="c-38416100">[-]</label><label class="expand" for="c-38416100">[47 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t buy this take, and this rebuttal does a better job than I could of explaining why: <a href="https:&#x2F;&#x2F;andersource.dev&#x2F;2022&#x2F;04&#x2F;19&#x2F;dk-autocorrelation.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;andersource.dev&#x2F;2022&#x2F;04&#x2F;19&#x2F;dk-autocorrelation.html</a><p>Basically, this autocorrelation take shows that if performance and evaluation of performance were random and independent, you would get a graph like the D-K one, and therefore it states that the effect is just autocorrelation. But in reality, it would be very surprising if performance and evaluation of performance were independent. We expect people to be able to accurately rate their own ability. And D-K did indeed show a correlation between the two, just not as strong of one as we would expect. Rather, they showed a consistent bias. That&#x27;s the interesting result. They then posit reasons for this. One could certainly debate those reasons. But to say the whole effect is just a statistical artifact because random, independent variables would act in a similar way ignores the fact that these variables aren&#x27;t expected to be independent.</div><br/><div id="38416964" class="c"><input type="checkbox" id="c-38416964" checked=""/><div class="controls bullet"><span class="by">crazygringo</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38417571">next</a><span>|</span><label class="collapse" for="c-38416964">[-]</label><label class="expand" for="c-38416964">[5 more]</label></div><br/><div class="children"><div class="content">Yup. Assuming the sample sizes are statistically significant, the original paper clearly shows:<p>- On average, people estimate their ability around the 65th percentile (actual results) rather than the 50th (simulated random results) -- a significant difference<p>- That people&#x27;s self-estimation <i>increases with their actual ability</i>, but only by a surprisingly small degree (actual results show a slight upwards trend, simulated random results are flat) -- another significant difference<p>The author&#x27;s entire discussion of &quot;autocorrelation&quot; is a red herring that has nothing to do with anything. Their randomly-generated results do <i>not</i> match what the original paper shows.<p>None of this really sheds much light on to what degree the results can be or have been robustly replicated, of course. But there&#x27;s nothing inherently problematic whatsoever about the way it&#x27;s visualized. (It would be nice to see bars for variance, though.)</div><br/><div id="38419139" class="c"><input type="checkbox" id="c-38419139" checked=""/><div class="controls bullet"><span class="by">cortesoft</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416964">parent</a><span>|</span><a href="#38418511">next</a><span>|</span><label class="collapse" for="c-38419139">[-]</label><label class="expand" for="c-38419139">[3 more]</label></div><br/><div class="children"><div class="content">&gt; That people&#x27;s self-estimation increases with their actual ability, but only by a surprisingly small degree (actual results show a slight upwards trend, simulated random results are flat) -- another significant difference<p>If everyone thinks they are slightly above average, isn&#x27;t this inevitable? If everyone thinks they are slightly above average, people who are slightly above average are going to be the most accurate at predicting where they land?</div><br/><div id="38420099" class="c"><input type="checkbox" id="c-38420099" checked=""/><div class="controls bullet"><span class="by">IanCal</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38419139">parent</a><span>|</span><a href="#38419424">next</a><span>|</span><label class="collapse" for="c-38420099">[-]</label><label class="expand" for="c-38420099">[1 more]</label></div><br/><div class="children"><div class="content">Yes but then you&#x27;d see a flat line for people&#x27;s estimates, which wasn&#x27;t the result.</div><br/></div></div><div id="38419424" class="c"><input type="checkbox" id="c-38419424" checked=""/><div class="controls bullet"><span class="by">zuminator</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38419139">parent</a><span>|</span><a href="#38420099">prev</a><span>|</span><a href="#38418511">next</a><span>|</span><label class="collapse" for="c-38419424">[-]</label><label class="expand" for="c-38419424">[1 more]</label></div><br/><div class="children"><div class="content">Even if &quot;people tend to slightly overrate their own ability,&quot; was the only takeaway, it would still refute the author&#x27;s conclusion that DK has nothing to do with human psychology.</div><br/></div></div></div></div><div id="38418511" class="c"><input type="checkbox" id="c-38418511" checked=""/><div class="controls bullet"><span class="by">ketozhang</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416964">parent</a><span>|</span><a href="#38419139">prev</a><span>|</span><a href="#38417571">next</a><span>|</span><label class="collapse" for="c-38418511">[-]</label><label class="expand" for="c-38418511">[1 more]</label></div><br/><div class="children"><div class="content">The autocorrelation is important to show that it&#x27;s transformation to D-K plot will always give you the D-K affect for independent variables.<p>However, the focus on autocorrelation is not very illuminating. We can explain the behaviors found quite easily:<p>- If everyone&#x27;s self-assessment score are (uniformally) random guesses, then the average self-assessment score for any quantile is 50%. Then of course those of lower quantile (less skilled) are overestimating.<p>- If self-assessment score vs actual score are dependent proportionally, then the average of each quantile is always at least it&#x27;s quantile value. This is the D-K effect, which is weaker as the correlation grows.<p>-The opposite is true for disproportional relation.<p>So, the D-K plot is extremely sensitive to correlations and can easily over-exaggerate the weakest of correlations.</div><br/></div></div></div></div><div id="38417571" class="c"><input type="checkbox" id="c-38417571" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38416964">prev</a><span>|</span><a href="#38416264">next</a><span>|</span><label class="collapse" for="c-38417571">[-]</label><label class="expand" for="c-38417571">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  And D-K did indeed show a correlation between the two, just not as strong of one as we would expect. Rather, they showed a consistent bias. That&#x27;s the interesting result.<p>&quot;D-K effect in its original form&quot; vs &quot;D-K effect in pop culture&quot; is the biggest D-K effect live example. Of course I mean D-K effect in pop culture here.<p>Interestingly, the &quot;interesting&quot; part of the original result is that the correlation between actual performance and perceived performance is less than people intuitively think.<p>But as the &quot;D-K effect in pop culture&quot; spreads, people&#x27;s collective intuition changes. Today if you explained the original D-K effect to a random person on the internet, they might find it interesting because the correlation is <i>greater</i> than they thought: they thought the correlation would be negative!</div><br/><div id="38417589" class="c"><input type="checkbox" id="c-38417589" checked=""/><div class="controls bullet"><span class="by">hoosieree</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417571">parent</a><span>|</span><a href="#38416264">next</a><span>|</span><label class="collapse" for="c-38417589">[-]</label><label class="expand" for="c-38417589">[1 more]</label></div><br/><div class="children"><div class="content">D-K effect effect is almost as entertaining as the Butterfly effect effect[1].<p>[1]: Which is the far-away effect attributed to having watched the movie The Butterfly Effect.</div><br/></div></div></div></div><div id="38416264" class="c"><input type="checkbox" id="c-38416264" checked=""/><div class="controls bullet"><span class="by">svnt</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38417571">prev</a><span>|</span><a href="#38416567">next</a><span>|</span><label class="collapse" for="c-38416264">[-]</label><label class="expand" for="c-38416264">[7 more]</label></div><br/><div class="children"><div class="content">The author of this assumes the conclusion in order to decide how to analyze his data.<p>He cannot reasonably say both:<p>&gt; we have a decision to make: what are we going to assume? How are we going to quantify our surprise from the results?<p>&gt; The first option is, as in the case of the state census, to assume dependence between X and Y. I.e. to assume that, generally, people are capable of self-assessing their performance.<p>&gt; The second option conforms with the Research Methods 101 rule-of-thumb “always assume independence.” Until proven otherwise, we should assume people have no ability to self-assess their performance.<p>&gt; It seems to me glaringly obvious that the first option is much, much more reasonable than the second.<p>— and -<p>&gt; most notably the claim that the more skilled people are, the better they are at self-assessing their performance. This result is supported by their plot, but in any case, my issue is not with objections to this claim<p>and then expect to carry any credibility.<p>The author of this piece both suggests that a key variable  is fixed and later admits it varies within the same dataset.<p>I guess at least they admit it, but this lacks basic self-consistency.</div><br/><div id="38418495" class="c"><input type="checkbox" id="c-38418495" checked=""/><div class="controls bullet"><span class="by">contravariant</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416264">parent</a><span>|</span><a href="#38416617">next</a><span>|</span><label class="collapse" for="c-38418495">[-]</label><label class="expand" for="c-38418495">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m utterly confused. The latter statements it just the author explaining which parts they didn&#x27;t discuss in their article; it has no bearing whatsoever on the section before it.</div><br/></div></div><div id="38416617" class="c"><input type="checkbox" id="c-38416617" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416264">parent</a><span>|</span><a href="#38418495">prev</a><span>|</span><a href="#38416567">next</a><span>|</span><label class="collapse" for="c-38416617">[-]</label><label class="expand" for="c-38416617">[5 more]</label></div><br/><div class="children"><div class="content">&gt; The author of this piece both suggests that a key variable is fixed and later admits it varies within the same dataset.<p>I don&#x27;t see how that variable changes, here is an example how the error variable can be exactly the same for everyone and reproduce the results:<p>Lets say the overconfidence is always that you feel 50% of those better than you are actually worse than you. So everyone is equally overconfident, just that the top wont move their own placings as much as the bottom since there are much fewer people that they can mistake being worse than them. Then apply noise to this and you get the graph Dunning-Kruger got.<p>You could say &quot;But they are better at estimating their rank!&quot;, but that is just a mathematical artefact, it isn&#x27;t a psychological result. Even if everyone always guessed that they are number 1, the better you are the better your guess will be, but in that case it is easy to see that everyone overestimates their skill in the same way instead of the better people having a fundamentally different way of evaluating themselves.</div><br/><div id="38418130" class="c"><input type="checkbox" id="c-38418130" checked=""/><div class="controls bullet"><span class="by">svnt</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416617">parent</a><span>|</span><a href="#38417655">next</a><span>|</span><label class="collapse" for="c-38418130">[-]</label><label class="expand" for="c-38418130">[2 more]</label></div><br/><div class="children"><div class="content">Both analyses seem to agree on one finding: people’s skill at estimating their own ability increases with that skill. It can’t be a purely mathematical artifact because you would see a tapering at either end, or a narrowing distribution of errors at the bottom end, not just a narrowing toward the top end.<p>This should be unsurprising for anyone who has become sufficiently skilled at something. Beginners can’t even discern the differences the experts are discussing, and frequently make errors in classes they don’t even understand.</div><br/><div id="38418602" class="c"><input type="checkbox" id="c-38418602" checked=""/><div class="controls bullet"><span class="by">chiefalchemist</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38418130">parent</a><span>|</span><a href="#38417655">next</a><span>|</span><label class="collapse" for="c-38418602">[-]</label><label class="expand" for="c-38418602">[1 more]</label></div><br/><div class="children"><div class="content">Beginners, by definition, are guessing 100%. Some will guess high, others low, and the rest in between. But they are all guessing. Perhaps There&#x27;s a cultural bias to over-estimate their skill? Perhaps there&#x27;s a nudge in the process of the study that led them to overestimate?<p>The lede isn&#x27;t that people over-estimate their skill level. The lede is, why would that be as they have nothing else to go on. That is the trigger or triggers? And to say, the more experienced estimate better? Well, duh.</div><br/></div></div></div></div><div id="38417655" class="c"><input type="checkbox" id="c-38417655" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416617">parent</a><span>|</span><a href="#38418130">prev</a><span>|</span><a href="#38416567">next</a><span>|</span><label class="collapse" for="c-38417655">[-]</label><label class="expand" for="c-38417655">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Lets say the overconfidence is always that you feel 50% of those better than you are actually worse than you. So everyone is equally overconfident, just that the top wont move their own placings as much as the bottom since there are much fewer people that they can mistake being worse than them. Then apply noise to this and you get the graph Dunning-Kruger got.<p>But the data of original D-K paper shows that the top 25% people <i>underestimate</i> their placings. So this whole paragraph, while logically true, has little to do with the original D-K effect.<p>&gt; You could say &quot;But they are better at estimating their rank!&quot;, but that is just a mathematical artefact, it isn&#x27;t a psychological result. Even if everyone always guessed that they are number 1...<p>If everyone always guessed that they are number 1, it&#x27;s a huge psychological result: it means people are extremely irrational when it comes to self-evaluation.</div><br/><div id="38418062" class="c"><input type="checkbox" id="c-38418062" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417655">parent</a><span>|</span><a href="#38416567">next</a><span>|</span><label class="collapse" for="c-38418062">[-]</label><label class="expand" for="c-38418062">[1 more]</label></div><br/><div class="children"><div class="content">&gt; But the data of original D-K paper shows that the top 25% people underestimate their placings. So this whole paragraph, while logically true, has little to do with the original D-K effect.<p>That is what you would expect under my model, due to the randomness being limited upwards for the high placings but still go downwards. That is the effect the article we are talking about refers to when they say &quot;Autocorrelation&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="38416567" class="c"><input type="checkbox" id="c-38416567" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38416264">prev</a><span>|</span><a href="#38418980">next</a><span>|</span><label class="collapse" for="c-38416567">[-]</label><label class="expand" for="c-38416567">[4 more]</label></div><br/><div class="children"><div class="content">The issue is people have differing personal definitions of Dunning Kruger. The generally demonstrated effect in the sample  of people Dunning and Kruger analyzed was &quot;people tend to estimate the percentile of their own skill as closer to the average than it really is, with a slight bias towards an above-average mean. This leads to overestimation of relative ability by those in lower percentiles, and the opposite for those in higher percentiles&quot;<p>However when people cite Dunning Kruger in popular culture they mean &quot;below average people think they&#x27;re above average, and above average people assume they&#x27;re below average&quot;, which was not shown in the original study, and wouldn&#x27;t show up in an analysis attempting to justify it via a misunderstanding of autocorrelation.<p>The general point in the rebuttal is correct. A completely noisy graph of people&#x27;s estimations of their own ability would show a Dunning-Kruger resembling residual graph (x-y vs x). However, one wouldn&#x27;t expect people in the 1st percentile to have an equal distribution of perceived skill as people in the 50th or 99th percentile. If that were true, it would be worth reporting.</div><br/><div id="38416980" class="c"><input type="checkbox" id="c-38416980" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416567">parent</a><span>|</span><a href="#38418980">next</a><span>|</span><label class="collapse" for="c-38416980">[-]</label><label class="expand" for="c-38416980">[3 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;below average people think they&#x27;re above average, and above average people assume they&#x27;re below average&quot;<p>There’s no way to know if you’re wrong, but when I see it used it seems to be pointing out - “some (not all) under qualified people tend to defer to their own beliefs rather than the views&#x2F;statements from experts, even when that is demonstrably silly.”<p>^ Referring to the pop-sci interpretation, not in disagreement with the general point.</div><br/><div id="38417226" class="c"><input type="checkbox" id="c-38417226" checked=""/><div class="controls bullet"><span class="by">staunton</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416980">parent</a><span>|</span><a href="#38418980">next</a><span>|</span><label class="collapse" for="c-38417226">[-]</label><label class="expand" for="c-38417226">[2 more]</label></div><br/><div class="children"><div class="content">Which also has nothing at all to do with this study by Dunning and Kruger. So you agree with the general point of parent.</div><br/><div id="38417272" class="c"><input type="checkbox" id="c-38417272" checked=""/><div class="controls bullet"><span class="by">ShamelessC</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417226">parent</a><span>|</span><a href="#38418980">next</a><span>|</span><label class="collapse" for="c-38417272">[-]</label><label class="expand" for="c-38417272">[1 more]</label></div><br/><div class="children"><div class="content">Yes. Just clarifying a small disagreement about the pop-sci interpretation of the phrase.</div><br/></div></div></div></div></div></div></div></div><div id="38418980" class="c"><input type="checkbox" id="c-38418980" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38416567">prev</a><span>|</span><a href="#38419793">next</a><span>|</span><label class="collapse" for="c-38418980">[-]</label><label class="expand" for="c-38418980">[2 more]</label></div><br/><div class="children"><div class="content">The rebuttal by Daniel (andersource.dev) is useful, generally. However, when he writes ...<p>&gt; The history of statistics is well out of scope for this post, but very succinctly, my answer is that statistics is an attempt to objectively quantify surprise.<p>... I cannot agree. Statistics is not this; it is much broader. One may or may not be surprised by particular statistics, sure, but there are _specific_ concepts that map more directly to surprise, such as entropy from information theory.</div><br/><div id="38420127" class="c"><input type="checkbox" id="c-38420127" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38418980">parent</a><span>|</span><a href="#38419793">next</a><span>|</span><label class="collapse" for="c-38420127">[-]</label><label class="expand" for="c-38420127">[1 more]</label></div><br/><div class="children"><div class="content">If entropy is defined as statistical disorder than I think the definition of &quot;quantifying surprise&quot; is great.</div><br/></div></div></div></div><div id="38419793" class="c"><input type="checkbox" id="c-38419793" checked=""/><div class="controls bullet"><span class="by">bradley13</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38418980">prev</a><span>|</span><a href="#38417530">next</a><span>|</span><label class="collapse" for="c-38419793">[-]</label><label class="expand" for="c-38419793">[2 more]</label></div><br/><div class="children"><div class="content">I have to agree. You cannot separate the statistical analysis from the <i>meaning</i> of the study. In the article, the author&#x27;s random data is <i>exactly</i> an extreme replication of Dunning-Kruger. Why? Because, in his random data, people with low test scores almost always overestimate their ability, while people with high test scores almost always underestimate.<p>That is precisely the premise of the Dunning-Kruger effect. The fact that the original Dunning-Kruger paper shows a less extreme effect? That just shows that people are slightly better than random at estimating their own abilities - but still nowhere accurate.</div><br/><div id="38420060" class="c"><input type="checkbox" id="c-38420060" checked=""/><div class="controls bullet"><span class="by">jgilias</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38419793">parent</a><span>|</span><a href="#38417530">next</a><span>|</span><label class="collapse" for="c-38420060">[-]</label><label class="expand" for="c-38420060">[1 more]</label></div><br/><div class="children"><div class="content">So that’s what the Dunning-Kruger effect basically boils down to, right? That people in general are just bad at assessing their skills.</div><br/></div></div></div></div><div id="38417530" class="c"><input type="checkbox" id="c-38417530" checked=""/><div class="controls bullet"><span class="by">t_mann</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38419793">prev</a><span>|</span><a href="#38418986">next</a><span>|</span><label class="collapse" for="c-38417530">[-]</label><label class="expand" for="c-38417530">[10 more]</label></div><br/><div class="children"><div class="content">I was surprised by the figure from the original article, imho that&#x27;s the strongest rebuttal: perceived ability grows strictly mononotonically with actual ability, no sign of the famous non-monotonic U-curve. Yeah, the slope is less than one, and it grows a bit faster from the second to the third quartile than from the first to the second, but none of that changes the fact that people tend to slot themselves correctly. The chart is interesting in that it confirms that everyone perceives themselves to be slightly above average in terms of ability, which of course can&#x27;t be true in practice. But what it also shows is that when they think they&#x27;ll be below or above that (false) baseline, they&#x27;re actually correct about it. So pretty much the exact opposite of what the Dunning-Kruger effect claims.</div><br/><div id="38417742" class="c"><input type="checkbox" id="c-38417742" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417530">parent</a><span>|</span><a href="#38417622">next</a><span>|</span><label class="collapse" for="c-38417742">[-]</label><label class="expand" for="c-38417742">[5 more]</label></div><br/><div class="children"><div class="content">&gt; The chart is interesting in that it confirms that everyone perceives themselves to be slightly above average in terms of ability, which of course can&#x27;t be true in practice.<p>No, everyone biases their self-assessments <i>toward</i> a point slightly above the mean. That&#x27;s not the same as saying everyone thinks they&#x27;re slightly above average, nor that people&#x27;s self-assessments have no predictive power whatsoever. The lowest performers still think they&#x27;re below average, just not as much as they should. The highest performers still think they&#x27;re considerably above average. But they all have a bias toward (slightly above) the middle.<p>So yes, people are generally correct in the direction that they deviate from that median self-assessment, but that just shows that people&#x27;s self-assessments aren&#x27;t completely without basis. Which D-K certainly didn&#x27;t claim.</div><br/><div id="38417782" class="c"><input type="checkbox" id="c-38417782" checked=""/><div class="controls bullet"><span class="by">t_mann</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417742">parent</a><span>|</span><a href="#38418935">next</a><span>|</span><label class="collapse" for="c-38417782">[-]</label><label class="expand" for="c-38417782">[2 more]</label></div><br/><div class="children"><div class="content">D-K claim a non-monotonic relationship, which simply isn&#x27;t supported by that data, as you yourself point out: people rank themselves correctly (ordinally). I didn&#x27;t mean to say that all self-assessments are the same, if that was the misunderstanding. My point is that the self-assessments indeed are meaningful, even more so than D-K claim.</div><br/><div id="38418692" class="c"><input type="checkbox" id="c-38418692" checked=""/><div class="controls bullet"><span class="by">RevEng</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417782">parent</a><span>|</span><a href="#38418935">next</a><span>|</span><label class="collapse" for="c-38418692">[-]</label><label class="expand" for="c-38418692">[1 more]</label></div><br/><div class="children"><div class="content">Check the original paper by D-K. Fix only focused on the first plot which has a monotonically increasing trend. The later plots show varying degrees of nonmonotonicity, though sadly they don&#x27;t include error bars to indicate how statistically significant the differences between groups is.</div><br/></div></div></div></div><div id="38418935" class="c"><input type="checkbox" id="c-38418935" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417742">parent</a><span>|</span><a href="#38417782">prev</a><span>|</span><a href="#38417622">next</a><span>|</span><label class="collapse" for="c-38418935">[-]</label><label class="expand" for="c-38418935">[2 more]</label></div><br/><div class="children"><div class="content">But we don’t know their true ability, only the results on one test. It could be they accurately predicted their ability but because of random chance they did better&#x2F;worse than their guess. Then you would get the exact data that is observed.</div><br/><div id="38419405" class="c"><input type="checkbox" id="c-38419405" checked=""/><div class="controls bullet"><span class="by">lokar</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38418935">parent</a><span>|</span><a href="#38417622">next</a><span>|</span><label class="collapse" for="c-38419405">[-]</label><label class="expand" for="c-38419405">[1 more]</label></div><br/><div class="children"><div class="content">I thought they were estimating their performance on the test relative to others. There was no “real world” element.</div><br/></div></div></div></div></div></div><div id="38417622" class="c"><input type="checkbox" id="c-38417622" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417530">parent</a><span>|</span><a href="#38417742">prev</a><span>|</span><a href="#38418986">next</a><span>|</span><label class="collapse" for="c-38417622">[-]</label><label class="expand" for="c-38417622">[4 more]</label></div><br/><div class="children"><div class="content">The slope will be less than one if there&#x27;s e.g. any random guessing in the test even if the self-assesment is perfect (apart from whether they know if their guess is right or wrong of course) [1].<p>I think this is the effect that the post is dancing around, but doesn&#x27;t seem to really understand (and how &quot;autocorrelation&quot; and indepence are discussed is very nonstandard to be charitable).<p>[1] <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Regression_dilution" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Regression_dilution</a></div><br/><div id="38417743" class="c"><input type="checkbox" id="c-38417743" checked=""/><div class="controls bullet"><span class="by">t_mann</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417622">parent</a><span>|</span><a href="#38418986">next</a><span>|</span><label class="collapse" for="c-38417743">[-]</label><label class="expand" for="c-38417743">[3 more]</label></div><br/><div class="children"><div class="content">I agree, the statistical analysis in the original post makes me very uneasy. I think it could be a case where the conclusion is correct, even though argument isn&#x27;t necessarily.<p>And yes, the fact that the slope is less than one is fairly uninteresting.<p>The real problem here is that the Dunning-Kruger effect, as it&#x27;s classically stated, claims that if you asked four people to rank themselves in terms of ability, the result would be 1-3-2-4, ie the people who know a little would put themselves above the people who know a lot but aren&#x27;t quite experts. The problem is the data shows that they&#x27;d actually rank themselves correctly 1-2-3-4. But such a boring finding probably wouldn&#x27;t have made the authors quite as famous, which might be why they tried  bit of data mangling, and they found this really cool story that everyone would secretly love to be true.<p>Which is a shame, because I think the fact that the mean of perceived ability is too high (and the variance too low) is really interesting too, and perfectly supported by the raw data.</div><br/><div id="38417929" class="c"><input type="checkbox" id="c-38417929" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417743">parent</a><span>|</span><a href="#38418552">next</a><span>|</span><label class="collapse" for="c-38417929">[-]</label><label class="expand" for="c-38417929">[1 more]</label></div><br/><div class="children"><div class="content">Yes. The methodology in the original D&amp;K is quite shoddy, and vulnerable to e.g. good old regression to the mean, and the interpretations are too strong. This is sadly very common in psychology (and many other fields I&#x27;d guess) and even researchers don&#x27;t care so much if the story is juicy enough.<p>The pop version of the DK effect seems to be something like a 4-3-2-1 ranking, which is obviously not supported by the data.</div><br/></div></div><div id="38418552" class="c"><input type="checkbox" id="c-38418552" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417743">parent</a><span>|</span><a href="#38417929">prev</a><span>|</span><a href="#38418986">next</a><span>|</span><label class="collapse" for="c-38418552">[-]</label><label class="expand" for="c-38418552">[1 more]</label></div><br/><div class="children"><div class="content">But they wouldn&#x27;t. They&#x27;d rank themselves something like 1,2,2,3. We&#x27;re not dealing with a population collaborating to all rank themselves in order, but rather each person individually estimating where their abilities lie in the population.<p>The point is that if you ask someone in the, say, 5th percentile of ability what their ability is compared to the population, they might say 25th percentile. Ask someone at the 25th,and they might say 40th. At the 40th they could say 55th. And at the 90th, maybe they&#x27;ll say 80th. So yes, if you order their guesses, they will be in roughly the correct order. But, crucially, that doesn&#x27;t mean that they are ranking themselves correctly!</div><br/></div></div></div></div></div></div></div></div><div id="38418986" class="c"><input type="checkbox" id="c-38418986" checked=""/><div class="controls bullet"><span class="by">zeroonetwothree</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38417530">prev</a><span>|</span><a href="#38417883">next</a><span>|</span><label class="collapse" for="c-38418986">[-]</label><label class="expand" for="c-38418986">[1 more]</label></div><br/><div class="children"><div class="content">This rebuttal seems weak because it’s using unbounded datasets (population). A big issue with the DK research is using bounded data (test scores). For example if I get 100% right it’s mathematically impossible to have overestimated.</div><br/></div></div><div id="38417883" class="c"><input type="checkbox" id="c-38417883" checked=""/><div class="controls bullet"><span class="by">cool_dude85</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38418986">prev</a><span>|</span><a href="#38417811">next</a><span>|</span><label class="collapse" for="c-38417883">[-]</label><label class="expand" for="c-38417883">[2 more]</label></div><br/><div class="children"><div class="content">Yeah this must be some high end satire where the guy Dunning-Krugers up an explanation of Dunning-Kruger. Since even an economist is supposed to understand ANOVA I have to conclude that this article is a joke.</div><br/><div id="38418083" class="c"><input type="checkbox" id="c-38418083" checked=""/><div class="controls bullet"><span class="by">nickelpro</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417883">parent</a><span>|</span><a href="#38417811">next</a><span>|</span><label class="collapse" for="c-38418083">[-]</label><label class="expand" for="c-38418083">[1 more]</label></div><br/><div class="children"><div class="content">The incorrect usage of &quot;autocorrelation&quot; made me double take and wonder if this was satire the first time it was posted.</div><br/></div></div></div></div><div id="38417811" class="c"><input type="checkbox" id="c-38417811" checked=""/><div class="controls bullet"><span class="by">expazl</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38417883">prev</a><span>|</span><a href="#38417237">next</a><span>|</span><label class="collapse" for="c-38417811">[-]</label><label class="expand" for="c-38417811">[2 more]</label></div><br/><div class="children"><div class="content">&gt; But in reality, it would be very surprising if performance and evaluation of performance were independent. We expect people to be able to accurately rate their own ability.<p>This seems to be attacking an irrelevant point in the analysis. The argument goes as such: Researcher carries out all the studies needed to prove the Dunning-Kruger effect, then trips and drops all the results into a vat of acid. But he&#x27;s ashamed and quickly generates random numbers for the results, and somehow the data still proves the Dunning-Kruger effect. Not just that, repeating the same exercise again and again with completely random data leads to the same result, the effect is always present. So is the Dunning-kruger effect so powerful that it exists in the very fabric of the universe devoid of any human interaction, or is something amiss?<p>In this situation we are forced to look at the test we have that concluded from the data that the Dunning-Kruger effect exists and conclude that it&#x27;s a bad test, we need something different.<p>You seem to be arguing &quot;oh no, you can&#x27;t look at random data, because we wouldn&#x27;t expect the experiment to yield random data!&quot;. But that doesn&#x27;t work as an argument for why the test should still be considered good. If it&#x27;s supposed to have any worth, then the test has to be able to come to one of two conclusions: The Dunning-Kruger effect exists or the Dunning-Kruger effect doesn&#x27;t exist. And if the test is set up such that for positive experimental results, or just random noise, it comes out in the positive, and only in extremely unlikely and a narrow band of the possible outcome space come out negative, then the test is bad.<p>If we want to try to rephrase everything a bit to make the issue much clearer. Lets set up a coin-toss competition between ChatGPT and a group of 100 people. Each participant goes 1:1 against ChatGPT where both parties toss a coin and whoever has the most heads wins, on draws toss again, in case a pair goes into an infinite loop that doesn&#x27;t end before our allotted trial time, they get removed from the study. A human assistant tosses on the behalf of ChatGPT on account of it not having arms yet.<p>Now we ask each person how they would rate their ability vs. ChatGPT in a coin-toss, everyone answers 50&#x2F;50, for obvious reasons.<p>So we run the experiment, the line for &quot;ability plotted against ability&quot; is a straight diagonal line. The line for estimated ability vs actual ability is a a straight flat line at 50%.<p>Eureka! To the presses! we have just proven the Dunning-Coin-Kruger effect! People who are worse at throwing coins tend to over estimate their ability, and people who are better at throwing coins underestimate their ability! What a marvelous bit of psychological insight, it really tells us something about how the human mind works, and has broader insights about our society! But naturally we always expected this outcome, people who are bad a tossing coins are dumb and of cause they are overconfident, not like people who are good at tossing coins who have a remarkable Intellect about themselves and are therefore humble in their self estimation... and so on and on about preconceived biases that have nothing to do with the actual test we performed.</div><br/></div></div><div id="38417237" class="c"><input type="checkbox" id="c-38417237" checked=""/><div class="controls bullet"><span class="by">IAmGraydon</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38417811">prev</a><span>|</span><a href="#38416187">next</a><span>|</span><label class="collapse" for="c-38417237">[-]</label><label class="expand" for="c-38417237">[2 more]</label></div><br/><div class="children"><div class="content">So what we have here is some scientists trying to prove that the Dunning-Kruger effect doesn’t exist and instead they give us a perfect example of the Dunning-Kruger effect.</div><br/><div id="38417300" class="c"><input type="checkbox" id="c-38417300" checked=""/><div class="controls bullet"><span class="by">wyldfire</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38417237">parent</a><span>|</span><a href="#38416187">next</a><span>|</span><label class="collapse" for="c-38417300">[-]</label><label class="expand" for="c-38417300">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The irony is that the situation is actually reversed. In their seminal paper, Dunning and Kruger are the ones broadcasting their (statistical) incompetence by conflating autocorrelation for a psychological effect. In this light, the paper’s title may still be appropriate. It’s just that it was the authors (not the test subjects) who were ‘unskilled and unaware of it’.</div><br/></div></div></div></div><div id="38416187" class="c"><input type="checkbox" id="c-38416187" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#38416100">parent</a><span>|</span><a href="#38417237">prev</a><span>|</span><a href="#38419149">next</a><span>|</span><label class="collapse" for="c-38416187">[-]</label><label class="expand" for="c-38416187">[5 more]</label></div><br/><div class="children"><div class="content">The effect that the worst overestimate their skill is known since before, that wasn&#x27;t the main result of Dunning-Kruger. The effect that the best underestimate their skill can be chalked up to auto-correlation.</div><br/><div id="38416300" class="c"><input type="checkbox" id="c-38416300" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416187">parent</a><span>|</span><a href="#38419149">next</a><span>|</span><label class="collapse" for="c-38416300">[-]</label><label class="expand" for="c-38416300">[4 more]</label></div><br/><div class="children"><div class="content">The best don&#x27;t tend to overestimate their skill; they underestimate it. The D-K results show a consistent bias in estimates toward (somewhere near) the mean. Hence an overestimate at the bottom and an underestimate at the top.</div><br/><div id="38416311" class="c"><input type="checkbox" id="c-38416311" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416300">parent</a><span>|</span><a href="#38416476">next</a><span>|</span><label class="collapse" for="c-38416311">[-]</label><label class="expand" for="c-38416311">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The best don&#x27;t tend to overestimate their skill; they underestimate<p>I wrote the wrong word, I fixed it. The best can&#x27;t overestimate their rank, so of course that wasn&#x27;t what I meant.</div><br/></div></div><div id="38416476" class="c"><input type="checkbox" id="c-38416476" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416300">parent</a><span>|</span><a href="#38416311">prev</a><span>|</span><a href="#38419149">next</a><span>|</span><label class="collapse" for="c-38416476">[-]</label><label class="expand" for="c-38416476">[2 more]</label></div><br/><div class="children"><div class="content">Dunning-Kruger posits this as a psychological effect, yes? On the top half psychological effects such as imposter syndrome could come in to play.<p>Have sociological factors such as being kind or big fish little pond been considered as likely causes of the misestimates?</div><br/><div id="38418657" class="c"><input type="checkbox" id="c-38418657" checked=""/><div class="controls bullet"><span class="by">chiefalchemist</span><span>|</span><a href="#38416100">root</a><span>|</span><a href="#38416476">parent</a><span>|</span><a href="#38419149">next</a><span>|</span><label class="collapse" for="c-38418657">[-]</label><label class="expand" for="c-38418657">[1 more]</label></div><br/><div class="children"><div class="content">I have the same question...why do some get it so wrong? Was there a nudge in the process of the study that caused some to answer what they did?<p>Heck, I&#x27;m wondering if &quot;Honestly, I can&#x27;t say&quot; was an allowed response. Or were they forced to pick a number? If so, then I&#x27;d want to know what happens when you ask 100 ppl to pick a number between 0 and 100. I bet it&#x27;s not evenly distributed. Maybe the beginners give a &quot;discounted&quot; version of the distribution?<p>Even if the autocorrection explanation is off, there does now seem to be flaws in DK, at least from the perspective of pure and proper science</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38416412" class="c"><input type="checkbox" id="c-38416412" checked=""/><div class="controls bullet"><span class="by">bitshiftfaced</span><span>|</span><a href="#38416100">prev</a><span>|</span><a href="#38416285">next</a><span>|</span><label class="collapse" for="c-38416412">[-]</label><label class="expand" for="c-38416412">[14 more]</label></div><br/><div class="children"><div class="content">The authors did &quot;X - Y vs X,&quot; but that&#x27;s not even the biggest problem. The authors subtracted two measures that had been transformed and bounded from 0 to 1 (think percentiles). What happens at the extremes of those bounds? How much can your top performers overestimate their performance? They&#x27;re almost at 1 already, so not much. If they were to overestimate and underestimate at the same rate and by the same magnitude in terms of raw values, the ceiling effect on the transformed values means that the graph will make it look like they underestimate more often. The opposite problem happens for the worst performers.<p>See &quot;Random Number Simulations Reveal How Random Noise Affects the Measurements and Graphical Portrayals of Self-Assessed Competency.&quot; Numeracy 9, Iss. 1 (2016), particularly figures 7, 8, and 9.</div><br/><div id="38417205" class="c"><input type="checkbox" id="c-38417205" checked=""/><div class="controls bullet"><span class="by">SamBam</span><span>|</span><a href="#38416412">parent</a><span>|</span><a href="#38416672">next</a><span>|</span><label class="collapse" for="c-38417205">[-]</label><label class="expand" for="c-38417205">[5 more]</label></div><br/><div class="children"><div class="content">Exactly, that was my thought. How would it be <i>possible</i> to get anything other than the D-K effect, even if it wasn&#x27;t just averaging to the mean?<p>The lowest quartile can&#x27;t say they&#x27;re below the lowest quartile, so any error at all will be counted as &quot;overconfidence.&quot; The top quartile can&#x27;t say they&#x27;re above the top quartile, so any error at all will be counted as &quot;underconfidance.&quot;</div><br/><div id="38418341" class="c"><input type="checkbox" id="c-38418341" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38416412">root</a><span>|</span><a href="#38417205">parent</a><span>|</span><a href="#38419021">next</a><span>|</span><label class="collapse" for="c-38418341">[-]</label><label class="expand" for="c-38418341">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Exactly, that was my thought. How would it be possible to get anything other than the D-K effect, even if it wasn&#x27;t just averaging to the mean?<p>Quite easily with the method they demonstrate in the study in figure 11. In that study test participants are not rating themselves in terms of population percentages, but in terms of the percentage correct they got on the test. In such a case the test could be designed to have a huge ceiling that even the most knowledgeable participants would have trouble reaching. And could have such a low floor that even the least knowledgeable participants would still get some answers correct (unless they weren&#x27;t even trying, which would allow throwing out their data points).<p>With 20 questions you could have four gimmes and four impossible questions, bounding the worst participants to about 20% and the best to about 80%.</div><br/><div id="38418731" class="c"><input type="checkbox" id="c-38418731" checked=""/><div class="controls bullet"><span class="by">SamBam</span><span>|</span><a href="#38416412">root</a><span>|</span><a href="#38418341">parent</a><span>|</span><a href="#38419021">next</a><span>|</span><label class="collapse" for="c-38418731">[-]</label><label class="expand" for="c-38418731">[2 more]</label></div><br/><div class="children"><div class="content">Right. To clarify, I meant: with the original study design, how could they not have gotten the result they did? (And that&#x27;s rhetorical.)</div><br/><div id="38418766" class="c"><input type="checkbox" id="c-38418766" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38416412">root</a><span>|</span><a href="#38418731">parent</a><span>|</span><a href="#38419021">next</a><span>|</span><label class="collapse" for="c-38418766">[-]</label><label class="expand" for="c-38418766">[1 more]</label></div><br/><div class="children"><div class="content">It would have been noteworthy in the original design if more than one group of participants were, on average, within their quartiles on the guessing. I also find it noteworthy that the average guess of the lowest quartile is lower than the average guess of the second lowest quartile, and on up the quartiles. On one hand this shows some awareness of relative ability along a massively smooshed logarithmic scale. On the other hand I wonder if this laddering follows as the averages are split into quintiles and deciles.</div><br/></div></div></div></div></div></div><div id="38419021" class="c"><input type="checkbox" id="c-38419021" checked=""/><div class="controls bullet"><span class="by">jmpeax</span><span>|</span><a href="#38416412">root</a><span>|</span><a href="#38417205">parent</a><span>|</span><a href="#38418341">prev</a><span>|</span><a href="#38416672">next</a><span>|</span><label class="collapse" for="c-38419021">[-]</label><label class="expand" for="c-38419021">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if estimating on the logit scale would solve this problem.</div><br/></div></div></div></div><div id="38416672" class="c"><input type="checkbox" id="c-38416672" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38416412">parent</a><span>|</span><a href="#38417205">prev</a><span>|</span><a href="#38419163">next</a><span>|</span><label class="collapse" for="c-38416672">[-]</label><label class="expand" for="c-38416672">[1 more]</label></div><br/><div class="children"><div class="content">This can be dealt with to an extent by truncating the extreme ends. Even the middle quartiles in the graphs in the linked article show the same trends.</div><br/></div></div><div id="38419163" class="c"><input type="checkbox" id="c-38419163" checked=""/><div class="controls bullet"><span class="by">dimask</span><span>|</span><a href="#38416412">parent</a><span>|</span><a href="#38416672">prev</a><span>|</span><a href="#38416673">next</a><span>|</span><label class="collapse" for="c-38419163">[-]</label><label class="expand" for="c-38419163">[1 more]</label></div><br/><div class="children"><div class="content">The boundedness of the data is also the main argument here <a href="https:&#x2F;&#x2F;www.frontiersin.org&#x2F;articles&#x2F;10.3389&#x2F;fpsyg.2022.840180&#x2F;full" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.frontiersin.org&#x2F;articles&#x2F;10.3389&#x2F;fpsyg.2022.8401...</a></div><br/></div></div><div id="38416673" class="c"><input type="checkbox" id="c-38416673" checked=""/><div class="controls bullet"><span class="by">ImaCake</span><span>|</span><a href="#38416412">parent</a><span>|</span><a href="#38419163">prev</a><span>|</span><a href="#38416895">next</a><span>|</span><label class="collapse" for="c-38416673">[-]</label><label class="expand" for="c-38416673">[4 more]</label></div><br/><div class="children"><div class="content">Thanks for stating just how much of a statistical minefield this is. The reference does a great job showing just how wrong the DK studies are. Unfortunately, most people have already made up their minds and are happy to link conflicting blog posts as evidence.</div><br/><div id="38420143" class="c"><input type="checkbox" id="c-38420143" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38416412">root</a><span>|</span><a href="#38416673">parent</a><span>|</span><a href="#38417750">next</a><span>|</span><label class="collapse" for="c-38420143">[-]</label><label class="expand" for="c-38420143">[1 more]</label></div><br/><div class="children"><div class="content">&gt; wrong the DK studies are<p>The DK studies are not wrong, they are misinterpreted by people who don&#x27;t know what they&#x27;re talking about (e.g. what tge DK effect actually is), like this blogger.<p>&quot;People have worse self assessment ability as their real ability declines&quot; would be a valid interpretation of the DK data and notably would NOT be a valid conclusion from the random data in the blog post.</div><br/></div></div><div id="38417086" class="c"><input type="checkbox" id="c-38417086" checked=""/><div class="controls bullet"><span class="by">Probiotic6081</span><span>|</span><a href="#38416412">root</a><span>|</span><a href="#38416673">parent</a><span>|</span><a href="#38417750">prev</a><span>|</span><a href="#38416895">next</a><span>|</span><label class="collapse" for="c-38417086">[-]</label><label class="expand" for="c-38417086">[1 more]</label></div><br/><div class="children"><div class="content">Probably in another year or two they&#x27;ll find another statistic that will render the old one moot like again and again.</div><br/></div></div></div></div><div id="38416895" class="c"><input type="checkbox" id="c-38416895" checked=""/><div class="controls bullet"><span class="by">dclowd9901</span><span>|</span><a href="#38416412">parent</a><span>|</span><a href="#38416673">prev</a><span>|</span><a href="#38416285">next</a><span>|</span><label class="collapse" for="c-38416895">[-]</label><label class="expand" for="c-38416895">[2 more]</label></div><br/><div class="children"><div class="content">I think if people at all levels of skill were reasonably good at measuring their own ability, we would see two curves that roughly overlap. Instead we see the graph given.<p>The fact that random noise can generate a mean curve on the Y axis doesn’t mean DK doesn’t exist. It just means DK’s mean self analysis resembles a middling random mean, which if you think about it, makes sense. Most people will probably self evaluate as average, regardless of their actual skill. This means DK is right as rain.</div><br/><div id="38418114" class="c"><input type="checkbox" id="c-38418114" checked=""/><div class="controls bullet"><span class="by">expazl</span><span>|</span><a href="#38416412">root</a><span>|</span><a href="#38416895">parent</a><span>|</span><a href="#38416285">next</a><span>|</span><label class="collapse" for="c-38418114">[-]</label><label class="expand" for="c-38418114">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I think if people at all levels of skill were reasonably good at measuring their own ability, we would see two curves that roughly overlap. Instead we see the graph given.<p>Actually, due to the construction of the test, the ability to evaluate your own absolute ability in a subject isn&#x27;t sufficient for the two lines to be able to overlap.<p>It&#x27;s a percentile axis, so you need to be able to reasonably accurately estimate the ability of everyone taking the test, and where you fall in the quartile range of those participants.</div><br/></div></div></div></div></div></div><div id="38416285" class="c"><input type="checkbox" id="c-38416285" checked=""/><div class="controls bullet"><span class="by">r0uv3n</span><span>|</span><a href="#38416412">prev</a><span>|</span><a href="#38416580">next</a><span>|</span><label class="collapse" for="c-38416285">[-]</label><label class="expand" for="c-38416285">[6 more]</label></div><br/><div class="children"><div class="content">The discussion between Nicolas Boneel and the author in the comments of the article is interesting and Nicolas expresses the doubts I had when reading this. The whole point of the DK effect is that people are bad at estimating their skill, so if you assume that they randomly guess their skill level then of course you will replicate the results.<p>The correct model for a world without DK should be something like (estimated test scores)=(actual test scores)+noise, and then the only form of spurious DK you&#x27;d expect is caused by the fact that there&#x27;s a minimum and maximum test score. But this effect would be proportional to the variance of the noise, and I assume the variance on the additional dataset is too low to fully understand the effect seen there.<p>Also, in this model on average everyone should still guess correctly in which half of the distribution they are, but even the bottom quartile seemed to estimate their abilities as above the 50th percentile</div><br/><div id="38417691" class="c"><input type="checkbox" id="c-38417691" checked=""/><div class="controls bullet"><span class="by">jampekka</span><span>|</span><a href="#38416285">parent</a><span>|</span><a href="#38419031">next</a><span>|</span><label class="collapse" for="c-38417691">[-]</label><label class="expand" for="c-38417691">[1 more]</label></div><br/><div class="children"><div class="content">The correct model is probably (estimated test score + estimation noise) = (actual test score + test noise). The test contains a random element, e.g. guessing, that the person can&#x27;t estimate.<p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Regression_dilution" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Regression_dilution</a><p><a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Errors-in-variables_models" rel="nofollow noreferrer">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Errors-in-variables_models</a></div><br/></div></div><div id="38416369" class="c"><input type="checkbox" id="c-38416369" checked=""/><div class="controls bullet"><span class="by">svnt</span><span>|</span><a href="#38416285">parent</a><span>|</span><a href="#38419031">prev</a><span>|</span><a href="#38416391">next</a><span>|</span><label class="collapse" for="c-38416369">[-]</label><label class="expand" for="c-38416369">[1 more]</label></div><br/><div class="children"><div class="content">Just because the data appear random doesn’t mean you’ve gotten at the cause though.<p>From those charts it could equally be low skill throughout, or something nuanced like lack of skill at estimating at the bottom, improving skill in estimating through the middle, and high skill and learned modesty at the top.</div><br/></div></div><div id="38416391" class="c"><input type="checkbox" id="c-38416391" checked=""/><div class="controls bullet"><span class="by">Jensson</span><span>|</span><a href="#38416285">parent</a><span>|</span><a href="#38416369">prev</a><span>|</span><a href="#38416580">next</a><span>|</span><label class="collapse" for="c-38416391">[-]</label><label class="expand" for="c-38416391">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Also, in this model on average everyone should still guess correctly in which half of the distribution they are, but even the bottom quartile seemed to estimate their abilities as above the 50th percentile<p>Depends on the noise applied. If the noise is -10% to +100% for everyone then you get roughly the graph Dunning-Kruger got. So there is no reason to believe that the best are better at estimating their abilities, just that you can&#x27;t estimate your own rank as better than the best.</div><br/><div id="38416671" class="c"><input type="checkbox" id="c-38416671" checked=""/><div class="controls bullet"><span class="by">tempestn</span><span>|</span><a href="#38416285">root</a><span>|</span><a href="#38416391">parent</a><span>|</span><a href="#38416580">next</a><span>|</span><label class="collapse" for="c-38416671">[-]</label><label class="expand" for="c-38416671">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a great observation. For what it&#x27;s worth though, it does seem logical to me that the best would also be best at estimating their skill. Not necessarily because they&#x27;re better at it per se (though there&#x27;s likely some of that too, for the reasons originally posited by D-K), but also because they have an easier problem to solve. When you know something well, it&#x27;s fairly obvious that that&#x27;s the case. (Think of the experience of acing a math test. It&#x27;s entirely possible you&#x27;d know you answered everything correctly.) When you struggle somewhat though, it&#x27;s much more difficult to estimate how much you&#x27;re struggling compared to how others would fare.</div><br/></div></div></div></div></div></div><div id="38416580" class="c"><input type="checkbox" id="c-38416580" checked=""/><div class="controls bullet"><span class="by">snarkconjecture</span><span>|</span><a href="#38416285">prev</a><span>|</span><a href="#38416917">next</a><span>|</span><label class="collapse" for="c-38416580">[-]</label><label class="expand" for="c-38416580">[6 more]</label></div><br/><div class="children"><div class="content">Nonstandard terminology warning: the author is using &quot;autocorrelation&quot; in a way I&#x27;ve never seen before. There is a much more common usage of &quot;autocorrelation&quot; to refer to the correlation of a timeseries with itself (shifted by some amount).<p>If you use autocorrelation to refer to the thing in OP, you&#x27;ll probably confuse people who know statistics, and vice versa.</div><br/><div id="38418295" class="c"><input type="checkbox" id="c-38418295" checked=""/><div class="controls bullet"><span class="by">ketozhang</span><span>|</span><a href="#38416580">parent</a><span>|</span><a href="#38418896">next</a><span>|</span><label class="collapse" for="c-38418295">[-]</label><label class="expand" for="c-38418295">[1 more]</label></div><br/><div class="children"><div class="content">The more common experience with autocorrelations are with time series, but what the author said is correct even in that context. A time series autocorrelation relates the same time series function at different times. At the simplest you plot the arrays X vs X where X[i] = f(t[i]). You then may complicate it further by some transformation g(X) vs X (e.g., moving average).</div><br/></div></div><div id="38418896" class="c"><input type="checkbox" id="c-38418896" checked=""/><div class="controls bullet"><span class="by">xpe</span><span>|</span><a href="#38416580">parent</a><span>|</span><a href="#38418295">prev</a><span>|</span><a href="#38419359">next</a><span>|</span><label class="collapse" for="c-38418896">[-]</label><label class="expand" for="c-38418896">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Nonstandard terminology warning: the author is using &quot;autocorrelation&quot; in a way I&#x27;ve never seen before.<p>That&#x27;s a nice way of putting it. A more accurate description would be: the author is butchering the key essence of autocorrelation, since they don&#x27;t clearly mention that it is a temporal relationship!<p>&gt; What is autocorrelation?<p>&gt; Autocorrelation occurs when you correlate a variable with itself.<p>Groan.<p>A standard definition is:<p>&gt; Autocorrelation refers to the degree of correlation of the same variables between two successive time intervals. It measures how the lagged version of the value of a variable is related to the original version of it in a time series. Autocorrelation, as a statistical concept, is also known as serial correlation.</div><br/></div></div><div id="38419359" class="c"><input type="checkbox" id="c-38419359" checked=""/><div class="controls bullet"><span class="by">gnicholas</span><span>|</span><a href="#38416580">parent</a><span>|</span><a href="#38418896">prev</a><span>|</span><a href="#38418807">next</a><span>|</span><label class="collapse" for="c-38419359">[-]</label><label class="expand" for="c-38419359">[1 more]</label></div><br/><div class="children"><div class="content">What term is appropriate to describe what the author is referring to?</div><br/></div></div><div id="38418807" class="c"><input type="checkbox" id="c-38418807" checked=""/><div class="controls bullet"><span class="by">epigramx</span><span>|</span><a href="#38416580">parent</a><span>|</span><a href="#38419359">prev</a><span>|</span><a href="#38416917">next</a><span>|</span><label class="collapse" for="c-38418807">[-]</label><label class="expand" for="c-38418807">[2 more]</label></div><br/><div class="children"><div class="content">you might say the article author might have some ..dunning-kruger on what autocorrelation is.</div><br/><div id="38419852" class="c"><input type="checkbox" id="c-38419852" checked=""/><div class="controls bullet"><span class="by">nothrowaways</span><span>|</span><a href="#38416580">root</a><span>|</span><a href="#38418807">parent</a><span>|</span><a href="#38416917">next</a><span>|</span><label class="collapse" for="c-38419852">[-]</label><label class="expand" for="c-38419852">[1 more]</label></div><br/><div class="children"><div class="content">L2 of dk</div><br/></div></div></div></div></div></div><div id="38416917" class="c"><input type="checkbox" id="c-38416917" checked=""/><div class="controls bullet"><span class="by">randomizedalgs</span><span>|</span><a href="#38416580">prev</a><span>|</span><a href="#38418465">next</a><span>|</span><label class="collapse" for="c-38416917">[-]</label><label class="expand" for="c-38416917">[1 more]</label></div><br/><div class="children"><div class="content">Consider the imaginary world that the author describes, in which people&#x27;s estimate of their score is independent of their actual score. Wouldn&#x27;t it be fair to say that, in this imaginary world, the DK effect is real?<p>The point of the effect is that people who score low tend to overestimate their score and people who score high tend to underestimate. Of course there are lots of rational reasons why this could occur (including the toy example the author gave, where nobody has any good sense of what their score will be), but the phenomenon appears to me to be correct.</div><br/></div></div><div id="38418465" class="c"><input type="checkbox" id="c-38418465" checked=""/><div class="controls bullet"><span class="by">CalChris</span><span>|</span><a href="#38416917">prev</a><span>|</span><a href="#38417534">next</a><span>|</span><label class="collapse" for="c-38418465">[-]</label><label class="expand" for="c-38418465">[1 more]</label></div><br/><div class="children"><div class="content">The article&#x27;s definition of <i>autocorrelation</i>:<p><pre><code>  Autocorrelation occurs when you correlate a variable with itself. 
</code></pre>
Wikipedia&#x27;s definition of <i>autocorrelation</i>:<p><pre><code>  Autocorrelation, sometimes known as serial correlation in the discrete time case, is the correlation of a signal with a delayed copy of itself as a function of delay.
</code></pre>
Of course, 0 delay is the trivial case of time delay but really, the article&#x27;s definition is at best inaccurate. D-K has nothing to do with time delay and calling it autocorrelation seems like a weird pun that doesn&#x27;t quite land.</div><br/></div></div><div id="38417534" class="c"><input type="checkbox" id="c-38417534" checked=""/><div class="controls bullet"><span class="by">James_K</span><span>|</span><a href="#38418465">prev</a><span>|</span><a href="#38416607">next</a><span>|</span><label class="collapse" for="c-38417534">[-]</label><label class="expand" for="c-38417534">[1 more]</label></div><br/><div class="children"><div class="content">I think the issue here is a confusion about what &quot;bias&quot; means. If they are self-assessing at random, then the high performers will all underestimate themselves, but this is not a bias towards underestimation as they are choosing randomly.<p>That said, the chart from D-K seems to show a different bias and line up roughly with what you would expect. Someone with no knowledge assumes they are average skill and hence inflates their position, someone who is very good doesn&#x27;t want to rate themselves the best because they assume others know as much as they do. The assumption underlying both groups is that you are normal and others are similar to you.<p>I hypothesise that most people think they&#x27;re average, which is something you could easily test by asking them to rate how well they think the average person would do on a test and comparing it to that individual&#x27;s test score. I&#x27;m almost certain that high performers will overestimate the average, and low performers underestimate it.</div><br/></div></div><div id="38416607" class="c"><input type="checkbox" id="c-38416607" checked=""/><div class="controls bullet"><span class="by">abnry</span><span>|</span><a href="#38417534">prev</a><span>|</span><a href="#38419186">next</a><span>|</span><label class="collapse" for="c-38416607">[-]</label><label class="expand" for="c-38416607">[1 more]</label></div><br/><div class="children"><div class="content">If there is a linear relationship between test score (X, ability) and test score self-assessment (Y, self-perception), then the random variables are modeled as:<p>$$
Y \sim aX+b+N
$$<p>Where N is some statistically independent noise, mean zero.<p>This means the covariance between them is<p>$$
Cov(Y-X,X) = E[ ((a-1)X+b+N -(a-1)E[X]-b) (X - E[X]) ]
$$<p>Which is<p>$$
Cov(Y-X,X) = E[(a-1)(X-E[X])(X-E[X])] + E[N(X-E[X])]= (a-1) Var[X]
$$<p>To get a &quot;DK effect&quot; we need (a-1) &lt; 0, or a &lt; 1. If a=0, in the case of the blog post, then this is absolutely true. If a=1 (which, along with b=0, is the ideal scenario), then this is barely not true. If a &gt; 1, then we&#x27;d have a whole new effect about arrogant experts.<p>So the only thing that matters from this &quot;auto-correlation perspective&quot; is the rate at which an individual&#x27;s self-assessment increases with their ability. As long as they underestimate the increase, a &quot;DK effect&quot; will occur.<p>However, in the above analysis, we ignored the variable b. If a = 0.8 and b=0, we&#x27;d never have the so-called &quot;DK effect&quot; even though it matches the &quot;auto-correlation perspective&quot; because everyone would underestimate their ability.<p>This tells me that the value of b matters. It is sort of like the prior ability everyone assumes they have. What the DK papers shows is that b &gt; .5, which I think is in line with the spirit of the popular interpretation of the &quot;DK effect&quot;. People should not be assuming they have, at a minimum, a capacity higher than the average.<p>At the same time, the value b isn&#x27;t insanely higher than .5, which also makes me want to cut those unskilled and unaware some slack. It &quot;seems reasonable&quot; to assume your baseline is average. That can&#x27;t be the case, but it feels intuitive.</div><br/></div></div><div id="38419186" class="c"><input type="checkbox" id="c-38419186" checked=""/><div class="controls bullet"><span class="by">19f191ty</span><span>|</span><a href="#38416607">prev</a><span>|</span><a href="#38418922">next</a><span>|</span><label class="collapse" for="c-38419186">[-]</label><label class="expand" for="c-38419186">[1 more]</label></div><br/><div class="children"><div class="content">That is not an autocorrelation. The OP is equating linear dependence with autocorrelation, which not how we use that term. Autocorrelation is when a random process is correlated with time lagged version of itself.</div><br/></div></div><div id="38418922" class="c"><input type="checkbox" id="c-38418922" checked=""/><div class="controls bullet"><span class="by">zw123456</span><span>|</span><a href="#38419186">prev</a><span>|</span><a href="#38419897">next</a><span>|</span><label class="collapse" for="c-38418922">[-]</label><label class="expand" for="c-38418922">[2 more]</label></div><br/><div class="children"><div class="content">I know I&#x27;m not smart enough on statistics or psychology to evaluate the article but it always struck me that D&amp;K seemed to say something similar to what my grandpa said when I was a wee lad, &quot;The more you know, the more you realize how much you don&#x27;t know&quot;, I know he wasn&#x27;t the first person to say that, but he was the first person to say it to me. I don&#x27;t know if D&amp;K is autocorrelation or not, but I know that an awful lot of people seem to think they know more than maybe they actually do, probably me included. Hmmm, maybe the author of that article as well? I wonder if that occurred to him, seems like a glaring oversight not to at least recognize that possible irony.</div><br/><div id="38419070" class="c"><input type="checkbox" id="c-38419070" checked=""/><div class="controls bullet"><span class="by">Arch485</span><span>|</span><a href="#38418922">parent</a><span>|</span><a href="#38419897">next</a><span>|</span><label class="collapse" for="c-38419070">[-]</label><label class="expand" for="c-38419070">[1 more]</label></div><br/><div class="children"><div class="content">In the article, a real study was used as a counterexample to the DK effect.<p>Part of the results was a correlation that people who were &quot;less capable&quot; were also worse at predicting their own skill, and people who were &quot;more capable&quot; were better at predicting their own skill.<p>While similar to the DK effect, this is different, as the DK effect states that &quot;less capable&quot; individuals specifically _overestimate_ their skill, as opposed to simply being wrong (both over and under -estimating).<p>With relation to some people &quot;seeming to think they know more than they actually know&quot;, this is likely confirmation bias in the sense that there are an equal number of people who don&#x27;t know much, and know that they don&#x27;t know much.</div><br/></div></div></div></div><div id="38419897" class="c"><input type="checkbox" id="c-38419897" checked=""/><div class="controls bullet"><span class="by">PeterStuer</span><span>|</span><a href="#38418922">prev</a><span>|</span><a href="#38418345">next</a><span>|</span><label class="collapse" for="c-38419897">[-]</label><label class="expand" for="c-38419897">[1 more]</label></div><br/><div class="children"><div class="content">You can take out the x from both sides, and the y would still not be a horizontal line.<p>In their eagerness to &#x27;deconstruct&#x27; the narrative, do the authors merely provide another example of Dunning-Kuger by overestimating their own cleverness?</div><br/></div></div><div id="38418345" class="c"><input type="checkbox" id="c-38418345" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#38419897">prev</a><span>|</span><a href="#38418577">next</a><span>|</span><label class="collapse" for="c-38418345">[-]</label><label class="expand" for="c-38418345">[1 more]</label></div><br/><div class="children"><div class="content">I disagree. Dunning Kruger is not a statement about predicted score correlating with actual score in some way. It states that predicted score does not correlate well with actual score. This can be rephrased as the prediction error having a negative correlation with the actual score. The article then claims that this negative correlation is autocorrelation. That is true but the correlation still exist. The thing is that ideally we EXPECT there to be no correlation of the prediction error with the actual score, but we find autocorrelation. Going back to variables where this autocorrelation is not there, we EXPECTED to find a 1:1 positive correlation between predicted score and actual score but find no correlation, or a weak correlation.<p>So finding autocorrelation when you expected to find no correlation is pretty much the Dunning-Kruger effect here.<p>In fact their example with the random data totally makes sense: Suppose people uniformly randomly estimate their performance. Then the people who are low skilled will consistently over-estimate and the people who are high-skilled will consistently underestimate. Of course there is no causation here, as the people choose randomly, but there is an undeniable correlation. I guess the question is if you view the Dunning-Kruger effect as a claim to low skill CAUSING positive prediction error, or just correlating with it.</div><br/></div></div><div id="38418577" class="c"><input type="checkbox" id="c-38418577" checked=""/><div class="controls bullet"><span class="by">chmod600</span><span>|</span><a href="#38418345">prev</a><span>|</span><a href="#38419159">next</a><span>|</span><label class="collapse" for="c-38418577">[-]</label><label class="expand" for="c-38418577">[1 more]</label></div><br/><div class="children"><div class="content">A related effect that I&#x27;ve wondered about is: perhaps lower-skilled people compare themselves to the general public, while perhaps skilled people compare themselves to a smaller group of skilled peers.<p>In other words, if you asked me if I&#x27;m good at riding a bicycle, I&#x27;d compare myself to others in the general population and say &quot;yes&quot;. But if you ask a weekend bicyclist, they&#x27;d be better than me but perhaps compare themselves to weekend bicyclists, and rate themselves lower. And the effect might repeat for competitive bicyclists.<p>If true, this could explain why we intuitively believe the DK effect.</div><br/></div></div><div id="38419159" class="c"><input type="checkbox" id="c-38419159" checked=""/><div class="controls bullet"><span class="by">dimask</span><span>|</span><a href="#38418577">prev</a><span>|</span><a href="#38416364">next</a><span>|</span><label class="collapse" for="c-38419159">[-]</label><label class="expand" for="c-38419159">[1 more]</label></div><br/><div class="children"><div class="content">I would call this type of argument a case of regression to the mean rather than &quot;autocorrelation&quot;. That, of course, in principle requires independence between performance and assessment of performance. In many cases, it would make little sense to assume that the performance and assessment of performance are independent. But even then, one can simulate random data with some correlation, and still get a DK effect merely as statistical artifact. An overview of similar critiques, and a similar argument in  <a href="https:&#x2F;&#x2F;www.frontiersin.org&#x2F;articles&#x2F;10.3389&#x2F;fpsyg.2022.840180&#x2F;full" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.frontiersin.org&#x2F;articles&#x2F;10.3389&#x2F;fpsyg.2022.8401...</a> .</div><br/></div></div><div id="38416364" class="c"><input type="checkbox" id="c-38416364" checked=""/><div class="controls bullet"><span class="by">hn_throwaway_99</span><span>|</span><a href="#38419159">prev</a><span>|</span><a href="#38418916">next</a><span>|</span><label class="collapse" for="c-38416364">[-]</label><label class="expand" for="c-38416364">[1 more]</label></div><br/><div class="children"><div class="content">Previous discussion: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31036800">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31036800</a></div><br/></div></div><div id="38418916" class="c"><input type="checkbox" id="c-38418916" checked=""/><div class="controls bullet"><span class="by">civilized</span><span>|</span><a href="#38416364">prev</a><span>|</span><a href="#38418564">next</a><span>|</span><label class="collapse" for="c-38418916">[-]</label><label class="expand" for="c-38418916">[1 more]</label></div><br/><div class="children"><div class="content">We discussed this in a previous thread. The author is basically hypothesizing that perhaps people are so universally terrible at predicting their ability, their self-rating is like an unconditional random variable - just a random draw that is not influenced by their actual ability level at all.<p>If this is true, then when your actual ability is high, your self-rating is likely to be lower than your ability simply by random chance. For example, if ability ranges from 0-100, your actual ability is 99, and your self-rating is a uniform random number from 0-100, your self-rating is 99% likely to be lower than your actual ability. Conversely, if your actual ability is low, your self-rating is likely to exceed your actual ability level.<p>When it&#x27;s explained clearly and simply, the criticism raises a lot of questions. Are people <i>actually</i> that bad at rating their own ability? I doubt it.</div><br/></div></div><div id="38418564" class="c"><input type="checkbox" id="c-38418564" checked=""/><div class="controls bullet"><span class="by">hyperthesis</span><span>|</span><a href="#38418916">prev</a><span>|</span><a href="#38416108">next</a><span>|</span><label class="collapse" for="c-38418564">[-]</label><label class="expand" for="c-38418564">[1 more]</label></div><br/><div class="children"><div class="content"><i>If</i> unskilled and skilled self-assessed themselves the same on average, then unskilled overestimate, and skilled underestimate.<p>That would be a significant result alone - that no one had any idea. (but as <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38416100">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38416100</a> notes, there is a correlation).</div><br/></div></div><div id="38416108" class="c"><input type="checkbox" id="c-38416108" checked=""/><div class="controls bullet"><span class="by">dmbche</span><span>|</span><a href="#38418564">prev</a><span>|</span><a href="#38416194">next</a><span>|</span><label class="collapse" for="c-38416108">[-]</label><label class="expand" for="c-38416108">[3 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t it ironic that they fooled themselves?</div><br/><div id="38416569" class="c"><input type="checkbox" id="c-38416569" checked=""/><div class="controls bullet"><span class="by">ulizzle</span><span>|</span><a href="#38416108">parent</a><span>|</span><a href="#38416194">next</a><span>|</span><label class="collapse" for="c-38416569">[-]</label><label class="expand" for="c-38416569">[2 more]</label></div><br/><div class="children"><div class="content">It was actually hilarious but I don’t think many people here got the irony</div><br/><div id="38418551" class="c"><input type="checkbox" id="c-38418551" checked=""/><div class="controls bullet"><span class="by">DangitBobby</span><span>|</span><a href="#38416108">root</a><span>|</span><a href="#38416569">parent</a><span>|</span><a href="#38416194">next</a><span>|</span><label class="collapse" for="c-38418551">[-]</label><label class="expand" for="c-38418551">[1 more]</label></div><br/><div class="children"><div class="content">Literally the closing paragraph of TFA is about that exact irony.</div><br/></div></div></div></div></div></div><div id="38416194" class="c"><input type="checkbox" id="c-38416194" checked=""/><div class="controls bullet"><span class="by">mewpmewp2</span><span>|</span><a href="#38416108">prev</a><span>|</span><a href="#38416641">next</a><span>|</span><label class="collapse" for="c-38416194">[-]</label><label class="expand" for="c-38416194">[2 more]</label></div><br/><div class="children"><div class="content">My take on Dunning Kruger:<p>1. People really like the idea of smart people being humble and arrogance meaning stupidity, so they like to believe that DK is true, and they like to repeat this.<p>2. Some smart&#x2F;skilled people are humble, some are arrogant.<p>3. Some smart&#x2F;skilled people underestimate their skills, some overestimate.<p>4. Some stupid people are humble, some are arrogant.<p>5. Some stupid people underestimate their skills, some overestimate.<p>Overall, even if there is a correlation, you can&#x27;t tell by just arrogance of a person whether we are dealing with DK or whether it&#x27;s an effect at all. People&#x27;s personalities, skills and everything are a bit more complex than that.<p>Overall bringing DK up seems like some sort of social justice&#x2F;fairness effort rather than something that is actually true given any situation where someone is arrogant.</div><br/><div id="38416423" class="c"><input type="checkbox" id="c-38416423" checked=""/><div class="controls bullet"><span class="by">spacebacon</span><span>|</span><a href="#38416194">parent</a><span>|</span><a href="#38416641">next</a><span>|</span><label class="collapse" for="c-38416423">[-]</label><label class="expand" for="c-38416423">[1 more]</label></div><br/><div class="children"><div class="content">Maybe this shows how effective dumb people are at keeping smart people hammered down with thought stopping arguments.</div><br/></div></div></div></div><div id="38416641" class="c"><input type="checkbox" id="c-38416641" checked=""/><div class="controls bullet"><span class="by">concordDance</span><span>|</span><a href="#38416194">prev</a><span>|</span><a href="#38416257">next</a><span>|</span><label class="collapse" for="c-38416641">[-]</label><label class="expand" for="c-38416641">[1 more]</label></div><br/><div class="children"><div class="content">The author fails to make his point quite badly. Of course if everyone&#x27;s self assessment was random the bottom quartile would overrate themselves! And that would be half of the Dunning-Kruger effect and we could truthfully say &quot;the bottom quartile of people overrate themselves&quot;!<p>The other part where those at the top have a better idea or where they rank noticeably does not come out in his toy example.<p>Honestly, he comes across as not having the slightest understanding of how people interpet those graphs...</div><br/></div></div><div id="38416257" class="c"><input type="checkbox" id="c-38416257" checked=""/><div class="controls bullet"><span class="by">xanderlewis</span><span>|</span><a href="#38416641">prev</a><span>|</span><a href="#38416501">next</a><span>|</span><label class="collapse" for="c-38416257">[-]</label><label class="expand" for="c-38416257">[2 more]</label></div><br/><div class="children"><div class="content">Naïve take: I’ve always felt like Dunning-Kruger is just the result of the fact that when guessing the value of anything people tend towards some common mean, and so if the true value is low your guess tends to be high, and vice versa. This assumes nothing about what is being guessed, but does assume (perhaps wrongly) that there is a commonly believed mean value and that people tend to imagine they are close to it.</div><br/><div id="38416668" class="c"><input type="checkbox" id="c-38416668" checked=""/><div class="controls bullet"><span class="by">wavemode</span><span>|</span><a href="#38416257">parent</a><span>|</span><a href="#38416501">next</a><span>|</span><label class="collapse" for="c-38416668">[-]</label><label class="expand" for="c-38416668">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s essentially the plain-language interpretation of what the author of this article is pointing out - when you plot (actual score) against (difference between test score and actual score), you will always find a trend that underperformers overestimate and overperformers underestimate - for the exact reason you state.</div><br/></div></div></div></div><div id="38416501" class="c"><input type="checkbox" id="c-38416501" checked=""/><div class="controls bullet"><span class="by">vismwasm</span><span>|</span><a href="#38416257">prev</a><span>|</span><a href="#38416993">next</a><span>|</span><label class="collapse" for="c-38416501">[-]</label><label class="expand" for="c-38416501">[1 more]</label></div><br/><div class="children"><div class="content">The author measures the Dunning Kruger effect on his random data exactly because he assumes it when generating his random data.<p>By modelling skill and perceived skill as uniform draws between 0 and 100, the unskilled (e.g. skill=0) will over-estimate their skills (estimated skill = 50, the mean on the uniform random variable) and the skilled (e.g. skill=100) will underestimate it (as 50 as well, again the mean of the same random variable). The only ones who will be correct (on average) are the average skilled ones (skill=50).</div><br/></div></div><div id="38416993" class="c"><input type="checkbox" id="c-38416993" checked=""/><div class="controls bullet"><span class="by">ezekiel68</span><span>|</span><a href="#38416501">prev</a><span>|</span><a href="#38419807">next</a><span>|</span><label class="collapse" for="c-38416993">[-]</label><label class="expand" for="c-38416993">[2 more]</label></div><br/><div class="children"><div class="content">&gt; However, there is a delightful irony to the circumstances of their blunder.<p>Indeed. And I find the tendency of people in this comment section to defend the flawed theory is further confirmation of another scientific finding: that we decide based on emotion and then justify our decision using rationality.</div><br/><div id="38418780" class="c"><input type="checkbox" id="c-38418780" checked=""/><div class="controls bullet"><span class="by">stubish</span><span>|</span><a href="#38416993">parent</a><span>|</span><a href="#38419807">next</a><span>|</span><label class="collapse" for="c-38418780">[-]</label><label class="expand" for="c-38418780">[1 more]</label></div><br/><div class="children"><div class="content">Even when the article cites the 3 papers it is based on, no refutations of the published science by people who grok it.</div><br/></div></div></div></div><div id="38419807" class="c"><input type="checkbox" id="c-38419807" checked=""/><div class="controls bullet"><span class="by">dilawar</span><span>|</span><a href="#38416993">prev</a><span>|</span><a href="#38420030">next</a><span>|</span><label class="collapse" for="c-38419807">[-]</label><label class="expand" for="c-38419807">[1 more]</label></div><br/><div class="children"><div class="content">David Dunning response (2022): <a href="https:&#x2F;&#x2F;www.bps.org.uk&#x2F;psychologist&#x2F;dunning-kruger-effect-and-its-discontents" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.bps.org.uk&#x2F;psychologist&#x2F;dunning-kruger-effect-an...</a></div><br/></div></div><div id="38420030" class="c"><input type="checkbox" id="c-38420030" checked=""/><div class="controls bullet"><span class="by">eterevsky</span><span>|</span><a href="#38419807">prev</a><span>|</span><a href="#38419815">next</a><span>|</span><label class="collapse" for="c-38420030">[-]</label><label class="expand" for="c-38420030">[1 more]</label></div><br/><div class="children"><div class="content">I think this article would&#x27;ve made more sense if it had a title &quot;The Dunning-Kruger effect is regression toward the mean&quot;, because that&#x27;s what the author is actually showing.</div><br/></div></div><div id="38419815" class="c"><input type="checkbox" id="c-38419815" checked=""/><div class="controls bullet"><span class="by">BrenBarn</span><span>|</span><a href="#38420030">prev</a><span>|</span><a href="#38416252">next</a><span>|</span><label class="collapse" for="c-38419815">[-]</label><label class="expand" for="c-38419815">[1 more]</label></div><br/><div class="children"><div class="content">Yeah I don&#x27;t buy this either.<p>I do think the original Dunning-Kruger plot is a bit of an odd presentation.  The way I look at it is just to say that people&#x27;s self-estimates of their ability fall into a relatively narrow range (e.g., 55-75th percentile on the graph), whereas their actual abilities of course cover the whole range from 0-100th percentile.  You don&#x27;t really need the plot of &quot;x versus x&quot; (average score in each quartile).  You just need to say &quot;people&#x27;s self-assessments seem to start unrealistically high and only go up a little, even as their ability goes up a lot&quot;.</div><br/></div></div><div id="38416252" class="c"><input type="checkbox" id="c-38416252" checked=""/><div class="controls bullet"><span class="by">joefourier</span><span>|</span><a href="#38419815">prev</a><span>|</span><a href="#38416585">next</a><span>|</span><label class="collapse" for="c-38416252">[-]</label><label class="expand" for="c-38416252">[1 more]</label></div><br/><div class="children"><div class="content">So from my understanding, the Dunning-Kruger Effect paper doesn’t show the distribution of the perceived test scores nor the standard deviation, only an average, which rises with actual test score level.<p>If they showed the spread bar in each bin, you could form very different conclusions. Do low skilled people consistently estimate their score at around 60, or do they give effectively random results centred around 60?<p>Assuming the latter, it could mean that low skilled individuals are completely unable to evaluate their performance while higher skilled people are slightly better at it but still not very good, giving a slightly positive correlation which… is very distinct from what the DK effect implied.</div><br/></div></div><div id="38416585" class="c"><input type="checkbox" id="c-38416585" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38416252">prev</a><span>|</span><a href="#38416114">next</a><span>|</span><label class="collapse" for="c-38416585">[-]</label><label class="expand" for="c-38416585">[10 more]</label></div><br/><div class="children"><div class="content">&gt; If the Dunning-Kruger effect were present, it would show up in Figure 11 as a downward trend in the data (similar to the trend in Figure 7). Such a trend would indicate that unskilled people overestimate their ability, and that this overestimate decreases with skill. Looking at Figure 11, there is no hint of a trend.<p>There certainly <i>is</i> a hint of a trend. Why do people, when visualizing data with a distinct trend, say that because the &quot;error bars&quot; from a particular statistical test overlap zero that no trend exists!?<p>Freshman <i>trend</i> to over-confidence. Grad students <i>trend</i> to under-confidence. Undergrads in general <i>trend</i> to over-confidence (though this trend decreases as year in school increases), and post-graduates, whether grad students or professors, trend to under-confidence.<p>These &quot;trends&quot; are not statistically significant, but they certainly are a trend!<p>Also, the random data distribution in figure 9 doesn&#x27;t show the same trends as Dunning-Kruger&#x27;s curve in figure 2. Perhaps there is at least one psycho-social mechanism here worth investigating?</div><br/><div id="38416882" class="c"><input type="checkbox" id="c-38416882" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#38416585">parent</a><span>|</span><a href="#38416678">next</a><span>|</span><label class="collapse" for="c-38416882">[-]</label><label class="expand" for="c-38416882">[2 more]</label></div><br/><div class="children"><div class="content">If they&#x27;re actually error bars, you can shrink them with more data.  That will turn the hint of a trend into an observation of a trend.  If it wasn&#x27;t random noise giving a fake hint.</div><br/><div id="38416915" class="c"><input type="checkbox" id="c-38416915" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38416585">root</a><span>|</span><a href="#38416882">parent</a><span>|</span><a href="#38416678">next</a><span>|</span><label class="collapse" for="c-38416915">[-]</label><label class="expand" for="c-38416915">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If they&#x27;re actually error bars, you can shrink them with more data.<p>Assuming the new data has the same systemic or instrumental bias as the old data. Even using a different test date could skew results enough to widen the error bars.</div><br/></div></div></div></div><div id="38416678" class="c"><input type="checkbox" id="c-38416678" checked=""/><div class="controls bullet"><span class="by">mrkeen</span><span>|</span><a href="#38416585">parent</a><span>|</span><a href="#38416882">prev</a><span>|</span><a href="#38416114">next</a><span>|</span><label class="collapse" for="c-38416678">[-]</label><label class="expand" for="c-38416678">[7 more]</label></div><br/><div class="children"><div class="content">&gt; These &quot;trends&quot; are not statistically significant, but they certainly are a trend!<p>This is an oxymoron.</div><br/><div id="38416858" class="c"><input type="checkbox" id="c-38416858" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38416585">root</a><span>|</span><a href="#38416678">parent</a><span>|</span><a href="#38416817">next</a><span>|</span><label class="collapse" for="c-38416858">[-]</label><label class="expand" for="c-38416858">[4 more]</label></div><br/><div class="children"><div class="content">Show how.<p>I place mechanistic theory prior to statistics in science. Mechanistic theory can be tested, statistics are a kind of test.<p>If a statistically-insignificant result shows consistent, though non-significant deviations, such as the kind seen in Figure 11, then it tells me it&#x27;s worth investigating whether mechanism(s) are explaining a very small portion of the variation that will not, in itself, show up as statistically significant, as it&#x27;s being swamped by variation in other parameters.</div><br/><div id="38416943" class="c"><input type="checkbox" id="c-38416943" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#38416585">root</a><span>|</span><a href="#38416858">parent</a><span>|</span><a href="#38416817">next</a><span>|</span><label class="collapse" for="c-38416943">[-]</label><label class="expand" for="c-38416943">[3 more]</label></div><br/><div class="children"><div class="content">Consistency is a synonym for statistical significance.  If there&#x27;s consistency beyond random alignment, then there should be a statistical test you can apply over your data to extract the signal.<p>You can extract surprisingly small signals relative to variation in other parameters.  But if it&#x27;s <i>actually</i> swamped, then it might not be real, so go get more data.</div><br/><div id="38417369" class="c"><input type="checkbox" id="c-38417369" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38416585">root</a><span>|</span><a href="#38416943">parent</a><span>|</span><a href="#38416817">next</a><span>|</span><label class="collapse" for="c-38417369">[-]</label><label class="expand" for="c-38417369">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Consistency is a synonym for statistical significance.<p>So basically you&#x27;re telling me that if I can visually see a consistency that does not show up in their statistical test, then they aren&#x27;t running an appropriate statistical test on what I&#x27;m seeing.<p>&gt; But if it&#x27;s actually swamped, then it might not be real, so go get more data.<p>Even better to design other experiments.</div><br/><div id="38417500" class="c"><input type="checkbox" id="c-38417500" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#38416585">root</a><span>|</span><a href="#38417369">parent</a><span>|</span><a href="#38416817">next</a><span>|</span><label class="collapse" for="c-38417500">[-]</label><label class="expand" for="c-38417500">[1 more]</label></div><br/><div class="children"><div class="content">&gt; So basically you&#x27;re telling me that if I can visually see a consistency that does not show up in their statistical test, then they aren&#x27;t running an appropriate statistical test on what I&#x27;m seeing.<p><i>Either</i> they&#x27;re not doing the right statistics, <i>or</i> it&#x27;s a &quot;consistency&quot; that is much more likely to show up randomly than you naively expect, and the study needs to be repeated or enhanced.<p>Sometimes you can see a pattern that&#x27;s just a figment of chance.  See also: numerology, jelly bean xkcd</div><br/></div></div></div></div></div></div></div></div><div id="38416817" class="c"><input type="checkbox" id="c-38416817" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#38416585">root</a><span>|</span><a href="#38416678">parent</a><span>|</span><a href="#38416858">prev</a><span>|</span><a href="#38416114">next</a><span>|</span><label class="collapse" for="c-38416817">[-]</label><label class="expand" for="c-38416817">[2 more]</label></div><br/><div class="children"><div class="content">Oxymorons only sound contradictory on a surface level.<p>Something &quot;certainly&quot; being a &quot;trend&quot; is the definition of statistical significance, so this is a straight up contradiction.</div><br/><div id="38416868" class="c"><input type="checkbox" id="c-38416868" checked=""/><div class="controls bullet"><span class="by">anonymouskimmer</span><span>|</span><a href="#38416585">root</a><span>|</span><a href="#38416817">parent</a><span>|</span><a href="#38416114">next</a><span>|</span><label class="collapse" for="c-38416868">[-]</label><label class="expand" for="c-38416868">[1 more]</label></div><br/><div class="children"><div class="content">See here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38416858">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38416858</a><p>&quot;Trend&quot; has multiple meanings. Statistics doesn&#x27;t get to claim all of the meaning.</div><br/></div></div></div></div></div></div></div></div><div id="38416114" class="c"><input type="checkbox" id="c-38416114" checked=""/><div class="controls bullet"><span class="by">lencastre</span><span>|</span><a href="#38416585">prev</a><span>|</span><a href="#38417819">next</a><span>|</span><label class="collapse" for="c-38416114">[-]</label><label class="expand" for="c-38416114">[6 more]</label></div><br/><div class="children"><div class="content">Wasn’t this DK effect already debunked?</div><br/><div id="38416631" class="c"><input type="checkbox" id="c-38416631" checked=""/><div class="controls bullet"><span class="by">mrkeen</span><span>|</span><a href="#38416114">parent</a><span>|</span><a href="#38416313">next</a><span>|</span><label class="collapse" for="c-38416631">[-]</label><label class="expand" for="c-38416631">[1 more]</label></div><br/><div class="children"><div class="content">Yes but some claim to have debunked the debunking also. [1]<p>This paper (2023) claims &quot;the magnitude of the effect was minimal; bringing its meaningfulness into question.&quot; [2]<p>[1] <a href="https:&#x2F;&#x2F;andersource.dev&#x2F;2022&#x2F;04&#x2F;19&#x2F;dk-autocorrelation.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;andersource.dev&#x2F;2022&#x2F;04&#x2F;19&#x2F;dk-autocorrelation.html</a><p>[2] <a href="https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;S0160289622000988" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;abs&#x2F;pii&#x2F;S01602...</a></div><br/></div></div><div id="38416313" class="c"><input type="checkbox" id="c-38416313" checked=""/><div class="controls bullet"><span class="by">xbar</span><span>|</span><a href="#38416114">parent</a><span>|</span><a href="#38416631">prev</a><span>|</span><a href="#38416308">next</a><span>|</span><label class="collapse" for="c-38416313">[-]</label><label class="expand" for="c-38416313">[1 more]</label></div><br/><div class="children"><div class="content">Yes. This article highlights the 2016, 2017 and 2020 debunkings of DK. But it hangs on as an oft repeated scientific fallacy.<p>The fact that anyone has to ask if it has debunked shows how desirable some people find the DK myth. Even in the comments here, people are not willing to be skeptical of DK. That&#x27;s interesting psychology.</div><br/></div></div><div id="38416308" class="c"><input type="checkbox" id="c-38416308" checked=""/><div class="controls bullet"><span class="by">hasch</span><span>|</span><a href="#38416114">parent</a><span>|</span><a href="#38416313">prev</a><span>|</span><a href="#38416334">next</a><span>|</span><label class="collapse" for="c-38416308">[-]</label><label class="expand" for="c-38416308">[1 more]</label></div><br/><div class="children"><div class="content">Article mentions 2016 somewhere. They explain a bit on top of that, with more depth ... at least my rough take on this</div><br/></div></div><div id="38416265" class="c"><input type="checkbox" id="c-38416265" checked=""/><div class="controls bullet"><span class="by">jahewson</span><span>|</span><a href="#38416114">parent</a><span>|</span><a href="#38416334">prev</a><span>|</span><a href="#38417819">next</a><span>|</span><label class="collapse" for="c-38416265">[-]</label><label class="expand" for="c-38416265">[1 more]</label></div><br/><div class="children"><div class="content">I don’t know much about it but I’m sure you’re right.</div><br/></div></div></div></div><div id="38417819" class="c"><input type="checkbox" id="c-38417819" checked=""/><div class="controls bullet"><span class="by">nitwit005</span><span>|</span><a href="#38416114">prev</a><span>|</span><label class="collapse" for="c-38417819">[-]</label><label class="expand" for="c-38417819">[1 more]</label></div><br/><div class="children"><div class="content">If self evaluations are random, and you group a bunch of them together, then you&#x27;ll see values around the 50th percentile. That&#x27;s why their self evaluation line is nearly flat.<p>In the actual data though, the line clearly trends upward. The people who did well appear to be scoring themselves non-randomly.</div><br/></div></div></div></div></div></div></div></body></html>