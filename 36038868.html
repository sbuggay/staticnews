<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1684832454008" as="style"/><link rel="stylesheet" href="styles.css?v=1684832454008"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2305.13048">RWKV: Reinventing RNNs for the Transformer Era</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>ianbutler</span> | <span>126 comments</span></div><br/><div><div id="36039049" class="c"><input type="checkbox" id="c-36039049" checked=""/><div class="controls bullet"><span class="by">andy_xor_andrew</span><span>|</span><a href="#36039215">next</a><span>|</span><label class="collapse" for="c-36039049">[-]</label><label class="expand" for="c-36039049">[33 more]</label></div><br/><div class="children"><div class="content">One thing I&#x27;m keen to understand is: how well does attention hold across huge context sizes, with respect to the usual transformer models, and also these proposed RNN models?<p>All these 2k&#x2F;4k&#x2F;8k context sizes that we&#x27;ve had recently are able to map pretty well to what a human could reasonably remember. What I mean is, you could ask a human to read some text with 8k tokens, and for the most part they could answer questions about the text coherently.<p>But what about 32k contexts, or beyond? At some point, as token size increases, the ability of a human to give a highly precise and detailed answer decreases. They must start to generalize. A human could not read Infinite Jest in one pass and then answer details about every single sentence. But could a transformer, or a RNN? As the context grows, is it harder to keep a high granularity of detail? Or am I wrong in trying to think of these models the way I think about the human mind, and they are actually able to handle this problem just fine?<p>I&#x27;m aware that we can cheat a bit, by adding a lookup step into an embedding database, to provide &quot;infinite&quot; context with &quot;infinite&quot; precision. But to me, that is analogous to a human looking up information in a library in order to answer a question. I&#x27;m interested in the inherent, emergent memory that these models have available to them in just one forward pass.</div><br/><div id="36040195" class="c"><input type="checkbox" id="c-36040195" checked=""/><div class="controls bullet"><span class="by">coppsilgold</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36039119">next</a><span>|</span><label class="collapse" for="c-36040195">[-]</label><label class="expand" for="c-36040195">[3 more]</label></div><br/><div class="children"><div class="content">The word &quot;attention&quot; has been stretched pretty far to explain what is happening inside a transformer.<p>What&#x27;s actually happening is that every token embedding interacts with every other token embedding before it and as the product of this interaction (dot product + softmax) it takes a fraction of every other token embedding and adds it to itself. Technically, it&#x27;s different transforms&#x2F;functions of the embedding.<p>You can view it as every token embedding mixing information from other embeddings into itself. Done ~100 times in parallel (&quot;attention heads&quot;), ~100 times in sequence (layers). As per GPT-3 model (175B).</div><br/><div id="36041303" class="c"><input type="checkbox" id="c-36041303" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040195">parent</a><span>|</span><a href="#36040650">next</a><span>|</span><label class="collapse" for="c-36041303">[-]</label><label class="expand" for="c-36041303">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>every token embedding interacts with every other token embedding before it</i><p>&gt; <i>it takes a fraction of every other token embedding and adds it to itself.</i><p>&gt; <i>every token embedding mixing information from other embeddings into itself</i><p>Noting the use of the word <i>every</i>. Phrased this way, calling it &quot;attention&quot; hardly makes sense, as attention is typically focused on something specific at any given time - not always on the entire thing.</div><br/></div></div><div id="36040650" class="c"><input type="checkbox" id="c-36040650" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040195">parent</a><span>|</span><a href="#36041303">prev</a><span>|</span><a href="#36039119">next</a><span>|</span><label class="collapse" for="c-36040650">[-]</label><label class="expand" for="c-36040650">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. IMO - A part of me even argue we should stop calling it attention (but what to call it instead is a mess)<p>But since this was derived from apple lite attention paper. The name is gonna stick, due to a lack of better alternative</div><br/></div></div></div></div><div id="36039119" class="c"><input type="checkbox" id="c-36039119" checked=""/><div class="controls bullet"><span class="by">teruakohatu</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36040195">prev</a><span>|</span><a href="#36039629">next</a><span>|</span><label class="collapse" for="c-36039119">[-]</label><label class="expand" for="c-36039119">[12 more]</label></div><br/><div class="children"><div class="content">&gt; But what about 32k contexts, or beyond? At some point, as token size increases, the ability of a human to give a highly precise and detailed answer decreases<p>War and Peace is over 580,000 words long. Chapter one is ~2,020 words which encoded for GPT3 is ~2,956 tokens (lots of longer, older words and proper nouns eg. &quot;scarlet-liveried footman&quot; is six tokens), so we might expect the entire book to be ~750,000 tokens long.<p>Many people could reason about the book in its entirety. They would not have an encyclopedic recall of random dates and side characters or be able to quote any passage, but they could perform deep analysis on it.</div><br/><div id="36041334" class="c"><input type="checkbox" id="c-36041334" checked=""/><div class="controls bullet"><span class="by">MuteXR</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36039119">parent</a><span>|</span><a href="#36040070">next</a><span>|</span><label class="collapse" for="c-36041334">[-]</label><label class="expand" for="c-36041334">[1 more]</label></div><br/><div class="children"><div class="content">Realistically, you could not quote a passage from the chapter directly, and you don&#x27;t really need to anyway.<p>Summarizing chapters with the very same LLM and including that as context may very well get you far.</div><br/></div></div><div id="36040070" class="c"><input type="checkbox" id="c-36040070" checked=""/><div class="controls bullet"><span class="by">dcl</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36039119">parent</a><span>|</span><a href="#36041334">prev</a><span>|</span><a href="#36040756">next</a><span>|</span><label class="collapse" for="c-36040070">[-]</label><label class="expand" for="c-36040070">[9 more]</label></div><br/><div class="children"><div class="content">Similarly, consider a series like A Song of Ice and Fire. A human reader is still consciously aware of (and waiting for) the answers to questions raised in the very first book. This is millions of tokens ago, and that&#x27;s if our brains turn off when not reading the books.<p>I think this highlights a hurdle on the path to more human-like AGI. We keep track of so much stuff for very long periods of time, albeit perhaps with some loss of fidelity.<p>My guess is that there will need to be an advancement or two before we can can get an AI to read all of the ASIOF books so far and ask &quot;What really happened at the Tower of Joy?&quot;</div><br/><div id="36041284" class="c"><input type="checkbox" id="c-36041284" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040070">parent</a><span>|</span><a href="#36040544">next</a><span>|</span><label class="collapse" for="c-36041284">[-]</label><label class="expand" for="c-36041284">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Similarly, consider a series like A Song of Ice and Fire. A human reader is still consciously aware of (and waiting for) the answers to questions raised in the very first book.</i><p>Some of them, some of the time. This is best comparable with ChatGPT having those books in its training dataset.<p>The context window is more like short-term memory. GPT-4 can fit[0] ~1.5 chapters of <i>Game of Thrones</i>; GPT-4-32k <i>almost six</i>. Making space for prompt, questions and replies, say one chapter for GPT-4, and five chapters for GPT-4-32k.<p>Can you imagine having <i>a whole chapter</i> in your working memory at once? Being simultaneously aware of every word, every space, every comma, every turn of phrase, every character and every plot line mentioned in it - and then being able to take it all into account when answering questions? Humans can do it for a paragraph, a stanza, maybe half a page. Not a whole chapter in a novel. Definitely not <i>five</i>. Not simultaneously at every level.<p>I feel in this sense, LLMs already surpassed our low-level capacity - though the comparison is a bit flawed, since our short-term memory also keeps tracks of sights, sounds, smells, time, etc. and <i>emotions</i>. My point here isn&#x27;t really to compare who has more space for short-term recall - it&#x27;s to point out that answering questions about immediately read text is another <i>narrow, focused task</i> which machines can now do better than us.<p>----<p>[0] - 298000 words in the book (via [1]), over 72 chapters (via [2]), gives us 4139 words per chapter. Multiplying by 4&#x2F;3, we get 5519 tokens per chapter. GPT-4-8k can fit 1.45x that; GPT-4-32k can fit 5.8x that.<p>[1] - <a href="https:&#x2F;&#x2F;blog.fostergrant.co.uk&#x2F;2017&#x2F;08&#x2F;03&#x2F;word-counts-popular-books-world&#x2F;" rel="nofollow">https:&#x2F;&#x2F;blog.fostergrant.co.uk&#x2F;2017&#x2F;08&#x2F;03&#x2F;word-counts-popula...</a><p>[2] - <a href="https:&#x2F;&#x2F;awoiaf.westeros.org&#x2F;index.php&#x2F;Chapters_Table_of_contents" rel="nofollow">https:&#x2F;&#x2F;awoiaf.westeros.org&#x2F;index.php&#x2F;Chapters_Table_of_cont...</a></div><br/></div></div><div id="36040544" class="c"><input type="checkbox" id="c-36040544" checked=""/><div class="controls bullet"><span class="by">danielbln</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040070">parent</a><span>|</span><a href="#36041284">prev</a><span>|</span><a href="#36040347">next</a><span>|</span><label class="collapse" for="c-36040544">[-]</label><label class="expand" for="c-36040544">[2 more]</label></div><br/><div class="children"><div class="content">Some loss to fidelity? Our memories are hugely lossy, reconstructed at recall based on a bunch of concepts. It&#x27;s great, but it&#x27;s also very lossy.</div><br/><div id="36041194" class="c"><input type="checkbox" id="c-36041194" checked=""/><div class="controls bullet"><span class="by">dcl</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040544">parent</a><span>|</span><a href="#36040347">next</a><span>|</span><label class="collapse" for="c-36041194">[-]</label><label class="expand" for="c-36041194">[1 more]</label></div><br/><div class="children"><div class="content">You got me.</div><br/></div></div></div></div><div id="36040347" class="c"><input type="checkbox" id="c-36040347" checked=""/><div class="controls bullet"><span class="by">zamnos</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040070">parent</a><span>|</span><a href="#36040544">prev</a><span>|</span><a href="#36040756">next</a><span>|</span><label class="collapse" for="c-36040347">[-]</label><label class="expand" for="c-36040347">[5 more]</label></div><br/><div class="children"><div class="content">ASIOF spoiler below!<p><i>&gt; At the Tower of Joy, Ned Stark defeated three members of the Kingsguard and discovered his dying sister, Lyanna, who made him promise to protect her son, Jon Snow, whose true parentage remained a closely guarded secret.</i><p>Seems like ChatGPT-3 already knows, unless there&#x27;s a deeper secret that I&#x27;m not deep enough into ASIOF fandom to know.</div><br/><div id="36040652" class="c"><input type="checkbox" id="c-36040652" checked=""/><div class="controls bullet"><span class="by">jokteur</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040347">parent</a><span>|</span><a href="#36040756">next</a><span>|</span><label class="collapse" for="c-36040652">[-]</label><label class="expand" for="c-36040652">[4 more]</label></div><br/><div class="children"><div class="content">But this is becaude ASIOF was in the training dataset. Chatgpt wouldn&#x27;t be able to say anything about this book if it wasn&#x27;t in his dataset, and you wouldn&#x27;t be able to have enough tokens to present the whole book to chatgpt.</div><br/><div id="36041154" class="c"><input type="checkbox" id="c-36041154" checked=""/><div class="controls bullet"><span class="by">dcl</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040652">parent</a><span>|</span><a href="#36040760">next</a><span>|</span><label class="collapse" for="c-36041154">[-]</label><label class="expand" for="c-36041154">[1 more]</label></div><br/><div class="children"><div class="content">Exactly.<p>But also, not just ASIOF is in the training set, but presumably lots of discussion about it and all the interesting events in the book.</div><br/></div></div><div id="36040760" class="c"><input type="checkbox" id="c-36040760" checked=""/><div class="controls bullet"><span class="by">nl</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040652">parent</a><span>|</span><a href="#36041154">prev</a><span>|</span><a href="#36040756">next</a><span>|</span><label class="collapse" for="c-36040760">[-]</label><label class="expand" for="c-36040760">[2 more]</label></div><br/><div class="children"><div class="content">Thinking of it as &quot;the training dataset&quot; vs &quot;the context window&quot; is the wrong way of looking at it.<p>There&#x27;s a bunch of prior art for adaption techniques for getting new data into a trained model (fine tuning, RLHF etc). There&#x27;s no real reason to think there won&#x27;t be more techniques that turn what think of now as the context window into something that alters the weights in the model and is serialized back to disk.</div><br/><div id="36041189" class="c"><input type="checkbox" id="c-36041189" checked=""/><div class="controls bullet"><span class="by">dcl</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040760">parent</a><span>|</span><a href="#36040756">next</a><span>|</span><label class="collapse" for="c-36041189">[-]</label><label class="expand" for="c-36041189">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a reasonable way to look at it given that&#x27;s how pretty much all &#x27;deployed&#x27; versions of LLM&#x27;s work?</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36040756" class="c"><input type="checkbox" id="c-36040756" checked=""/><div class="controls bullet"><span class="by">TheFragenTaken</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36039119">parent</a><span>|</span><a href="#36040070">prev</a><span>|</span><a href="#36039629">next</a><span>|</span><label class="collapse" for="c-36040756">[-]</label><label class="expand" for="c-36040756">[1 more]</label></div><br/><div class="children"><div class="content">&quot;The Magical Number Seven, Plus or Minus Two&quot; [1] applies to many things. In this case, a book, could reasonably be reasoned about almost no matter the length as you argue, given the scope of a book is usually limited to a few topics (the French invasion of Russia). Similarly three to seven chapters could be retold, but not every 361 chapters. A &quot;580,000&quot; word long book about 58,000 things would be unfeasible for a human, but probably feasible for an LLM with a 580k context.<p>That in essence, I believe, is the difference. An LLM (while still predicting the next word, given it&#x27;s context), seem to care less about the number of subjects in a given context, than humans do.<p>[1]: <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Magical_Number_Seven,_Plus_or_Minus_Two" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Magical_Number_Seven,_Plus...</a></div><br/></div></div></div></div><div id="36039629" class="c"><input type="checkbox" id="c-36039629" checked=""/><div class="controls bullet"><span class="by">mlsu</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36039119">prev</a><span>|</span><a href="#36039490">next</a><span>|</span><label class="collapse" for="c-36039629">[-]</label><label class="expand" for="c-36039629">[5 more]</label></div><br/><div class="children"><div class="content">These things are very different from the human mind. With your mind, you read the words one by one, building up intuition as you go. As part of that, there&#x27;s a kind of continuous synthesis of information. The synthesis is highly temporal, because as you go you are training, and the hardware is changing (your emotions, dictated by your stomach or the sound you can hear or...) underneath you.<p>These things are very different. The mental model I have is that they put the entire book into a big hypercube and then *flash*, instantly, out comes the next token. And likewise, when they encounter text that is 8001 tokens long, token #1 is completely erased, gone, like it never existed.</div><br/><div id="36040181" class="c"><input type="checkbox" id="c-36040181" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36039629">parent</a><span>|</span><a href="#36039490">next</a><span>|</span><label class="collapse" for="c-36040181">[-]</label><label class="expand" for="c-36040181">[4 more]</label></div><br/><div class="children"><div class="content">&gt; These things are very different from the human mind. With your mind, you read the words one by one, building up intuition as you go.<p>You&#x27;re confusing your <i>perception</i> of how your mind works with how your mind <i>actually</i> works.<p>Simply put, we have no idea how the human mind works. For all we know, its underlying principles could be very similar to LLMs, or they could be something nobody has thought of yet. But under no circumstances is human intuition about the human mind a reliable indicator for what is actually going on.<p>This is like asking ChatGPT why it came up with a specific response. It will give you an answer, of course, but that answer is generated the same way all its answers are – ChatGPT doesn&#x27;t suddenly turn on a magic &quot;introspection mode&quot; that allows it to examine its internals. And there&#x27;s no reason to assume that humans have such an introspection mode either. In fact, many results from experimental psychology seem to indicate that humans don&#x27;t understand their own mental operations at all.</div><br/><div id="36040442" class="c"><input type="checkbox" id="c-36040442" checked=""/><div class="controls bullet"><span class="by">anon373839</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040181">parent</a><span>|</span><a href="#36039490">next</a><span>|</span><label class="collapse" for="c-36040442">[-]</label><label class="expand" for="c-36040442">[3 more]</label></div><br/><div class="children"><div class="content">While it&#x27;s true that we may not be able to observe the elemental building blocks of our own minds, metacognition is a real capability that people have and use.</div><br/><div id="36040579" class="c"><input type="checkbox" id="c-36040579" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040442">parent</a><span>|</span><a href="#36039490">next</a><span>|</span><label class="collapse" for="c-36040579">[-]</label><label class="expand" for="c-36040579">[2 more]</label></div><br/><div class="children"><div class="content">Is there any hard evidence that &quot;metacognition&quot; reflects actual cognitive processes, rather than being something that the mind pulls out of its ass?</div><br/><div id="36040744" class="c"><input type="checkbox" id="c-36040744" checked=""/><div class="controls bullet"><span class="by">heja2009</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36040579">parent</a><span>|</span><a href="#36039490">next</a><span>|</span><label class="collapse" for="c-36040744">[-]</label><label class="expand" for="c-36040744">[1 more]</label></div><br/><div class="children"><div class="content">To the contrary there is very good evidence that we pull arbitrary explanations whenever needed. See Gazzaniga&#x27;s split brain experiments where people gave all sorts of reasons when asked why they did something and just could not know.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="36039490" class="c"><input type="checkbox" id="c-36039490" checked=""/><div class="controls bullet"><span class="by">chaxor</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36039629">prev</a><span>|</span><a href="#36039080">next</a><span>|</span><label class="collapse" for="c-36039490">[-]</label><label class="expand" for="c-36039490">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;ll give a very simplistic answer to your question and skirt some detail.
Essentially, Transformers can &#x27;look at&#x27; everything within the context with perfect fidelity (only one &#x27;hop&#x27; between tokens to &#x27;get the info&#x27;), while RNNs struggle with this because the information gets &#x27;muddied&#x27; with all of the tokens in between.  Like telephone between you and one friend (transformer) vs you and a sea of people (RNN).<p>Hopefully this gets the point across without the mathematics and a precise description.</div><br/><div id="36039683" class="c"><input type="checkbox" id="c-36039683" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36039490">parent</a><span>|</span><a href="#36039080">next</a><span>|</span><label class="collapse" for="c-36039683">[-]</label><label class="expand" for="c-36039683">[2 more]</label></div><br/><div class="children"><div class="content">Yea using the analogy of the eyes can see the entire document<p>Vs<p>I need to memorise everything as it’s spoken out, and then answer on it<p>Is a good approximate on the difference.<p>The kicker though as people pointed out, there are individuals on earth who can memorise things to great length. So the same will apply here (need more training)<p>It’s also why it is recommended by the community to ask the question first, then put your context document. In a document QnA task</div><br/><div id="36040405" class="c"><input type="checkbox" id="c-36040405" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36039683">parent</a><span>|</span><a href="#36039080">next</a><span>|</span><label class="collapse" for="c-36040405">[-]</label><label class="expand" for="c-36040405">[1 more]</label></div><br/><div class="children"><div class="content">In the shower today I was thinking about Jungian archetypes as a visual programming language for the subconscious.<p>For example, if someone says, &quot;I should be a better mother&quot;, and hold this impression in their mind over time, the associations their brain makes with that image and various behaviors can be used as a guiding force during the physical reorganization which occurs when one creates a new habit, or adjusts a behavior or muscle memory.<p>And these associations depend upon observations made by the individual, which they have either been taught or innately know can be categorized as mother-like. The brain is typically trained to make this association in the case of the mother by mirroring and attaching to the first female who exhibits nursing behavior. These archetypes are a visual representation of deeper mental models which we are primed to carry on between generations.<p>And then I wondered how this might apply to neural models, if some system of archetypes naturally emerges, if they&#x27;re useful for programming or memorization&#x2F;compression, or how we might explore imbuing existing models with an archetypical system.</div><br/></div></div></div></div></div></div><div id="36039080" class="c"><input type="checkbox" id="c-36039080" checked=""/><div class="controls bullet"><span class="by">humbleharbinger</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36039490">prev</a><span>|</span><a href="#36039122">next</a><span>|</span><label class="collapse" for="c-36039080">[-]</label><label class="expand" for="c-36039080">[2 more]</label></div><br/><div class="children"><div class="content">Not sure if it answers your question but the paper notes something similar in its discussion of limitations:<p>&gt; the linear attention of RWKV
leads to significant efficiency gains but still, it may
also limit the model’s performance on tasks that
require recalling minutiae information over very
long contexts. This is due to the funneling of information through a single vector representation
over many time steps, compared with the full information maintained by the quadratic attention of
standard Transformers. In other words, the model’s
recurrent architecture inherently limits its ability to
“look back” at previous tokens, as opposed to traditional self-attention mechanisms. While learned
time decay helps prevent the loss of information,
it is mechanistically limited compared to full self-
attention.<p>&gt; Another limitation of this work is the increased
importance of prompt engineering in comparison to
standard Transformer models. The linear attention
mechanism used in RWKV limits the information
from the prompt that will be carried over to the
model’s continuation. As a result, carefully designed prompts may be even more crucial for the
model to perform well on tasks</div><br/><div id="36040789" class="c"><input type="checkbox" id="c-36040789" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36039080">parent</a><span>|</span><a href="#36039122">next</a><span>|</span><label class="collapse" for="c-36040789">[-]</label><label class="expand" for="c-36040789">[1 more]</label></div><br/><div class="children"><div class="content">Prompt design is definitely a huge one shifting to rwkv<p>Sadly too many folks copy and paste what works for openAI and move on when it fails</div><br/></div></div></div></div><div id="36039122" class="c"><input type="checkbox" id="c-36039122" checked=""/><div class="controls bullet"><span class="by">Buttons840</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36039080">prev</a><span>|</span><a href="#36039520">next</a><span>|</span><label class="collapse" for="c-36039122">[-]</label><label class="expand" for="c-36039122">[1 more]</label></div><br/><div class="children"><div class="content">To answer your question: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35904773" rel="nofollow">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35904773</a><p>&gt; we loaded the entire text of The Great Gatsby into Claude-Instant (72K tokens) and modified one line to say Mr. Carraway was “a software engineer that works on machine learning tooling at Anthropic.” When we asked the model to spot what was different, it responded with the correct answer in 22 seconds.</div><br/></div></div><div id="36039520" class="c"><input type="checkbox" id="c-36039520" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36039122">prev</a><span>|</span><a href="#36039128">next</a><span>|</span><label class="collapse" for="c-36039520">[-]</label><label class="expand" for="c-36039520">[1 more]</label></div><br/><div class="children"><div class="content">One of the biggest issue with incredibly large context sizes is the lack of training &#x2F; dataset meant specifically to use such large context sizes.<p>And this apply to all models. So when a specific model now does badly even at 32k or 50k it’s hard to say if it’s an architecture design issue, or a dataset issue</div><br/></div></div><div id="36039128" class="c"><input type="checkbox" id="c-36039128" checked=""/><div class="controls bullet"><span class="by">noduerme</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36039520">prev</a><span>|</span><a href="#36039898">next</a><span>|</span><label class="collapse" for="c-36039128">[-]</label><label class="expand" for="c-36039128">[2 more]</label></div><br/><div class="children"><div class="content">I know a guy who memorized &quot;Fahrenheit 451&quot; back in the &#x27;60s, and went on to memorize a dozen other books - I think it was a requirement of the anti-establishment cult he was in at the time. Anyhow, his recall is still pretty fantastic.</div><br/><div id="36039986" class="c"><input type="checkbox" id="c-36039986" checked=""/><div class="controls bullet"><span class="by">tanseydavid</span><span>|</span><a href="#36039049">root</a><span>|</span><a href="#36039128">parent</a><span>|</span><a href="#36039898">next</a><span>|</span><label class="collapse" for="c-36039986">[-]</label><label class="expand" for="c-36039986">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like your friend was sort of the Charles Babbage of Large Language Models.</div><br/></div></div></div></div><div id="36039898" class="c"><input type="checkbox" id="c-36039898" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36039128">prev</a><span>|</span><a href="#36039851">next</a><span>|</span><label class="collapse" for="c-36039898">[-]</label><label class="expand" for="c-36039898">[1 more]</label></div><br/><div class="children"><div class="content">Taking into account the limits of how much can be stored in a hidden state.<p>My theory is that the model will start generalising the information stored once it starts going past its limits (like real life humans)<p>So if we take books as an example, we probably do not remember every single word. But we might vaguely remember which section or book events occur<p>Combine this with the agent model, and we may have an alternative for embeddings. Where we can ask which pages the model recall is relevant to the question. Bring those pages up again. And get the answers<p>(Once again like how a human might answer in real life)</div><br/></div></div><div id="36039851" class="c"><input type="checkbox" id="c-36039851" checked=""/><div class="controls bullet"><span class="by">thomasahle</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36039898">prev</a><span>|</span><a href="#36039107">next</a><span>|</span><label class="collapse" for="c-36039851">[-]</label><label class="expand" for="c-36039851">[1 more]</label></div><br/><div class="children"><div class="content">&gt; One thing I&#x27;m keen to understand is: how well does attention hold across huge context sizes, with respect to the usual transformer models, and also these proposed RNN models?<p>We won&#x27;t know before we&#x27;ve tried it. Reasoning by analogy with humans is not useful. In a year we&#x27;ll have tried lots of things and can give a much better answer.</div><br/></div></div><div id="36039107" class="c"><input type="checkbox" id="c-36039107" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#36039049">parent</a><span>|</span><a href="#36039851">prev</a><span>|</span><a href="#36039215">next</a><span>|</span><label class="collapse" for="c-36039107">[-]</label><label class="expand" for="c-36039107">[1 more]</label></div><br/><div class="children"><div class="content">The primary benefit of transformers is that they generally can reference things within the context, but RNNs have trouble with that. The trade off is that transformers have memory and compute requirements quadratic in the context length.</div><br/></div></div></div></div><div id="36039215" class="c"><input type="checkbox" id="c-36039215" checked=""/><div class="controls bullet"><span class="by">noduerme</span><span>|</span><a href="#36039049">prev</a><span>|</span><a href="#36040956">next</a><span>|</span><label class="collapse" for="c-36039215">[-]</label><label class="expand" for="c-36039215">[6 more]</label></div><br/><div class="children"><div class="content">I wrote a home-brew neural network around 2006, just to see what would happen. I&#x27;d read no papers on it, and just kind of made it up as I went along. The result was basically a cube of &quot;neurons&quot; which had stronger and weaker trigger points to their neighbors and would propagate &quot;spark&quot; to one or more neighbors based on the strength and direction of spark they got from their other neighbors. Each of the connections and weights had a &quot;certainty&quot; attached to it which would go up when the output was closer to the ideal and would go down when the output was garbage. When those certainty values hit zero, the weights for that neuron would be re-randomized. I quickly realized that the only thing this could really do was try to transform one 10x10 pixel bitmap into a different one. But it was fascinating that it actually seemed to &quot;learn&quot; patterns as they got baked in.<p>What would be called &quot;attention&quot; now, though, basically didn&#x27;t exist in that system. Once you started training it on something new it lost everything.<p>For anyone wondering, it was written in Actionscript 3, and ridiculously, each neuron was bound to a display class that displayed as a semitransparent cube that lit up as the inputs propagated through them. A thoroughly ridiculous side project.<p>But other than scaling that from 1000 neurons to billions, I&#x27;m curious what has changed about the concepts of pathing or tolerance to make these models better? Maybe my concept of the principle behind modern LLMs is too archaic or rooted in a cartoon understanding of our own wetware that I tried to reproduce.<p>[edit: I&#x27;m describing an ancient home project... for anyone downvoting this, I&#x27;m more than receptive to hearing your reasons why it&#x27;s stupid. I&#x27;m the first to admit it seems stupid!]</div><br/><div id="36039756" class="c"><input type="checkbox" id="c-36039756" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039215">parent</a><span>|</span><a href="#36040084">next</a><span>|</span><label class="collapse" for="c-36039756">[-]</label><label class="expand" for="c-36039756">[1 more]</label></div><br/><div class="children"><div class="content">A large percent of the RWKV community ain’t experts. And are here doing weird, dumb or crazy homebrew experiments<p>So keep doing weird experiments</div><br/></div></div><div id="36040084" class="c"><input type="checkbox" id="c-36040084" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#36039215">parent</a><span>|</span><a href="#36039756">prev</a><span>|</span><a href="#36039237">next</a><span>|</span><label class="collapse" for="c-36040084">[-]</label><label class="expand" for="c-36040084">[2 more]</label></div><br/><div class="children"><div class="content">&gt; But other than scaling that from 1000 neurons to billions, I&#x27;m curious what has changed about the concepts of pathing or tolerance to make these models better? Maybe my concept of the principle behind modern LLMs is too archaic or rooted in a cartoon understanding of our own wetware that I tried to reproduce.<p>Realastically... the problem is a data problem. The math is mostly there. Transformers et al would have been figured out in no time had we had the sort of data tools we have today. I&#x27;m talking about the ease with which you can take gigabytes of data, throw it in S3, and analyze it in minutes.<p>That, combined with cheap and accessible compute (cloud) and the maturation of CUDA meant it was all a matter of time before this took place.</div><br/><div id="36040208" class="c"><input type="checkbox" id="c-36040208" checked=""/><div class="controls bullet"><span class="by">cypress66</span><span>|</span><a href="#36039215">root</a><span>|</span><a href="#36040084">parent</a><span>|</span><a href="#36039237">next</a><span>|</span><label class="collapse" for="c-36040208">[-]</label><label class="expand" for="c-36040208">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Transformers et al would have been figured out in no time had we had the sort of data tools we have today.<p>I disagree. Even things that seem obvious in retrospect, take some time to be figured out.<p>Resnets, batch norm, dropout, etc are examples of this.<p>And I don&#x27;t think transformers are obvious.</div><br/></div></div></div></div><div id="36039237" class="c"><input type="checkbox" id="c-36039237" checked=""/><div class="controls bullet"><span class="by">cma</span><span>|</span><a href="#36039215">parent</a><span>|</span><a href="#36040084">prev</a><span>|</span><a href="#36040956">next</a><span>|</span><label class="collapse" for="c-36039237">[-]</label><label class="expand" for="c-36039237">[2 more]</label></div><br/><div class="children"><div class="content">What determined whether it&#x27;s output was &quot;ideal&quot; for the certainty measure to go off of?  Backprop?</div><br/><div id="36039277" class="c"><input type="checkbox" id="c-36039277" checked=""/><div class="controls bullet"><span class="by">noduerme</span><span>|</span><a href="#36039215">root</a><span>|</span><a href="#36039237">parent</a><span>|</span><a href="#36040956">next</a><span>|</span><label class="collapse" for="c-36039277">[-]</label><label class="expand" for="c-36039277">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d need to go back and look at the code, but it was something primitive but similar to backprop. There was an evaluation routine that compared what lit up on the back of the cube to the desired output. The farther off it was, the more the certainty got docked from any of the [connected] neurons one layer up from the bad pixel, and that dragged down the certainties on the next layer and so on. It didn&#x27;t have the ability to back check which neurons were involved in which specific output node. But I guess it was a scatter shot attempt at that.</div><br/></div></div></div></div></div></div><div id="36040956" class="c"><input type="checkbox" id="c-36040956" checked=""/><div class="controls bullet"><span class="by">chrgy</span><span>|</span><a href="#36039215">prev</a><span>|</span><a href="#36040690">next</a><span>|</span><label class="collapse" for="c-36040956">[-]</label><label class="expand" for="c-36040956">[1 more]</label></div><br/><div class="children"><div class="content">Here is a summary of all comments by Transformers, wonder how RNN does:<p>RWKV is a new language model architecture that is comparable to transformers in terms of performance.
RWKV is more efficient than transformers, which makes it possible to train larger models on smaller datasets.
The RWKV community is open source and welcomes contributions from anyone.
There are plans to create larger versions of RWKV, but this will require more computational resources.
Here are some additional details about the chinchilla law and the dataset problem:<p>The chinchilla law states that the amount of data required to train a language model grows exponentially with the model size.
This means that it is very expensive to train large language models, even with the latest hardware.
The RWKV community is working on developing new methods for training large language models more efficiently.
There are a number of datasets available to the RWKV community, including:<p>The Pile: A massive dataset of text and code.
The Chinchilla: A smaller dataset of text and code that is designed for training RWKV models.
The Red Pajamas: A dataset of text and code that is being used to train a 65B RWKV model.
These datasets are stored in a variety of locations, including:<p>The RWKV GitHub repository
The Chinchilla website
The Red Pajamas website
The RWKV community is constantly updating the datasets and adding new ones. If you are interested in contributing, please visit the RWKV GitHub repository.</div><br/></div></div><div id="36040690" class="c"><input type="checkbox" id="c-36040690" checked=""/><div class="controls bullet"><span class="by">hiddencost</span><span>|</span><a href="#36040956">prev</a><span>|</span><a href="#36040966">next</a><span>|</span><label class="collapse" for="c-36040690">[-]</label><label class="expand" for="c-36040690">[1 more]</label></div><br/><div class="children"><div class="content">EleutherAI is stunning. The only other papers I&#x27;ve seen with such a diversity of institutions are high energy particle physics.</div><br/></div></div><div id="36040966" class="c"><input type="checkbox" id="c-36040966" checked=""/><div class="controls bullet"><span class="by">zwaps</span><span>|</span><a href="#36040690">prev</a><span>|</span><a href="#36039510">next</a><span>|</span><label class="collapse" for="c-36040966">[-]</label><label class="expand" for="c-36040966">[2 more]</label></div><br/><div class="children"><div class="content">I wish this was written with more care. None of the symbols are defined.<p>Worst of all, they use &quot;channel dimension&quot; in a sequence model. What even is a channel in a sequence of tokens? 
This happens as soon as you have a single person with CNN background on the team and it makes zero sense.
What if you actually have channels in your data? What then?</div><br/><div id="36041280" class="c"><input type="checkbox" id="c-36041280" checked=""/><div class="controls bullet"><span class="by">sorz</span><span>|</span><a href="#36040966">parent</a><span>|</span><a href="#36039510">next</a><span>|</span><label class="collapse" for="c-36041280">[-]</label><label class="expand" for="c-36041280">[1 more]</label></div><br/><div class="children"><div class="content">They said the paper is still working in progress and will improve it.<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;AiEleuther&#x2F;status&#x2F;1660811180901019648" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;AiEleuther&#x2F;status&#x2F;1660811180901019648</a></div><br/></div></div></div></div><div id="36039510" class="c"><input type="checkbox" id="c-36039510" checked=""/><div class="controls bullet"><span class="by">stellaathena</span><span>|</span><a href="#36040966">prev</a><span>|</span><a href="#36039148">next</a><span>|</span><label class="collapse" for="c-36039510">[-]</label><label class="expand" for="c-36039510">[1 more]</label></div><br/><div class="children"><div class="content">Twitter thread announcing the paper with some additional color commentary: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;AiEleuther&#x2F;status&#x2F;1660811179239849986" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;AiEleuther&#x2F;status&#x2F;1660811179239849986</a></div><br/></div></div><div id="36039148" class="c"><input type="checkbox" id="c-36039148" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#36039510">prev</a><span>|</span><a href="#36039214">next</a><span>|</span><label class="collapse" for="c-36039148">[-]</label><label class="expand" for="c-36039148">[1 more]</label></div><br/><div class="children"><div class="content">See also, ChatRWKV, an open source LLM powered by RWKV instead of transformers.<p><a href="https:&#x2F;&#x2F;github.com&#x2F;BlinkDL&#x2F;ChatRWKV">https:&#x2F;&#x2F;github.com&#x2F;BlinkDL&#x2F;ChatRWKV</a></div><br/></div></div><div id="36039214" class="c"><input type="checkbox" id="c-36039214" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039148">prev</a><span>|</span><a href="#36038995">next</a><span>|</span><label class="collapse" for="c-36039214">[-]</label><label class="expand" for="c-36039214">[33 more]</label></div><br/><div class="children"><div class="content">Hi Everyone,<p>I&#x27;m a regular involved with the RWKV community.<p>AMA, on RWKV, and I will do my best to answer them here for the next hour (one at a time)<p>PS: you can find our discord here : <a href="https:&#x2F;&#x2F;discord.gg&#x2F;qt9egFA7ve" rel="nofollow">https:&#x2F;&#x2F;discord.gg&#x2F;qt9egFA7ve</a></div><br/><div id="36039507" class="c"><input type="checkbox" id="c-36039507" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36039214">parent</a><span>|</span><a href="#36039330">next</a><span>|</span><label class="collapse" for="c-36039507">[-]</label><label class="expand" for="c-36039507">[2 more]</label></div><br/><div class="children"><div class="content">Do you think there could be a kind of universality principle at work here, where once you make a good enough architecture then the details don&#x27;t matter so much compared to the model size and training flops and dataset size? In other words, maybe it wasn&#x27;t a coincidence that your architecture worked about as well as the transformer architecture?</div><br/><div id="36039572" class="c"><input type="checkbox" id="c-36039572" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039507">parent</a><span>|</span><a href="#36039330">next</a><span>|</span><label class="collapse" for="c-36039572">[-]</label><label class="expand" for="c-36039572">[1 more]</label></div><br/><div class="children"><div class="content">There is a reasonable argument for that (heard the idea go around between multiple AI engineers, that once you go past a certain scale, it does not matter for its evals)<p>One of the biggest issue for testing all of this, is it takes a crap ton of GPUs to prove all the alternatives to transformers beyond 1B param.<p>For example I’m waiting for someone to do a 1B-14B text based diffusion network<p>Finally, if this is truely the case (and all that really matter is size+dataset)<p>We really should use an architecture that is cheaper to train and run. And that’s what RWKV represents here<p>You can even run the 7B quantized model reasonably on most laptops (try the rwkv-cpp &#x2F; rwkv-cpp-node project)</div><br/></div></div></div></div><div id="36039330" class="c"><input type="checkbox" id="c-36039330" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36039214">parent</a><span>|</span><a href="#36039507">prev</a><span>|</span><a href="#36040841">next</a><span>|</span><label class="collapse" for="c-36039330">[-]</label><label class="expand" for="c-36039330">[8 more]</label></div><br/><div class="children"><div class="content">The paper says it&#x27;s comparable to transformers right now but that means that it might be better later. Do you guys have concrete plans to make it better? Are they secret? Also, what&#x27;s the deal with that foundation? Is it a cult or like the new OpenAI that will turn closed or maybe it&#x27;s to reap the value of random contributors to the project?</div><br/><div id="36039411" class="c"><input type="checkbox" id="c-36039411" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039330">parent</a><span>|</span><a href="#36039402">next</a><span>|</span><label class="collapse" for="c-36039411">[-]</label><label class="expand" for="c-36039411">[6 more]</label></div><br/><div class="children"><div class="content">Completely the opposite.<p>- it is NOT backed directly or owned by any VC funded company<p>- it is 100% OSS driven by the community (Apache 2 license)<p>- it’s currently the top OSS chat model that can be used commercially on the chatbot arena score board<p>- IMO it is undertrained, so expanding the training data alone will make it much better (however for the sake of this paper, we wanted to focus on architecture not training data, so we compared similarly trained models)<p>And yes we do have multiple experiments and plans to make it better. It’s a list, and we will not know which is final until we try. Individual members can go to great lengths on what they are working on<p>For better or worse, being truly OSS means our initiatives are more disorganized then a centrally planned org</div><br/><div id="36039882" class="c"><input type="checkbox" id="c-36039882" checked=""/><div class="controls bullet"><span class="by">redox99</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039411">parent</a><span>|</span><a href="#36039504">next</a><span>|</span><label class="collapse" for="c-36039882">[-]</label><label class="expand" for="c-36039882">[2 more]</label></div><br/><div class="children"><div class="content">&gt; it’s currently the top OSS chat model that can be used commercially on the chatbot arena score board<p>To be fair, that filters the majority of models in the scoreboard.</div><br/><div id="36040422" class="c"><input type="checkbox" id="c-36040422" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039882">parent</a><span>|</span><a href="#36039504">next</a><span>|</span><label class="collapse" for="c-36040422">[-]</label><label class="expand" for="c-36040422">[1 more]</label></div><br/><div class="children"><div class="content">Dun we all wish this wasn’t the case?<p>Where we have more OSS models to choose from without weird rule lawyering gotchas. Or needing to be from a research institute &#x2F; a license to download the weights</div><br/></div></div></div></div><div id="36039504" class="c"><input type="checkbox" id="c-36039504" checked=""/><div class="controls bullet"><span class="by">bluepoint</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039411">parent</a><span>|</span><a href="#36039882">prev</a><span>|</span><a href="#36039402">next</a><span>|</span><label class="collapse" for="c-36039504">[-]</label><label class="expand" for="c-36039504">[3 more]</label></div><br/><div class="children"><div class="content">Can beginners without money with by PhDs, contribute? If so what would be the best way to start?</div><br/><div id="36039600" class="c"><input type="checkbox" id="c-36039600" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039504">parent</a><span>|</span><a href="#36039542">next</a><span>|</span><label class="collapse" for="c-36039600">[-]</label><label class="expand" for="c-36039600">[1 more]</label></div><br/><div class="children"><div class="content">There are lots of really low hanging fruits<p>- integrating this with AI platform X&#x2F;Y&#x2F;Z<p>- setting up evals<p>- improving the code quality<p>- making a how to guide (it’s stuck on my todo list)<p>- helping with dataset<p>- doing silly experiments on how the architecture work (and if the changes give good result)<p>- etc etc<p>One of the community goals is to make this a model for EVERYONE on earth that means we need quality dataset for all the non English languages<p>So even on that level there are things to do<p>( find something that interest you on the community )</div><br/></div></div><div id="36039542" class="c"><input type="checkbox" id="c-36039542" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039504">parent</a><span>|</span><a href="#36039600">prev</a><span>|</span><a href="#36039402">next</a><span>|</span><label class="collapse" for="c-36039542">[-]</label><label class="expand" for="c-36039542">[1 more]</label></div><br/><div class="children"><div class="content">i would guess, go to their discord. also they put their github so you could fix a bug in their github.</div><br/></div></div></div></div></div></div><div id="36039402" class="c"><input type="checkbox" id="c-36039402" checked=""/><div class="controls bullet"><span class="by">FallDead</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039330">parent</a><span>|</span><a href="#36039411">prev</a><span>|</span><a href="#36040841">next</a><span>|</span><label class="collapse" for="c-36039402">[-]</label><label class="expand" for="c-36039402">[1 more]</label></div><br/><div class="children"><div class="content">(Note: My comments do not represent or project those of my collaborators)
I remember talking to Blink DL about this, I think the plan is just to build an ecosystem, provide more diversity in the DL space. There are plans to make a RWKV5, they are in the open in the RWKV5 channel. From an engineering standpoint I don&#x27;t really see the &quot;reap&quot; the value of random contributors to the project. Most of us I believe ... are hackers and tinkerers that just want to learn and contribute and be apart of something that can change the current</div><br/></div></div></div></div><div id="36040841" class="c"><input type="checkbox" id="c-36040841" checked=""/><div class="controls bullet"><span class="by">lukeplato</span><span>|</span><a href="#36039214">parent</a><span>|</span><a href="#36039330">prev</a><span>|</span><a href="#36039761">next</a><span>|</span><label class="collapse" for="c-36040841">[-]</label><label class="expand" for="c-36040841">[2 more]</label></div><br/><div class="children"><div class="content">Is there any potential improvements over transformers for interpretablity or alignment?</div><br/><div id="36041213" class="c"><input type="checkbox" id="c-36041213" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040841">parent</a><span>|</span><a href="#36039761">next</a><span>|</span><label class="collapse" for="c-36041213">[-]</label><label class="expand" for="c-36041213">[1 more]</label></div><br/><div class="children"><div class="content">For anything past 8k context size<p>We are talking about over 10x reduction in GPU time for inferencing tokens and for training too<p>Aka it’s cheaper and faster<p>Alignment is frankly IMO purely a dataset design and training issue. And has nothing to do with the model</div><br/></div></div></div></div><div id="36039761" class="c"><input type="checkbox" id="c-36039761" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#36039214">parent</a><span>|</span><a href="#36040841">prev</a><span>|</span><a href="#36040091">next</a><span>|</span><label class="collapse" for="c-36039761">[-]</label><label class="expand" for="c-36039761">[11 more]</label></div><br/><div class="children"><div class="content">Are there currently any plans to create a RWKV 30B or 65B? That seems to be the size at which the LLaMA transformer models become genuinely competitive with GPT3.5 for many tasks.</div><br/><div id="36039845" class="c"><input type="checkbox" id="c-36039845" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039761">parent</a><span>|</span><a href="#36040091">next</a><span>|</span><label class="collapse" for="c-36039845">[-]</label><label class="expand" for="c-36039845">[10 more]</label></div><br/><div class="children"><div class="content">TLDR: please donate A100s to make this happen<p>Most of the focus is in the 1-14B range. Due to constraints of the dataset sizes (chinchilla law), and GPUs available<p>Community demand is also mostly in this range as there is a strong desire to optimise and run on local GPU. So more focus is in this range.<p>Not representing blink directly here - but if anyone wants to see a 30B &#x2F; 65B model. Reach out to contribute the GPUs required to make it happen<p>The code is already there, just need someone to run it,<p>Ps: I too am personally interested in how it will perform at ~60B, which I believe will be to be optimal model size for higher level of thoughts (this number is based on intuition not research)</div><br/><div id="36039871" class="c"><input type="checkbox" id="c-36039871" checked=""/><div class="controls bullet"><span class="by">ianbutler</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039845">parent</a><span>|</span><a href="#36039895">next</a><span>|</span><label class="collapse" for="c-36039871">[-]</label><label class="expand" for="c-36039871">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;twitter.com&#x2F;boborado&#x2F;status&#x2F;1659608452849897472" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;boborado&#x2F;status&#x2F;1659608452849897472</a><p>You might find that thread interesting, they&#x27;re taking submissions for potential partnership with LambdaLabs a cloud compute company that has a few hundred H100s laying around. They have an open form and their cofounder is currently doing the rounds having meetings and this may be a good candidate.<p>I&#x27;m not associated with them at all, just interested in the space and things going on.</div><br/></div></div><div id="36039895" class="c"><input type="checkbox" id="c-36039895" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039845">parent</a><span>|</span><a href="#36039871">prev</a><span>|</span><a href="#36040091">next</a><span>|</span><label class="collapse" for="c-36039895">[-]</label><label class="expand" for="c-36039895">[8 more]</label></div><br/><div class="children"><div class="content">Are there any estimates anywhere of how many A100s would be needed to e.g. train a 30B model in 6 months?</div><br/><div id="36039922" class="c"><input type="checkbox" id="c-36039922" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039895">parent</a><span>|</span><a href="#36040091">next</a><span>|</span><label class="collapse" for="c-36039922">[-]</label><label class="expand" for="c-36039922">[7 more]</label></div><br/><div class="children"><div class="content">That’s a loaded question without deciding dataset size</div><br/><div id="36040556" class="c"><input type="checkbox" id="c-36040556" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039922">parent</a><span>|</span><a href="#36039976">next</a><span>|</span><label class="collapse" for="c-36040556">[-]</label><label class="expand" for="c-36040556">[4 more]</label></div><br/><div class="children"><div class="content">Would it be possible to just use the exact same dataset as LLaMA? (There&#x27;s an open source project currently training a transformer on exactly that).</div><br/><div id="36040677" class="c"><input type="checkbox" id="c-36040677" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040556">parent</a><span>|</span><a href="#36039976">next</a><span>|</span><label class="collapse" for="c-36040677">[-]</label><label class="expand" for="c-36040677">[3 more]</label></div><br/><div class="children"><div class="content">You mean red pajama? I believe that has already started for 1-14B (need to double check)</div><br/><div id="36040752" class="c"><input type="checkbox" id="c-36040752" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040677">parent</a><span>|</span><a href="#36039976">next</a><span>|</span><label class="collapse" for="c-36040752">[-]</label><label class="expand" for="c-36040752">[2 more]</label></div><br/><div class="children"><div class="content">Yep that&#x27;s the one. Curious roughly how many A100s it&#x27;d take to train a 65B RWKV on that.</div><br/><div id="36041157" class="c"><input type="checkbox" id="c-36041157" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040752">parent</a><span>|</span><a href="#36039976">next</a><span>|</span><label class="collapse" for="c-36041157">[-]</label><label class="expand" for="c-36041157">[1 more]</label></div><br/><div class="children"><div class="content">Really bad napkin math as no one has attempted 65B (so +\- 50%)<p>8 x 8 x 8 A100, should be able to do a 100k++ tokens&#x2F;s at that size<p>With a dataset of 1.2 trillion tokens. That’s 12 million seconds. Or 140 days</div><br/></div></div></div></div></div></div></div></div><div id="36039976" class="c"><input type="checkbox" id="c-36039976" checked=""/><div class="controls bullet"><span class="by">pas</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039922">parent</a><span>|</span><a href="#36040556">prev</a><span>|</span><a href="#36040091">next</a><span>|</span><label class="collapse" for="c-36039976">[-]</label><label class="expand" for="c-36039976">[2 more]</label></div><br/><div class="children"><div class="content">can you elaborate on the chinchilla law &#x2F; dataset problem a bit? (perhaps by editing your previous comment?)<p>what datasets are available to the community, how big are these, are they needed to be updated from time to time, where are these stored, what are the usual cost ranges involved, ...? :o<p>thank you!</div><br/><div id="36040607" class="c"><input type="checkbox" id="c-36040607" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36039976">parent</a><span>|</span><a href="#36040091">next</a><span>|</span><label class="collapse" for="c-36040607">[-]</label><label class="expand" for="c-36040607">[1 more]</label></div><br/><div class="children"><div class="content">Chinchilla law is a rule of thumb that you should have 11++ x training tokens for every param<p>If not, you are getting diminishing benefits for each param you add<p>I’m extreme cases your model can even perform worse with more param due to lack of training data<p>More complicated: the quality of the data matters as well<p>So there are 2 major directions. Build efficient models with good dataset and optimal param count for the task<p>Or go big on everything (aka openAI) which requires monster GPU time for every reply token<p>There are obviously in between as well. Hence why the question is so loaded<p>Ballpark: if your not setting aside a 100k for GPUs alone, to train a 60B model from scratch, your probably not ready to train one</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="36040091" class="c"><input type="checkbox" id="c-36040091" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#36039214">parent</a><span>|</span><a href="#36039761">prev</a><span>|</span><a href="#36040659">next</a><span>|</span><label class="collapse" for="c-36040091">[-]</label><label class="expand" for="c-36040091">[8 more]</label></div><br/><div class="children"><div class="content">Currently, what I&#x27;m seeing with RWKV is that attention fades of quickly. The model will start to produce output, but very quickly (a few dozen tokens), its own output tokens are suddenly taking &#x27;precedence&#x27; over the input question and it starts to simply repeat itself.<p>For example, I&#x27;m currently attempting to use RWKV for named entity extraction. I ask it to analyze a piece of text and provide output in JSON format. It starts off great. However, eventually, it seems like the beginning of the JSON list &#x27;overtakes&#x27; the question I asked, and it starts to just produce random data that would seem plausible based on the set of things in the list. I realize this is due perhaps to the precision losses of the RNN as weights decay.<p>However, I feel there ought to be some way we can prevent that. Any thoughts?</div><br/><div id="36040439" class="c"><input type="checkbox" id="c-36040439" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040091">parent</a><span>|</span><a href="#36040659">next</a><span>|</span><label class="collapse" for="c-36040439">[-]</label><label class="expand" for="c-36040439">[7 more]</label></div><br/><div class="children"><div class="content">Rearrange the query.<p>Ask the question &#x2F; explain the task first. Then give it the data you want to extract from.<p>Also you may want to give a one shot example for best result (the instruct training of raven model is very limited)</div><br/><div id="36040794" class="c"><input type="checkbox" id="c-36040794" checked=""/><div class="controls bullet"><span class="by">zaptrem</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040439">parent</a><span>|</span><a href="#36040606">next</a><span>|</span><label class="collapse" for="c-36040794">[-]</label><label class="expand" for="c-36040794">[2 more]</label></div><br/><div class="children"><div class="content">Why would asking the question first improve quality? Is it because the model will be better aware of what info it Can and can’t throw away at each step? This seems like the opposite of transformers.</div><br/><div id="36040858" class="c"><input type="checkbox" id="c-36040858" checked=""/><div class="controls bullet"><span class="by">LoganDark</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040794">parent</a><span>|</span><a href="#36040606">next</a><span>|</span><label class="collapse" for="c-36040858">[-]</label><label class="expand" for="c-36040858">[1 more]</label></div><br/><div class="children"><div class="content">RWKV does not work like transformers. The &quot;transformer&quot; part here is the training step. RWKV is an RNN with fixed-size state, so old information slightly decays each time it reads a new token. Hence the freshest memory is of the most recent tokens.</div><br/></div></div></div></div><div id="36040606" class="c"><input type="checkbox" id="c-36040606" checked=""/><div class="controls bullet"><span class="by">Tostino</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040439">parent</a><span>|</span><a href="#36040794">prev</a><span>|</span><a href="#36040529">next</a><span>|</span><label class="collapse" for="c-36040606">[-]</label><label class="expand" for="c-36040606">[2 more]</label></div><br/><div class="children"><div class="content">Are there any ways to train it to maintain attention on the original prompt no matter the distance from it, and selectively pay attention to its own output where relevant?</div><br/><div id="36041229" class="c"><input type="checkbox" id="c-36041229" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040606">parent</a><span>|</span><a href="#36040529">next</a><span>|</span><label class="collapse" for="c-36041229">[-]</label><label class="expand" for="c-36041229">[1 more]</label></div><br/><div class="children"><div class="content">Instruction training. This is a WIP</div><br/></div></div></div></div><div id="36040529" class="c"><input type="checkbox" id="c-36040529" checked=""/><div class="controls bullet"><span class="by">anon291</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040439">parent</a><span>|</span><a href="#36040606">prev</a><span>|</span><a href="#36040659">next</a><span>|</span><label class="collapse" for="c-36040529">[-]</label><label class="expand" for="c-36040529">[2 more]</label></div><br/><div class="children"><div class="content">Yeah... So I did that which is how I got it to begin correctly. This is what I mean though.<p>I&#x27;ll say &quot;get a list of Blah from the following document in Json format like this:<p>Example&quot;<p>Then I feed the document and add a spot for the answer.<p>The model begins correctly. But usually in the middle of the Json list generation, it will veer off, and start hallucinating as if it forgot the document and the task. I&#x27;m happy to share specifics and datasets but this is a cross cutting problem.<p>Rwkv is able to answer my questions when I ask simple yes&#x2F;no or classification. It&#x27;s the listing that throws it for a loop. Transformers do not have the same problem. Both llama and gpt are able to maintain focus.<p>Also, do you know where I&#x27;d find information on how the current weights were trained?</div><br/><div id="36040707" class="c"><input type="checkbox" id="c-36040707" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039214">root</a><span>|</span><a href="#36040529">parent</a><span>|</span><a href="#36040659">next</a><span>|</span><label class="collapse" for="c-36040707">[-]</label><label class="expand" for="c-36040707">[1 more]</label></div><br/><div class="children"><div class="content">Hmm we might need to look into the instruct training data. Which is mostly based on gpt4all filtered and mixed with others<p>(You are using raven right? That’s the instruct trained varient)<p>Btw ping the discord if ur looking into finetuning for your usecase</div><br/></div></div></div></div></div></div></div></div><div id="36040659" class="c"><input type="checkbox" id="c-36040659" checked=""/><div class="controls bullet"><span class="by">taneq</span><span>|</span><a href="#36039214">parent</a><span>|</span><a href="#36040091">prev</a><span>|</span><a href="#36038995">next</a><span>|</span><label class="collapse" for="c-36040659">[-]</label><label class="expand" for="c-36040659">[1 more]</label></div><br/><div class="children"><div class="content">Is everyone still carefully not mentioning that it looks like it’s pronounced “Roku”? ;)</div><br/></div></div></div></div><div id="36038995" class="c"><input type="checkbox" id="c-36038995" checked=""/><div class="controls bullet"><span class="by">mindwok</span><span>|</span><a href="#36039214">prev</a><span>|</span><a href="#36039732">next</a><span>|</span><label class="collapse" for="c-36038995">[-]</label><label class="expand" for="c-36038995">[5 more]</label></div><br/><div class="children"><div class="content">As a (mostly) layperson, this seems like it could be a very significant paper. What are the odds we see the next few years of machine learning models based on RWKV like we have seen with transformers since the attention is all you need paper?</div><br/><div id="36039234" class="c"><input type="checkbox" id="c-36039234" checked=""/><div class="controls bullet"><span class="by">FallDead</span><span>|</span><a href="#36038995">parent</a><span>|</span><a href="#36039063">next</a><span>|</span><label class="collapse" for="c-36039234">[-]</label><label class="expand" for="c-36039234">[1 more]</label></div><br/><div class="children"><div class="content">Pretty high, we are going to be deploying something similar to Sono&#x27;s GPT based LLM, and leverage RWKV for that, still playing around with it though!</div><br/></div></div><div id="36039063" class="c"><input type="checkbox" id="c-36039063" checked=""/><div class="controls bullet"><span class="by">m3kw9</span><span>|</span><a href="#36038995">parent</a><span>|</span><a href="#36039234">prev</a><span>|</span><a href="#36039732">next</a><span>|</span><label class="collapse" for="c-36039063">[-]</label><label class="expand" for="c-36039063">[3 more]</label></div><br/><div class="children"><div class="content">This model seem to be good when input context is large in comparison to OpenAI, would just wait till if someone productize it. Most likely it wine be just one paper but many new and old ideas combined</div><br/><div id="36040085" class="c"><input type="checkbox" id="c-36040085" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36038995">root</a><span>|</span><a href="#36039063">parent</a><span>|</span><a href="#36039732">next</a><span>|</span><label class="collapse" for="c-36040085">[-]</label><label class="expand" for="c-36040085">[2 more]</label></div><br/><div class="children"><div class="content">Being a RNN there is another trick: caching a long prompt, because RNNs only look back one step while transformers see the whole sequence. So you can load your long context only once and reuse it many times.</div><br/><div id="36040487" class="c"><input type="checkbox" id="c-36040487" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36038995">root</a><span>|</span><a href="#36040085">parent</a><span>|</span><a href="#36039732">next</a><span>|</span><label class="collapse" for="c-36040487">[-]</label><label class="expand" for="c-36040487">[1 more]</label></div><br/><div class="children"><div class="content">Yup. This is commonly done in the community for the chat models as well (due to the huge amount of reuse for each reply)</div><br/></div></div></div></div></div></div></div></div><div id="36039732" class="c"><input type="checkbox" id="c-36039732" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36038995">prev</a><span>|</span><a href="#36038961">next</a><span>|</span><label class="collapse" for="c-36039732">[-]</label><label class="expand" for="c-36039732">[1 more]</label></div><br/><div class="children"><div class="content">Layperson summary<p>Good<p>- substantially cheaper and faster to run &#x2F; train<p>- scalable to ridiculous context size<p>Bad<p>- you will need to change how you prompt this model sadly (it works differently)</div><br/></div></div><div id="36038961" class="c"><input type="checkbox" id="c-36038961" checked=""/><div class="controls bullet"><span class="by">whimsicalism</span><span>|</span><a href="#36039732">prev</a><span>|</span><a href="#36039073">next</a><span>|</span><label class="collapse" for="c-36038961">[-]</label><label class="expand" for="c-36038961">[2 more]</label></div><br/><div class="children"><div class="content">Awesome to see this published.<p>Work on transformer alternatives, especially parallelizable ones like this, is incredibly important - it would suck if we get sucked down a local optima in architecture without actually looking at nearby viable alternatives.</div><br/><div id="36039343" class="c"><input type="checkbox" id="c-36039343" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36038961">parent</a><span>|</span><a href="#36039073">next</a><span>|</span><label class="collapse" for="c-36039343">[-]</label><label class="expand" for="c-36039343">[1 more]</label></div><br/><div class="children"><div class="content">Yup. I’m all here for infinite scaling of context size</div><br/></div></div></div></div><div id="36039073" class="c"><input type="checkbox" id="c-36039073" checked=""/><div class="controls bullet"><span class="by">bigdict</span><span>|</span><a href="#36038961">prev</a><span>|</span><a href="#36040292">next</a><span>|</span><label class="collapse" for="c-36039073">[-]</label><label class="expand" for="c-36039073">[20 more]</label></div><br/><div class="children"><div class="content">Jesus H. Christ, first time I see a collaboration this big on a ML paper. How does a team like that even come together? This isn&#x27;t the LHC.</div><br/><div id="36039272" class="c"><input type="checkbox" id="c-36039272" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039073">parent</a><span>|</span><a href="#36039430">next</a><span>|</span><label class="collapse" for="c-36039272">[-]</label><label class="expand" for="c-36039272">[2 more]</label></div><br/><div class="children"><div class="content">RWKV has been running in public (relatively obscure to other models) for the past 2 years<p>Mostly lead by a single person (blink). This community consist mostly of people outside the academia &#x2F; big VC tech scene<p>When eleutherAI offered to help us with writing the paper. Various key folks banded together for the paper, as it’s what seems to be a very strong alternative to transformers<p>This does not mean everyone in the discord was credited.<p>The requirements are for significant contributions to the paper. typically several paragraphs long worth of drafting and revisions<p>Just doing a line of grammar change or a single benchmark is not enough</div><br/><div id="36039302" class="c"><input type="checkbox" id="c-36039302" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039272">parent</a><span>|</span><a href="#36039430">next</a><span>|</span><label class="collapse" for="c-36039302">[-]</label><label class="expand" for="c-36039302">[1 more]</label></div><br/><div class="children"><div class="content">AKA: no one here is incentivised to fight for bigger ownership, no promotion or KPI or pay was on the line</div><br/></div></div></div></div><div id="36039430" class="c"><input type="checkbox" id="c-36039430" checked=""/><div class="controls bullet"><span class="by">evolve7942</span><span>|</span><a href="#36039073">parent</a><span>|</span><a href="#36039272">prev</a><span>|</span><a href="#36039102">next</a><span>|</span><label class="collapse" for="c-36039430">[-]</label><label class="expand" for="c-36039430">[3 more]</label></div><br/><div class="children"><div class="content">If you think this is wild, see the PaLM 2 paper with 2.5 pages of 2 column attributions.<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.10403.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.10403.pdf</a></div><br/><div id="36040118" class="c"><input type="checkbox" id="c-36040118" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039430">parent</a><span>|</span><a href="#36039823">next</a><span>|</span><label class="collapse" for="c-36040118">[-]</label><label class="expand" for="c-36040118">[1 more]</label></div><br/><div class="children"><div class="content">No, the Bloom paper is wild: 2.5 pages of author names written with no spacing, I counted 472 authors after deduplication. PaLM 2 has <i>only</i> 181 authors. ;)<p><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2211.05100.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2211.05100.pdf</a></div><br/></div></div><div id="36039823" class="c"><input type="checkbox" id="c-36039823" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039430">parent</a><span>|</span><a href="#36040118">prev</a><span>|</span><a href="#36039102">next</a><span>|</span><label class="collapse" for="c-36039823">[-]</label><label class="expand" for="c-36039823">[1 more]</label></div><br/><div class="children"><div class="content">Page 28.<p>That is wild, almost like film credits</div><br/></div></div></div></div><div id="36039102" class="c"><input type="checkbox" id="c-36039102" checked=""/><div class="controls bullet"><span class="by">lordofgibbons</span><span>|</span><a href="#36039073">parent</a><span>|</span><a href="#36039430">prev</a><span>|</span><a href="#36039132">next</a><span>|</span><label class="collapse" for="c-36039102">[-]</label><label class="expand" for="c-36039102">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re a group of volunteers who came together over Discord.</div><br/></div></div><div id="36039132" class="c"><input type="checkbox" id="c-36039132" checked=""/><div class="controls bullet"><span class="by">cttet</span><span>|</span><a href="#36039073">parent</a><span>|</span><a href="#36039102">prev</a><span>|</span><a href="#36039099">next</a><span>|</span><label class="collapse" for="c-36039132">[-]</label><label class="expand" for="c-36039132">[1 more]</label></div><br/><div class="children"><div class="content">The model is created by one person, he does not have enough time to write the paper</div><br/></div></div><div id="36039099" class="c"><input type="checkbox" id="c-36039099" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36039073">parent</a><span>|</span><a href="#36039132">prev</a><span>|</span><a href="#36040425">next</a><span>|</span><label class="collapse" for="c-36039099">[-]</label><label class="expand" for="c-36039099">[10 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s just, everyone in their discord channel.</div><br/><div id="36039433" class="c"><input type="checkbox" id="c-36039433" checked=""/><div class="controls bullet"><span class="by">stellaathena</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039099">parent</a><span>|</span><a href="#36039144">next</a><span>|</span><label class="collapse" for="c-36039433">[-]</label><label class="expand" for="c-36039433">[4 more]</label></div><br/><div class="children"><div class="content">Our discord servers (a primary one, a spin-off for RWKV, another spinoff for BioML, etc) have tens of thousands of people between them :) So not quite everyone. But this was a community effort with a public call for contributions</div><br/><div id="36039687" class="c"><input type="checkbox" id="c-36039687" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039433">parent</a><span>|</span><a href="#36039599">next</a><span>|</span><label class="collapse" for="c-36039687">[-]</label><label class="expand" for="c-36039687">[2 more]</label></div><br/><div class="children"><div class="content">Are you the Stella from the Acknowledgements section? Are you in one of those spinoffs like BioML, or you aren&#x27;t on the author list because you have some conflict with your work where you can&#x27;t legally do something because of intellectual property laws or license things or NDA? Also when you talk about &#x27;our discord servers&#x27; which ones do you mean? Is it ones run by Eleuther?</div><br/><div id="36039901" class="c"><input type="checkbox" id="c-36039901" checked=""/><div class="controls bullet"><span class="by">stellaathena</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039687">parent</a><span>|</span><a href="#36039599">next</a><span>|</span><label class="collapse" for="c-36039901">[-]</label><label class="expand" for="c-36039901">[1 more]</label></div><br/><div class="children"><div class="content">Yes I am (apparently) in the acknowledgments. I was not an author on the paper because I didn’t have time to contribute too much. I also try to err on the side of not being added to papers, as my position (I run EleutherAI) tends to encourage people to be overgenerous with offers. I anticipate having more time this coming month and being on the version that’s submitted for peer review, but we’ll see.<p>BlinkDL has been working on this project for two-ish years, originally in the EleutherAI discord and then created his own to house the project.<p>I wasn’t thinking too hard about my exact wording, but yes I was thinking of EleutherAI and its various spin-off servers. EleutherAI doesn’t &#x2F;run&#x2F; any of the other servers, but we all have a close collaborative relationship. I’m sure there’s a lot of duplication of membership (e.g., I’m in all of them) but quickly adding up the membership of each server comes out to around 70,000. EleutherAI and LAION are the largest at 25k each, with the others typically having around 5k each. I would expect at least 30k of those users to be unique though.</div><br/></div></div></div></div></div></div><div id="36039144" class="c"><input type="checkbox" id="c-36039144" checked=""/><div class="controls bullet"><span class="by">Buttons840</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039099">parent</a><span>|</span><a href="#36039433">prev</a><span>|</span><a href="#36040425">next</a><span>|</span><label class="collapse" for="c-36039144">[-]</label><label class="expand" for="c-36039144">[5 more]</label></div><br/><div class="children"><div class="content">What channel? I have an application for sequence models I think might be novel, and I&#x27;d like to be able to get credit and help research it if possible. Probably somebody has already done it, but I cannot search well enough to find related literature.</div><br/><div id="36039188" class="c"><input type="checkbox" id="c-36039188" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039144">parent</a><span>|</span><a href="#36039351">next</a><span>|</span><label class="collapse" for="c-36039188">[-]</label><label class="expand" for="c-36039188">[3 more]</label></div><br/><div class="children"><div class="content">Write it and submit it yourself. Sole authorship is given more weight these days for whatever reason. In a multi author publication, even if you are first author or listed as equal contribution, if there is a more famous person on the paper everyone will assume they did it.</div><br/><div id="36039478" class="c"><input type="checkbox" id="c-36039478" checked=""/><div class="controls bullet"><span class="by">Buttons840</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039188">parent</a><span>|</span><a href="#36039351">next</a><span>|</span><label class="collapse" for="c-36039478">[-]</label><label class="expand" for="c-36039478">[2 more]</label></div><br/><div class="children"><div class="content">Write it and submit it to who? I&#x27;m not familiar enough with the field to find any prior work or related work.</div><br/><div id="36039526" class="c"><input type="checkbox" id="c-36039526" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039478">parent</a><span>|</span><a href="#36039351">next</a><span>|</span><label class="collapse" for="c-36039526">[-]</label><label class="expand" for="c-36039526">[1 more]</label></div><br/><div class="children"><div class="content">find the most closely related paper that you know of, even if it&#x27;s not very close, and submit your idea to the same journal that published that other idea</div><br/></div></div></div></div></div></div><div id="36039351" class="c"><input type="checkbox" id="c-36039351" checked=""/><div class="controls bullet"><span class="by">rahimnathwani</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36039144">parent</a><span>|</span><a href="#36039188">prev</a><span>|</span><a href="#36040425">next</a><span>|</span><label class="collapse" for="c-36039351">[-]</label><label class="expand" for="c-36039351">[1 more]</label></div><br/><div class="children"><div class="content">&gt; What channel?<p><a href="https:&#x2F;&#x2F;discord.gg&#x2F;qt9egFA7ve" rel="nofollow">https:&#x2F;&#x2F;discord.gg&#x2F;qt9egFA7ve</a></div><br/></div></div></div></div></div></div><div id="36040425" class="c"><input type="checkbox" id="c-36040425" checked=""/><div class="controls bullet"><span class="by">skykooler</span><span>|</span><a href="#36039073">parent</a><span>|</span><a href="#36039099">prev</a><span>|</span><a href="#36040292">next</a><span>|</span><label class="collapse" for="c-36040425">[-]</label><label class="expand" for="c-36040425">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s Type 10 of <a href="https:&#x2F;&#x2F;xkcd.com&#x2F;2456&#x2F;" rel="nofollow">https:&#x2F;&#x2F;xkcd.com&#x2F;2456&#x2F;</a>.</div><br/><div id="36040467" class="c"><input type="checkbox" id="c-36040467" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039073">root</a><span>|</span><a href="#36040425">parent</a><span>|</span><a href="#36040292">next</a><span>|</span><label class="collapse" for="c-36040467">[-]</label><label class="expand" for="c-36040467">[1 more]</label></div><br/><div class="children"><div class="content">Hahaha. True. And even then it’s an undersell (the limited scope of the paper drops lots of the things being done)</div><br/></div></div></div></div></div></div><div id="36040292" class="c"><input type="checkbox" id="c-36040292" checked=""/><div class="controls bullet"><span class="by">p-e-w</span><span>|</span><a href="#36039073">prev</a><span>|</span><a href="#36039744">next</a><span>|</span><label class="collapse" for="c-36040292">[-]</label><label class="expand" for="c-36040292">[2 more]</label></div><br/><div class="children"><div class="content">The paper lists the first author&#x27;s institutional affiliation as &quot;RWKV Foundation&quot;. However, I cannot find anything about this supposed &quot;foundation&quot; online, and as far as I can tell, the term RWKV originates in this very paper.<p>What&#x27;s going on here?</div><br/><div id="36040522" class="c"><input type="checkbox" id="c-36040522" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36040292">parent</a><span>|</span><a href="#36039744">next</a><span>|</span><label class="collapse" for="c-36040522">[-]</label><label class="expand" for="c-36040522">[1 more]</label></div><br/><div class="children"><div class="content">It does not exists (yet maybe)<p>Blink is an individual and does not represent a company (aka not google, not eleuther, not &lt;insert VC company&gt;, etc)<p>So he had to fill something up i guess haha<p>The idea of a foundation has been tossed around. So it may eventually happen<p>Also the RWKV project predates this paper by over 2 years - nothing is truely new and revealed today on this paper<p>Your simply just finding out about it now in a formal paper consolidating various things that was learnt in this project</div><br/></div></div></div></div><div id="36039189" class="c"><input type="checkbox" id="c-36039189" checked=""/><div class="controls bullet"><span class="by">cs702</span><span>|</span><a href="#36039744">prev</a><span>|</span><a href="#36039109">next</a><span>|</span><label class="collapse" for="c-36039189">[-]</label><label class="expand" for="c-36039189">[3 more]</label></div><br/><div class="children"><div class="content">Alas, it doesn&#x27;t appear to work well for longer contexts:<p><a href="https:&#x2F;&#x2F;twitter.com&#x2F;arankomatsuzaki&#x2F;status&#x2F;1639000379978403853" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;arankomatsuzaki&#x2F;status&#x2F;16390003799784038...</a><p>Has anyone here experimented with this recently to confirm?</div><br/><div id="36039375" class="c"><input type="checkbox" id="c-36039375" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039189">parent</a><span>|</span><a href="#36039218">next</a><span>|</span><label class="collapse" for="c-36039375">[-]</label><label class="expand" for="c-36039375">[1 more]</label></div><br/><div class="children"><div class="content">It has already been confirmed that with the right dataset we can scale it effectively from 2k to 4K, and 4K to 8k via fine tuning (you dun even need to train a new foundation model)<p>We believe this can be done for 16k to way beyond 100k<p>Research in how RWKV handle the hidden state shows that it is barely used (imo: &lt;5%??) meaning lots of headroom for scaling context size<p>(This is actively being experimented on - we dun really know the limit yet)</div><br/></div></div><div id="36039218" class="c"><input type="checkbox" id="c-36039218" checked=""/><div class="controls bullet"><span class="by">FallDead</span><span>|</span><a href="#36039189">parent</a><span>|</span><a href="#36039375">prev</a><span>|</span><a href="#36039109">next</a><span>|</span><label class="collapse" for="c-36039218">[-]</label><label class="expand" for="c-36039218">[1 more]</label></div><br/><div class="children"><div class="content">one of the authors here!, I think someone in our discord did experiments to prove that it does work for longer contexts, The pace of this work moves really fast. This might have been an earlier models in the series. RWKV it needs to be trained for longer contexts lengths in order to obtain that skill a context tuning if you will. IRCC there will be a follow up paper for it.</div><br/></div></div></div></div><div id="36039109" class="c"><input type="checkbox" id="c-36039109" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36039189">prev</a><span>|</span><a href="#36039769">next</a><span>|</span><label class="collapse" for="c-36039109">[-]</label><label class="expand" for="c-36039109">[1 more]</label></div><br/><div class="children"><div class="content">&gt; &quot;Our experiments reveal that RWKV performs on par with similarly sized Transformers&quot;</div><br/></div></div><div id="36039062" class="c"><input type="checkbox" id="c-36039062" checked=""/><div class="controls bullet"><span class="by">bee_rider</span><span>|</span><a href="#36039769">prev</a><span>|</span><a href="#36039131">next</a><span>|</span><label class="collapse" for="c-36039062">[-]</label><label class="expand" for="c-36039062">[6 more]</label></div><br/><div class="children"><div class="content">Dumb arxiv question (sorry); is it possible to see what journal a paper was actually submitted to, to help find the reviewed version when it comes out?</div><br/><div id="36039390" class="c"><input type="checkbox" id="c-36039390" checked=""/><div class="controls bullet"><span class="by">rsfern</span><span>|</span><a href="#36039062">parent</a><span>|</span><a href="#36039522">next</a><span>|</span><label class="collapse" for="c-36039390">[-]</label><label class="expand" for="c-36039390">[1 more]</label></div><br/><div class="children"><div class="content">Sometimes that is included in the journal LaTeX template, but otherwise authors (in my field at least) typically won’t say where a paper is submitted before it’s accepted for publication there, or at the very least if it’s made it past the editorial  rejection hurdle and been sent out for review<p>Probably your best bet for getting a feed heads up is to set a GScholar alert on the first author?</div><br/></div></div><div id="36039522" class="c"><input type="checkbox" id="c-36039522" checked=""/><div class="controls bullet"><span class="by">sbierwagen</span><span>|</span><a href="#36039062">parent</a><span>|</span><a href="#36039390">prev</a><span>|</span><a href="#36039419">next</a><span>|</span><label class="collapse" for="c-36039522">[-]</label><label class="expand" for="c-36039522">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not required for arxiv authors to submit papers to journals. As far as I can tell &quot;Language Models are Unsupervised Multitask Learners&quot;, (the GPT-2 paper) which has 9,786 citations, was never published in a journal.</div><br/></div></div><div id="36039419" class="c"><input type="checkbox" id="c-36039419" checked=""/><div class="controls bullet"><span class="by">stellaathena</span><span>|</span><a href="#36039062">parent</a><span>|</span><a href="#36039522">prev</a><span>|</span><a href="#36039221">next</a><span>|</span><label class="collapse" for="c-36039419">[-]</label><label class="expand" for="c-36039419">[1 more]</label></div><br/><div class="children"><div class="content">The paper is going to be submitted to EMNLP next month. An early version is being released now to garner feedback and improve the paper before submission.</div><br/></div></div><div id="36039221" class="c"><input type="checkbox" id="c-36039221" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039062">parent</a><span>|</span><a href="#36039419">prev</a><span>|</span><a href="#36039115">next</a><span>|</span><label class="collapse" for="c-36039221">[-]</label><label class="expand" for="c-36039221">[1 more]</label></div><br/><div class="children"><div class="content">This is straight to ARXIV (its not even the final copy yet)</div><br/></div></div><div id="36039115" class="c"><input type="checkbox" id="c-36039115" checked=""/><div class="controls bullet"><span class="by">ftxbro</span><span>|</span><a href="#36039062">parent</a><span>|</span><a href="#36039221">prev</a><span>|</span><a href="#36039131">next</a><span>|</span><label class="collapse" for="c-36039115">[-]</label><label class="expand" for="c-36039115">[1 more]</label></div><br/><div class="children"><div class="content">that&#x27;s what arxiv used to be, but that&#x27;s not what it is anymore</div><br/></div></div></div></div><div id="36039131" class="c"><input type="checkbox" id="c-36039131" checked=""/><div class="controls bullet"><span class="by">elromulous</span><span>|</span><a href="#36039062">prev</a><span>|</span><a href="#36039829">next</a><span>|</span><label class="collapse" for="c-36039131">[-]</label><label class="expand" for="c-36039131">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.13048" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2305.13048</a><p>^direct pdf link</div><br/></div></div><div id="36039829" class="c"><input type="checkbox" id="c-36039829" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36039131">prev</a><span>|</span><a href="#36040540">next</a><span>|</span><label class="collapse" for="c-36039829">[-]</label><label class="expand" for="c-36039829">[3 more]</label></div><br/><div class="children"><div class="content">My goal this year: to understand what this is about :-)</div><br/><div id="36039857" class="c"><input type="checkbox" id="c-36039857" checked=""/><div class="controls bullet"><span class="by">pico_creator</span><span>|</span><a href="#36039829">parent</a><span>|</span><a href="#36040540">next</a><span>|</span><label class="collapse" for="c-36039857">[-]</label><label class="expand" for="c-36039857">[2 more]</label></div><br/><div class="children"><div class="content">If you are familiar with how transformer network works<p>There is RWKV in 150 lines to help understand all the nitty gritty<p><a href="https:&#x2F;&#x2F;github.com&#x2F;BlinkDL&#x2F;ChatRWKV&#x2F;blob&#x2F;main&#x2F;RWKV_in_150_lines.py">https:&#x2F;&#x2F;github.com&#x2F;BlinkDL&#x2F;ChatRWKV&#x2F;blob&#x2F;main&#x2F;RWKV_in_150_li...</a></div><br/><div id="36040261" class="c"><input type="checkbox" id="c-36040261" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#36039829">root</a><span>|</span><a href="#36039857">parent</a><span>|</span><a href="#36040540">next</a><span>|</span><label class="collapse" for="c-36040261">[-]</label><label class="expand" for="c-36040261">[1 more]</label></div><br/><div class="children"><div class="content">Almost familiar: one more Karpathy lecture to go. Thanks!</div><br/></div></div></div></div></div></div><div id="36040540" class="c"><input type="checkbox" id="c-36040540" checked=""/><div class="controls bullet"><span class="by">RC_ITR</span><span>|</span><a href="#36039829">prev</a><span>|</span><label class="collapse" for="c-36040540">[-]</label><label class="expand" for="c-36040540">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We propose a novel model architecture, Receptance Weighted Key Value (RWKV), that combines the efficient parallelizable training of Transformers with the efficient inference of RNNs.<p>Just to be clear to everyone: this is “use attention to train parameters, use recurrence for inference”<p>It’s a very cool idea and I hope we get more interesting approaches to inference, but attention is here to stay for training.</div><br/></div></div></div></div></div></div></div></body></html>