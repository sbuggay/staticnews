<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1701334879169" as="style"/><link rel="stylesheet" href="styles.css?v=1701334879169"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://xuanwo.io/2023/04-rust-std-fs-slower-than-python/">Rust std fs slower than Python? No, it&#x27;s hardware</a> <span class="domain">(<a href="https://xuanwo.io">xuanwo.io</a>)</span></div><div class="subtext"><span>Pop_-</span> | <span>204 comments</span></div><br/><div><div id="38462407" class="c"><input type="checkbox" id="c-38462407" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#38459231">next</a><span>|</span><label class="collapse" for="c-38462407">[-]</label><label class="expand" for="c-38462407">[11 more]</label></div><br/><div class="children"><div class="content">There are two dedicated CPU feature flags to indicate that REP STOS&#x2F;MOV are fast and usable as short instruction sequence for memset&#x2F;memcpy.
Having to hand-roll optimized routines for each new CPU generation has been an ongoing pain for decades.<p>And yet here we are again. Shouldn&#x27;t this be part of some timing testsuite of CPU vendors by now?</div><br/><div id="38462455" class="c"><input type="checkbox" id="c-38462455" checked=""/><div class="controls bullet"><span class="by">giancarlostoro</span><span>|</span><a href="#38462407">parent</a><span>|</span><a href="#38467366">next</a><span>|</span><label class="collapse" for="c-38462455">[-]</label><label class="expand" for="c-38462455">[9 more]</label></div><br/><div class="children"><div class="content">So correct me if I am wrong but does this mean you need to compile two executables for a specific compile time build? Or is it just you need to compile it from specific hardware? Wondering what the fix would be, some sort of runtime check?</div><br/><div id="38462683" class="c"><input type="checkbox" id="c-38462683" checked=""/><div class="controls bullet"><span class="by">fweimer</span><span>|</span><a href="#38462407">root</a><span>|</span><a href="#38462455">parent</a><span>|</span><a href="#38463638">next</a><span>|</span><label class="collapse" for="c-38462683">[-]</label><label class="expand" for="c-38462683">[2 more]</label></div><br/><div class="children"><div class="content">The exact nature of the fix is unclear at present.<p>During dynamic linking, glibc picks a memcpy implementation which seems most appropriate for the current machine. We have about 13 different implementations just for x86-64. We could add another one for current(ish) AMD CPUs, select a different existing implementation for them, or change the default for a configurable cutover point in a parameterized implementation.</div><br/><div id="38467020" class="c"><input type="checkbox" id="c-38467020" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38462407">root</a><span>|</span><a href="#38462683">parent</a><span>|</span><a href="#38463638">next</a><span>|</span><label class="collapse" for="c-38467020">[-]</label><label class="expand" for="c-38467020">[1 more]</label></div><br/><div class="children"><div class="content">This code is in the kernel, so dynamic linking and glibc is not really relevant.</div><br/></div></div></div></div><div id="38463638" class="c"><input type="checkbox" id="c-38463638" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#38462407">root</a><span>|</span><a href="#38462455">parent</a><span>|</span><a href="#38462683">prev</a><span>|</span><a href="#38462682">next</a><span>|</span><label class="collapse" for="c-38463638">[-]</label><label class="expand" for="c-38463638">[2 more]</label></div><br/><div class="children"><div class="content">The sibling comments mention the hardware specific dynamic linking in glibc that&#x27;s used for function calls. But if your compiler inlines memcpy (usually for short, fixed-sized copies) into the binary then yes you&#x27;ll have to compile it for a specific CPU to get optimal performance. But that&#x27;s true for all target-dependent optimizations.<p>More broadly compatible routines will still work on newer CPUs, they just won yield the best performance.<p>It still would be nice if such central routines could just be compiled to the REP-prefixed instructions and would deliver (near-)optimal performance so we could stop worrying about that particular part.</div><br/><div id="38467097" class="c"><input type="checkbox" id="c-38467097" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38462407">root</a><span>|</span><a href="#38463638">parent</a><span>|</span><a href="#38462682">next</a><span>|</span><label class="collapse" for="c-38467097">[-]</label><label class="expand" for="c-38467097">[1 more]</label></div><br/><div class="children"><div class="content">They are, glibc already has an ERMS code path for memcpy.</div><br/></div></div></div></div><div id="38462682" class="c"><input type="checkbox" id="c-38462682" checked=""/><div class="controls bullet"><span class="by">dralley</span><span>|</span><a href="#38462407">root</a><span>|</span><a href="#38462455">parent</a><span>|</span><a href="#38463638">prev</a><span>|</span><a href="#38462841">next</a><span>|</span><label class="collapse" for="c-38462682">[-]</label><label class="expand" for="c-38462682">[1 more]</label></div><br/><div class="children"><div class="content">Glibc supports runtime selection of different optimized paths, yes.  There was a recent discussion about a security vulnerability in that feature (discussion <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37756357">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37756357</a>), but in essence this is exactly the kind of thing it&#x27;s useful for.</div><br/></div></div><div id="38462841" class="c"><input type="checkbox" id="c-38462841" checked=""/><div class="controls bullet"><span class="by">ww520</span><span>|</span><a href="#38462407">root</a><span>|</span><a href="#38462455">parent</a><span>|</span><a href="#38462682">prev</a><span>|</span><a href="#38462668">next</a><span>|</span><label class="collapse" for="c-38462841">[-]</label><label class="expand" for="c-38462841">[2 more]</label></div><br/><div class="children"><div class="content">Since the CPU instructions are the same, instruction patching at startup or install time can be used.  Just patch in the correct instructions for the respective hardware.</div><br/><div id="38467082" class="c"><input type="checkbox" id="c-38467082" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38462407">root</a><span>|</span><a href="#38462841">parent</a><span>|</span><a href="#38462668">next</a><span>|</span><label class="collapse" for="c-38467082">[-]</label><label class="expand" for="c-38467082">[1 more]</label></div><br/><div class="children"><div class="content">This is generally a bad idea because it requires code modification, which has security implications. Most implementations will bring in multiple implementations and select the right one at startup (amortizing the indirect call into something like the GOT which already exists).</div><br/></div></div></div></div><div id="38462668" class="c"><input type="checkbox" id="c-38462668" checked=""/><div class="controls bullet"><span class="by">immibis</span><span>|</span><a href="#38462407">root</a><span>|</span><a href="#38462455">parent</a><span>|</span><a href="#38462841">prev</a><span>|</span><a href="#38467366">next</a><span>|</span><label class="collapse" for="c-38462668">[-]</label><label class="expand" for="c-38462668">[1 more]</label></div><br/><div class="children"><div class="content">glibc has the ability to dynamically link a different version of a function based on the CPU.</div><br/></div></div></div></div><div id="38467366" class="c"><input type="checkbox" id="c-38467366" checked=""/><div class="controls bullet"><span class="by">mike_hock</span><span>|</span><a href="#38462407">parent</a><span>|</span><a href="#38462455">prev</a><span>|</span><a href="#38459231">next</a><span>|</span><label class="collapse" for="c-38467366">[-]</label><label class="expand" for="c-38467366">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;d think the CPU vendor knows their CPU best. If there&#x27;s a faster &quot;software&quot; implementation, why doesn&#x27;t REP MOVS at least do the same thing in microcode?</div><br/></div></div></div></div><div id="38459231" class="c"><input type="checkbox" id="c-38459231" checked=""/><div class="controls bullet"><span class="by">Aissen</span><span>|</span><a href="#38462407">prev</a><span>|</span><a href="#38458473">next</a><span>|</span><label class="collapse" for="c-38459231">[-]</label><label class="expand" for="c-38459231">[4 more]</label></div><br/><div class="children"><div class="content">Associated glibc bug (Zen 4 though): <a href="https:&#x2F;&#x2F;sourceware.org&#x2F;bugzilla&#x2F;show_bug.cgi?id=30994" rel="nofollow noreferrer">https:&#x2F;&#x2F;sourceware.org&#x2F;bugzilla&#x2F;show_bug.cgi?id=30994</a></div><br/><div id="38462707" class="c"><input type="checkbox" id="c-38462707" checked=""/><div class="controls bullet"><span class="by">fweimer</span><span>|</span><a href="#38459231">parent</a><span>|</span><a href="#38461986">next</a><span>|</span><label class="collapse" for="c-38462707">[-]</label><label class="expand" for="c-38462707">[1 more]</label></div><br/><div class="children"><div class="content">And AMD is investigating: <a href="https:&#x2F;&#x2F;inbox.sourceware.org&#x2F;libc-alpha&#x2F;20231115190559.2911267-1-sajan.karumanchi@amd.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;inbox.sourceware.org&#x2F;libc-alpha&#x2F;20231115190559.29112...</a></div><br/></div></div><div id="38461986" class="c"><input type="checkbox" id="c-38461986" checked=""/><div class="controls bullet"><span class="by">Arnavion</span><span>|</span><a href="#38459231">parent</a><span>|</span><a href="#38462707">prev</a><span>|</span><a href="#38458473">next</a><span>|</span><label class="collapse" for="c-38461986">[-]</label><label class="expand" for="c-38461986">[2 more]</label></div><br/><div class="children"><div class="content">The bug is also about Zen 3, and even mentions the 5900X (the article author&#x27;s CPU).</div><br/><div id="38465122" class="c"><input type="checkbox" id="c-38465122" checked=""/><div class="controls bullet"><span class="by">nabakin</span><span>|</span><a href="#38459231">root</a><span>|</span><a href="#38461986">parent</a><span>|</span><a href="#38458473">next</a><span>|</span><label class="collapse" for="c-38465122">[-]</label><label class="expand" for="c-38465122">[1 more]</label></div><br/><div class="children"><div class="content">If you read the bug tracker, a comment mentions this affects Zen 3 and Zen 4</div><br/></div></div></div></div></div></div><div id="38458473" class="c"><input type="checkbox" id="c-38458473" checked=""/><div class="controls bullet"><span class="by">royjacobs</span><span>|</span><a href="#38459231">prev</a><span>|</span><a href="#38459021">next</a><span>|</span><label class="collapse" for="c-38458473">[-]</label><label class="expand" for="c-38458473">[8 more]</label></div><br/><div class="children"><div class="content">I was prepared to read the article and scoff at the author&#x27;s misuse of std::fs. However, the article is a delightful succession of rabbit holes and mysteries. Well written and very interesting!</div><br/><div id="38460958" class="c"><input type="checkbox" id="c-38460958" checked=""/><div class="controls bullet"><span class="by">bri3d</span><span>|</span><a href="#38458473">parent</a><span>|</span><a href="#38461893">next</a><span>|</span><label class="collapse" for="c-38460958">[-]</label><label class="expand" for="c-38460958">[1 more]</label></div><br/><div class="children"><div class="content">This was such a good article! The debugging was smart (writing test programs to peel each layer off), the conclusion was fascinating and unexpected, and the writing was clear and easy to follow.</div><br/></div></div></div></div><div id="38459021" class="c"><input type="checkbox" id="c-38459021" checked=""/><div class="controls bullet"><span class="by">quietbritishjim</span><span>|</span><a href="#38458473">prev</a><span>|</span><a href="#38458692">next</a><span>|</span><label class="collapse" for="c-38459021">[-]</label><label class="expand" for="c-38459021">[43 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a bit confused about the premise. This is not comparing pure Python code against some native (C or Rust) code. It&#x27;s comparing one Python wrapper around native code (Python&#x27;s file read method) against another Python wrapper around some native code (OpenDAL). OK it&#x27;s still interesting that there&#x27;s a difference in performance, but it&#x27;s very odd to describe it as &quot;slower than Python&quot;. Did they expect that the Python standard library is all written in pure Python? On the contrary, I would expect the implementations of functions in Python&#x27;s standard library to be native and, individually, highly optimised.<p>I&#x27;m not surprised the conclusion had something to do with the way that native code works. Admittedly I was surprised at the specific answer - still a very interesting article despite the confusing start.<p>Edit: The conclusion also took me a couple of attempts to parse. There&#x27;s a heading &quot;C is slower than Python with specified offset&quot;. To me, as a native English speaker, this reads as &quot;C is slower (than Python) with specified offset&quot; i.e. it sounds like they took the C code, specified the same offset as Python, and then it&#x27;s still slower than Python. But it&#x27;s the opposite: once the offset from Python was also specified in the C code, the C code was then faster. Still very interesting once I got what they were saying though.</div><br/><div id="38466106" class="c"><input type="checkbox" id="c-38466106" checked=""/><div class="controls bullet"><span class="by">lambda</span><span>|</span><a href="#38459021">parent</a><span>|</span><a href="#38462251">next</a><span>|</span><label class="collapse" for="c-38466106">[-]</label><label class="expand" for="c-38466106">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m a bit confused by why you are confused.<p>It&#x27;s surprising that something as simple as reading a file is slower in the Rust standard library as the Python standard library. Even knowing that a Python standard library call like this is written in C, you&#x27;d still expect the Rust standard library call to be of a similar speed; so you&#x27;d expect either that you&#x27;re using it wrong, or that the Rust standard library has some weird behavior.<p>In this case, it turns out that neither were the case; there&#x27;s just a weird hardware performance cliff based on the exact alignment of an allocation on particular hardware.<p>So, yeah, I&#x27;d expect a filesystem read to be pretty well optimized in Python, but I&#x27;d expect the same in Rust, so it&#x27;s surprising that the latter was so much slower, and especially surprising that it turned out to be hardware and allocator dependent.</div><br/></div></div><div id="38462251" class="c"><input type="checkbox" id="c-38462251" checked=""/><div class="controls bullet"><span class="by">qd011</span><span>|</span><a href="#38459021">parent</a><span>|</span><a href="#38466106">prev</a><span>|</span><a href="#38459136">next</a><span>|</span><label class="collapse" for="c-38462251">[-]</label><label class="expand" for="c-38462251">[29 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t understand why Python gets shit for being a slow language when it&#x27;s slow but no credit for being fast when it&#x27;s fast just because &quot;it&#x27;s not really Python&quot;.<p>If I write Python and my code is fast, to me that sounds like Python is fast, I couldn&#x27;t care less whether it&#x27;s because the implementation is in another language or for some other reason.</div><br/><div id="38462900" class="c"><input type="checkbox" id="c-38462900" checked=""/><div class="controls bullet"><span class="by">kbenson</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462251">parent</a><span>|</span><a href="#38463003">next</a><span>|</span><label class="collapse" for="c-38462900">[-]</label><label class="expand" for="c-38462900">[7 more]</label></div><br/><div class="children"><div class="content">Because for any nontrivial case you would expect python+compiled library and associated marshaling of data to be slower than that library in its native implementation without any inyerop&#x2F;marshaling required.<p>When you see an interpreted language faster than a compiled one, it&#x27;s worth looking at why, because <i>most</i> the time it&#x27;s because there&#x27;s some hidden issue causing the other to be slow (which could just be a different and much worse implementation).<p>Put another way, you can do a lot to make a Honda Civic very fast, but when you hear one goes up against a Ferrari and wins your first thoughts should be about what the test was, how the Civic was modified, and if the Ferrari had problems or the test wasn&#x27;t to its strengths at all. If you just think &quot;yeah, I love Civics, that&#x27;s awesome&quot; then you&#x27;re not thinking critically enough about it.</div><br/><div id="38463269" class="c"><input type="checkbox" id="c-38463269" checked=""/><div class="controls bullet"><span class="by">Attummm</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462900">parent</a><span>|</span><a href="#38466558">next</a><span>|</span><label class="collapse" for="c-38463269">[-]</label><label class="expand" for="c-38463269">[2 more]</label></div><br/><div class="children"><div class="content">In this case, Python&#x27;s code (opening and loading the content of a file) operates almost fully within its C runtime.<p>The C components initiate the system call and manage the file pointer, which loads the data from the disk into a pyobj string.<p>Therefore, it isn&#x27;t so much Python itself that is being tested, but rather python underlying C runtime.</div><br/><div id="38463440" class="c"><input type="checkbox" id="c-38463440" checked=""/><div class="controls bullet"><span class="by">kbenson</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38463269">parent</a><span>|</span><a href="#38466558">next</a><span>|</span><label class="collapse" for="c-38463440">[-]</label><label class="expand" for="c-38463440">[1 more]</label></div><br/><div class="children"><div class="content">Yep, and the next logical question when both implementations are for the most part bare metal (compiled and low-level), is why is there a large difference?  Is it a matter of implementation&#x2F;algorithm, inefficiency, or a bug somewhere?  In this case, that search turned up a hardware issue that should be addressed, which is why it&#x27;s so useful to examine these things.</div><br/></div></div></div></div><div id="38466558" class="c"><input type="checkbox" id="c-38466558" checked=""/><div class="controls bullet"><span class="by">heavyset_go</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462900">parent</a><span>|</span><a href="#38463269">prev</a><span>|</span><a href="#38468564">next</a><span>|</span><label class="collapse" for="c-38466558">[-]</label><label class="expand" for="c-38466558">[1 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re staying within Python and its C-extensions, there is no marshalling, you&#x27;re dealing with raw PyObjects that are exposed to the interpreter.</div><br/></div></div><div id="38468564" class="c"><input type="checkbox" id="c-38468564" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462900">parent</a><span>|</span><a href="#38466558">prev</a><span>|</span><a href="#38463003">next</a><span>|</span><label class="collapse" for="c-38468564">[-]</label><label class="expand" for="c-38468564">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Because for any nontrivial case you would expect python+compiled library and associated marshaling of data to be slower than that library in its native implementation without any inyerop&#x2F;marshaling required.<p>&gt; When you see an interpreted language faster than a compiled one, it&#x27;s worth looking at why, because most the time it&#x27;s because there&#x27;s some hidden issue causing the other to be slow (which could just be a different and much worse implementation).<p>On the contrary, the compiled languages tend to only be faster in trivial benchmarks. In real-world systems the Python-based systems tends to be faster because they haven&#x27;t had to spend so long twiddling which integers they&#x27;re using and debugging crashes and memory leaks, and got to spend more time on the problem.</div><br/><div id="38468634" class="c"><input type="checkbox" id="c-38468634" checked=""/><div class="controls bullet"><span class="by">kbenson</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38468564">parent</a><span>|</span><a href="#38463003">next</a><span>|</span><label class="collapse" for="c-38468634">[-]</label><label class="expand" for="c-38468634">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t doubt that can happen, but I&#x27;m also highly doubtful that it&#x27;s the norm for large, established, mature projects with lots of attention, such as popular libraries and the standard library of popular languages.  As time spent on the project increases, I suspect that any gain an interpreted language has over an (efficient) compiled one not only gets smaller, but eventually reverses in most cases.<p>So, like in most things, the details can sometimes matter quite a bit.</div><br/><div id="38468992" class="c"><input type="checkbox" id="c-38468992" checked=""/><div class="controls bullet"><span class="by">lmm</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38468634">parent</a><span>|</span><a href="#38463003">next</a><span>|</span><label class="collapse" for="c-38468992">[-]</label><label class="expand" for="c-38468992">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I don&#x27;t doubt that can happen, but I&#x27;m also highly doubtful that it&#x27;s the norm for large, established, mature projects with lots of attention, such as popular libraries and the standard library of popular languages.<p>Code that has lots of attention is different, certainly, but it&#x27;s also the exception rather than the rule; the last figure I saw was that 90% of code is internal business applications that are never even made publicly available in any form, much less subject to outside code review or contributions.<p>&gt; As time spent on the project increases, I suspect that any gain an interpreted language has over an (efficient) compiled one not only gets smaller, but eventually reverses in most cases.<p>In terms of the limit of an efficient implementation (which certainly something like Python is nowhere near), I&#x27;ve seen it argued both ways; with something like K the argument is that a tiny interpreter that sits in L1 and takes its instructions in a very compact form ends up saving you more memory bandwidth (compared to what you&#x27;d have to compile those tiny interpreter instructions into if you wanted them to execute &quot;directly&quot;) than it costs.</div><br/></div></div></div></div></div></div></div></div><div id="38463003" class="c"><input type="checkbox" id="c-38463003" checked=""/><div class="controls bullet"><span class="by">rafaelmn</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462251">parent</a><span>|</span><a href="#38462900">prev</a><span>|</span><a href="#38462597">next</a><span>|</span><label class="collapse" for="c-38463003">[-]</label><label class="expand" for="c-38463003">[1 more]</label></div><br/><div class="children"><div class="content">But you will care if that &quot;python&quot; breaks - you get to drop down to C&#x2F;C++ and debugging native code. Likewise for adding features or understanding the implementation. Not to mention having to deal with native build tooling and platform specific stuff.<p>It&#x27;s completely fair to say that&#x27;s not python because it isn&#x27;t - any language out there can FFI to C and it has the same problems mentioned above.</div><br/></div></div><div id="38462597" class="c"><input type="checkbox" id="c-38462597" checked=""/><div class="controls bullet"><span class="by">benrutter</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462251">parent</a><span>|</span><a href="#38463003">prev</a><span>|</span><a href="#38462564">next</a><span>|</span><label class="collapse" for="c-38462597">[-]</label><label class="expand" for="c-38462597">[2 more]</label></div><br/><div class="children"><div class="content">I wonder if its because we&#x27;re sometimes talking cross purposes.<p>For me, coding is almost exclusively using python libraries like numpy to call out to other languages like c or FORTRAN. It feels silly to say I&#x27;m not coding in Python to me.<p>On the other hand, if you&#x27;re writing those libraries, coding to you is mostly writing FORTRAN and c optimizations. It probably feels silly to say you&#x27;re coding in Python just because that&#x27;s where your code is called from.</div><br/><div id="38467616" class="c"><input type="checkbox" id="c-38467616" checked=""/><div class="controls bullet"><span class="by">zare_st</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462597">parent</a><span>|</span><a href="#38462564">next</a><span>|</span><label class="collapse" for="c-38467616">[-]</label><label class="expand" for="c-38467616">[1 more]</label></div><br/><div class="children"><div class="content">There is a version of BASIC, a QuickBasic clone called Qb64 that is lightning fast because it transpiles to C++. By your admission a programmer should think that BASIC is fast because he only does BASIC and does not care about the environment details?<p>It&#x27;s actually the opposite, a Python programmer should know how to offload most, or use the libraries that do so, out of Python into C. He should not be oblivious to the fact that any decent Python performance is due to shrinking down the ratio of actual Python instructions vs native instructions.</div><br/></div></div></div></div><div id="38462564" class="c"><input type="checkbox" id="c-38462564" checked=""/><div class="controls bullet"><span class="by">afdbcreid</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462251">parent</a><span>|</span><a href="#38462597">prev</a><span>|</span><a href="#38469528">next</a><span>|</span><label class="collapse" for="c-38462564">[-]</label><label class="expand" for="c-38462564">[8 more]</label></div><br/><div class="children"><div class="content">Usually, yes, but when it&#x27;s a bug in the hardware, it&#x27;s not really that Python is fast, more like that CPython developers were lucky enough to not have the bug.</div><br/><div id="38463139" class="c"><input type="checkbox" id="c-38463139" checked=""/><div class="controls bullet"><span class="by">munch117</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462564">parent</a><span>|</span><a href="#38469528">next</a><span>|</span><label class="collapse" for="c-38463139">[-]</label><label class="expand" for="c-38463139">[7 more]</label></div><br/><div class="children"><div class="content">How do you know that it&#x27;s luck?</div><br/><div id="38464122" class="c"><input type="checkbox" id="c-38464122" checked=""/><div class="controls bullet"><span class="by">cozzyd</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38463139">parent</a><span>|</span><a href="#38464159">next</a><span>|</span><label class="collapse" for="c-38464122">[-]</label><label class="expand" for="c-38464122">[5 more]</label></div><br/><div class="children"><div class="content">Because the offset is entirely due to space for the PyObject header.</div><br/><div id="38465544" class="c"><input type="checkbox" id="c-38465544" checked=""/><div class="controls bullet"><span class="by">munch117</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38464122">parent</a><span>|</span><a href="#38464159">next</a><span>|</span><label class="collapse" for="c-38465544">[-]</label><label class="expand" for="c-38465544">[4 more]</label></div><br/><div class="children"><div class="content">The PyObject header is a target for optimisation.  Performance regressions are likely to be noticed, and if a different header layout is faster, then it&#x27;s entirely possible that it will be used for purely empirical reasons.  Trying different options and picking the best performing one is not luck, even if you can&#x27;t explain why it&#x27;s the best performing.</div><br/><div id="38465867" class="c"><input type="checkbox" id="c-38465867" checked=""/><div class="controls bullet"><span class="by">cozzyd</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38465544">parent</a><span>|</span><a href="#38466986">next</a><span>|</span><label class="collapse" for="c-38465867">[-]</label><label class="expand" for="c-38465867">[1 more]</label></div><br/><div class="children"><div class="content">I suspect any size other than 0 would lead to this.<p>But the Zen3&#x2F;4 were developed far, far after the PyObject header...</div><br/></div></div><div id="38466986" class="c"><input type="checkbox" id="c-38466986" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38465544">parent</a><span>|</span><a href="#38465867">prev</a><span>|</span><a href="#38464159">next</a><span>|</span><label class="collapse" for="c-38466986">[-]</label><label class="expand" for="c-38466986">[2 more]</label></div><br/><div class="children"><div class="content">You can expect the Python developers to look very closely at any benchmark that significantly benefits from adding random padding to the object header. Performance isn’t just trying a bunch of random things and picking whatever works the best, it’s critical to understand <i>why</i> so you know that the improvement is not a fluke. Especially since it is very easy to introduce bias and significantly perturb the results if you don’t understand what’s going on.</div><br/><div id="38470792" class="c"><input type="checkbox" id="c-38470792" checked=""/><div class="controls bullet"><span class="by">munch117</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38466986">parent</a><span>|</span><a href="#38464159">next</a><span>|</span><label class="collapse" for="c-38470792">[-]</label><label class="expand" for="c-38470792">[1 more]</label></div><br/><div class="children"><div class="content">We&#x27;re not talking about random changes.  We&#x27;re talking about paying attention to the measured performance of changes made for other reasons.<p>Just like in this article.  The author measured, wondered, investigated, experimented, and finally, after a lot of hard work, made the C&#x2F;Rust programs faster. You wouldn&#x27;t call that luck, would you?  If there had been a similar performance regression in CPython, then a benchmark could have picked up on it, and the CPython developers would then have done the same.</div><br/></div></div></div></div></div></div></div></div><div id="38464159" class="c"><input type="checkbox" id="c-38464159" checked=""/><div class="controls bullet"><span class="by">adgjlsfhk1</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38463139">parent</a><span>|</span><a href="#38464122">prev</a><span>|</span><a href="#38469528">next</a><span>|</span><label class="collapse" for="c-38464159">[-]</label><label class="expand" for="c-38464159">[1 more]</label></div><br/><div class="children"><div class="content">because the offset here is a result of python&#x27;s reference counting which dates ~20 years before zen3</div><br/></div></div></div></div></div></div><div id="38469528" class="c"><input type="checkbox" id="c-38469528" checked=""/><div class="controls bullet"><span class="by">p5a0u9l</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462251">parent</a><span>|</span><a href="#38462564">prev</a><span>|</span><a href="#38466684">next</a><span>|</span><label class="collapse" for="c-38469528">[-]</label><label class="expand" for="c-38469528">[1 more]</label></div><br/><div class="children"><div class="content">I constantly get low key shade for choosing to build everything in Python. It’s really interesting to me. People can’t break out of thinking, “oh, you wrote a script for that?”. Actually, no, it’s software, not a script.<p>99% of my use cases are easily, maintainably solved with good, modern Python. The Python execution is almost never the bottleneck in my workflows. It’s disk or network I&#x2F;O.<p>I’m not against building better languages and ecosystems, and compiled languages are clearly appropriate&#x2F;required in many workflows, but the language parochialism gets old. I just want to build shit that works and get stuff done.</div><br/></div></div><div id="38466684" class="c"><input type="checkbox" id="c-38466684" checked=""/><div class="controls bullet"><span class="by">analog31</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462251">parent</a><span>|</span><a href="#38469528">prev</a><span>|</span><a href="#38465223">next</a><span>|</span><label class="collapse" for="c-38466684">[-]</label><label class="expand" for="c-38466684">[2 more]</label></div><br/><div class="children"><div class="content">I think the confusion comes from people not having a good understanding of what an interpreted programming language does, and what actual portion of time is spent in high versus low level code. I&#x27;ve always assumed that most of my programs amount to a bit of glue thrown in between system calls.<p>Also, when we talk about &quot;faster&quot; and &quot;slower,&quot; it&#x27;s not clear the order of magnitude.<p>Maybe an analysis of actual code execution would shed more light than a simplistic explanation that the Python interpreter is written in C. I don&#x27;t think the BASIC interpreter in my first computer was written in BASIC.</div><br/><div id="38467675" class="c"><input type="checkbox" id="c-38467675" checked=""/><div class="controls bullet"><span class="by">zare_st</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38466684">parent</a><span>|</span><a href="#38465223">next</a><span>|</span><label class="collapse" for="c-38467675">[-]</label><label class="expand" for="c-38467675">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. The speed of a language is reverse proportional to number of CPU instructions emitted to do something meaningful, e.g. solve a problem. Not whether it can target system calls without overhead and move memory around freely. That&#x27;s a given.</div><br/></div></div></div></div><div id="38465223" class="c"><input type="checkbox" id="c-38465223" checked=""/><div class="controls bullet"><span class="by">insanitybit</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462251">parent</a><span>|</span><a href="#38466684">prev</a><span>|</span><a href="#38464772">next</a><span>|</span><label class="collapse" for="c-38465223">[-]</label><label class="expand" for="c-38465223">[1 more]</label></div><br/><div class="children"><div class="content">&gt;I don&#x27;t understand why Python gets shit for being a slow language when it&#x27;s slow but no credit for being fast when it&#x27;s fast just because &quot;it&#x27;s not really Python&quot;.<p>What&#x27;s there to understand? When it&#x27;s fast it&#x27;s not really Python, it&#x27;s C. C is fast. Python can call out to C. You don&#x27;t have to care that the implementation is in another language, but it is.</div><br/></div></div><div id="38464772" class="c"><input type="checkbox" id="c-38464772" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462251">parent</a><span>|</span><a href="#38465223">prev</a><span>|</span><a href="#38462342">next</a><span>|</span><label class="collapse" for="c-38464772">[-]</label><label class="expand" for="c-38464772">[5 more]</label></div><br/><div class="children"><div class="content">Because when people talk about Python performance they&#x27;re talking about the performance of Python code itself, not C&#x2F;Rust code that it&#x27;s wrapping.<p>Pretty much any language can wrap C&#x2F;Rust code.<p>Why does it matter?<p>1. Having to split your code across 2 languages via FFI is a huge pain.<p>2. You are still writing <i>some</i> Python. There&#x27;s plenty of code that is pure Python. That code is slow.</div><br/><div id="38465582" class="c"><input type="checkbox" id="c-38465582" checked=""/><div class="controls bullet"><span class="by">munch117</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38464772">parent</a><span>|</span><a href="#38462342">next</a><span>|</span><label class="collapse" for="c-38465582">[-]</label><label class="expand" for="c-38465582">[4 more]</label></div><br/><div class="children"><div class="content">Of course in this case there&#x27;s no FFI involved - the <i>open</i> function is built-in.  It&#x27;s as pure-Python as it can get.</div><br/><div id="38468250" class="c"><input type="checkbox" id="c-38468250" checked=""/><div class="controls bullet"><span class="by">jwueller</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38465582">parent</a><span>|</span><a href="#38465952">next</a><span>|</span><label class="collapse" for="c-38468250">[-]</label><label class="expand" for="c-38468250">[2 more]</label></div><br/><div class="children"><div class="content">How is it pure Python if it delegates all of the actual work to the Kernel?</div><br/><div id="38470659" class="c"><input type="checkbox" id="c-38470659" checked=""/><div class="controls bullet"><span class="by">munch117</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38468250">parent</a><span>|</span><a href="#38465952">next</a><span>|</span><label class="collapse" for="c-38470659">[-]</label><label class="expand" for="c-38470659">[1 more]</label></div><br/><div class="children"><div class="content">All I&#x2F;O delegates to the kernel, eventually.<p>It&#x27;s pure Python in that there&#x27;s no cffi, no ctypes, no Cython, no C extensions of any kind.</div><br/></div></div></div></div><div id="38465952" class="c"><input type="checkbox" id="c-38465952" checked=""/><div class="controls bullet"><span class="by">IshKebab</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38465582">parent</a><span>|</span><a href="#38468250">prev</a><span>|</span><a href="#38462342">next</a><span>|</span><label class="collapse" for="c-38465952">[-]</label><label class="expand" for="c-38465952">[1 more]</label></div><br/><div class="children"><div class="content">Not sure I agree there, but anyway in this case the performance had nothing to do with Python being a slow or fast language.</div><br/></div></div></div></div></div></div><div id="38462342" class="c"><input type="checkbox" id="c-38462342" checked=""/><div class="controls bullet"><span class="by">paulddraper</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462251">parent</a><span>|</span><a href="#38464772">prev</a><span>|</span><a href="#38459136">next</a><span>|</span><label class="collapse" for="c-38462342">[-]</label><label class="expand" for="c-38462342">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, it&#x27;s weird.</div><br/></div></div></div></div><div id="38459136" class="c"><input type="checkbox" id="c-38459136" checked=""/><div class="controls bullet"><span class="by">xuanwo</span><span>|</span><a href="#38459021">parent</a><span>|</span><a href="#38462251">prev</a><span>|</span><a href="#38461311">next</a><span>|</span><label class="collapse" for="c-38459136">[-]</label><label class="expand" for="c-38459136">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the comments. I have fixed the headers :)</div><br/></div></div><div id="38461311" class="c"><input type="checkbox" id="c-38461311" checked=""/><div class="controls bullet"><span class="by">crabbone</span><span>|</span><a href="#38459021">parent</a><span>|</span><a href="#38459136">prev</a><span>|</span><a href="#38471075">next</a><span>|</span><label class="collapse" for="c-38461311">[-]</label><label class="expand" for="c-38461311">[8 more]</label></div><br/><div class="children"><div class="content">&gt; individually, highly optimised.<p>Now why would you expect <i>that</i>?<p>What happened to OP is a pure chance.  CPython&#x27;s C code doesn&#x27;t even care about const-consistency.  It&#x27;s flush with dynamic memory allocations, bunch of helper &#x2F; convenience calls...  Even stuff like arithmetic does dynamic memory allocation...<p>Normally, you don&#x27;t expect CPython to perform well, not if you have any experience working with it.  Whenever you want to improve performance you want to sidestep all the functionality available there.<p>Also, while Python doesn&#x27;t have a standard library, since it doesn&#x27;t have a standard... the library that&#x27;s distributed with it is <i>mostly</i> written in Python.  Of course, some of it comes written in C, but there&#x27;s also a sizable fraction of that C code that&#x27;s essentially Python code translated mechanically into C (a good example of this is Python&#x27;s binary search implementation which was originally written in Python, and later translated into C using Python&#x27;s C API).<p>What one would expect is that functionality that is simple to map to operating system functionality has a relatively thin wrapper.  I.e. reading files wouldn&#x27;t require much in terms of binding code because, essentially, it goes straight into the system interface.</div><br/><div id="38462584" class="c"><input type="checkbox" id="c-38462584" checked=""/><div class="controls bullet"><span class="by">codr7</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38461311">parent</a><span>|</span><a href="#38471075">next</a><span>|</span><label class="collapse" for="c-38462584">[-]</label><label class="expand" for="c-38462584">[7 more]</label></div><br/><div class="children"><div class="content">Have you ever attempted to write a scripting language that performs better?<p>I have, several, and it&#x27;s far from trivial.<p>The basics are seriously optimized for typical use cases, take a look at the source code for the dict type.</div><br/><div id="38466392" class="c"><input type="checkbox" id="c-38466392" checked=""/><div class="controls bullet"><span class="by">wahern</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462584">parent</a><span>|</span><a href="#38462837">next</a><span>|</span><label class="collapse" for="c-38466392">[-]</label><label class="expand" for="c-38466392">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The basics are seriously optimized for typical use cases, take a look at the source code for the dict type<p>Python is well micro-optimized, but the broader architecture of the language and especially the CPython implementation did not put much concern into performance, even for a dynamically typed scripting language. For example, in CPython values of built-in types are still allocated as regular objects and passed by reference; this is atrocious for performance and no amount of micro optimization will suffice to completely bridge the performance gap for tasks which stress this aspect of CPython. By contrast, primitive types in Lua (including PUC Lua, the reference, non-JIT implementation) and JavaScript are passed around internally as scalar values, and the languages were designed with this in mind.<p>Perl is similar to Python in this regard--the language constructs and type systems weren&#x27;t designed for high primitive operation throughput. Rather, performance considerations were focused on higher level, functional tasks. For example, Perl string objects were designed to support fast concatenation and copy-on-write references, optimizations which pay huge dividends for the tasks for which Perl became popular. Perl can often seem ridiculously fast for naive string munging compared to even compiled languages, yet few people care to defend Perl as a performant language per se.</div><br/></div></div><div id="38462837" class="c"><input type="checkbox" id="c-38462837" checked=""/><div class="controls bullet"><span class="by">svieira</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462584">parent</a><span>|</span><a href="#38466392">prev</a><span>|</span><a href="#38463364">next</a><span>|</span><label class="collapse" for="c-38462837">[-]</label><label class="expand" for="c-38462837">[2 more]</label></div><br/><div class="children"><div class="content">Raymond Hettinger&#x27;s talk <i>Modern Python Dictionaries: A confluence of a dozen great ideas</i> is an awesome &quot;history of how we got these optimizations&quot; and a walk through why they are so effective - <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=npw4s1QTmPg" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=npw4s1QTmPg</a></div><br/><div id="38462956" class="c"><input type="checkbox" id="c-38462956" checked=""/><div class="controls bullet"><span class="by">codr7</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462837">parent</a><span>|</span><a href="#38463364">next</a><span>|</span><label class="collapse" for="c-38462956">[-]</label><label class="expand" for="c-38462956">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I had a nice chat with Raymond Hettinger at a Pycon in Birmingham&#x2F;UK back in the days (had no idea who he was at the time). He seemed like a dedicated and intelligent person, I&#x27;m sure we can thank him for some of that.</div><br/></div></div></div></div><div id="38463364" class="c"><input type="checkbox" id="c-38463364" checked=""/><div class="controls bullet"><span class="by">crabbone</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462584">parent</a><span>|</span><a href="#38462837">prev</a><span>|</span><a href="#38467550">next</a><span>|</span><label class="collapse" for="c-38463364">[-]</label><label class="expand" for="c-38463364">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Have you ever attempted to write a scripting language that performs better?<p>No, because &quot;scripting language&quot; is not a thing.<p>But, if we are talking about implementing languages, then I worked with many language implementations.  The most comparable one that I know fairly well, inside-and-out would be the AVM, i.e. the ActionScript Virtual Machine.  It&#x27;s not well-written either unfortunately.<p>I&#x27;ve looked at implementations of Lua, Emacs Lisp and Erlang at different times and to various degree.  I&#x27;m also somewhat familiar with SBCL and ECL, the implementation side.  There are different things the authors looked for in these implementations.  For example, SBCL emphasizes performance, where ECL emphasizes simplicity and interop with C.<p>If I had to grade language implementations I&#x27;ve seen, Erlang would absolutely take the cake.  It&#x27;s a very thoughtful and disciplined program where authors went to a great length to design and implement it.  CPython is on the lower end of such programs.  It&#x27;s anarchic, very unevenly implemented, you run into comments testifying to the author not knowing what they are doing, what their predecessor did, nor what to do next.  Sometimes the code is written from that perspective as well, as in if the author somehow manages to drive themselves in the corner they don&#x27;t know what the reference count is anymore, they&#x27;ll just hammer it until they hope all references are dead (well, maybe).<p>It&#x27;s the code style that, unfortunately, I associate with proprietary projects where deadlines and cost dictate the quality, where concurrency problems are solved with sleeps, and if that doesn&#x27;t work, then the sleep delay is doubled.  It&#x27;s not because I specifically hate code being proprietary, but because I meet that kind of code in my day job more than I meet it in hobby open-source projects.<p>&gt;  take a look at the source code for the dict type.<p>I wrote a Protobuf parser in C with the intention of exposing its bindings to Python.  Dictionaries were a natural choice for the hash-map Protobuf elements.  I benchmarked my implementation against C++ (Google&#x27;s) implementation only to discover that std::map wins against Python&#x27;s dictionary by a landslide.<p>Maybe Python&#x27;s dict isn&#x27;t as bad as most of the rest of the interpreter, but being the best of the worst still doesn&#x27;t make it good.</div><br/><div id="38464478" class="c"><input type="checkbox" id="c-38464478" checked=""/><div class="controls bullet"><span class="by">codr7</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38463364">parent</a><span>|</span><a href="#38467550">next</a><span>|</span><label class="collapse" for="c-38464478">[-]</label><label class="expand" for="c-38464478">[1 more]</label></div><br/><div class="children"><div class="content">Except it is, because everyone knows sort of what it means, an interpreted language that prioritizes convenience over performance; Perl&#x2F;Python&#x2F;Ruby&#x2F;Lua&#x2F;PHP&#x2F;etc.<p>SBCL is definitely a different beast.<p>I would expect Emacs Lisp &amp; Lua to be more similar.<p>Erlang had plenty more funding and stricter requirements.<p>C++&#x27;s std::map has most likely gotten even more attention than Python&#x27;s dict, but I&#x27;m not sure from your comment if you&#x27;re including Python&#x27;s VM dispatch in that comparison.<p>What are you trying to prove here?</div><br/></div></div></div></div><div id="38467550" class="c"><input type="checkbox" id="c-38467550" checked=""/><div class="controls bullet"><span class="by">rowanG077</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38462584">parent</a><span>|</span><a href="#38463364">prev</a><span>|</span><a href="#38471075">next</a><span>|</span><label class="collapse" for="c-38467550">[-]</label><label class="expand" for="c-38467550">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Have you ever attempted to write a scripting language that performs better?<p>Way to miss the mark. The point is precisely that Python is slow and one of the causes is that it is a scripting language. Stomping your foot and essentially: &quot;You couldn&#x27;t do any better&quot; helps no one and is counterproductive.</div><br/></div></div></div></div></div></div><div id="38465585" class="c"><input type="checkbox" id="c-38465585" checked=""/><div class="controls bullet"><span class="by">fl0ki</span><span>|</span><a href="#38459021">parent</a><span>|</span><a href="#38471075">prev</a><span>|</span><a href="#38458692">next</a><span>|</span><label class="collapse" for="c-38465585">[-]</label><label class="expand" for="c-38465585">[2 more]</label></div><br/><div class="children"><div class="content">The premise is that any time you say &quot;Python [...] faster than Rust [...]&quot; you get page views even if it&#x27;s not true. People have noticed after the last few dozen times something like this was posted.</div><br/><div id="38469582" class="c"><input type="checkbox" id="c-38469582" checked=""/><div class="controls bullet"><span class="by">p5a0u9l</span><span>|</span><a href="#38459021">root</a><span>|</span><a href="#38465585">parent</a><span>|</span><a href="#38458692">next</a><span>|</span><label class="collapse" for="c-38469582">[-]</label><label class="expand" for="c-38469582">[1 more]</label></div><br/><div class="children"><div class="content">This is the answer. The thread is chasing various smart-people opinions about languages, interpreters, system calls. We got tricked into click bait title and are using the opportunity to rehash our favorite topics and biases.<p>On the other hand… so what? It’s kind of fun.</div><br/></div></div></div></div></div></div><div id="38458692" class="c"><input type="checkbox" id="c-38458692" checked=""/><div class="controls bullet"><span class="by">iampims</span><span>|</span><a href="#38459021">prev</a><span>|</span><a href="#38460285">next</a><span>|</span><label class="collapse" for="c-38458692">[-]</label><label class="expand" for="c-38458692">[1 more]</label></div><br/><div class="children"><div class="content">Most interesting article I&#x27;ve read this week. Excellent write-up.</div><br/></div></div><div id="38460285" class="c"><input type="checkbox" id="c-38460285" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#38458692">prev</a><span>|</span><a href="#38459571">next</a><span>|</span><label class="collapse" for="c-38460285">[-]</label><label class="expand" for="c-38460285">[6 more]</label></div><br/><div class="children"><div class="content">So the obvious thing to do...   Send a patch to change the &quot;copy_user_generic&quot; kernel method to use a different memory copying implementation when the CPU is detected to be a bad one and the memory alignment is one that triggers the slowness bug...</div><br/><div id="38460838" class="c"><input type="checkbox" id="c-38460838" checked=""/><div class="controls bullet"><span class="by">p3n1s</span><span>|</span><a href="#38460285">parent</a><span>|</span><a href="#38467126">next</a><span>|</span><label class="collapse" for="c-38460838">[-]</label><label class="expand" for="c-38460838">[4 more]</label></div><br/><div class="children"><div class="content">Not obvious. Seems like if it can be corrected with microcode just have people use updated microcode rather than litter the kernel with fixes that are effectively patchable software problems.<p>The accepted fix would not be trivial to anyone not already experienced with the kernel. But more important, it obviously isn’t obvious what is the right way to enable the workaround. The best way is to probably measure at boot time, otherwise how do you know which models and steppings are affected.</div><br/><div id="38460879" class="c"><input type="checkbox" id="c-38460879" checked=""/><div class="controls bullet"><span class="by">londons_explore</span><span>|</span><a href="#38460285">root</a><span>|</span><a href="#38460838">parent</a><span>|</span><a href="#38467126">next</a><span>|</span><label class="collapse" for="c-38460879">[-]</label><label class="expand" for="c-38460879">[3 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think AMD does microcode updates for performance issues do they?   I thought it was strictly correctness or security issues.<p>If the vendor won&#x27;t patch it, then a workaround is the next best thing.  There shouldn&#x27;t be many - that&#x27;s why all copying code is in just a handful of functions.</div><br/><div id="38460988" class="c"><input type="checkbox" id="c-38460988" checked=""/><div class="controls bullet"><span class="by">p3n1s</span><span>|</span><a href="#38460285">root</a><span>|</span><a href="#38460879">parent</a><span>|</span><a href="#38461953">next</a><span>|</span><label class="collapse" for="c-38460988">[-]</label><label class="expand" for="c-38460988">[1 more]</label></div><br/><div class="children"><div class="content">A significant performance degradation due to normal use of the instruction (FSRM) not otherwise documented is a correctness problem. Especially considering that the workaround is to avoid using the CPU feature in many cases. People pay for this CPU feature now they need kernel tooling to warn them when they fallback to some slower workaround because of an alignment issue way up the stack.</div><br/></div></div><div id="38461953" class="c"><input type="checkbox" id="c-38461953" checked=""/><div class="controls bullet"><span class="by">prirun</span><span>|</span><a href="#38460285">root</a><span>|</span><a href="#38460879">parent</a><span>|</span><a href="#38460988">prev</a><span>|</span><a href="#38467126">next</a><span>|</span><label class="collapse" for="c-38461953">[-]</label><label class="expand" for="c-38461953">[1 more]</label></div><br/><div class="children"><div class="content">If AMD has a performance issue and doesn&#x27;t fix it, AMD should pay the negative publicity costs rather than kernel and library authors adding exceptions. IMHO.</div><br/></div></div></div></div></div></div><div id="38467126" class="c"><input type="checkbox" id="c-38467126" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38460285">parent</a><span>|</span><a href="#38460838">prev</a><span>|</span><a href="#38459571">next</a><span>|</span><label class="collapse" for="c-38467126">[-]</label><label class="expand" for="c-38467126">[1 more]</label></div><br/><div class="children"><div class="content">It’s not a trivial fix. Besides the fix likely being in microcode (where AMD figures out why aliasing is broke for addresses that are close to page-aligned), even a software mitigation would be complex because the kernel cannot actually use vector instructions that are typically used for the fallback path when ERMS is not available.</div><br/></div></div></div></div><div id="38459571" class="c"><input type="checkbox" id="c-38459571" checked=""/><div class="controls bullet"><span class="by">a1o</span><span>|</span><a href="#38460285">prev</a><span>|</span><a href="#38461164">next</a><span>|</span><label class="collapse" for="c-38459571">[-]</label><label class="expand" for="c-38459571">[27 more]</label></div><br/><div class="children"><div class="content">&gt; Rust developers might consider switching to jemallocator for improved performance<p>I am curious if this is something that everyone can do to get free performance or if there are caveats. Can C codebases benefit from this too? Is this performance that is simply left on table currently?</div><br/><div id="38461174" class="c"><input type="checkbox" id="c-38461174" checked=""/><div class="controls bullet"><span class="by">nh2</span><span>|</span><a href="#38459571">parent</a><span>|</span><a href="#38470053">next</a><span>|</span><label class="collapse" for="c-38461174">[-]</label><label class="expand" for="c-38461174">[7 more]</label></div><br/><div class="children"><div class="content">Be aware `jemalloc` will make you suffer the observability issues of `MADV_FREE`. `htop` will no longer show the truth about how much memory is in use.<p>* <a href="https:&#x2F;&#x2F;github.com&#x2F;jemalloc&#x2F;jemalloc&#x2F;issues&#x2F;387#issuecomment-443480621">https:&#x2F;&#x2F;github.com&#x2F;jemalloc&#x2F;jemalloc&#x2F;issues&#x2F;387#issuecomment...</a><p>* <a href="https:&#x2F;&#x2F;gitlab.haskell.org&#x2F;ghc&#x2F;ghc&#x2F;-&#x2F;issues&#x2F;17411" rel="nofollow noreferrer">https:&#x2F;&#x2F;gitlab.haskell.org&#x2F;ghc&#x2F;ghc&#x2F;-&#x2F;issues&#x2F;17411</a><p>Apparently now `jemalloc` will call `MADV_DONTNEED` 10 seconds after `MADV_FREE`:
<a href="https:&#x2F;&#x2F;github.com&#x2F;JuliaLang&#x2F;julia&#x2F;issues&#x2F;51086#issuecomment-1696078203">https:&#x2F;&#x2F;github.com&#x2F;JuliaLang&#x2F;julia&#x2F;issues&#x2F;51086#issuecomment...</a><p>So while this &quot;fixes&quot; the issue, it&#x27;ll introduce a confusing time delay between you freeing the memory and you observing that in `htop`.<p>But according to <a href="https:&#x2F;&#x2F;jemalloc.net&#x2F;jemalloc.3.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;jemalloc.net&#x2F;jemalloc.3.html</a> you can set `opt.muzzy_decay_ms = 0` to remove the delay.<p>Still, the musl author has some reservations against making `jemalloc` the default:<p><a href="https:&#x2F;&#x2F;www.openwall.com&#x2F;lists&#x2F;musl&#x2F;2018&#x2F;04&#x2F;23&#x2F;2" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.openwall.com&#x2F;lists&#x2F;musl&#x2F;2018&#x2F;04&#x2F;23&#x2F;2</a><p>&gt; It&#x27;s got serious bloat problems, problems with undermining ASLR, and is optimized pretty much only for being as fast as possible without caring how much memory you use.<p>With the above-mentioned tunables, this should be mitigated to some extent, but the general &quot;theme&quot; (focusing on e.g. performance vs memory usage) will likely still mean &quot;it&#x27;s a tradeoff&quot; or &quot;it&#x27;s no tradeoff, but only if you set tunables to what you need&quot;.</div><br/><div id="38461556" class="c"><input type="checkbox" id="c-38461556" checked=""/><div class="controls bullet"><span class="by">singron</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38461174">parent</a><span>|</span><a href="#38462005">next</a><span>|</span><label class="collapse" for="c-38461556">[-]</label><label class="expand" for="c-38461556">[1 more]</label></div><br/><div class="children"><div class="content">Note that glibc has a similar problem in multithreaded contexts. It strands unused memory in thread-local pools, which grows your memory usage over time like a memory leak. We got lower memory usage that didn&#x27;t grow over time by switching to jemalloc.<p>Example of this: <a href="https:&#x2F;&#x2F;github.com&#x2F;prestodb&#x2F;presto&#x2F;issues&#x2F;8993">https:&#x2F;&#x2F;github.com&#x2F;prestodb&#x2F;presto&#x2F;issues&#x2F;8993</a></div><br/></div></div><div id="38462005" class="c"><input type="checkbox" id="c-38462005" checked=""/><div class="controls bullet"><span class="by">masklinn</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38461174">parent</a><span>|</span><a href="#38461556">prev</a><span>|</span><a href="#38464302">next</a><span>|</span><label class="collapse" for="c-38462005">[-]</label><label class="expand" for="c-38462005">[1 more]</label></div><br/><div class="children"><div class="content">The musl remark is funny, because jemalloc&#x27;s use of pretty fine-grained arenas sometimes leads to better memory utilisation through reduced fragmentation. For instance Aerospike couldn&#x27;t fit in available memory under (admittedly old) glibc, and jemalloc fixed the issue: <a href="http:&#x2F;&#x2F;highscalability.com&#x2F;blog&#x2F;2015&#x2F;3&#x2F;17&#x2F;in-memory-computing-at-aerospike-scale-when-to-choose-and-ho.html" rel="nofollow noreferrer">http:&#x2F;&#x2F;highscalability.com&#x2F;blog&#x2F;2015&#x2F;3&#x2F;17&#x2F;in-memory-computin...</a><p>And this is not a one-off: <a href="https:&#x2F;&#x2F;hackernoon.com&#x2F;reducing-rails-memory-use-on-amazon-linux-with-jemalloc" rel="nofollow noreferrer">https:&#x2F;&#x2F;hackernoon.com&#x2F;reducing-rails-memory-use-on-amazon-l...</a> <a href="https:&#x2F;&#x2F;engineering.linkedin.com&#x2F;blog&#x2F;2021&#x2F;taming-memory-fragmentation-in-venice-with-jemalloc" rel="nofollow noreferrer">https:&#x2F;&#x2F;engineering.linkedin.com&#x2F;blog&#x2F;2021&#x2F;taming-memory-fra...</a><p>jemalloc also has extensive observability &#x2F; debugging capabilities, which can provide a useful global view of the system, it&#x27;s been used to debug memleaks in JNI-bridge code: <a href="https:&#x2F;&#x2F;www.evanjones.ca&#x2F;java-native-leak-bug.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.evanjones.ca&#x2F;java-native-leak-bug.html</a> <a href="https:&#x2F;&#x2F;technology.blog.gov.uk&#x2F;2015&#x2F;12&#x2F;11&#x2F;using-jemalloc-to-get-to-the-bottom-of-a-memory-leak&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;technology.blog.gov.uk&#x2F;2015&#x2F;12&#x2F;11&#x2F;using-jemalloc-to-...</a></div><br/></div></div><div id="38464302" class="c"><input type="checkbox" id="c-38464302" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38461174">parent</a><span>|</span><a href="#38462005">prev</a><span>|</span><a href="#38467171">next</a><span>|</span><label class="collapse" for="c-38464302">[-]</label><label class="expand" for="c-38464302">[1 more]</label></div><br/><div class="children"><div class="content">Aiming to please people who panic about their RSS numbers seems... misguided? It seems like worrying about RAM being &quot;used&quot; as file cache[0].<p>If you want to gauge whether your system is memory-limited look at the PSI metrics instead.<p>[0] <a href="https:&#x2F;&#x2F;www.linuxatemyram.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.linuxatemyram.com&#x2F;</a></div><br/></div></div><div id="38467171" class="c"><input type="checkbox" id="c-38467171" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38461174">parent</a><span>|</span><a href="#38464302">prev</a><span>|</span><a href="#38461243">next</a><span>|</span><label class="collapse" for="c-38467171">[-]</label><label class="expand" for="c-38467171">[1 more]</label></div><br/><div class="children"><div class="content">Not that I would recommend using jemalloc by default but it’s definitely going to be better than musl’s allocator ;)</div><br/></div></div><div id="38461243" class="c"><input type="checkbox" id="c-38461243" checked=""/><div class="controls bullet"><span class="by">a1o</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38461174">parent</a><span>|</span><a href="#38467171">prev</a><span>|</span><a href="#38462951">next</a><span>|</span><label class="collapse" for="c-38461243">[-]</label><label class="expand" for="c-38461243">[1 more]</label></div><br/><div class="children"><div class="content">Thank you! That was very thorough! I will be reading the links. :)</div><br/></div></div><div id="38462951" class="c"><input type="checkbox" id="c-38462951" checked=""/><div class="controls bullet"><span class="by">dralley</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38461174">parent</a><span>|</span><a href="#38461243">prev</a><span>|</span><a href="#38470053">next</a><span>|</span><label class="collapse" for="c-38462951">[-]</label><label class="expand" for="c-38462951">[1 more]</label></div><br/><div class="children"><div class="content">glibc isn&#x27;t totally free of such issues <a href="https:&#x2F;&#x2F;www.algolia.com&#x2F;blog&#x2F;engineering&#x2F;when-allocators-are-hoarding-your-precious-memory&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.algolia.com&#x2F;blog&#x2F;engineering&#x2F;when-allocators-are...</a></div><br/></div></div></div></div><div id="38470053" class="c"><input type="checkbox" id="c-38470053" checked=""/><div class="controls bullet"><span class="by">kelnos</span><span>|</span><a href="#38459571">parent</a><span>|</span><a href="#38461174">prev</a><span>|</span><a href="#38459601">next</a><span>|</span><label class="collapse" for="c-38470053">[-]</label><label class="expand" for="c-38470053">[1 more]</label></div><br/><div class="children"><div class="content">Rust used to use jemalloc as the default, but went back to using the system malloc back in 2018-ish[0].  Since Rust now has the GlobalAlloc trait (and the #[global_allocator] attribute), apps can use jemalloc as their allocator if they want.  Not sure if there&#x27;s a way for users to override via LD_PRELOAD or something, though.<p>It turns out jemalloc isn&#x27;t always best for every workload and use case.  While the system allocator is often far from perfect, it at least has been widely tested as a general-purpose allocator.<p>[0] <a href="https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;issues&#x2F;36963">https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;issues&#x2F;36963</a></div><br/></div></div><div id="38459601" class="c"><input type="checkbox" id="c-38459601" checked=""/><div class="controls bullet"><span class="by">nicoburns</span><span>|</span><a href="#38459571">parent</a><span>|</span><a href="#38470053">prev</a><span>|</span><a href="#38459624">next</a><span>|</span><label class="collapse" for="c-38459601">[-]</label><label class="expand" for="c-38459601">[1 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s pretty much free performance that&#x27;s being left on the table. There&#x27;s slight cost to binary size. And it may not perform better in absolutely all circumstances (but it will in almost all).<p>Rust used to use jemalloc by default but switched as people found this surprising as the default.</div><br/></div></div><div id="38459624" class="c"><input type="checkbox" id="c-38459624" checked=""/><div class="controls bullet"><span class="by">Pop_-</span><span>|</span><a href="#38459571">parent</a><span>|</span><a href="#38459601">prev</a><span>|</span><a href="#38467213">next</a><span>|</span><label class="collapse" for="c-38459624">[-]</label><label class="expand" for="c-38459624">[12 more]</label></div><br/><div class="children"><div class="content">Switching to non-default allocator does not always brings performance boost. It really depend on your workload, which requires profiling and benchmarking. But C&#x2F;C++&#x2F;Rust and other lower level languages should all at least be able to choose from these allocators. One caveat is binary size. Custom allocator does add more bytes to executable.</div><br/><div id="38461735" class="c"><input type="checkbox" id="c-38461735" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38459624">parent</a><span>|</span><a href="#38462192">next</a><span>|</span><label class="collapse" for="c-38461735">[-]</label><label class="expand" for="c-38461735">[10 more]</label></div><br/><div class="children"><div class="content">I don’t know why people still look to jemalloc. Mimalloc outperforms the standard allocator on nearly every single benchmark. Glibc’s allocator &amp; jemalloc both are long in the tooth &amp; don’t actually perform as well as state of the art allocators. I wish Rust would switch to mimalloc or the latest tcmalloc (not the one in gperftools).</div><br/><div id="38462122" class="c"><input type="checkbox" id="c-38462122" checked=""/><div class="controls bullet"><span class="by">masklinn</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38461735">parent</a><span>|</span><a href="#38462192">next</a><span>|</span><label class="collapse" for="c-38462122">[-]</label><label class="expand" for="c-38462122">[9 more]</label></div><br/><div class="children"><div class="content">&gt; I wish Rust would switch to mimalloc or the latest tcmalloc (not the one in gperftools).<p>That&#x27;s nonsensical. Rust uses the system allocators for reliability, compatibility, binary bloat, maintenance burden, ..., not because they&#x27;re <i>good</i> (they were not when Rust switched away from jemalloc, and they aren&#x27;t now).<p>If you want to use mimalloc in your rust programs, you can just set it as global allocator same as jemalloc, that takes all of three lines: <a href="https:&#x2F;&#x2F;github.com&#x2F;purpleprotocol&#x2F;mimalloc_rust#usage">https:&#x2F;&#x2F;github.com&#x2F;purpleprotocol&#x2F;mimalloc_rust#usage</a><p>If you want the rust compiler to link against mimilloc rather than jemalloc, feel free to test it out and open an issue, but maybe take a gander at the previous attempt: <a href="https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;pull&#x2F;103944">https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;pull&#x2F;103944</a> which died for the exact same reason the the one before that (<a href="https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;pull&#x2F;92249">https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;pull&#x2F;92249</a>) did: unacceptable regression of max-rss.</div><br/><div id="38462281" class="c"><input type="checkbox" id="c-38462281" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38462122">parent</a><span>|</span><a href="#38462192">next</a><span>|</span><label class="collapse" for="c-38462281">[-]</label><label class="expand" for="c-38462281">[8 more]</label></div><br/><div class="children"><div class="content">I know it’s easy to change but the arguments for using glibc’s allocator are less clear to me:<p>1. Reliability - how is an alternate allocator less reliable? Seems like a FUD-based argument. Unless by reliability you mean performance in which case yes - jemalloc isn’t reliably faster than standard allocators, but mimalloc is.<p>2. Compatibility - again sounds like a FUD argument. How is compatibility reduced by swapping out the allocator? You don’t even have to do it on all systems if you want. Glibc is just unequivocally bad.<p>3. Binary bloat - This one is maybe an OK argument although I don’t know what size difference we’re talking about for mimalloc. Also, most people aren’t writing hello world applications so the default should probably be for a good allocator. I’d also note that having a dependency of the std runtime on glibc in the first place likely bloats your binary more than the specific allocator selected.<p>4. Maintenance burden - I don’t really buy this argument. In both cases you’re relying on a 3rd party to maintain the code.</div><br/><div id="38462657" class="c"><input type="checkbox" id="c-38462657" checked=""/><div class="controls bullet"><span class="by">masklinn</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38462281">parent</a><span>|</span><a href="#38462192">next</a><span>|</span><label class="collapse" for="c-38462657">[-]</label><label class="expand" for="c-38462657">[7 more]</label></div><br/><div class="children"><div class="content">&gt; I know it’s easy to change but the arguments for using glibc’s allocator are less clear to me:<p>You can find them at the original motivation for removing jemalloc, 7 years ago: <a href="https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;issues&#x2F;36963">https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;issues&#x2F;36963</a><p>Also it&#x27;s not &quot;glibc&#x27;s allocator&quot;, it&#x27;s the system allocator. If you&#x27;re unhappy with glibc&#x27;s, get that replaced.<p>&gt; 1. Reliability - how is an alternate allocator less reliable?<p>Jemalloc had to be disabled on various platforms and architectures, there is no reason to think mimalloc or tcmalloc are any different.<p>The system allocator, while shit, is always there and functional, the project does not have to curate its availability across platforms.<p>&gt; 2. Compatibility - again sounds like a FUD argument. How is compatibility reduced by swapping out the allocator?<p>It makes interactions with anything which <i>does</i> use the system allocator worse, and almost certainly fails to interact correctly with some of the more specialised system facilities (e.g. malloc.conf) or tooling (in rust, jemalloc as shipped did not work with valgrind).<p>&gt; Also, most people aren’t writing hello world applications<p>Most people aren&#x27;t writing applications bound on allocation throughput either<p>&gt; so the default should probably be for a good allocator.<p>Probably not, no.<p>&gt; I’d also note that having a dependency of the std runtime on glibc in the first place likely bloats your binary more than the specific allocator selected.<p>That makes no sense whatsoever. The libc is the system&#x27;s and dynamically linked. And changing allocator does not magically unlink it.<p>&gt; 4. Maintenance burden - I don’t really buy this argument.<p>It doesn&#x27;t matter that you don&#x27;t buy it. Having to ship, resync, debug, and curate (cf (1)) an allocator is a maintenance burden. With a system allocator, all the project does is ensure it calls the system allocators correctly, the rest is out of its purview.</div><br/><div id="38462971" class="c"><input type="checkbox" id="c-38462971" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38462657">parent</a><span>|</span><a href="#38467256">next</a><span>|</span><label class="collapse" for="c-38462971">[-]</label><label class="expand" for="c-38462971">[5 more]</label></div><br/><div class="children"><div class="content">The reason the reliability &amp; compatibility arguments don’t make sense to me is that jemalloc is still in use for rustc (again - not sure why they haven’t switched to mimalloc) which has all the same platform requirements as the standard library. There’s also no reason an alternate allocator can’t be used on Linux specifically because glibc’s allocator is just bad full stop.<p>&gt; It makes interactions with anything which does use the system allocator worse<p>That’s a really niche argument. Most people are not doing any of that and malloc.conf is only for people who are tuning the glibc allocator which is a silly thing to do when mimalloc will outperform whatever tuning you do (yes - glibc really is that bad).<p>&gt; or tooling (in rust, jemalloc as shipped did not work with valgrind)<p>That’s a fair argument, but it’s not an unsolvable one.<p>&gt; Most people aren’t writing applications bound on allocation throughput either<p>You’d be surprised at how big an impact the allocator can make even when you don’t think you’re bound on allocations. There’s also all sorts of other things beyond allocation throughput &amp; glibc sucks at all of them (e.g. freeing memory, behavior in multithreaded programs, fragmentation etc etc).<p>&gt; The libc is the system’s and dynamically linked. And changing allocator does not magically unlink it<p>I meant that the dependency on libc at all in the standard library bloats the size of a statically linked executable.</div><br/><div id="38464334" class="c"><input type="checkbox" id="c-38464334" checked=""/><div class="controls bullet"><span class="by">josephg</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38462971">parent</a><span>|</span><a href="#38467256">next</a><span>|</span><label class="collapse" for="c-38464334">[-]</label><label class="expand" for="c-38464334">[4 more]</label></div><br/><div class="children"><div class="content">&gt; jemalloc is still in use for rustc (again - not sure why they haven’t switched to mimalloc)<p>Performance of rustc matters a lot! If the rust compiler runs faster when using mimalloc, please benchmark &amp; submit a patch to the compiler.</div><br/><div id="38465702" class="c"><input type="checkbox" id="c-38465702" checked=""/><div class="controls bullet"><span class="by">masklinn</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38464334">parent</a><span>|</span><a href="#38465199">next</a><span>|</span><label class="collapse" for="c-38465702">[-]</label><label class="expand" for="c-38465702">[2 more]</label></div><br/><div class="children"><div class="content">I literally linked two attempts to use mimalloc in rustc just a few comments upthread.</div><br/><div id="38469987" class="c"><input type="checkbox" id="c-38469987" checked=""/><div class="controls bullet"><span class="by">josephg</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38465702">parent</a><span>|</span><a href="#38465199">next</a><span>|</span><label class="collapse" for="c-38469987">[-]</label><label class="expand" for="c-38469987">[1 more]</label></div><br/><div class="children"><div class="content">Ah - my mistake; I somehow misread your comment. Pity about the RSS regression.<p>Personally I have plenty of RAM and I&#x27;d happily use more in exchange for a faster compile. Its much cheaper to buy more ram than a faster CPU, but I certainly understand the choice.<p>With compilers I sometimes wonder if it wouldn&#x27;t be better to just switch to an arena allocator for the whole compilation job. But it wouldn&#x27;t surprise me if LLVM allocates way more memory than you&#x27;d expect.</div><br/></div></div></div></div><div id="38465199" class="c"><input type="checkbox" id="c-38465199" checked=""/><div class="controls bullet"><span class="by">vlovich123</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38464334">parent</a><span>|</span><a href="#38465702">prev</a><span>|</span><a href="#38467256">next</a><span>|</span><label class="collapse" for="c-38465199">[-]</label><label class="expand" for="c-38465199">[1 more]</label></div><br/><div class="children"><div class="content">Any links to instructions on how to run said benchmarks?</div><br/></div></div></div></div></div></div><div id="38467256" class="c"><input type="checkbox" id="c-38467256" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38462657">parent</a><span>|</span><a href="#38462971">prev</a><span>|</span><a href="#38462192">next</a><span>|</span><label class="collapse" for="c-38467256">[-]</label><label class="expand" for="c-38467256">[1 more]</label></div><br/><div class="children"><div class="content">Not to mention that by using the system allocator you get all sorts of things “for free” that the system developers provide for you, wrt observability and standard tooling. This is especially true of the OS and the allocator are shipped by one group rather than being developed independently.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38462192" class="c"><input type="checkbox" id="c-38462192" checked=""/><div class="controls bullet"><span class="by">charcircuit</span><span>|</span><a href="#38459571">root</a><span>|</span><a href="#38459624">parent</a><span>|</span><a href="#38461735">prev</a><span>|</span><a href="#38467213">next</a><span>|</span><label class="collapse" for="c-38462192">[-]</label><label class="expand" for="c-38462192">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never not gotten increased performance by swapping outc the allocator.</div><br/></div></div></div></div><div id="38467213" class="c"><input type="checkbox" id="c-38467213" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38459571">parent</a><span>|</span><a href="#38459624">prev</a><span>|</span><a href="#38462306">next</a><span>|</span><label class="collapse" for="c-38467213">[-]</label><label class="expand" for="c-38467213">[1 more]</label></div><br/><div class="children"><div class="content">Performance is not a one-dimensional scale where programs go from “slow” to “fast”, because there are always other factors at play. jemalloc can be the right fit for some applications but for others another choice might be faster, but it also might be that the choice is slower but better matches their goals (less dirty memory, better observability, certain security guarantees, …)</div><br/></div></div><div id="38462306" class="c"><input type="checkbox" id="c-38462306" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#38459571">parent</a><span>|</span><a href="#38467213">prev</a><span>|</span><a href="#38461811">next</a><span>|</span><label class="collapse" for="c-38462306">[-]</label><label class="expand" for="c-38462306">[1 more]</label></div><br/><div class="children"><div class="content">basically that&#x27;s why jason wrote it in the first place, but other allocators have caught up since then to some extent. so jemalloc might make your c either slower or faster, you&#x27;ll have to test to know. it&#x27;s pretty reliable at being close to the best choice<p>does tend to use more ram tho</div><br/></div></div><div id="38461811" class="c"><input type="checkbox" id="c-38461811" checked=""/><div class="controls bullet"><span class="by">TillE</span><span>|</span><a href="#38459571">parent</a><span>|</span><a href="#38462306">prev</a><span>|</span><a href="#38462579">next</a><span>|</span><label class="collapse" for="c-38461811">[-]</label><label class="expand" for="c-38461811">[1 more]</label></div><br/><div class="children"><div class="content">jemalloc and mimalloc are very popular in C and C++ software, yes. There are few drawbacks, and it&#x27;s really easy to benchmark different allocators against eachother in your particular use case.</div><br/></div></div><div id="38462579" class="c"><input type="checkbox" id="c-38462579" checked=""/><div class="controls bullet"><span class="by">secondcoming</span><span>|</span><a href="#38459571">parent</a><span>|</span><a href="#38461811">prev</a><span>|</span><a href="#38463362">next</a><span>|</span><label class="collapse" for="c-38462579">[-]</label><label class="expand" for="c-38462579">[1 more]</label></div><br/><div class="children"><div class="content">You can override the allocator for any app via LD_PRELOAD</div><br/></div></div></div></div><div id="38461164" class="c"><input type="checkbox" id="c-38461164" checked=""/><div class="controls bullet"><span class="by">comonoid</span><span>|</span><a href="#38459571">prev</a><span>|</span><a href="#38461882">next</a><span>|</span><label class="collapse" for="c-38461164">[-]</label><label class="expand" for="c-38461164">[2 more]</label></div><br/><div class="children"><div class="content">jemalloc was Rust&#x27;s default allocator till 2018.<p><a href="https:&#x2F;&#x2F;internals.rust-lang.org&#x2F;t&#x2F;jemalloc-was-just-removed-from-the-standard-library&#x2F;8759" rel="nofollow noreferrer">https:&#x2F;&#x2F;internals.rust-lang.org&#x2F;t&#x2F;jemalloc-was-just-removed-...</a></div><br/></div></div><div id="38461882" class="c"><input type="checkbox" id="c-38461882" checked=""/><div class="controls bullet"><span class="by">diamondlovesyou</span><span>|</span><a href="#38461164">prev</a><span>|</span><a href="#38460113">next</a><span>|</span><label class="collapse" for="c-38461882">[-]</label><label class="expand" for="c-38461882">[6 more]</label></div><br/><div class="children"><div class="content">AMD&#x27;s string store is not like Intel&#x27;s. Generally, you don&#x27;t want to use it until you are past the CPU&#x27;s L2 size (L3 is a victim cache), making ~2k WAY too small. Once past that point, it&#x27;s profitable to use string store, and should run at &quot;DRAM speed&quot;. But it has a high startup cost, hence 256bit vector loads&#x2F;stores should be used until that threshold is met.</div><br/><div id="38462302" class="c"><input type="checkbox" id="c-38462302" checked=""/><div class="controls bullet"><span class="by">js2</span><span>|</span><a href="#38461882">parent</a><span>|</span><a href="#38462202">next</a><span>|</span><label class="collapse" for="c-38462302">[-]</label><label class="expand" for="c-38462302">[3 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t the high startup cost what FSRM is intended to solve?<p>&gt; With the new Zen3 CPUs, Fast Short REP MOV (FSRM) is finally added to AMD’s CPU functions analog to Intel’s X86_FEATURE_FSRM.  Intel had already introduced this in 2017 with the Ice Lake Client microarchitecture. But now AMD is obviously using this feature to increase the performance of REP MOVSB for short and very short operations. This improvement applies to Intel for string lengths between 1 and 128 bytes and one can assume that AMD’s implementation will look the same for compatibility reasons.<p><a href="https:&#x2F;&#x2F;www.igorslab.de&#x2F;en&#x2F;cracks-on-the-core-3-yet-the-5-ghz-sample-of-the-16-kernels-with-4-9-ghz-sample-emerged-on-the-implemented-further-x86-instructions-from-intel&#x2F;%0A" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.igorslab.de&#x2F;en&#x2F;cracks-on-the-core-3-yet-the-5-gh...</a></div><br/><div id="38463286" class="c"><input type="checkbox" id="c-38463286" checked=""/><div class="controls bullet"><span class="by">diamondlovesyou</span><span>|</span><a href="#38461882">root</a><span>|</span><a href="#38462302">parent</a><span>|</span><a href="#38462202">next</a><span>|</span><label class="collapse" for="c-38463286">[-]</label><label class="expand" for="c-38463286">[2 more]</label></div><br/><div class="children"><div class="content">Fast is relative here. These are microcoded instructions, which are generally terrible for latency: microcoded instructions don&#x27;t get branch prediction benefits, nor OoO benefits (they lock the FE&#x2F;scheduler while running). Small memcpy&#x2F;moves are always latency bound, hence even if the HW supports &quot;fast&quot; rep store, you&#x27;re better off not using them. L2 is wicked fast, and these copies are linear, so prediction will be good.<p>Note that for rep store to be better it must overcome the cost of the initial latency and then catch up to the 32byte vector copies, which yes generally have not-as-good-perf vs DRAM speed, but they aren&#x27;t that bad either. Thus for small copies.... just don&#x27;t use string store.<p>All this is not even considering non-temporal loads&#x2F;stores; many larger copies would see better perf by not trashing the L2 cache, since the destination or source is often not inspected right after. String stores don&#x27;t have a non-temporal option, so this has to be done with vectors.</div><br/><div id="38465069" class="c"><input type="checkbox" id="c-38465069" checked=""/><div class="controls bullet"><span class="by">js2</span><span>|</span><a href="#38461882">root</a><span>|</span><a href="#38463286">parent</a><span>|</span><a href="#38462202">next</a><span>|</span><label class="collapse" for="c-38465069">[-]</label><label class="expand" for="c-38465069">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure that your comment is responsive to the original post.<p>FSRM is fast on Intel, even with single byte strings. AMD claims to support FSRM with recent CPUs but performs poorly on small strings, so code which Just Works on Intel has a performance regression when running on AMD.<p>Now here you&#x27;re saying `REP MOVSB` shouldn&#x27;t be used on AMD with small strings. In that case, AMD CPUs shouldn&#x27;t advertise FSRM. As long as they&#x27;re advertising it, it shouldn&#x27;t perform worse than the alternative.<p><a href="https:&#x2F;&#x2F;bugs.launchpad.net&#x2F;ubuntu&#x2F;+source&#x2F;glibc&#x2F;+bug&#x2F;2030515" rel="nofollow noreferrer">https:&#x2F;&#x2F;bugs.launchpad.net&#x2F;ubuntu&#x2F;+source&#x2F;glibc&#x2F;+bug&#x2F;2030515</a><p><a href="https:&#x2F;&#x2F;sourceware.org&#x2F;bugzilla&#x2F;show_bug.cgi?id=30994" rel="nofollow noreferrer">https:&#x2F;&#x2F;sourceware.org&#x2F;bugzilla&#x2F;show_bug.cgi?id=30994</a><p>I&#x27;m not a CPU expert so perhaps I&#x27;m misinterpreting you and we&#x27;re talking past each other. If so, please clarify.</div><br/></div></div></div></div></div></div><div id="38462202" class="c"><input type="checkbox" id="c-38462202" checked=""/><div class="controls bullet"><span class="by">rasz</span><span>|</span><a href="#38461882">parent</a><span>|</span><a href="#38462302">prev</a><span>|</span><a href="#38460113">next</a><span>|</span><label class="collapse" for="c-38462202">[-]</label><label class="expand" for="c-38462202">[2 more]</label></div><br/><div class="children"><div class="content">Or you leave it as is forcing AMD to fix their shit.  &quot;fast string mode&quot; has been strongly hinted as _the_ optimal way over 30 years ago with Pentium Pro, further enforced over 10 years ago with ERMSB and FSRM 4 years ago. AMD get with the program.</div><br/><div id="38467291" class="c"><input type="checkbox" id="c-38467291" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38461882">root</a><span>|</span><a href="#38462202">parent</a><span>|</span><a href="#38460113">next</a><span>|</span><label class="collapse" for="c-38467291">[-]</label><label class="expand" for="c-38467291">[1 more]</label></div><br/><div class="children"><div class="content">rep movsb might have been fast at one point but it definitely was not for a few decades in the middle, where vector stores were the fastest way to implement memcpy. Intel decided that they should probably make it fast again and they have slowly made it competitive with the extensions you’ve mentioned. But for processors that don’t support it, using rep movsb is going to be slow and probably not something you’d want to pick unless you have weird constraints (binary size?)</div><br/></div></div></div></div></div></div><div id="38460113" class="c"><input type="checkbox" id="c-38460113" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#38461882">prev</a><span>|</span><a href="#38458516">next</a><span>|</span><label class="collapse" for="c-38460113">[-]</label><label class="expand" for="c-38460113">[3 more]</label></div><br/><div class="children"><div class="content">I sent this to the right people.</div><br/><div id="38467299" class="c"><input type="checkbox" id="c-38467299" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38460113">parent</a><span>|</span><a href="#38458516">next</a><span>|</span><label class="collapse" for="c-38467299">[-]</label><label class="expand" for="c-38467299">[2 more]</label></div><br/><div class="children"><div class="content">(…at AMD?)</div><br/><div id="38467378" class="c"><input type="checkbox" id="c-38467378" checked=""/><div class="controls bullet"><span class="by">amluto</span><span>|</span><a href="#38460113">root</a><span>|</span><a href="#38467299">parent</a><span>|</span><a href="#38458516">next</a><span>|</span><label class="collapse" for="c-38467378">[-]</label><label class="expand" for="c-38467378">[1 more]</label></div><br/><div class="children"><div class="content">At AMD.</div><br/></div></div></div></div></div></div><div id="38458516" class="c"><input type="checkbox" id="c-38458516" checked=""/><div class="controls bullet"><span class="by">Pesthuf</span><span>|</span><a href="#38460113">prev</a><span>|</span><a href="#38464100">next</a><span>|</span><label class="collapse" for="c-38458516">[-]</label><label class="expand" for="c-38458516">[3 more]</label></div><br/><div class="children"><div class="content">Clickbait headline, but the article is great!</div><br/><div id="38462023" class="c"><input type="checkbox" id="c-38462023" checked=""/><div class="controls bullet"><span class="by">saghm</span><span>|</span><a href="#38458516">parent</a><span>|</span><a href="#38461687">next</a><span>|</span><label class="collapse" for="c-38462023">[-]</label><label class="expand" for="c-38462023">[1 more]</label></div><br/><div class="children"><div class="content">I think there might be a range of where people draw the line between reasonable headlines and clickbait, because I tend to think of clickbait as something where the &quot;answer&quot; to some question is intentionally left out to try to bait people into clicking. For this article, something I&#x27;d consider clickbait would be something like &quot;Rust std fs is slower than Python?&quot; without the answer after. More commonly, the headline isn&#x27;t phrased directly as a question, but instead of saying something like &quot;So-and-so musician loves burritos&quot;, it will leave out the main detail and say something like &quot;The meal so-and-so eats before every concert&quot;, which is trying to get you to click and have to read through lots of extraneous prose just to find the word &quot;burritos&quot;.<p>Having a hook to get people to want to read the article is reasonable in my opinion; after all, if you could fit every detail in the size of a headline, you wouldn&#x27;t need an article at all! Clickbait inverts this by _only_ having enough enough substance that you could get all the info in the headline, but instead it leaves out the one detail that&#x27;s interesting and then pads it with fluff that you&#x27;re forced to click and read through if you want the answer.</div><br/></div></div><div id="38461687" class="c"><input type="checkbox" id="c-38461687" checked=""/><div class="controls bullet"><span class="by">joshfee</span><span>|</span><a href="#38458516">parent</a><span>|</span><a href="#38462023">prev</a><span>|</span><a href="#38464100">next</a><span>|</span><label class="collapse" for="c-38461687">[-]</label><label class="expand" for="c-38461687">[1 more]</label></div><br/><div class="children"><div class="content">Surprisingly I think this usage of clickbait is totally reasonable because it matches the author&#x27;s initial thoughts&#x2F;experiences of &quot;what?! this can&#x27;t be right...&quot;</div><br/></div></div></div></div><div id="38464100" class="c"><input type="checkbox" id="c-38464100" checked=""/><div class="controls bullet"><span class="by">codedokode</span><span>|</span><a href="#38458516">prev</a><span>|</span><a href="#38460060">next</a><span>|</span><label class="collapse" for="c-38464100">[-]</label><label class="expand" for="c-38464100">[5 more]</label></div><br/><div class="children"><div class="content">Why is there need to move memory? Hardware cannot DMA data into non-page-aligned memory? Or Linux doesn&#x27;t want to load non-aligned data?</div><br/><div id="38464738" class="c"><input type="checkbox" id="c-38464738" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#38464100">parent</a><span>|</span><a href="#38460060">next</a><span>|</span><label class="collapse" for="c-38464738">[-]</label><label class="expand" for="c-38464738">[4 more]</label></div><br/><div class="children"><div class="content">The Linux page cache keeps data page-aligned so if you want the data to be unaligned Linux will copy it.</div><br/><div id="38464882" class="c"><input type="checkbox" id="c-38464882" checked=""/><div class="controls bullet"><span class="by">codedokode</span><span>|</span><a href="#38464100">root</a><span>|</span><a href="#38464738">parent</a><span>|</span><a href="#38460060">next</a><span>|</span><label class="collapse" for="c-38464882">[-]</label><label class="expand" for="c-38464882">[3 more]</label></div><br/><div class="children"><div class="content">What if I don&#x27;t want to use cache?</div><br/><div id="38465332" class="c"><input type="checkbox" id="c-38465332" checked=""/><div class="controls bullet"><span class="by">wmf</span><span>|</span><a href="#38464100">root</a><span>|</span><a href="#38464882">parent</a><span>|</span><a href="#38465114">next</a><span>|</span><label class="collapse" for="c-38465332">[-]</label><label class="expand" for="c-38465332">[1 more]</label></div><br/><div class="children"><div class="content">You can use O_DIRECT although that also forces alignment IIRC.</div><br/></div></div><div id="38465114" class="c"><input type="checkbox" id="c-38465114" checked=""/><div class="controls bullet"><span class="by">tedunangst</span><span>|</span><a href="#38464100">root</a><span>|</span><a href="#38464882">parent</a><span>|</span><a href="#38465332">prev</a><span>|</span><a href="#38460060">next</a><span>|</span><label class="collapse" for="c-38465114">[-]</label><label class="expand" for="c-38465114">[1 more]</label></div><br/><div class="children"><div class="content">Pull out some RAM sticks.</div><br/></div></div></div></div></div></div></div></div><div id="38460060" class="c"><input type="checkbox" id="c-38460060" checked=""/><div class="controls bullet"><span class="by">fsniper</span><span>|</span><a href="#38464100">prev</a><span>|</span><a href="#38465098">next</a><span>|</span><label class="collapse" for="c-38460060">[-]</label><label class="expand" for="c-38460060">[2 more]</label></div><br/><div class="children"><div class="content">The article itself is a great read and it has fascinating info related to this issue.<p>However I am more interested&#x2F;concerned about another part. How the issue is reported&#x2F;recorded and how the communications are handled.<p>Reporting is done over discord, which is a proprietary environment which is not indexed, or searchable. Will not be archived.<p>Communications and deliberations are done over discord and telegram, which is probably worse than discord in this context.<p>This blog post and the github repository is the lingering remains of them. If Xuanwo did not blog this. It would be lost in timeline.<p>Isn&#x27;t this fascinating?</div><br/><div id="38466918" class="c"><input type="checkbox" id="c-38466918" checked=""/><div class="controls bullet"><span class="by">jll29</span><span>|</span><a href="#38460060">parent</a><span>|</span><a href="#38465098">next</a><span>|</span><label class="collapse" for="c-38466918">[-]</label><label class="expand" for="c-38466918">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Reporting is done over discord, which is a proprietary environment which is not indexed, or searchable. Will not be archived.<p>That&#x27;s why I don&#x27;t accept the response &quot;but there&#x27;s Discord now&quot; whenever I moan about USENET&#x27;s demise. Back in the days before it, every post was nicely searchable by DejaNews (later Google).<p>We need to get back to open standards for important communications (e.g. all open source projects that are important to the Internet&#x2F;WWW stack and core programming and libraries).</div><br/></div></div></div></div><div id="38465098" class="c"><input type="checkbox" id="c-38465098" checked=""/><div class="controls bullet"><span class="by">eigenform</span><span>|</span><a href="#38460060">prev</a><span>|</span><a href="#38461217">next</a><span>|</span><label class="collapse" for="c-38465098">[-]</label><label class="expand" for="c-38465098">[2 more]</label></div><br/><div class="children"><div class="content">would be lovely if ${cpu_vendor} would document exactly how FSRM&#x2F;ERMS&#x2F;etc are implemented and what the expected behavior is</div><br/><div id="38467309" class="c"><input type="checkbox" id="c-38467309" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38465098">parent</a><span>|</span><a href="#38461217">next</a><span>|</span><label class="collapse" for="c-38467309">[-]</label><label class="expand" for="c-38467309">[1 more]</label></div><br/><div class="children"><div class="content">It is documented; this is a performance bug.</div><br/></div></div></div></div><div id="38461217" class="c"><input type="checkbox" id="c-38461217" checked=""/><div class="controls bullet"><span class="by">titaniumtown</span><span>|</span><a href="#38465098">prev</a><span>|</span><a href="#38462428">next</a><span>|</span><label class="collapse" for="c-38461217">[-]</label><label class="expand" for="c-38461217">[1 more]</label></div><br/><div class="children"><div class="content">Extremely well written article! Very surprising outcome.</div><br/></div></div><div id="38462428" class="c"><input type="checkbox" id="c-38462428" checked=""/><div class="controls bullet"><span class="by">lxe</span><span>|</span><a href="#38461217">prev</a><span>|</span><a href="#38461931">next</a><span>|</span><label class="collapse" for="c-38462428">[-]</label><label class="expand" for="c-38462428">[2 more]</label></div><br/><div class="children"><div class="content">I wonder what other things we can improve by removing spectre mitigations and tuning hugepage, syscall altency, and core affinity</div><br/><div id="38467321" class="c"><input type="checkbox" id="c-38467321" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38462428">parent</a><span>|</span><a href="#38461931">next</a><span>|</span><label class="collapse" for="c-38467321">[-]</label><label class="expand" for="c-38467321">[1 more]</label></div><br/><div class="children"><div class="content">Mitigations did not have a meaningful performance impact here.</div><br/></div></div></div></div><div id="38461931" class="c"><input type="checkbox" id="c-38461931" checked=""/><div class="controls bullet"><span class="by">forrestthewoods</span><span>|</span><a href="#38462428">prev</a><span>|</span><a href="#38458709">next</a><span>|</span><label class="collapse" for="c-38461931">[-]</label><label class="expand" for="c-38461931">[1 more]</label></div><br/><div class="children"><div class="content">Delightful article. Thank you author for sharing! I felt like I experienced every shock twist in surprise in your journey like I was right there with you all along.</div><br/></div></div><div id="38458709" class="c"><input type="checkbox" id="c-38458709" checked=""/><div class="controls bullet"><span class="by">Pop_-</span><span>|</span><a href="#38461931">prev</a><span>|</span><a href="#38460460">next</a><span>|</span><label class="collapse" for="c-38458709">[-]</label><label class="expand" for="c-38458709">[10 more]</label></div><br/><div class="children"><div class="content">Disclaimer: The title has been changed to &quot;Rust std fs slower than Python!? No, it&#x27;s hardware!&quot; to avoid clickbait. However I&#x27;m not able to fix the title in HN.</div><br/><div id="38460323" class="c"><input type="checkbox" id="c-38460323" checked=""/><div class="controls bullet"><span class="by">sharperguy</span><span>|</span><a href="#38458709">parent</a><span>|</span><a href="#38460722">next</a><span>|</span><label class="collapse" for="c-38460323">[-]</label><label class="expand" for="c-38460323">[1 more]</label></div><br/><div class="children"><div class="content">&quot;Works on contingency? No, money down!&quot;</div><br/></div></div><div id="38460722" class="c"><input type="checkbox" id="c-38460722" checked=""/><div class="controls bullet"><span class="by">pvg</span><span>|</span><a href="#38458709">parent</a><span>|</span><a href="#38460323">prev</a><span>|</span><a href="#38460707">next</a><span>|</span><label class="collapse" for="c-38460722">[-]</label><label class="expand" for="c-38460722">[1 more]</label></div><br/><div class="children"><div class="content">you can mail hn@ycombinator.com and they can change it for you to whatever.</div><br/></div></div><div id="38459663" class="c"><input type="checkbox" id="c-38459663" checked=""/><div class="controls bullet"><span class="by">3cats-in-a-coat</span><span>|</span><a href="#38458709">parent</a><span>|</span><a href="#38460707">prev</a><span>|</span><a href="#38460460">next</a><span>|</span><label class="collapse" for="c-38459663">[-]</label><label class="expand" for="c-38459663">[6 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the TLDR on how... hardware performs differently on two software runtimes?</div><br/><div id="38459804" class="c"><input type="checkbox" id="c-38459804" checked=""/><div class="controls bullet"><span class="by">pornel</span><span>|</span><a href="#38458709">root</a><span>|</span><a href="#38459663">parent</a><span>|</span><a href="#38459790">next</a><span>|</span><label class="collapse" for="c-38459804">[-]</label><label class="expand" for="c-38459804">[2 more]</label></div><br/><div class="children"><div class="content">AMD&#x27;s implementation of `rep movsb` instruction is surprisingly slow when addresses are page aligned. Python&#x27;s allocator happens to add a 16-byte offset that avoids the hardware quirk&#x2F;bug.</div><br/><div id="38462213" class="c"><input type="checkbox" id="c-38462213" checked=""/><div class="controls bullet"><span class="by">sound1</span><span>|</span><a href="#38458709">root</a><span>|</span><a href="#38459804">parent</a><span>|</span><a href="#38459790">next</a><span>|</span><label class="collapse" for="c-38462213">[-]</label><label class="expand" for="c-38462213">[1 more]</label></div><br/><div class="children"><div class="content">thank you, upvoted!</div><br/></div></div></div></div><div id="38459790" class="c"><input type="checkbox" id="c-38459790" checked=""/><div class="controls bullet"><span class="by">lynndotpy</span><span>|</span><a href="#38458709">root</a><span>|</span><a href="#38459663">parent</a><span>|</span><a href="#38459804">prev</a><span>|</span><a href="#38460460">next</a><span>|</span><label class="collapse" for="c-38459790">[-]</label><label class="expand" for="c-38459790">[3 more]</label></div><br/><div class="children"><div class="content">One of the very first things in the article is a TLDR section that points you to the conclusion.<p>&gt; In conclusion, the issue isn&#x27;t software-related. Python outperforms C&#x2F;Rust due to an AMD CPU bug.</div><br/><div id="38459830" class="c"><input type="checkbox" id="c-38459830" checked=""/><div class="controls bullet"><span class="by">j16sdiz</span><span>|</span><a href="#38458709">root</a><span>|</span><a href="#38459790">parent</a><span>|</span><a href="#38460460">next</a><span>|</span><label class="collapse" for="c-38459830">[-]</label><label class="expand" for="c-38459830">[2 more]</label></div><br/><div class="children"><div class="content">It <i>is</i> software-related.
Just the CPU perform badly on some <i>software</i> instruction.</div><br/><div id="38460217" class="c"><input type="checkbox" id="c-38460217" checked=""/><div class="controls bullet"><span class="by">xuanwo</span><span>|</span><a href="#38458709">root</a><span>|</span><a href="#38459830">parent</a><span>|</span><a href="#38460460">next</a><span>|</span><label class="collapse" for="c-38460217">[-]</label><label class="expand" for="c-38460217">[1 more]</label></div><br/><div class="children"><div class="content">FSRM is a CPU feature embedded in the microcode (in this instance, amd-ucode) that software such as glibc cannot interact with. I refer to it as hardware because I consider microcode a part of the hardware.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38460460" class="c"><input type="checkbox" id="c-38460460" checked=""/><div class="controls bullet"><span class="by">pmontra</span><span>|</span><a href="#38458709">prev</a><span>|</span><a href="#38459549">next</a><span>|</span><label class="collapse" for="c-38460460">[-]</label><label class="expand" for="c-38460460">[11 more]</label></div><br/><div class="children"><div class="content">&gt; However, mmap has other uses too. It&#x27;s commonly used to allocate large regions of memory for applications.<p>Slack is allocating 1132 GB of virtual memory on my laptop right now. I don&#x27;t know if they are using mmap but that&#x27;s 1100 GB more than the physical memory.</div><br/><div id="38461106" class="c"><input type="checkbox" id="c-38461106" checked=""/><div class="controls bullet"><span class="by">aseipp</span><span>|</span><a href="#38460460">parent</a><span>|</span><a href="#38460535">next</a><span>|</span><label class="collapse" for="c-38461106">[-]</label><label class="expand" for="c-38461106">[2 more]</label></div><br/><div class="children"><div class="content">That is Chromium doing it, and yes, it is using mmap to create a very large, (almost certainly) contiguous range of memory. Many runtimes do this, because it&#x27;s useful (on 64-bit systems) to create a ridiculously large virtually mapped address space and then only commit small parts of it over time as needed, because it makes memory allocation simpler in several ways; notably it means you don&#x27;t have to worry about allocating new address spaces when simply allocating memory, and it means answering things like &quot;Is this a heap object?&quot; is easier.</div><br/><div id="38463461" class="c"><input type="checkbox" id="c-38463461" checked=""/><div class="controls bullet"><span class="by">rasz</span><span>|</span><a href="#38460460">root</a><span>|</span><a href="#38461106">parent</a><span>|</span><a href="#38460535">next</a><span>|</span><label class="collapse" for="c-38463461">[-]</label><label class="expand" for="c-38463461">[1 more]</label></div><br/><div class="children"><div class="content">dolphin emulator has recent example of this: 
<a href="https:&#x2F;&#x2F;dolphin-emu.org&#x2F;blog&#x2F;2023&#x2F;11&#x2F;25&#x2F;dolphin-progress-report-august-september-and-october-2023&#x2F;#50-19415-and-50-20126-improve-jit-block-lookup-performance-by-krnlyng" rel="nofollow noreferrer">https:&#x2F;&#x2F;dolphin-emu.org&#x2F;blog&#x2F;2023&#x2F;11&#x2F;25&#x2F;dolphin-progress-rep...</a><p>seems its not without perils on Windows:<p>&quot;In an ideal world, that would be all we have to say about the new solution. But for Windows users, there&#x27;s a special quirk. On most operating systems, we can use a special flag to signal that we don&#x27;t really care if the system has 32 GiB of real memory. Unfortunately, Windows has no convenient way to do this. Dolphin still works fine on Windows computers that have less than 32 GiB of RAM, but if Windows is set to automatically manage the size of the page file, which is the case by default, starting any game in Dolphin will cause the page file to balloon in size. Dolphin isn&#x27;t actually writing to all this newly allocated space in the page file, so there are no concerns about performance or disk lifetime. Also, Windows won&#x27;t try to grow the page file beyond the amount of available disk space, and the page file shrinks back to its previous size when you close Dolphin, so for the most part there are no real consequences... &quot;</div><br/></div></div></div></div><div id="38460535" class="c"><input type="checkbox" id="c-38460535" checked=""/><div class="controls bullet"><span class="by">Pop_-</span><span>|</span><a href="#38460460">parent</a><span>|</span><a href="#38461106">prev</a><span>|</span><a href="#38460479">next</a><span>|</span><label class="collapse" for="c-38460535">[-]</label><label class="expand" for="c-38460535">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t know why but this really makes me laugh</div><br/></div></div><div id="38460479" class="c"><input type="checkbox" id="c-38460479" checked=""/><div class="controls bullet"><span class="by">Waterluvian</span><span>|</span><a href="#38460460">parent</a><span>|</span><a href="#38460535">prev</a><span>|</span><a href="#38461022">next</a><span>|</span><label class="collapse" for="c-38460479">[-]</label><label class="expand" for="c-38460479">[6 more]</label></div><br/><div class="children"><div class="content">I’m not sure allocations mean anything practical anymore. I recall OSX allocating ridiculous amounts of virtual memory to stuff but never found OSX or the software to ever feel slow and pagey.</div><br/><div id="38460577" class="c"><input type="checkbox" id="c-38460577" checked=""/><div class="controls bullet"><span class="by">dietrichepp</span><span>|</span><a href="#38460460">root</a><span>|</span><a href="#38460479">parent</a><span>|</span><a href="#38461022">next</a><span>|</span><label class="collapse" for="c-38460577">[-]</label><label class="expand" for="c-38460577">[5 more]</label></div><br/><div class="children"><div class="content">The way I describe mmap these days is to say it allocates address space. This can sometimes be a clearer way of describing it, since the physical memory will only get allocated once you use the memory (maybe never).</div><br/><div id="38460790" class="c"><input type="checkbox" id="c-38460790" checked=""/><div class="controls bullet"><span class="by">byteknight</span><span>|</span><a href="#38460460">root</a><span>|</span><a href="#38460577">parent</a><span>|</span><a href="#38461022">next</a><span>|</span><label class="collapse" for="c-38460790">[-]</label><label class="expand" for="c-38460790">[4 more]</label></div><br/><div class="children"><div class="content">But is it not still limited by allocating the RAM + Page&#x2F;Swap size?</div><br/><div id="38461126" class="c"><input type="checkbox" id="c-38461126" checked=""/><div class="controls bullet"><span class="by">aseipp</span><span>|</span><a href="#38460460">root</a><span>|</span><a href="#38460790">parent</a><span>|</span><a href="#38460927">next</a><span>|</span><label class="collapse" for="c-38461126">[-]</label><label class="expand" for="c-38461126">[2 more]</label></div><br/><div class="children"><div class="content">Maybe I&#x27;m misunderstanding you but: no, you can allocate terabytes of address space on modern 64-bit Linux on a machine with only 8GB of RAM with overcommit. Try it; you can allocate 2^46 bytes of space (~= 100TB) today, with no problem. There is no limit to the allocation space in an overcommit system; there is only a limit to the actual working set, which is very different.</div><br/><div id="38462989" class="c"><input type="checkbox" id="c-38462989" checked=""/><div class="controls bullet"><span class="by">j16sdiz</span><span>|</span><a href="#38460460">root</a><span>|</span><a href="#38461126">parent</a><span>|</span><a href="#38460927">next</a><span>|</span><label class="collapse" for="c-38462989">[-]</label><label class="expand" for="c-38462989">[1 more]</label></div><br/><div class="children"><div class="content">You can do it without overcommit -- you can just back the mmap with file</div><br/></div></div></div></div><div id="38460927" class="c"><input type="checkbox" id="c-38460927" checked=""/><div class="controls bullet"><span class="by">wbkang</span><span>|</span><a href="#38460460">root</a><span>|</span><a href="#38460790">parent</a><span>|</span><a href="#38461126">prev</a><span>|</span><a href="#38461022">next</a><span>|</span><label class="collapse" for="c-38460927">[-]</label><label class="expand" for="c-38460927">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think so, but it&#x27;s difficult to find an actual reference. For sure it does overcommit like crazy. Here&#x27;s an output from my mac:<p>% ps aux | sort -k5 -rh | head -1<p>xxxxxxxx         88273   1.2  0.9 1597482768 316064   ??  S     4:07PM  35:09.71 &#x2F;Applications&#x2F;Slack.app&#x2F;Contents&#x2F;Frameworks&#x2F;Slack Helper (Renderer).app&#x2F;...<p>Since ps displays vsz column in KiB, 1597482768 corresponds to 1TB+.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38459549" class="c"><input type="checkbox" id="c-38459549" checked=""/><div class="controls bullet"><span class="by">explodingwaffle</span><span>|</span><a href="#38460460">prev</a><span>|</span><a href="#38458488">next</a><span>|</span><label class="collapse" for="c-38459549">[-]</label><label class="expand" for="c-38459549">[3 more]</label></div><br/><div class="children"><div class="content">Anyone else feeling the frequency illusion with rep movsb?<p>(<a href="https:&#x2F;&#x2F;lock.cmpxchg8b.com&#x2F;reptar.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;lock.cmpxchg8b.com&#x2F;reptar.html</a>)</div><br/><div id="38467336" class="c"><input type="checkbox" id="c-38467336" checked=""/><div class="controls bullet"><span class="by">saagarjha</span><span>|</span><a href="#38459549">parent</a><span>|</span><a href="#38461901">next</a><span>|</span><label class="collapse" for="c-38467336">[-]</label><label class="expand" for="c-38467336">[1 more]</label></div><br/><div class="children"><div class="content">This is unrelated.</div><br/></div></div></div></div><div id="38458488" class="c"><input type="checkbox" id="c-38458488" checked=""/><div class="controls bullet"><span class="by">sgift</span><span>|</span><a href="#38459549">prev</a><span>|</span><a href="#38461954">next</a><span>|</span><label class="collapse" for="c-38458488">[-]</label><label class="expand" for="c-38458488">[7 more]</label></div><br/><div class="children"><div class="content">Either the author changed the headline to something less clickbaity in the meantime or you edited it for clickbait Pop_- (in that case: shame on you) - current headline: &quot;Rust std fs slower than Python!? No, it&#x27;s hardware!&quot;</div><br/><div id="38458607" class="c"><input type="checkbox" id="c-38458607" checked=""/><div class="controls bullet"><span class="by">epage</span><span>|</span><a href="#38458488">parent</a><span>|</span><a href="#38458616">next</a><span>|</span><label class="collapse" for="c-38458607">[-]</label><label class="expand" for="c-38458607">[1 more]</label></div><br/><div class="children"><div class="content">Based on the &#x2F;r&#x2F;rust thread, the author seemed to change the headline based on feedback to make it less clickbait-y</div><br/></div></div><div id="38458616" class="c"><input type="checkbox" id="c-38458616" checked=""/><div class="controls bullet"><span class="by">xuanwo</span><span>|</span><a href="#38458488">parent</a><span>|</span><a href="#38458607">prev</a><span>|</span><a href="#38458668">next</a><span>|</span><label class="collapse" for="c-38458616">[-]</label><label class="expand" for="c-38458616">[3 more]</label></div><br/><div class="children"><div class="content">Sorry for the clickbaity title, I have changed it based on others advice.</div><br/><div id="38459264" class="c"><input type="checkbox" id="c-38459264" checked=""/><div class="controls bullet"><span class="by">thechao</span><span>|</span><a href="#38458488">root</a><span>|</span><a href="#38458616">parent</a><span>|</span><a href="#38466989">next</a><span>|</span><label class="collapse" for="c-38459264">[-]</label><label class="expand" for="c-38459264">[1 more]</label></div><br/><div class="children"><div class="content">I disagree that it&#x27;s clickbait-y. Diving down from Python bindings to ucode is ... not how things usually go. Doubly so, since Python is a very mature runtime, and I&#x27;d be inclined to believe they&#x27;ve dug up file-reading Kung Fu not available to the Average Joe.</div><br/></div></div><div id="38466989" class="c"><input type="checkbox" id="c-38466989" checked=""/><div class="controls bullet"><span class="by">jll29</span><span>|</span><a href="#38458488">root</a><span>|</span><a href="#38458616">parent</a><span>|</span><a href="#38459264">prev</a><span>|</span><a href="#38458668">next</a><span>|</span><label class="collapse" for="c-38466989">[-]</label><label class="expand" for="c-38466989">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for this unexpected, thriller-like read.<p>I&#x27;m impressed by your perseverance, how you follow through with your investigation to the lowest (hardware) level.</div><br/></div></div></div></div><div id="38458668" class="c"><input type="checkbox" id="c-38458668" checked=""/><div class="controls bullet"><span class="by">Pop_-</span><span>|</span><a href="#38458488">parent</a><span>|</span><a href="#38458616">prev</a><span>|</span><a href="#38461039">next</a><span>|</span><label class="collapse" for="c-38458668">[-]</label><label class="expand" for="c-38458668">[1 more]</label></div><br/><div class="children"><div class="content">The author has updated the title and also contacted me. But unfortunately I&#x27;m no longer able to update it so.</div><br/></div></div></div></div><div id="38461954" class="c"><input type="checkbox" id="c-38461954" checked=""/><div class="controls bullet"><span class="by">darkwater</span><span>|</span><a href="#38458488">prev</a><span>|</span><a href="#38460673">next</a><span>|</span><label class="collapse" for="c-38461954">[-]</label><label class="expand" for="c-38461954">[2 more]</label></div><br/><div class="children"><div class="content">Totally unrelated but: this post talks about the bug being first discovered in OpenDAL [1], which seems to be an Apache (Incubator) project to add an abstraction layer for storage over several types of storage backend. What&#x27;s the point&#x2F;use case of such an abstraction? Anybody using it?<p>[1] <a href="https:&#x2F;&#x2F;opendal.apache.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;opendal.apache.org&#x2F;</a></div><br/></div></div><div id="38459192" class="c"><input type="checkbox" id="c-38459192" checked=""/><div class="controls bullet"><span class="by">exxos</span><span>|</span><a href="#38458671">prev</a><span>|</span><a href="#38462672">next</a><span>|</span><label class="collapse" for="c-38459192">[-]</label><label class="expand" for="c-38459192">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s the hardware. Of course Rust remains the fastest and safest language and you must rewrite your applications in Rust.</div><br/><div id="38463292" class="c"><input type="checkbox" id="c-38463292" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#38459192">parent</a><span>|</span><a href="#38462672">next</a><span>|</span><label class="collapse" for="c-38463292">[-]</label><label class="expand" for="c-38463292">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;ve been posting like this so frequently as to cross into abusing the forum, so I&#x27;ve banned the account.<p>If you don&#x27;t want to be banned, you&#x27;re welcome to email hn@ycombinator.com and give us reason to believe that you&#x27;ll follow the rules in the future. They&#x27;re here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html</a>.</div><br/></div></div></div></div><div id="38462672" class="c"><input type="checkbox" id="c-38462672" checked=""/><div class="controls bullet"><span class="by">jokethrowaway</span><span>|</span><a href="#38459192">prev</a><span>|</span><a href="#38462475">next</a><span>|</span><label class="collapse" for="c-38462672">[-]</label><label class="expand" for="c-38462672">[1 more]</label></div><br/><div class="children"><div class="content">Clickbait title but interesting article.<p>This has nothing to do with python or rust</div><br/></div></div><div id="38462475" class="c"><input type="checkbox" id="c-38462475" checked=""/><div class="controls bullet"><span class="by">lxe</span><span>|</span><a href="#38462672">prev</a><span>|</span><a href="#38459070">next</a><span>|</span><label class="collapse" for="c-38462475">[-]</label><label class="expand" for="c-38462475">[2 more]</label></div><br/><div class="children"><div class="content">So Python isn&#x27;t affected by the bug because pymalloc performs better on buggy CPUs than jemalloc or malloc?</div><br/><div id="38466445" class="c"><input type="checkbox" id="c-38466445" checked=""/><div class="controls bullet"><span class="by">js2</span><span>|</span><a href="#38462475">parent</a><span>|</span><a href="#38459070">next</a><span>|</span><label class="collapse" for="c-38466445">[-]</label><label class="expand" for="c-38466445">[1 more]</label></div><br/><div class="children"><div class="content">It has nothing to do with pymalloc&#x27;s performance per se.<p>Rather, the performance issue only occurs when using `rep movsb` on AMD CPUs with certain page&#x2F;data alignment.<p>Pymalloc just happens to be using page&#x2F;data alignment that makes `rep movsb` happy while Rust&#x27;s default allocator is using alignments that just happen to make `rep movsb` sad.</div><br/></div></div></div></div><div id="38459070" class="c"><input type="checkbox" id="c-38459070" checked=""/><div class="controls bullet"><span class="by">drtgh</span><span>|</span><a href="#38462475">prev</a><span>|</span><a href="#38462291">next</a><span>|</span><label class="collapse" for="c-38459070">[-]</label><label class="expand" for="c-38459070">[22 more]</label></div><br/><div class="children"><div class="content">&gt;Rust std fs slower than Python!? No, it&#x27;s hardware!<p>&gt;...<p>&gt;Python features three memory domains, each representing different allocation strategies and optimized for various purposes.<p>&gt;...<p>&gt;Rust is slower than Python only on my machine.<p>if one library performs wildly better than the other in the same test, on the same hardware, how can that not be a software-related problem? sounds like a contradiction.<p>Maybe should be considered a coding issue and&#x2F;or feature absent? IMHO it would be expected Rust&#x27;s std library perform well without making all the users to circumvent the issue manually.<p>The article is well investigated so I assume the author just want to show the problem existence without creating controversy because other way I can not understand.</div><br/><div id="38459176" class="c"><input type="checkbox" id="c-38459176" checked=""/><div class="controls bullet"><span class="by">Pop_-</span><span>|</span><a href="#38459070">parent</a><span>|</span><a href="#38459391">next</a><span>|</span><label class="collapse" for="c-38459176">[-]</label><label class="expand" for="c-38459176">[19 more]</label></div><br/><div class="children"><div class="content">The root cause is AMD&#x27;s bad support for rep movsb (which is a hardware problem). However, python by default has a small offset when reading memories while lower level language (rust and c) does not, which is why python seems to perform better than c&#x2F;rust. It &quot;accidentally&quot; avoided the hardware problem.</div><br/><div id="38459911" class="c"><input type="checkbox" id="c-38459911" checked=""/><div class="controls bullet"><span class="by">meneer_oke</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459176">parent</a><span>|</span><a href="#38461244">next</a><span>|</span><label class="collapse" for="c-38459911">[-]</label><label class="expand" for="c-38459911">[5 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t seem faster. Seem would imply that it isn&#x27;t the case.
It is faster currently on that setup.<p>But since python runtime is written in C, the issue can&#x27;t be Python vs C.</div><br/><div id="38462205" class="c"><input type="checkbox" id="c-38462205" checked=""/><div class="controls bullet"><span class="by">topaz0</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459911">parent</a><span>|</span><a href="#38460905">next</a><span>|</span><label class="collapse" for="c-38462205">[-]</label><label class="expand" for="c-38462205">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s obviously not python vs c -- the time difference turns out to be in kernel code (system call) and not user code at all, and the post explicitly constructs a c program that doesn&#x27;t have the slowdown by adding a memory offset. It just turns up by default in a comparison of python vs c code because python reads have a memory offset by default (for completely unrelated reasons) and analogous c reads don&#x27;t by default. In principle you could also construct python code that does see this slowdown, it would just be much less likely to show up at random. So the python vs c comp is a total red herring here, it just happened to be what the author noticed and used as a hook to understand the problem.</div><br/></div></div><div id="38460905" class="c"><input type="checkbox" id="c-38460905" checked=""/><div class="controls bullet"><span class="by">TylerE</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459911">parent</a><span>|</span><a href="#38462205">prev</a><span>|</span><a href="#38461244">next</a><span>|</span><label class="collapse" for="c-38460905">[-]</label><label class="expand" for="c-38460905">[3 more]</label></div><br/><div class="children"><div class="content">C is a very wide target. There are plenty of things that one can do “in C” that no human would ever write. For instance, the C code generated by languages like nim and zig that essentially use C as a sort of IR.</div><br/><div id="38460951" class="c"><input type="checkbox" id="c-38460951" checked=""/><div class="controls bullet"><span class="by">meneer_oke</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38460905">parent</a><span>|</span><a href="#38461244">next</a><span>|</span><label class="collapse" for="c-38460951">[-]</label><label class="expand" for="c-38460951">[2 more]</label></div><br/><div class="children"><div class="content">That is true, With C allot of possible<p>&gt;  However, python by default has a small offset when reading memories while lower level language (rust and c)<p>Yet if the runtime is made with C, then that statement is incorrect.</div><br/><div id="38464156" class="c"><input type="checkbox" id="c-38464156" checked=""/><div class="controls bullet"><span class="by">bilkow</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38460951">parent</a><span>|</span><a href="#38461244">next</a><span>|</span><label class="collapse" for="c-38464156">[-]</label><label class="expand" for="c-38464156">[1 more]</label></div><br/><div class="children"><div class="content">By going through that line of thought, you could also argue that the slow implementation for the slow version in C and Rust is actually implemented in C, as memcpy is on glibc. Hence, Python being faster than Rust would also mean in this case that Python is faster than C.<p>The point is not that one language is faster than another. The point is that the default way to implement something in a language ended up being surprisingly faster when compared to other languages in this specific scenario due to a performance issue in the hardware.<p>In other words: on this specific hardware, the default way to do this in Python is faster than the default way to do this in C and Rust. That can be true, as Python does not use C in the default way, it adds an offset! You can change your implementation in any of those languages to make it faster, in this case by just adding an offset, so it doesn&#x27;t mean that &quot;Python is faster than C or Rust in general&quot;.</div><br/></div></div></div></div></div></div></div></div><div id="38461244" class="c"><input type="checkbox" id="c-38461244" checked=""/><div class="controls bullet"><span class="by">magicalhippo</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459176">parent</a><span>|</span><a href="#38459911">prev</a><span>|</span><a href="#38459569">next</a><span>|</span><label class="collapse" for="c-38461244">[-]</label><label class="expand" for="c-38461244">[1 more]</label></div><br/><div class="children"><div class="content">I recall when Pentium was introduced we were told to avoid rep and write a carefully tuned loop ourselves. To go really fast one could use the FPU to do the loads and stores.<p>Not too long ago I read in Intel&#x27;s optimization guidelines that rep was now faster again and should be used.<p>Seems most of these things needs to be benchmarked on the CPU, as they change &quot;all the time&quot;. I&#x27;ve sped up plenty of code by just replacing hand crafted assembly with high-level functional equivalent code.<p>Of course so-slow-it&#x27;s-bad is different, however a runtime-determined implementation choice would avoid that as well.</div><br/></div></div><div id="38459569" class="c"><input type="checkbox" id="c-38459569" checked=""/><div class="controls bullet"><span class="by">formerly_proven</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459176">parent</a><span>|</span><a href="#38461244">prev</a><span>|</span><a href="#38459370">next</a><span>|</span><label class="collapse" for="c-38459569">[-]</label><label class="expand" for="c-38459569">[2 more]</label></div><br/><div class="children"><div class="content">That extra 0x20 (32 byte) offset is the size of the PyBytes object header for anyone wondering; 64 bits each for type object pointer, reference count, base pointer and item count.</div><br/><div id="38462320" class="c"><input type="checkbox" id="c-38462320" checked=""/><div class="controls bullet"><span class="by">mrweasel</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459569">parent</a><span>|</span><a href="#38459370">next</a><span>|</span><label class="collapse" for="c-38462320">[-]</label><label class="expand" for="c-38462320">[1 more]</label></div><br/><div class="children"><div class="content">Thank you, because I was wondering if some Python developer found the same issue and decided to just implement the offset. It makes much more sense that it just happens to work out that way in Python.</div><br/></div></div></div></div><div id="38459370" class="c"><input type="checkbox" id="c-38459370" checked=""/><div class="controls bullet"><span class="by">CoastalCoder</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459176">parent</a><span>|</span><a href="#38459569">prev</a><span>|</span><a href="#38459391">next</a><span>|</span><label class="collapse" for="c-38459370">[-]</label><label class="expand" for="c-38459370">[10 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure it makes sense to pin this only on AMD.<p>Whenever you&#x27;re writing performance-critical software, you need to consider the relevant combinations of hardware + software + workload + configuration.<p>Sometimes a problem can be created or fixed by adjusting any one &#x2F; some subset of those details.</div><br/><div id="38459476" class="c"><input type="checkbox" id="c-38459476" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459370">parent</a><span>|</span><a href="#38459498">next</a><span>|</span><label class="collapse" for="c-38459476">[-]</label><label class="expand" for="c-38459476">[8 more]</label></div><br/><div class="children"><div class="content">If that&#x27;s a bug that only happens with AMD CPUs, I think that&#x27;s totally fair.<p>If we start adding in exceptions at the top of the software stack for individuals failures of specific CPUs&#x2F;vendors, that seems like a strong regression from where we are today in terms of ergonomics of writing performance-critical software. We can&#x27;t be writing individual code for each N x M x O x P combination of hardware + software + workload + configuration (even if you can narrow down the &quot;relevant&quot; ones).</div><br/><div id="38460153" class="c"><input type="checkbox" id="c-38460153" checked=""/><div class="controls bullet"><span class="by">jpc0</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459476">parent</a><span>|</span><a href="#38461299">next</a><span>|</span><label class="collapse" for="c-38460153">[-]</label><label class="expand" for="c-38460153">[4 more]</label></div><br/><div class="children"><div class="content">&gt; We can&#x27;t be writing individual code for each N x M x O x P combination of hardware + software + workload + configuration<p>That is kind of exactly what you would do when optimising for popular platforms.<p>If this error occurs on an AMD Cpu used by half your users is your response to your user going to be &quot;just buy a different CPU&quot; or are you going to fix it in code and ship a &quot;performance improvement on XYZ platform&quot; update</div><br/><div id="38460563" class="c"><input type="checkbox" id="c-38460563" checked=""/><div class="controls bullet"><span class="by">jacoblambda</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38460153">parent</a><span>|</span><a href="#38460611">next</a><span>|</span><label class="collapse" for="c-38460563">[-]</label><label class="expand" for="c-38460563">[1 more]</label></div><br/><div class="children"><div class="content">Nobody said &quot;just buy a different CPU&quot; anywhere in this discussion or the article. And they are pinning the root cause on AMD which is completely fair because they are the source of the issue.<p>Given that the fix is within the memory allocator, there is already a relatively trivial fix for users who really need it (recompile with jemalloc as the global memory allocator).<p>For everyone else, it&#x27;s probably better to wait until AMD reports back with an analysis from their side and either recommends an &quot;official&quot; mitigation or pushes out a microcode update.</div><br/></div></div><div id="38460611" class="c"><input type="checkbox" id="c-38460611" checked=""/><div class="controls bullet"><span class="by">ansible</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38460153">parent</a><span>|</span><a href="#38460563">prev</a><span>|</span><a href="#38466949">next</a><span>|</span><label class="collapse" for="c-38460611">[-]</label><label class="expand" for="c-38460611">[1 more]</label></div><br/><div class="children"><div class="content">The fix is that AMD needs to develop, test and deploy a microcode update for their affected CPUs, and then the problem is truly fixed for everyone, not just the people who have detected the issue and tried to mitigate it.</div><br/></div></div><div id="38466949" class="c"><input type="checkbox" id="c-38466949" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38460153">parent</a><span>|</span><a href="#38460611">prev</a><span>|</span><a href="#38461299">next</a><span>|</span><label class="collapse" for="c-38466949">[-]</label><label class="expand" for="c-38466949">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but even if you&#x27;d take this on as your responsibility (while it should really be the CPU vendor fixing it), you would like to resolve it much lower in the stack, like the Rust compiler&#x2F;standard library or LLVM, and not individually in any Rust library that happens to stumble upon that problem.</div><br/></div></div></div></div><div id="38461299" class="c"><input type="checkbox" id="c-38461299" checked=""/><div class="controls bullet"><span class="by">pmontra</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459476">parent</a><span>|</span><a href="#38460153">prev</a><span>|</span><a href="#38460481">next</a><span>|</span><label class="collapse" for="c-38461299">[-]</label><label class="expand" for="c-38461299">[1 more]</label></div><br/><div class="children"><div class="content">Well, if Excel would be running at half the speed (or half of LibreOffice Calc!) on half of the machines around here somebody at Redmond would notice, find the hardware bug and work around it.<p>I guess that in most big companies it suffices that there is a problem with their own software running on the laptop of a C* manager or of somebody close to there. When I was working for a mobile operator the antennas the network division cared about most were the ones close to the home of the CEO. If he could make his test calls with no problems they had the time to fix the problems of the rest of the network in all the country.</div><br/></div></div><div id="38460481" class="c"><input type="checkbox" id="c-38460481" checked=""/><div class="controls bullet"><span class="by">richardwhiuk</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459476">parent</a><span>|</span><a href="#38461299">prev</a><span>|</span><a href="#38459498">next</a><span>|</span><label class="collapse" for="c-38460481">[-]</label><label class="expand" for="c-38460481">[2 more]</label></div><br/><div class="children"><div class="content">You are going to be disappointed when you find out there&#x27;s lots of architecture and CPU specific code in software libraries and the kernel.</div><br/><div id="38466996" class="c"><input type="checkbox" id="c-38466996" checked=""/><div class="controls bullet"><span class="by">hobofan</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38460481">parent</a><span>|</span><a href="#38459498">next</a><span>|</span><label class="collapse" for="c-38466996">[-]</label><label class="expand" for="c-38466996">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s completely fine in kernels and low-level libraries, but if I find that in a library as high-level as opendal, I&#x27;ll definitely mark it down as a code smell.</div><br/></div></div></div></div></div></div><div id="38459498" class="c"><input type="checkbox" id="c-38459498" checked=""/><div class="controls bullet"><span class="by">Pop_-</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459370">parent</a><span>|</span><a href="#38459476">prev</a><span>|</span><a href="#38459391">next</a><span>|</span><label class="collapse" for="c-38459498">[-]</label><label class="expand" for="c-38459498">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a known issue for AMD and has been tested by multiple people, and by the data provided by the author. It&#x27;s fair to pin this problem to AMD.</div><br/></div></div></div></div></div></div><div id="38459391" class="c"><input type="checkbox" id="c-38459391" checked=""/><div class="controls bullet"><span class="by">mwcampbell</span><span>|</span><a href="#38459070">parent</a><span>|</span><a href="#38459176">prev</a><span>|</span><a href="#38462291">next</a><span>|</span><label class="collapse" for="c-38459391">[-]</label><label class="expand" for="c-38459391">[2 more]</label></div><br/><div class="children"><div class="content">Years ago, Rust&#x27;s standard library used jemalloc. That decision substantially increased the minimum executable size, though. I didn&#x27;t publicly complain about it back then (as far as I can recall), but perhaps others did. So the Rust library team switched to using the OS&#x27;s allocator by default.<p>Maybe using an alternative allocator only solves the problem by accident and there&#x27;s another way to solve it intentionally; I don&#x27;t yet fully understand the problem. My point is that using a different allocator by default was already tried.</div><br/><div id="38462273" class="c"><input type="checkbox" id="c-38462273" checked=""/><div class="controls bullet"><span class="by">saghm</span><span>|</span><a href="#38459070">root</a><span>|</span><a href="#38459391">parent</a><span>|</span><a href="#38462291">next</a><span>|</span><label class="collapse" for="c-38462273">[-]</label><label class="expand" for="c-38462273">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  I didn&#x27;t publicly complain about it back then (as far as I can recall), but perhaps others did. So the Rust library team switched to using the OS&#x27;s allocator by default.<p>I&#x27;ve honestly never worked in a domain where binary size ever really mattered beyond maybe invoking `strip` on a binary before deploying it, so I try to keep an open mind. That said, this has always been a topic of discussion around Rust[0], and while I obviously don&#x27;t have anything against binary sizes being smaller, bugs like this do make me wonder about huge changes like switching the default allocator where we can&#x27;t really test all of the potential side effects; next time, the unintended consequences might not be worth the tradeoff.<p>[0]: <a href="https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&amp;page=0&amp;prefix=false&amp;query=rust%20binary%20size&amp;sort=byPopularity&amp;type=comment" rel="nofollow noreferrer">https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&amp;page=0&amp;prefix=false&amp;qu...</a></div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>