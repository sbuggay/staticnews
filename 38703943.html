<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1703062865710" as="style"/><link rel="stylesheet" href="styles.css?v=1703062865710"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://blog.elicit.com/search-vs-vector-db/">Build a search engine, not a vector DB</a> <span class="domain">(<a href="https://blog.elicit.com">blog.elicit.com</a>)</span></div><div class="subtext"><span>stuhlmueller</span> | <span>17 comments</span></div><br/><div><div id="38706576" class="c"><input type="checkbox" id="c-38706576" checked=""/><div class="controls bullet"><span class="by">bambax</span><span>|</span><a href="#38706366">next</a><span>|</span><label class="collapse" for="c-38706576">[-]</label><label class="expand" for="c-38706576">[1 more]</label></div><br/><div class="children"><div class="content">Many, many big companies don&#x27;t see any value in search. They simply use the defaults, and when those defaults are abysmal (like in the case of Confluence for example), well... they just suffer through it in silence.<p>I have so far mostly failed in trying to explain 1&#x2F; why search matters and 2&#x2F; that not all &quot;search&quot; functionality are equal and that building good search is an art form.</div><br/></div></div><div id="38706366" class="c"><input type="checkbox" id="c-38706366" checked=""/><div class="controls bullet"><span class="by">jankovicsandras</span><span>|</span><a href="#38706576">prev</a><span>|</span><a href="#38706092">next</a><span>|</span><label class="collapse" for="c-38706366">[-]</label><label class="expand" for="c-38706366">[2 more]</label></div><br/><div class="children"><div class="content">I agree too. My impression is that almost all RAG tutorials _only_ talk about vector DBs, when these are not strictly required for Retrieval Augmented Generation. I&#x27;m guessing vector DBs are useful when you have massive amounts of documents on diverse topics.<p>Some gotchas I experienced (but I might be using the wrong embedding&#x2F;vector DB: spaCy&#x2F;FAISS):<p>- Short user questions might result a low signal query vector, e. g. user : &quot;Who is Keanu Reeves?&quot; -&gt; false positives on Wikipedia articles which only contain &quot;Who is&quot;<p>- Typos and formatting affects the vectorization, a small difference might lead to a miss, e.g. &quot;Who is Keanu Reeves?&quot; -&gt; match, &quot;Who is keanu Reeves?&quot; -&gt; no match, no match with any other capitalization.<p>If there&#x27;s only a single document, a simple keyword search might lead to better results.<p>In my experience, false positives (retrieving an irrelevant text and generating completely wrong answer) are a bigger problem than negatives (not retrieving text, possibly can&#x27;t answer question).<p>Has somebody experience with Apache Lucene &#x2F; Solr or Elasticsearch?</div><br/><div id="38706559" class="c"><input type="checkbox" id="c-38706559" checked=""/><div class="controls bullet"><span class="by">bryanrasmussen</span><span>|</span><a href="#38706366">parent</a><span>|</span><a href="#38706092">next</a><span>|</span><label class="collapse" for="c-38706559">[-]</label><label class="expand" for="c-38706559">[1 more]</label></div><br/><div class="children"><div class="content">Lucene supports decompounding and stemming, <a href="https:&#x2F;&#x2F;core.ac.uk&#x2F;reader&#x2F;154370300" rel="nofollow noreferrer">https:&#x2F;&#x2F;core.ac.uk&#x2F;reader&#x2F;154370300</a> depending on the language decompounding can be very important or of little import, Germanic languages should probably have decompounding.</div><br/></div></div></div></div><div id="38706092" class="c"><input type="checkbox" id="c-38706092" checked=""/><div class="controls bullet"><span class="by">avereveard</span><span>|</span><a href="#38706366">prev</a><span>|</span><a href="#38706487">next</a><span>|</span><label class="collapse" for="c-38706092">[-]</label><label class="expand" for="c-38706092">[2 more]</label></div><br/><div class="children"><div class="content">Agree fully, vector search in embedding space is insufficient if you are working wirh a single document domain (i.e. They are all fish restaurant menu) and then the only thing that can save you is text search. Just make sure the underlying database supports synonyms lists and normalization in the languages you plan using.<p>About the &quot;bad news&quot; section.<p>You can do that today by just asking the llm using the ReAct pattern. Give it the database schema, a few shots prompt, and will happily decide to build query, read titles, and do more query if the titles aren&#x27;t relevant enough, and fetch the content of titles that are relevant and use those to form an opinion.<p>This may not sem fast, but there are 7b token models that can do it today, at 150+token&#x2F;second.</div><br/><div id="38706330" class="c"><input type="checkbox" id="c-38706330" checked=""/><div class="controls bullet"><span class="by">barrenko</span><span>|</span><a href="#38706092">parent</a><span>|</span><a href="#38706487">next</a><span>|</span><label class="collapse" for="c-38706330">[-]</label><label class="expand" for="c-38706330">[1 more]</label></div><br/><div class="children"><div class="content">please elaborate, thanks.</div><br/></div></div></div></div><div id="38706487" class="c"><input type="checkbox" id="c-38706487" checked=""/><div class="controls bullet"><span class="by">summarity</span><span>|</span><a href="#38706092">prev</a><span>|</span><a href="#38706337">next</a><span>|</span><label class="collapse" for="c-38706487">[-]</label><label class="expand" for="c-38706487">[1 more]</label></div><br/><div class="children"><div class="content">I have a related project here: <a href="https:&#x2F;&#x2F;findsight.ai" rel="nofollow noreferrer">https:&#x2F;&#x2F;findsight.ai</a> and also gave a talk about building it here: <a href="https:&#x2F;&#x2F;youtu.be&#x2F;elNrRU12xRc" rel="nofollow noreferrer">https:&#x2F;&#x2F;youtu.be&#x2F;elNrRU12xRc</a></div><br/></div></div><div id="38706337" class="c"><input type="checkbox" id="c-38706337" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#38706487">prev</a><span>|</span><a href="#38706395">next</a><span>|</span><label class="collapse" for="c-38706337">[-]</label><label class="expand" for="c-38706337">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m trying to alleviate the issue with tagging (<a href="https:&#x2F;&#x2F;kristiandupont.medium.com&#x2F;empathy-articulated-750a6601b122" rel="nofollow noreferrer">https:&#x2F;&#x2F;kristiandupont.medium.com&#x2F;empathy-articulated-750a66...</a>), but it&#x27;s not a panacea.<p>I feel that a big part of the solution will simply be in the form of increased speeds. If you can ask the model for a strategy and then let it search&#x2F;process a few times in a loop, responses will improve vastly.</div><br/><div id="38706380" class="c"><input type="checkbox" id="c-38706380" checked=""/><div class="controls bullet"><span class="by">pryelluw</span><span>|</span><a href="#38706337">parent</a><span>|</span><a href="#38706395">next</a><span>|</span><label class="collapse" for="c-38706380">[-]</label><label class="expand" for="c-38706380">[2 more]</label></div><br/><div class="children"><div class="content">I joke that is akin to applying taxonomy on a live tv interview. You need to tag and categorize but may only do so with precision after a point is made.<p>My current solution is to have an nlp pipeline that does so as tokens are returned. Not quite as precise yet but shows promise.<p>Should be open source sooner rather than later.</div><br/><div id="38706420" class="c"><input type="checkbox" id="c-38706420" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#38706337">root</a><span>|</span><a href="#38706380">parent</a><span>|</span><a href="#38706395">next</a><span>|</span><label class="collapse" for="c-38706420">[-]</label><label class="expand" for="c-38706420">[1 more]</label></div><br/><div class="children"><div class="content">I like that analogy.</div><br/></div></div></div></div></div></div><div id="38706395" class="c"><input type="checkbox" id="c-38706395" checked=""/><div class="controls bullet"><span class="by">deckar01</span><span>|</span><a href="#38706337">prev</a><span>|</span><a href="#38706099">next</a><span>|</span><label class="collapse" for="c-38706395">[-]</label><label class="expand" for="c-38706395">[5 more]</label></div><br/><div class="children"><div class="content">Instead of embedding the user prompt, I let the LLM invert it into keywords and search the embedding of that. It very much does feel like a magic bullet.</div><br/><div id="38706426" class="c"><input type="checkbox" id="c-38706426" checked=""/><div class="controls bullet"><span class="by">kristiandupont</span><span>|</span><a href="#38706395">parent</a><span>|</span><a href="#38706099">next</a><span>|</span><label class="collapse" for="c-38706426">[-]</label><label class="expand" for="c-38706426">[4 more]</label></div><br/><div class="children"><div class="content">&quot;Search the embedding&quot;? Could you elaborate on this, it sounds interesting!</div><br/><div id="38706491" class="c"><input type="checkbox" id="c-38706491" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#38706395">root</a><span>|</span><a href="#38706426">parent</a><span>|</span><a href="#38706499">next</a><span>|</span><label class="collapse" for="c-38706491">[-]</label><label class="expand" for="c-38706491">[2 more]</label></div><br/><div class="children"><div class="content">Ask the LLM to summarize the question, then take an embedding of that.<p>I think you can do the same with data you store… summarize it to same number of tokens, then get an embedding for <i>that</i> to save with the original text.<p>Test! Different combinations of summarizing LLM and embedding generation LLM can get different results. But once you decide, you are locked in the summarizer as much as the embedding generator.<p>Not sure is this is what the parent meant though.</div><br/><div id="38706504" class="c"><input type="checkbox" id="c-38706504" checked=""/><div class="controls bullet"><span class="by">sroussey</span><span>|</span><a href="#38706395">root</a><span>|</span><a href="#38706491">parent</a><span>|</span><a href="#38706499">next</a><span>|</span><label class="collapse" for="c-38706504">[-]</label><label class="expand" for="c-38706504">[1 more]</label></div><br/><div class="children"><div class="content">BTW: I think of this like asking someone to put things into their own words, and then it’s easier for them to remember. Matching on your way of talking can be weird from the LLM’s point of view, so use their point of view!</div><br/></div></div></div></div><div id="38706499" class="c"><input type="checkbox" id="c-38706499" checked=""/><div class="controls bullet"><span class="by">CGamesPlay</span><span>|</span><a href="#38706395">root</a><span>|</span><a href="#38706426">parent</a><span>|</span><a href="#38706491">prev</a><span>|</span><a href="#38706099">next</a><span>|</span><label class="collapse" for="c-38706499">[-]</label><label class="expand" for="c-38706499">[1 more]</label></div><br/><div class="children"><div class="content">I think OP means to filter the user input through an LLM with “convert this question into a keyword list” and then calculating the embedding of the LLM’s output (instead of calculating the embedding of the user input directly). The “search the embedding” is the normal vector DB part.</div><br/></div></div></div></div></div></div><div id="38706099" class="c"><input type="checkbox" id="c-38706099" checked=""/><div class="controls bullet"><span class="by">ravetcofx</span><span>|</span><a href="#38706395">prev</a><span>|</span><label class="collapse" for="c-38706099">[-]</label><label class="expand" for="c-38706099">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to have a search engine for all of my different conversations I&#x27;ve ever had with people through various messaging apps, that combines email and my scanned documents through paperless-ngx and any other PDFs or documents in my nextcloud in a single search interface</div><br/><div id="38706185" class="c"><input type="checkbox" id="c-38706185" checked=""/><div class="controls bullet"><span class="by">vasco</span><span>|</span><a href="#38706099">parent</a><span>|</span><label class="collapse" for="c-38706185">[-]</label><label class="expand" for="c-38706185">[1 more]</label></div><br/><div class="children"><div class="content">Maybe at some point the NSA will let us download them all!</div><br/></div></div></div></div></div></div></div></div></div></body></html>