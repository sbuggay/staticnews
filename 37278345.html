<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1693126853352" as="style"/><link rel="stylesheet" href="styles.css?v=1693126853352"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://twitter.com/paulg/status/1695596853864321055">If you&#x27;re interested in eye-tracking, I&#x27;m interested in funding you</a> <span class="domain">(<a href="https://twitter.com">twitter.com</a>)</span></div><div class="subtext"><span>pg</span> | <span>70 comments</span></div><br/><div><div id="37280777" class="c"><input type="checkbox" id="c-37280777" checked=""/><div class="controls bullet"><span class="by">bacon_waffle</span><span>|</span><a href="#37280785">next</a><span>|</span><label class="collapse" for="c-37280777">[-]</label><label class="expand" for="c-37280777">[1 more]</label></div><br/><div class="children"><div class="content">I remember seeing a program years ago, which used the mouse cursor in a really neat way to enter text.  Seems like it would be far better than clicking on keys of a virtual keyboard, but I can&#x27;t remember the name of this program nor seem to find it...<p>Will probably get some of this wrong, but just in case it rings a bell (or someone wants to reinvent it - wouldn&#x27;t be hard):<p>The interface felt like a side-scrolling through through a map of characters.  Moving left and right controlled speed through the characters; for instance moving to the left extent would backspace, and moving further to the right would enter more characters per time.<p>Up and down would select the next character - in my memory these are presented as a stack of map-coloured boxes where each box held a letter (or, group of letters?), say &#x27;a&#x27; to &#x27;z&#x27; top-to-bottom, plus a few punctuation marks.  The height of each box was proportional to the likelihood that letter would be the next you&#x27;d want, so the most likely targets would be easier+quicker to navigate to.  Navigating in to a box for a character would &quot;type&quot; it.  IIRC, at any instant, you could see a couple levels of letters, so if you had entered c-o, maybe &#x27;o&#x27; and &#x27;u&#x27; would be particularly large, and inside the &#x27;o&#x27; box you might see that &#x27;l&#x27; and &#x27;k&#x27; are bigger.</div><br/></div></div><div id="37280785" class="c"><input type="checkbox" id="c-37280785" checked=""/><div class="controls bullet"><span class="by">MasterYoda</span><span>|</span><a href="#37280777">prev</a><span>|</span><a href="#37279470">next</a><span>|</span><label class="collapse" for="c-37280785">[-]</label><label class="expand" for="c-37280785">[1 more]</label></div><br/><div class="children"><div class="content">PG mention that the solution his friend used wasn&#x27;t any good. How does the best system there is out today work? And what different solutions are?</div><br/></div></div><div id="37279470" class="c"><input type="checkbox" id="c-37279470" checked=""/><div class="controls bullet"><span class="by">Componica</span><span>|</span><a href="#37280785">prev</a><span>|</span><a href="#37278657">next</a><span>|</span><label class="collapse" for="c-37279470">[-]</label><label class="expand" for="c-37279470">[1 more]</label></div><br/><div class="children"><div class="content">My three partners and I have be developing and selling multi-camera arrays specifically for eye tracking as well as measuring other physiological features for several years now. Our main customers are a couple university research groups, a human factors group in Lockheed, and just recently the US Air Force. In fact we just returned from a trip to Wright-Patterson installing an array in a hypobaric chamber to perform gaze tracker and pupil response for pilots under hypoxic conditions. Phase two will be a custom gaze tracker for their centrifuge. Our main features are accurate eye and face tracking up to a meter from the array, minimal calibration per subject (about 10 seconds staring at a dot), pupil response for measuring fatigue and other things, plus we can adapt the array for the client ranging from a cockpit to a large flat screen TV. We&#x27;ve looked into medical usage such as ALS, but we&#x27;re bootstrapped based in Iowa and found the military niche as a more direct way to generate cash flow. It&#x27;s ashame we can&#x27;t apply this work towards people with medical needs, but we don&#x27;t have the funds nor the clients to make such a pivot.</div><br/></div></div><div id="37278657" class="c"><input type="checkbox" id="c-37278657" checked=""/><div class="controls bullet"><span class="by">AndrewKemendo</span><span>|</span><a href="#37279470">prev</a><span>|</span><a href="#37279413">next</a><span>|</span><label class="collapse" for="c-37278657">[-]</label><label class="expand" for="c-37278657">[1 more]</label></div><br/><div class="children"><div class="content">I responded to the thread but Senseye has been working on this for a while now. Originally they were working with the US Air Force to help with improving pilot training - fatigue etc.. inference with retinal reading<p><a href="https:&#x2F;&#x2F;senseye.co&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;senseye.co&#x2F;</a><p>They have generally struggled to find funding for their eye tracking focused work, and have recently had to pivot away from the really exciting but hard to fund stuff into PTSD screening (which is important too).<p>I can connect you with the founder if desired via the email in my bio</div><br/></div></div><div id="37279413" class="c"><input type="checkbox" id="c-37279413" checked=""/><div class="controls bullet"><span class="by">justinlloyd</span><span>|</span><a href="#37278657">prev</a><span>|</span><a href="#37278653">next</a><span>|</span><label class="collapse" for="c-37279413">[-]</label><label class="expand" for="c-37279413">[2 more]</label></div><br/><div class="children"><div class="content">I do hardware. I do software. I do computer vision. I built some software that ran on a cellphone used by LEO (law enforcement officers) to determine if the person they are quizzing is inebriated or impaired through controlled substances by examining the person&#x27;s eyes and having them focus on images displayed on the phone screen. I&#x27;ve done eye tracking using fully custom solutions and also through a few of the off-the-shelf SDKs such as GazeSense from eyeware and a few other SDKs.<p>The problem is not the eye-tracking, it is reasonably easy to build robust systems that can do that easily enough, even with custom hardware under all sorts of lighting conditions. The hard part is the UX if you are trying to build something that isn&#x27;t hampered by current UI paradigms.<p>Rapid typing and menus of custom actions with just eye movement, though fatiguing, shouldn&#x27;t be hard to solve, and then render the output however you want; text, text to speech, commands issued to an machine, etc. Making a usable user interface to do anything else, that&#x27;s where the rubber hits the road.<p>@pg, which software is your friend using? If it is anything like I&#x27;ve looked in to in the past, it&#x27;s over-priced accessibility crap with a UI straight out of the 1990s.</div><br/><div id="37279523" class="c"><input type="checkbox" id="c-37279523" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#37279413">parent</a><span>|</span><a href="#37278653">next</a><span>|</span><label class="collapse" for="c-37279523">[-]</label><label class="expand" for="c-37279523">[1 more]</label></div><br/><div class="children"><div class="content">Yes, UX is the key. The iPhone succeeded because they didn&#x27;t just take macOS&#x27;s mouse&#x2F;keyboard UI and slap it under a touchscreen. They took the limitations and strengths of capacitive touch and designed a bespoke UX with new concepts everywhere.<p>Input modalities define platforms. Eye tracking is a new input modality and will define a new platform. It needs a whole new UX designed around its limitations and strengths. It needs a keyboard, it needs a browser, it needs copy and paste, it needs an app switcher, it needs a whole vocabulary of standard interactions and best practices. Apple has a good start in Vision Pro but they&#x27;re not going to be the only ones doing UX for eye tracking. There&#x27;s definitely room for other players with fresh ideas.</div><br/></div></div></div></div><div id="37278653" class="c"><input type="checkbox" id="c-37278653" checked=""/><div class="controls bullet"><span class="by">dewarrn1</span><span>|</span><a href="#37279413">prev</a><span>|</span><a href="#37278675">next</a><span>|</span><label class="collapse" for="c-37278653">[-]</label><label class="expand" for="c-37278653">[5 more]</label></div><br/><div class="children"><div class="content">EEG recording is an alternative that would outlast the potential disease-related degradation of eye movements.  Manny Donchin gave a brown bag at UIUC about the possibilities of using this approach to support communication by ALS patients many years ago.  It&#x27;s clever: they use the P300 marker to index attention&#x2F;intention.  I do not recall whether he and his colleagues ever commercialized the tech.  I believe that this publication is representative: <a href="https:&#x2F;&#x2F;doi.org&#x2F;10.1016&#x2F;j.clinph.2005.06.027" rel="nofollow noreferrer">https:&#x2F;&#x2F;doi.org&#x2F;10.1016&#x2F;j.clinph.2005.06.027</a></div><br/><div id="37279469" class="c"><input type="checkbox" id="c-37279469" checked=""/><div class="controls bullet"><span class="by">mikpanko</span><span>|</span><a href="#37278653">parent</a><span>|</span><a href="#37278752">next</a><span>|</span><label class="collapse" for="c-37279469">[-]</label><label class="expand" for="c-37279469">[2 more]</label></div><br/><div class="children"><div class="content">I did a PhD in brain-computer interfaces, including EEG and implanted electrodes. BCI research to a big extent focuses on helping paralyzed individuals regain communication.<p>Unfortunately, EEG (including P300) doesn’t provide sufficient signal-to-noise ratio to support good communication speeds outside of the lab with Faraday cages and days&#x2F;weeks of de-noising including removing eye-movement artifacts in the recordings. This is a physical limit due to attenuation of brain’s electrical fields outside of the skull, which is hard to overcome. For example, all commercial “mind-reading” toys are actually working based off head and eye muscle signals.<p>Implanted electrodes provide better signal but are many iterations away from becoming viable commercially. Signal degrades over months as the brain builds scar tissue around electrodes and the brain surgery is obviously pretty dangerous. Iteration cycles are very slow because of the need for government approval for testing in humans (for a good reason).<p>If I wanted to help a paralyzed friend, who could only move his&#x2F;her eyes, I would definitely focus on the eye-tracking tech. It hands-down beat all BCIs I’ve heard of.</div><br/><div id="37279885" class="c"><input type="checkbox" id="c-37279885" checked=""/><div class="controls bullet"><span class="by">minihat</span><span>|</span><a href="#37278653">root</a><span>|</span><a href="#37279469">parent</a><span>|</span><a href="#37278752">next</a><span>|</span><label class="collapse" for="c-37279885">[-]</label><label class="expand" for="c-37279885">[1 more]</label></div><br/><div class="children"><div class="content">+1 from a fellow BCI PhD. EEG tech is not ready for this application yet.</div><br/></div></div></div></div><div id="37278752" class="c"><input type="checkbox" id="c-37278752" checked=""/><div class="controls bullet"><span class="by">incongruity</span><span>|</span><a href="#37278653">parent</a><span>|</span><a href="#37279469">prev</a><span>|</span><a href="#37279190">next</a><span>|</span><label class="collapse" for="c-37278752">[-]</label><label class="expand" for="c-37278752">[1 more]</label></div><br/><div class="children"><div class="content">This! Eye tracking is slow and not good - but does that just mean we need to “faster horse” it or is there another option for bridging the communication gap for people with ALS and similar diseases? I have to believe there are better answers with other tech - likely EEG (+ AI).<p>My family is one of the unlucky ones that has genes for ALS so I’ve watched enough family members struggle. (I’m lucky, selfishly, because I dodged the gene but I still care deeply about this).</div><br/></div></div><div id="37279190" class="c"><input type="checkbox" id="c-37279190" checked=""/><div class="controls bullet"><span class="by">BoorishBears</span><span>|</span><a href="#37278653">parent</a><span>|</span><a href="#37278752">prev</a><span>|</span><a href="#37278675">next</a><span>|</span><label class="collapse" for="c-37279190">[-]</label><label class="expand" for="c-37279190">[1 more]</label></div><br/><div class="children"><div class="content">I had this thought, but then I thought about if my friend was struggling with a problem had had practical but imperfect solutions, would I better serve them by funding highly feasible solutions that they&#x27;re already familiar with, or experimental moonshots that are more likely to fail, will take longer to implement, and my friend may not even care for at all...</div><br/></div></div></div></div><div id="37278675" class="c"><input type="checkbox" id="c-37278675" checked=""/><div class="controls bullet"><span class="by">blackguardx</span><span>|</span><a href="#37278653">prev</a><span>|</span><a href="#37279057">next</a><span>|</span><label class="collapse" for="c-37278675">[-]</label><label class="expand" for="c-37278675">[3 more]</label></div><br/><div class="children"><div class="content">I worked on eye tracking hardware for Microsoft HoloLens. Several AR headsets offer decent eye tracking, including Hololens 2 and Magic Leap&#x27;s ML2. I think Tobii&#x27;s eye tracking glasses are probably better as a stand-alone solution though: <a href="https:&#x2F;&#x2F;www.tobii.com&#x2F;products&#x2F;eye-trackers&#x2F;wearables&#x2F;tobii-pro-glasses-3" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.tobii.com&#x2F;products&#x2F;eye-trackers&#x2F;wearables&#x2F;tobii-...</a></div><br/><div id="37279901" class="c"><input type="checkbox" id="c-37279901" checked=""/><div class="controls bullet"><span class="by">zh3</span><span>|</span><a href="#37278675">parent</a><span>|</span><a href="#37279786">next</a><span>|</span><label class="collapse" for="c-37279901">[-]</label><label class="expand" for="c-37279901">[1 more]</label></div><br/><div class="children"><div class="content">Agreed, the eye tracking itself is really a mostly-solved problem (Tobii are indeed leaders in the area). It&#x27;s how <i>it&#x27;s used</i> that matters - and as mentioned above, it&#x27;s likely that it&#x27;s the usability&#x2F;interface that needs work.</div><br/></div></div><div id="37279786" class="c"><input type="checkbox" id="c-37279786" checked=""/><div class="controls bullet"><span class="by">tootie</span><span>|</span><a href="#37278675">parent</a><span>|</span><a href="#37279901">prev</a><span>|</span><a href="#37279057">next</a><span>|</span><label class="collapse" for="c-37279786">[-]</label><label class="expand" for="c-37279786">[1 more]</label></div><br/><div class="children"><div class="content">Have used Tobii as well and they are very accurate with a bit of calibration.</div><br/></div></div></div></div><div id="37279057" class="c"><input type="checkbox" id="c-37279057" checked=""/><div class="controls bullet"><span class="by">musesum</span><span>|</span><a href="#37278675">prev</a><span>|</span><a href="#37278698">next</a><span>|</span><label class="collapse" for="c-37279057">[-]</label><label class="expand" for="c-37279057">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been working on the menuing side [1] based on crossing Fitt&#x27;s Law with Huffman trees. But, don&#x27;t know the constraints for ALS.<p>Hopefully, whomever takes this on doesn&#x27;t take the standard Accessibility approach, which is adding an extra layer of complexity on an existing UI.<p>A good friend, Gordon Fuller, found out he was going blind. So, he co-founded one of the first VR startups in the 90&#x27;s. Why? For wayfinding.<p>What we came up with is a concept of Universal design. Start over from first principles. Seeing Gordon use an Accessible UI is painful to watch, it takes three times as many steps to navigate and confirm. So, what is the factor? 0.3 X?<p>Imagine if we could refactor all apps with a LLM, and then couple it with an auto compete menu. Within that menu is personal history of all your past transversals.<p>What would be the result? A 10X? Would my sister in a wheelchair be able to use it? Would love to find out!<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;musesum&#x2F;DeepMenu">https:&#x2F;&#x2F;github.com&#x2F;musesum&#x2F;DeepMenu</a></div><br/></div></div><div id="37278698" class="c"><input type="checkbox" id="c-37278698" checked=""/><div class="controls bullet"><span class="by">readyplayernull</span><span>|</span><a href="#37279057">prev</a><span>|</span><a href="#37278549">next</a><span>|</span><label class="collapse" for="c-37278698">[-]</label><label class="expand" for="c-37278698">[1 more]</label></div><br/><div class="children"><div class="content">&gt; A friend of mine has ALS and can only move his eyes. He has an eye-controlled keyboard, but it&#x27;s not very good. Can you make him a better one?<p>When I worked for one of the big game engines I got contacted by the makers of the tech that Stephen Hawking used to communicate, which includes an eye tracker:<p><a href="https:&#x2F;&#x2F;www.businessinsider.com&#x2F;an-eye-tracking-interface-helps-als-patients-use-computers-2015-9" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.businessinsider.com&#x2F;an-eye-tracking-interface-he...</a></div><br/></div></div><div id="37278549" class="c"><input type="checkbox" id="c-37278549" checked=""/><div class="controls bullet"><span class="by">fastball</span><span>|</span><a href="#37278698">prev</a><span>|</span><a href="#37279787">next</a><span>|</span><label class="collapse" for="c-37278549">[-]</label><label class="expand" for="c-37278549">[14 more]</label></div><br/><div class="children"><div class="content">Is the lack of mentioning Apple deliberate? It seems like they&#x27;ve already poured a lot of R&amp;D into this for the Vision Pro, which might be exactly the kind of thing the friend needs.</div><br/><div id="37278578" class="c"><input type="checkbox" id="c-37278578" checked=""/><div class="controls bullet"><span class="by">pg</span><span>|</span><a href="#37278549">parent</a><span>|</span><a href="#37280407">next</a><span>|</span><label class="collapse" for="c-37278578">[-]</label><label class="expand" for="c-37278578">[10 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not available yet. And in any case if this is the future there should be multiple companies doing it, not just Apple.</div><br/><div id="37278800" class="c"><input type="checkbox" id="c-37278800" checked=""/><div class="controls bullet"><span class="by">ladberg</span><span>|</span><a href="#37278549">root</a><span>|</span><a href="#37278578">parent</a><span>|</span><a href="#37279152">next</a><span>|</span><label class="collapse" for="c-37278800">[-]</label><label class="expand" for="c-37278800">[5 more]</label></div><br/><div class="children"><div class="content">I used to work on it and have spent tons of time in the headset. The eye tracking is next-level and it&#x27;s really the only platform that exists with eye tracking as a primary input method. I&#x27;m pretty confident it will greatly improve your friend&#x27;s quality of life.<p>Because of that, I&#x27;m also sure that eye tracking will go mainstream in other areas once the Vision Pro is released once everyone else catches on to it as a great input method.</div><br/><div id="37280734" class="c"><input type="checkbox" id="c-37280734" checked=""/><div class="controls bullet"><span class="by">GnarlyWhale</span><span>|</span><a href="#37278549">root</a><span>|</span><a href="#37278800">parent</a><span>|</span><a href="#37279490">next</a><span>|</span><label class="collapse" for="c-37280734">[-]</label><label class="expand" for="c-37280734">[1 more]</label></div><br/><div class="children"><div class="content">This is pretty much exactly why I vehemently disagree with Apple&#x27;s decision to draw such a firm line in the sand preventing devs from accessing the eye&#x2F;gaze data directly. I&#x27;m part of an academic spin-off start-up that specializes in analyzing gaze and movement data. Locking the gaze information outside of the app sandbox severely hampers the ability to quickly iterate design and UI patterns that could be game changing for accessibility. Hopefully they make accommodations moving forward for these circumstances.<p>The issue is doubly close to my heart because my father has ALS and is nearly at the point where eye-tracking will be his only means of communicating effectively with the world. While existing Tobii systems work well enough, typing with your eyes is still <i>exhausting</i> to do.<p>Ultimately I don&#x27;t think a platform like the vision pro is suitable for ALS patients, especially later term. They cannot support the weight of the headset and&#x2F;or fatigue will set in rapidly. Many (including my father) also require use of a ventilator, accompanied with a mask that can seal effectively enough to support the positive pressure necessary to inflate their lungs. Unless the form factor for HMD&#x27;s minimalizes significantly, it will likely interfere with the respirator&#x27;s efficacy.</div><br/></div></div><div id="37279490" class="c"><input type="checkbox" id="c-37279490" checked=""/><div class="controls bullet"><span class="by">blululu</span><span>|</span><a href="#37278549">root</a><span>|</span><a href="#37278800">parent</a><span>|</span><a href="#37280734">prev</a><span>|</span><a href="#37279342">next</a><span>|</span><label class="collapse" for="c-37279490">[-]</label><label class="expand" for="c-37279490">[1 more]</label></div><br/><div class="children"><div class="content">The level of eye tracking performance for general population interactions is really only possible when you control the illumination like in a VR headset. A Vision Pro might work for the friend in question. More generally this requires the full vr display to make it work. See through AR or just plane glasses will not be nearly as good, and I think that will cap the general acceptance.</div><br/></div></div><div id="37279342" class="c"><input type="checkbox" id="c-37279342" checked=""/><div class="controls bullet"><span class="by">dgrin91</span><span>|</span><a href="#37278549">root</a><span>|</span><a href="#37278800">parent</a><span>|</span><a href="#37279490">prev</a><span>|</span><a href="#37279152">next</a><span>|</span><label class="collapse" for="c-37279342">[-]</label><label class="expand" for="c-37279342">[2 more]</label></div><br/><div class="children"><div class="content">Doesn&#x27;t it rely on external cameras to see users hands and use that as the &quot;click&quot; inputs? Seems like that negates usage for ALS cases.<p>Also, I&#x27;m not an ALS expert, but if the only muscular control is in the eyes, then lack of control in the head&#x2F;neck probably breaks some assumptions about how the vision headset works (just a guess though).</div><br/><div id="37279459" class="c"><input type="checkbox" id="c-37279459" checked=""/><div class="controls bullet"><span class="by">extra88</span><span>|</span><a href="#37278549">root</a><span>|</span><a href="#37279342">parent</a><span>|</span><a href="#37279152">next</a><span>|</span><label class="collapse" for="c-37279459">[-]</label><label class="expand" for="c-37279459">[1 more]</label></div><br/><div class="children"><div class="content">It does not require using one&#x27;s hands to click, it supports various input hardware (keyboard, mouse, switch, etc.). If someone has control of basically any muscle, it can use a switch input. The Vision Pro also has Dwell Control, activating things by keeping your gaze on it long enough, but I don&#x27;t know whether it can currently be solely operated using nothing but one&#x27;s eyes.</div><br/></div></div></div></div></div></div><div id="37279152" class="c"><input type="checkbox" id="c-37279152" checked=""/><div class="controls bullet"><span class="by">Anticlockwise</span><span>|</span><a href="#37278549">root</a><span>|</span><a href="#37278578">parent</a><span>|</span><a href="#37278800">prev</a><span>|</span><a href="#37278718">next</a><span>|</span><label class="collapse" for="c-37279152">[-]</label><label class="expand" for="c-37279152">[1 more]</label></div><br/><div class="children"><div class="content">Not just multiple companies, multiple approaches. Eye tracking is exhausting, and that&#x27;s pretty fundamental to the modality - dwell time requires significant control to be usable as a click, and even able bodied people find it exhausting. Some folks have tried doing eye tracking and using something else (EMG for example) as the click, but it doesn&#x27;t work consistently for the population. ALS is also progressive, and people lose their eye control. Blackrock Neurotech has been working on a brain implant, with spinal cord injury as a first target population (because they&#x27;re less fragile, among other reasons), and it works for current research patients, but medical devices take a lot of time, money and work to get cleared in the US. The implant itself is cleared, but the FDA wants the entire system to be cleared too.</div><br/></div></div><div id="37278718" class="c"><input type="checkbox" id="c-37278718" checked=""/><div class="controls bullet"><span class="by">Difwif</span><span>|</span><a href="#37278549">root</a><span>|</span><a href="#37278578">parent</a><span>|</span><a href="#37279152">prev</a><span>|</span><a href="#37279046">next</a><span>|</span><label class="collapse" for="c-37278718">[-]</label><label class="expand" for="c-37278718">[1 more]</label></div><br/><div class="children"><div class="content">Glad to see you still lurk around here. How do you think about going up against a company like Apple when it comes to patents in this space?<p>I think that would be my major hesitation but I don&#x27;t have a lot of experience evaluating patents.<p>Apples Eye Tracking Patent: <a href="https:&#x2F;&#x2F;patents.google.com&#x2F;patent&#x2F;US20180113508A1&#x2F;en" rel="nofollow noreferrer">https:&#x2F;&#x2F;patents.google.com&#x2F;patent&#x2F;US20180113508A1&#x2F;en</a></div><br/></div></div><div id="37279046" class="c"><input type="checkbox" id="c-37279046" checked=""/><div class="controls bullet"><span class="by">dtihanyi</span><span>|</span><a href="#37278549">root</a><span>|</span><a href="#37278578">parent</a><span>|</span><a href="#37278718">prev</a><span>|</span><a href="#37279030">next</a><span>|</span><label class="collapse" for="c-37279046">[-]</label><label class="expand" for="c-37279046">[1 more]</label></div><br/><div class="children"><div class="content">Agreed. It would be great if the hardware was more affordable&#x2F;accessible as well. That&#x27;s potentially a barrier to entry worth addressing for devs who might otherwise be interested in tackling the problem, but don&#x27;t have the quality eye tracking hardware to start. A Tobii-like hardware devkit could be a starting point.</div><br/></div></div></div></div><div id="37280407" class="c"><input type="checkbox" id="c-37280407" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#37278549">parent</a><span>|</span><a href="#37278578">prev</a><span>|</span><a href="#37278821">next</a><span>|</span><label class="collapse" for="c-37280407">[-]</label><label class="expand" for="c-37280407">[1 more]</label></div><br/><div class="children"><div class="content">Yes, because:<p>1) its eye tracking isn&#x27;t good enough for this kind of application.<p>2) direct access to the gaze vector is disabled<p>3) its really intrusive<p>4) its heavy.<p>5) it doesn&#x27;t exist(in consumer world) yet.<p>The goal is to enable someone who has motor control issues, be able to communicate directly with the outside world. Shoving a heavy skimask that totally obscures the outside world on their face directly stops that.<p>Not only that, but you&#x27;ll need to create and keep up to date the software needed to make a communicator. Apple are many thing, but it&#x27;s new platforms are not stable, rapid os updates will break things.</div><br/></div></div><div id="37278821" class="c"><input type="checkbox" id="c-37278821" checked=""/><div class="controls bullet"><span class="by">omeze</span><span>|</span><a href="#37278549">parent</a><span>|</span><a href="#37280407">prev</a><span>|</span><a href="#37279035">next</a><span>|</span><label class="collapse" for="c-37278821">[-]</label><label class="expand" for="c-37278821">[1 more]</label></div><br/><div class="children"><div class="content">ALS really doesn’t leave much strength for having a headset strapped to you…</div><br/></div></div></div></div><div id="37279787" class="c"><input type="checkbox" id="c-37279787" checked=""/><div class="controls bullet"><span class="by">acyou</span><span>|</span><a href="#37278549">prev</a><span>|</span><a href="#37279625">next</a><span>|</span><label class="collapse" for="c-37279787">[-]</label><label class="expand" for="c-37279787">[1 more]</label></div><br/><div class="children"><div class="content">Yes, the ALS&#x2F;disability angle is noble. Viewed another way, the entire human race is afflicted by the disability of not having access to eye-tracking (and other) technologies. Paul Graham and co. are also invested in companies that are going to be highly enabled and boosted by the growth of eye-tracking and related technologies. I don&#x27;t view his statement of motivation related to ALS as insincere, I just also notice that it&#x27;s accessible, easily understandable, and also in line with other aspects of Paul&#x27;s motivation (and that&#x27;s a good thing).<p>I would also recommend Jean-Dominique Bauby&#x27;s Le Scaphandre et le Papillon to anyone interested in this topic. Typing using eye movements was used in that book in a slow, inefficient manner. In the book&#x27;s case, the question one should ask is, was his UI paced at the exact correct speed? I was and still am deeply emotionally moved by what the author was able to accomplish and convey. I am unsure if a faster keyboard would have made a meaningful and positive difference in that particular case, to the author&#x27;s quality of life. I&#x27;ll need to give that book another read with that question in mind.<p>Happily, I expect eye tracking to find fascinating, novel and unexpected applications. As others have stated, UI&#x2F;UX design is an interesting part of this puzzle. For example, if you ask an LLM to output short branches of text and have a writer look at the words that he wants to convey. It&#x27;s definitely blurring the line between reading and writing. Myself, finding writing to be a tactile exercise, I think that emotional state comes into play. That&#x27;s what I&#x27;m interested in. Yes, can you literally read someone&#x27;s eyes and tell what they are thinking?</div><br/></div></div><div id="37279625" class="c"><input type="checkbox" id="c-37279625" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#37279787">prev</a><span>|</span><a href="#37279435">next</a><span>|</span><label class="collapse" for="c-37279625">[-]</label><label class="expand" for="c-37279625">[3 more]</label></div><br/><div class="children"><div class="content">Tobii have been doing eye-tracking since 2001 and have a product for that. <a href="https:&#x2F;&#x2F;www.tobiidynavox.com&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.tobiidynavox.com&#x2F;</a></div><br/><div id="37279673" class="c"><input type="checkbox" id="c-37279673" checked=""/><div class="controls bullet"><span class="by">tpmx</span><span>|</span><a href="#37279625">parent</a><span>|</span><a href="#37279435">next</a><span>|</span><label class="collapse" for="c-37279673">[-]</label><label class="expand" for="c-37279673">[2 more]</label></div><br/><div class="children"><div class="content">But that&#x27;s not in California so it doesn&#x27;t matter.<p>(&#x2F;s)</div><br/><div id="37279762" class="c"><input type="checkbox" id="c-37279762" checked=""/><div class="controls bullet"><span class="by">arketyp</span><span>|</span><a href="#37279625">root</a><span>|</span><a href="#37279673">parent</a><span>|</span><a href="#37279435">next</a><span>|</span><label class="collapse" for="c-37279762">[-]</label><label class="expand" for="c-37279762">[1 more]</label></div><br/><div class="children"><div class="content">You were being facetious, but Swedes are used to being flexible with collaborations. I don&#x27;t why I&#x27;m playing the ambassador, I don&#x27;t work there.</div><br/></div></div></div></div></div></div><div id="37279435" class="c"><input type="checkbox" id="c-37279435" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#37279625">prev</a><span>|</span><a href="#37278645">next</a><span>|</span><label class="collapse" for="c-37279435">[-]</label><label class="expand" for="c-37279435">[3 more]</label></div><br/><div class="children"><div class="content">I agree, eye tracking is going to have really broad applications. I&#x27;ve been interested in eye tracking for over a decade, and in fact built my own eye tracker, joined a startup, and got acquired by Google[1]. But there&#x27;s way more to do. We&#x27;ve barely scratched the surface of what&#x27;s possible with eye tracking and I&#x27;d love to take a second crack at it.<p>[1] <a href="https:&#x2F;&#x2F;techcrunch.com&#x2F;2016&#x2F;10&#x2F;24&#x2F;google-buys-eyefluence-eye-tracking-startup&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;techcrunch.com&#x2F;2016&#x2F;10&#x2F;24&#x2F;google-buys-eyefluence-eye...</a></div><br/><div id="37279463" class="c"><input type="checkbox" id="c-37279463" checked=""/><div class="controls bullet"><span class="by">krsrhe</span><span>|</span><a href="#37279435">parent</a><span>|</span><a href="#37278645">next</a><span>|</span><label class="collapse" for="c-37279463">[-]</label><label class="expand" for="c-37279463">[2 more]</label></div><br/><div class="children"><div class="content">What happened to the tech after acquisition?</div><br/><div id="37279744" class="c"><input type="checkbox" id="c-37279744" checked=""/><div class="controls bullet"><span class="by">modeless</span><span>|</span><a href="#37279435">root</a><span>|</span><a href="#37279463">parent</a><span>|</span><a href="#37278645">next</a><span>|</span><label class="collapse" for="c-37279744">[-]</label><label class="expand" for="c-37279744">[1 more]</label></div><br/><div class="children"><div class="content">The &quot;Daydream View&quot; VR headset developed before we were acquired totally bombed. Then a bunch of VR tech, including both long running internal projects and recent acquisitions, got shelved.</div><br/></div></div></div></div></div></div><div id="37278645" class="c"><input type="checkbox" id="c-37278645" checked=""/><div class="controls bullet"><span class="by">fartjetpack</span><span>|</span><a href="#37279435">prev</a><span>|</span><a href="#37279054">next</a><span>|</span><label class="collapse" for="c-37278645">[-]</label><label class="expand" for="c-37278645">[5 more]</label></div><br/><div class="children"><div class="content">Another route might also be sub-vocalization[1], like TTS for your thoughts. I recently picked up some cheap toys to get started trying to emulate the results[2].<p>1. <a href="https:&#x2F;&#x2F;www.nasa.gov&#x2F;centers&#x2F;ames&#x2F;news&#x2F;releases&#x2F;2004&#x2F;subvocal&#x2F;subvocal.html" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.nasa.gov&#x2F;centers&#x2F;ames&#x2F;news&#x2F;releases&#x2F;2004&#x2F;subvoca...</a><p>2. <a href="https:&#x2F;&#x2F;github.com&#x2F;kitschpatrol&#x2F;Brain">https:&#x2F;&#x2F;github.com&#x2F;kitschpatrol&#x2F;Brain</a></div><br/><div id="37279386" class="c"><input type="checkbox" id="c-37279386" checked=""/><div class="controls bullet"><span class="by">tbenst</span><span>|</span><a href="#37278645">parent</a><span>|</span><a href="#37278662">next</a><span>|</span><label class="collapse" for="c-37279386">[-]</label><label class="expand" for="c-37279386">[1 more]</label></div><br/><div class="children"><div class="content">I agree! My PhD thesis is on this topic [1]. We’ve also done a very limited pilot test on a patient with ALS, with above random chance. Actual results may vary heavily on individual disease progression—the more motor recruitment that’s intact, the better.<p>[1] <a href="https:&#x2F;&#x2F;neuroscience.stanford.edu&#x2F;research&#x2F;funded-research&#x2F;silent-speech-decoding-using-flexible-electronics-and-artificial-0" rel="nofollow noreferrer">https:&#x2F;&#x2F;neuroscience.stanford.edu&#x2F;research&#x2F;funded-research&#x2F;s...</a></div><br/></div></div><div id="37278662" class="c"><input type="checkbox" id="c-37278662" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#37278645">parent</a><span>|</span><a href="#37279386">prev</a><span>|</span><a href="#37279054">next</a><span>|</span><label class="collapse" for="c-37278662">[-]</label><label class="expand" for="c-37278662">[3 more]</label></div><br/><div class="children"><div class="content">How is it going? It&#x27;s not obvious to me at a glance.</div><br/><div id="37278748" class="c"><input type="checkbox" id="c-37278748" checked=""/><div class="controls bullet"><span class="by">fartjetpack</span><span>|</span><a href="#37278645">root</a><span>|</span><a href="#37278662">parent</a><span>|</span><a href="#37279054">next</a><span>|</span><label class="collapse" for="c-37278748">[-]</label><label class="expand" for="c-37278748">[2 more]</label></div><br/><div class="children"><div class="content">I should clarify that is not my repo. I just received the Mind Trainers and am in the process of finding suitable EEG pads.</div><br/><div id="37278897" class="c"><input type="checkbox" id="c-37278897" checked=""/><div class="controls bullet"><span class="by">qup</span><span>|</span><a href="#37278645">root</a><span>|</span><a href="#37278748">parent</a><span>|</span><a href="#37279054">next</a><span>|</span><label class="collapse" for="c-37278897">[-]</label><label class="expand" for="c-37278897">[1 more]</label></div><br/><div class="children"><div class="content">I guess I&#x27;m just interested in more information. Do people who aren&#x27;t NASA have this working? I am just learning this sci-fi feature from Ender&#x27;s universe is possibly a reality, and if I can check it out, I want to.<p>Got any jumping off points?</div><br/></div></div></div></div></div></div></div></div><div id="37279054" class="c"><input type="checkbox" id="c-37279054" checked=""/><div class="controls bullet"><span class="by">sailplease</span><span>|</span><a href="#37278645">prev</a><span>|</span><a href="#37279287">next</a><span>|</span><label class="collapse" for="c-37279054">[-]</label><label class="expand" for="c-37279054">[1 more]</label></div><br/><div class="children"><div class="content">Adhawk, adhawk.io,  has the only all day ultralight eye tracking wearable I&#x27;m aware of, all MEMS based with ultra high scan rates, 500Hz+ and research grade accuracy. For ALS u likely need something light and frictionless, wearing a hot and heavy headset all day probably doesn&#x27;t work.</div><br/></div></div><div id="37279287" class="c"><input type="checkbox" id="c-37279287" checked=""/><div class="controls bullet"><span class="by">sprocket</span><span>|</span><a href="#37279054">prev</a><span>|</span><a href="#37279231">next</a><span>|</span><label class="collapse" for="c-37279287">[-]</label><label class="expand" for="c-37279287">[1 more]</label></div><br/><div class="children"><div class="content">I used this software when my mom was battling ALS:<p><pre><code>   https:&#x2F;&#x2F;www.optikey.org&#x2F;
</code></pre>
which ran on a &lt; $1k computer<p>At the time, the other options were much more expensive (&gt; $10-15k) which were sadly out of out budget.</div><br/></div></div><div id="37279231" class="c"><input type="checkbox" id="c-37279231" checked=""/><div class="controls bullet"><span class="by">ZeroCool2u</span><span>|</span><a href="#37279287">prev</a><span>|</span><a href="#37280055">next</a><span>|</span><label class="collapse" for="c-37279231">[-]</label><label class="expand" for="c-37279231">[1 more]</label></div><br/><div class="children"><div class="content">I literally just bought this last night. Works with just a webcam and is shockingly accurate. <a href="https:&#x2F;&#x2F;beam.eyeware.tech&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;beam.eyeware.tech&#x2F;</a></div><br/></div></div><div id="37280380" class="c"><input type="checkbox" id="c-37280380" checked=""/><div class="controls bullet"><span class="by">supremearkitect</span><span>|</span><a href="#37280055">prev</a><span>|</span><a href="#37279766">next</a><span>|</span><label class="collapse" for="c-37280380">[-]</label><label class="expand" for="c-37280380">[2 more]</label></div><br/><div class="children"><div class="content">Looking at the downvoted comments, it feels like YC&#x2F;PG has been hit by the &quot;curse of desirability&quot;, like Google did back in the day when it was desirable: so many people have been rejected by them that they have accumulated a critical mass haters who will attack them at every opportunity.</div><br/><div id="37280444" class="c"><input type="checkbox" id="c-37280444" checked=""/><div class="controls bullet"><span class="by">sillysaurusx</span><span>|</span><a href="#37280380">parent</a><span>|</span><a href="#37279766">next</a><span>|</span><label class="collapse" for="c-37280444">[-]</label><label class="expand" for="c-37280444">[1 more]</label></div><br/><div class="children"><div class="content">Hmm. I was curious and started looking for the comments you mention, and was pleasantly surprised to find zero pg hate comments, downvoted or otherwise. People seem pretty on board with billionaires solving problems for disabled people in exchange for mutual upside.<p>I used to be bothered by those kinds of sentiments too, by the way. The way I got over it was to realize how many people are just bitter, and not because of pg or YC. This is different than having an actual issue with pg or YC — it’s random noise rather than points worth listening to.<p>Weirder than the haters are the people who reply to his tweets. Some of them post bizarre things. I find it fascinating when people project their own feelings on him, whether it’s hate, admiration, or (my favorite, having been a victim of it myself) misplaced ambition.</div><br/></div></div></div></div><div id="37279766" class="c"><input type="checkbox" id="c-37279766" checked=""/><div class="controls bullet"><span class="by">mercurialsolo</span><span>|</span><a href="#37280380">prev</a><span>|</span><a href="#37280005">next</a><span>|</span><label class="collapse" for="c-37279766">[-]</label><label class="expand" for="c-37279766">[3 more]</label></div><br/><div class="children"><div class="content">Eye tracking is essentially a model of visual attention. Visual attention is part of the overall attention space and big companies and use-cases are built around visual attention. Today we track attention by explicit interactions, if we can model around implicitly observable interactions - then we have a much larger observable data space around the user.,</div><br/><div id="37279783" class="c"><input type="checkbox" id="c-37279783" checked=""/><div class="controls bullet"><span class="by">mcbutterbunz</span><span>|</span><a href="#37279766">parent</a><span>|</span><a href="#37280005">next</a><span>|</span><label class="collapse" for="c-37279783">[-]</label><label class="expand" for="c-37279783">[2 more]</label></div><br/><div class="children"><div class="content">This comment makes me think we’ve gone too far and I should shut off my phone.</div><br/><div id="37280304" class="c"><input type="checkbox" id="c-37280304" checked=""/><div class="controls bullet"><span class="by">guerrilla</span><span>|</span><a href="#37279766">root</a><span>|</span><a href="#37279783">parent</a><span>|</span><a href="#37280005">next</a><span>|</span><label class="collapse" for="c-37280304">[-]</label><label class="expand" for="c-37280304">[1 more]</label></div><br/><div class="children"><div class="content">Indeed, it&#x27;s time to re-learn how to live without the Internet and such advanced technology.</div><br/></div></div></div></div></div></div><div id="37280005" class="c"><input type="checkbox" id="c-37280005" checked=""/><div class="controls bullet"><span class="by">tmalsburg2</span><span>|</span><a href="#37279766">prev</a><span>|</span><a href="#37278595">next</a><span>|</span><label class="collapse" for="c-37280005">[-]</label><label class="expand" for="c-37280005">[2 more]</label></div><br/><div class="children"><div class="content">Solving eye-tracking keyboards is not so much a task for a company with eye-tracking expertise but for one with expertise in large language models.</div><br/><div id="37280012" class="c"><input type="checkbox" id="c-37280012" checked=""/><div class="controls bullet"><span class="by">jfrbfbreudh</span><span>|</span><a href="#37280005">parent</a><span>|</span><a href="#37278595">next</a><span>|</span><label class="collapse" for="c-37280012">[-]</label><label class="expand" for="c-37280012">[1 more]</label></div><br/><div class="children"><div class="content">Please elaborate.</div><br/></div></div></div></div><div id="37278595" class="c"><input type="checkbox" id="c-37278595" checked=""/><div class="controls bullet"><span class="by">gwurldz</span><span>|</span><a href="#37280005">prev</a><span>|</span><a href="#37279850">next</a><span>|</span><label class="collapse" for="c-37278595">[-]</label><label class="expand" for="c-37278595">[3 more]</label></div><br/><div class="children"><div class="content">This seems like it would fit<p><a href="https:&#x2F;&#x2F;thinksmartbox.com&#x2F;products&#x2F;eye-gaze&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;thinksmartbox.com&#x2F;products&#x2F;eye-gaze&#x2F;</a><p>I once interviewed at this company. Unfortunately didn&#x27;t get the job but very impressed nonetheless.</div><br/><div id="37279904" class="c"><input type="checkbox" id="c-37279904" checked=""/><div class="controls bullet"><span class="by">Verath</span><span>|</span><a href="#37278595">parent</a><span>|</span><a href="#37279245">next</a><span>|</span><label class="collapse" for="c-37279904">[-]</label><label class="expand" for="c-37279904">[1 more]</label></div><br/><div class="children"><div class="content">I was part of developing the Lumin-i variant of this (working for Smart Eye)! Working with the Smartbox team was a pleasure :).<p>The solution actually works pretty well, especially when calibrated to a single individual.</div><br/></div></div><div id="37279245" class="c"><input type="checkbox" id="c-37279245" checked=""/><div class="controls bullet"><span class="by">ankaAr</span><span>|</span><a href="#37278595">parent</a><span>|</span><a href="#37279904">prev</a><span>|</span><a href="#37279850">next</a><span>|</span><label class="collapse" for="c-37279245">[-]</label><label class="expand" for="c-37279245">[1 more]</label></div><br/><div class="children"><div class="content">I work for them.., they have their ins and outs. The stack is very impressive but there is a loooot to improve yet</div><br/></div></div></div></div><div id="37279850" class="c"><input type="checkbox" id="c-37279850" checked=""/><div class="controls bullet"><span class="by">6stringmerc</span><span>|</span><a href="#37278595">prev</a><span>|</span><a href="#37278879">next</a><span>|</span><label class="collapse" for="c-37279850">[-]</label><label class="expand" for="c-37279850">[1 more]</label></div><br/><div class="children"><div class="content">Jason Becker is a great subject because if you can help him compose with his eyes the world can use his music he’s a genius.</div><br/></div></div><div id="37278879" class="c"><input type="checkbox" id="c-37278879" checked=""/><div class="controls bullet"><span class="by">user3939382</span><span>|</span><a href="#37279850">prev</a><span>|</span><a href="#37279428">next</a><span>|</span><label class="collapse" for="c-37278879">[-]</label><label class="expand" for="c-37278879">[1 more]</label></div><br/><div class="children"><div class="content">How about a library that starts loading a link when you look at it with intent. Or maybe with BCI integration that detects the moment you decide you want to access it.<p>Or how about a UI that automatically adapts to your eye movement and access patterns to minimize the amount of eye movement required to complete your most common tasks by rearranging the UI elements.</div><br/></div></div><div id="37279428" class="c"><input type="checkbox" id="c-37279428" checked=""/><div class="controls bullet"><span class="by">quietthrow</span><span>|</span><a href="#37278879">prev</a><span>|</span><a href="#37280075">next</a><span>|</span><label class="collapse" for="c-37279428">[-]</label><label class="expand" for="c-37279428">[2 more]</label></div><br/><div class="children"><div class="content">@paulg look in to this: <a href="https:&#x2F;&#x2F;spectrum.ieee.org&#x2F;brain-implant-speech" rel="nofollow noreferrer">https:&#x2F;&#x2F;spectrum.ieee.org&#x2F;brain-implant-speech</a></div><br/><div id="37280418" class="c"><input type="checkbox" id="c-37280418" checked=""/><div class="controls bullet"><span class="by">KaiserPro</span><span>|</span><a href="#37279428">parent</a><span>|</span><a href="#37280075">next</a><span>|</span><label class="collapse" for="c-37280418">[-]</label><label class="expand" for="c-37280418">[1 more]</label></div><br/><div class="children"><div class="content">no. Thats super intrusive, and given the the risks of major surgery with ALS, its  not a good option.</div><br/></div></div></div></div><div id="37280075" class="c"><input type="checkbox" id="c-37280075" checked=""/><div class="controls bullet"><span class="by">joshm93</span><span>|</span><a href="#37279428">prev</a><span>|</span><a href="#37278568">next</a><span>|</span><label class="collapse" for="c-37280075">[-]</label><label class="expand" for="c-37280075">[1 more]</label></div><br/><div class="children"><div class="content">I can make an eye tracking keyboard with tensor flow, if anyone is interested in this problem.<p>It would be great to hear from paul about how his friend uses the keyboard and what kind of tasks he’d love to do but can’t with current solutions.<p>It seems like a throughput problem to me. How can you type quickly using only your eyes?<p>Have people explored using small phonetic alphabets or Morse code style encoding?<p>Once I got tensorflow working, I’d start mapping different kinds of ux. Throughput is king.</div><br/></div></div><div id="37278597" class="c"><input type="checkbox" id="c-37278597" checked=""/><div class="controls bullet"><span class="by">PBnFlash</span><span>|</span><a href="#37278568">prev</a><span>|</span><a href="#37280472">next</a><span>|</span><label class="collapse" for="c-37278597">[-]</label><label class="expand" for="c-37278597">[3 more]</label></div><br/><div class="children"><div class="content">I suspect a foveated system is going to be a big thing in machine vision as well.</div><br/><div id="37278681" class="c"><input type="checkbox" id="c-37278681" checked=""/><div class="controls bullet"><span class="by">steve_adams_86</span><span>|</span><a href="#37278597">parent</a><span>|</span><a href="#37280472">next</a><span>|</span><label class="collapse" for="c-37278681">[-]</label><label class="expand" for="c-37278681">[2 more]</label></div><br/><div class="children"><div class="content">That&#x27;s an interesting idea. How do you see it being beneficial to machine learning models, other than (I assume) it could work more efficiently within less foveal regions? Perhaps cases where you want the vision to emulate human vision?</div><br/><div id="37278955" class="c"><input type="checkbox" id="c-37278955" checked=""/><div class="controls bullet"><span class="by">PBnFlash</span><span>|</span><a href="#37278597">root</a><span>|</span><a href="#37278681">parent</a><span>|</span><a href="#37280472">next</a><span>|</span><label class="collapse" for="c-37278955">[-]</label><label class="expand" for="c-37278955">[1 more]</label></div><br/><div class="children"><div class="content">Running a fast network on sparse data then calling one optimized for a task on a subset seems like a good optimization and dealing with video we are probably going to need them.<p>After you parse what an object is, tracking it doesn&#x27;t take anywhere near the effort of original segmentation. No need to re-evaluate until something changes.<p>Maybe even use activations to turn on and off networks. &quot;Oh text better load ocr into memory&quot;<p>And it does inform a lot of our built world
It&#x27;s strange to think that when watching a movie only 10% is in focus.<p>Eye movement does provide a lot of information to other people and I think the physical movement produces feedback for velocities and things too. Mimicking biology is often a good bet.</div><br/></div></div></div></div></div></div><div id="37280472" class="c"><input type="checkbox" id="c-37280472" checked=""/><div class="controls bullet"><span class="by">peter_retief</span><span>|</span><a href="#37278597">prev</a><span>|</span><a href="#37278873">next</a><span>|</span><label class="collapse" for="c-37280472">[-]</label><label class="expand" for="c-37280472">[1 more]</label></div><br/><div class="children"><div class="content">I would like to look at the problem more deeply, the eyes can be tracked but what about facial movement, the more data the better training for machine learning</div><br/></div></div><div id="37278873" class="c"><input type="checkbox" id="c-37278873" checked=""/><div class="controls bullet"><span class="by">kken</span><span>|</span><a href="#37280472">prev</a><span>|</span><label class="collapse" for="c-37278873">[-]</label><label class="expand" for="c-37278873">[3 more]</label></div><br/><div class="children"><div class="content">In case anyone is interested: There are plenty of companies around.<p>Both apple and Facebook acquired eye tracking companies to kickstart their own development.<p>Here are some Top-lists<p><a href="https:&#x2F;&#x2F;imotions.com&#x2F;blog&#x2F;insights&#x2F;trend&#x2F;top-eye-tracking-hardware-companies&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;imotions.com&#x2F;blog&#x2F;insights&#x2F;trend&#x2F;top-eye-tracking-ha...</a>
<a href="https:&#x2F;&#x2F;valentinazezelj.medium.com&#x2F;top-10-eye-tracking-companies-on-the-market-today-3b96ef131ab5" rel="nofollow noreferrer">https:&#x2F;&#x2F;valentinazezelj.medium.com&#x2F;top-10-eye-tracking-compa...</a><p>Its also an active research field, this is one of the bigger conferences:
<a href="https:&#x2F;&#x2F;etra.acm.org&#x2F;2023&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;etra.acm.org&#x2F;2023&#x2F;</a></div><br/><div id="37278943" class="c"><input type="checkbox" id="c-37278943" checked=""/><div class="controls bullet"><span class="by">TootsMagoon</span><span>|</span><a href="#37278873">parent</a><span>|</span><label class="collapse" for="c-37278943">[-]</label><label class="expand" for="c-37278943">[2 more]</label></div><br/><div class="children"><div class="content">Re: There are plenty of companies around.<p>I believe Paul Graham can Google or use AI and already knows about the companies and links you posted. His post was a call to action to connect with people working on yet to be discovered innovations and inspire those and others quietly working to come forward and connect with him.</div><br/><div id="37279066" class="c"><input type="checkbox" id="c-37279066" checked=""/><div class="controls bullet"><span class="by">kken</span><span>|</span><a href="#37278873">root</a><span>|</span><a href="#37278943">parent</a><span>|</span><label class="collapse" for="c-37279066">[-]</label><label class="expand" for="c-37279066">[1 more]</label></div><br/><div class="children"><div class="content">Well I thought people may be interested in learning what is already out there.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>