<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1695027663760" as="style"/><link rel="stylesheet" href="styles.css?v=1695027663760"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arxiv.org/abs/2309.07062">Large Language Models for Compiler Optimization</a> <span class="domain">(<a href="https://arxiv.org">arxiv.org</a>)</span></div><div class="subtext"><span>og_kalu</span> | <span>92 comments</span></div><br/><div><div id="37552783" class="c"><input type="checkbox" id="c-37552783" checked=""/><div class="controls bullet"><span class="by">PhilipRoman</span><span>|</span><a href="#37550394">next</a><span>|</span><label class="collapse" for="c-37552783">[-]</label><label class="expand" for="c-37552783">[2 more]</label></div><br/><div class="children"><div class="content">I see a lot of misconceptions about using ML for compilers. You don&#x27;t ask the model what instructions to emit. Instead, you prepare a set of passes which are guaranteed to preserve correctness (we already have hundreds of them). Then you ask the model - what passes should I apply and in what order.<p>Writing code to unroll a loop is trivial. The limitations of compilers are that almost all currently existing languages are too low level for optimization. ML has the potential to extract back this lost information. Basically the opposite of lowering an IR.</div><br/><div id="37552890" class="c"><input type="checkbox" id="c-37552890" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37552783">parent</a><span>|</span><a href="#37550394">next</a><span>|</span><label class="collapse" for="c-37552890">[-]</label><label class="expand" for="c-37552890">[1 more]</label></div><br/><div class="children"><div class="content">ML for phase ordering is just one problem that ML could solve within compilers.<p>Heuristic replacement (like loop unrolling) is another big one. For the specific case of loop unrolling, I would think lower level elements like how much iCache pressure the unrolling creates&#x2F;whether or not the loop could fit in the DSB buffer  would matter more.<p>For your point about existing IRs being too low-level, there has been a large push to try and work on that. MLIR has been used pretty extensively for that problem in ML applications, and languages like Rust have multiple higher level IRs. There&#x27;s also a preliminary implementation of a Clang-IR for C&#x2F;C++, and there&#x27;s even be some work on higher level representations within LLVM-IR itself.</div><br/></div></div></div></div><div id="37550394" class="c"><input type="checkbox" id="c-37550394" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37552783">prev</a><span>|</span><a href="#37553610">next</a><span>|</span><label class="collapse" for="c-37550394">[-]</label><label class="expand" for="c-37550394">[4 more]</label></div><br/><div class="children"><div class="content">One of the biggest things that seems to be holding back ML in compilers right now is dataset size. This model was only trained on a gigabyte of source code, 30+% of that synthetic. Even on much simpler models, there have been massive performance gains by just throwing more data at them. Some experimentation with the original MLGO inlining model on a much bigger data corpus doubled the code-size wins. LLMs have also been shown to perform better they more data they are fed [1].<p>1. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.15556" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.15556</a></div><br/><div id="37552524" class="c"><input type="checkbox" id="c-37552524" checked=""/><div class="controls bullet"><span class="by">isaacfung</span><span>|</span><a href="#37550394">parent</a><span>|</span><a href="#37552692">next</a><span>|</span><label class="collapse" for="c-37552524">[-]</label><label class="expand" for="c-37552524">[1 more]</label></div><br/><div class="children"><div class="content">Quality matters just as much as quantity.<p>LIMA: Less Is More for Alignment
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.11206" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.11206</a><p>AlpaGasus: Training A Better Alpaca with Fewer Data
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.08701" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.08701</a><p>Textbooks Are All You Need II: phi-1.5 technical report
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.05463" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2309.05463</a></div><br/></div></div><div id="37552692" class="c"><input type="checkbox" id="c-37552692" checked=""/><div class="controls bullet"><span class="by">uoaei</span><span>|</span><a href="#37550394">parent</a><span>|</span><a href="#37552524">prev</a><span>|</span><a href="#37553610">next</a><span>|</span><label class="collapse" for="c-37552692">[-]</label><label class="expand" for="c-37552692">[2 more]</label></div><br/><div class="children"><div class="content">What&#x27;s holding them back is provable correctness.<p>It&#x27;s possible, nay, mandatory to constrain the outputs of the model at each step of generation in order to guarantee that a given structure or grammar is adhered to. If you can fine-tune the model with these constraints in place you can offload a lot of the effort that the LLM otherwise has to perform in comprehending correctness so it has more capacity for generating good content. To be sure, quality and quantity of data are important, but it&#x27;s all too easy to introduce subtle bugs that take years to tease out if you don&#x27;t adhere to the right constraints.</div><br/><div id="37552794" class="c"><input type="checkbox" id="c-37552794" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37550394">root</a><span>|</span><a href="#37552692">parent</a><span>|</span><a href="#37553610">next</a><span>|</span><label class="collapse" for="c-37552794">[-]</label><label class="expand" for="c-37552794">[1 more]</label></div><br/><div class="children"><div class="content">Most of the work in this space is not focused on neural compilation (having a ML model perform the transformation&#x2F;entire compilation), but on replacing heuristics or phase ordering, where the issue of correctness falls back onto the compiler. For pretty much exactly the reasons you mentioned, neural compilation isn&#x27;t really tractable.<p>This specific paper focuses on phase ordering, which should guarantee correctness, assuming the underlying transformations are correct. They do train the model to perform compilation, but as an auxiliary task.</div><br/></div></div></div></div></div></div><div id="37553610" class="c"><input type="checkbox" id="c-37553610" checked=""/><div class="controls bullet"><span class="by">smusamashah</span><span>|</span><a href="#37550394">prev</a><span>|</span><a href="#37549533">next</a><span>|</span><label class="collapse" for="c-37553610">[-]</label><label class="expand" for="c-37553610">[2 more]</label></div><br/><div class="children"><div class="content">Do LLMs need to see some information just once to answer about it? My understanding was that they need to see many examples of the same thing to be able to answer it correctly (generate text around it correctly).<p>Shouldn&#x27;t this mean that it is safe to ask GPTs about something proprietary if it was just once because rare examples should just disappear in weights of everything else. And this also means that even GPT4 won&#x27;t be able to answer any queries about obscure or rare knowledge it has seen in its training dataset.</div><br/><div id="37553664" class="c"><input type="checkbox" id="c-37553664" checked=""/><div class="controls bullet"><span class="by">aratauto</span><span>|</span><a href="#37553610">parent</a><span>|</span><a href="#37549533">next</a><span>|</span><label class="collapse" for="c-37553664">[-]</label><label class="expand" for="c-37553664">[1 more]</label></div><br/><div class="children"><div class="content">Some recent discoveries indicate that LLMs might remember information after seeing it only once. See e.g.: <a href="https:&#x2F;&#x2F;www.fast.ai&#x2F;posts&#x2F;2023-09-04-learning-jumps&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.fast.ai&#x2F;posts&#x2F;2023-09-04-learning-jumps&#x2F;</a></div><br/></div></div></div></div><div id="37549533" class="c"><input type="checkbox" id="c-37549533" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#37553610">prev</a><span>|</span><a href="#37549617">next</a><span>|</span><label class="collapse" for="c-37549533">[-]</label><label class="expand" for="c-37549533">[19 more]</label></div><br/><div class="children"><div class="content">This kind of application of LLMs is most interesting to me, since it&#x27;s possible to evaluate correctness and performance quantitatively.</div><br/><div id="37549571" class="c"><input type="checkbox" id="c-37549571" checked=""/><div class="controls bullet"><span class="by">jebarker</span><span>|</span><a href="#37549533">parent</a><span>|</span><a href="#37549617">next</a><span>|</span><label class="collapse" for="c-37549571">[-]</label><label class="expand" for="c-37549571">[18 more]</label></div><br/><div class="children"><div class="content">It seems like a poor fit to me precisely because correctness is boolean, difficult to measure and getting it wrong is very bad. I do think there&#x27;s a place for AI here but it&#x27;s probably not LLMs in their current form.</div><br/><div id="37549642" class="c"><input type="checkbox" id="c-37549642" checked=""/><div class="controls bullet"><span class="by">kukkamario</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549571">parent</a><span>|</span><a href="#37549681">next</a><span>|</span><label class="collapse" for="c-37549642">[-]</label><label class="expand" for="c-37549642">[12 more]</label></div><br/><div class="children"><div class="content">They are not using LLM to directly produce the result code, but as tool that lists which optimisations should be done and in which order, which is fairly complex problem to solve. But if optimisation passes are implemented correctly (which is anyway required for a functioning optimising compiler), it cannot produce incorrect code, maybe only suboptimal compared to default heuristics used.</div><br/><div id="37549739" class="c"><input type="checkbox" id="c-37549739" checked=""/><div class="controls bullet"><span class="by">jebarker</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549642">parent</a><span>|</span><a href="#37551262">next</a><span>|</span><label class="collapse" for="c-37549739">[-]</label><label class="expand" for="c-37549739">[10 more]</label></div><br/><div class="children"><div class="content">If there&#x27;s a list of known optimizations that preserve correctness then it becomes an optimization problem based on output length (as a proxy for cycle count). So is the idea that an LLM is more efficient than a search or direct optimization?</div><br/><div id="37550168" class="c"><input type="checkbox" id="c-37550168" checked=""/><div class="controls bullet"><span class="by">sagarm</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549739">parent</a><span>|</span><a href="#37553400">next</a><span>|</span><label class="collapse" for="c-37550168">[-]</label><label class="expand" for="c-37550168">[1 more]</label></div><br/><div class="children"><div class="content">There tend to be a lot of heuristics involved when deciding which optimizations to apply and in which order, so there&#x27;s plenty of room to apply some machine learning.<p>Whether LLMs are the right approach is a separate question.<p>In SQL optimization, the problem is a bit trickier (IMO) because compilation is in the query path. One successful approach I know of is Bao: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2004.03814" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2004.03814</a></div><br/></div></div><div id="37553400" class="c"><input type="checkbox" id="c-37553400" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549739">parent</a><span>|</span><a href="#37550168">prev</a><span>|</span><a href="#37550843">next</a><span>|</span><label class="collapse" for="c-37553400">[-]</label><label class="expand" for="c-37553400">[1 more]</label></div><br/><div class="children"><div class="content">Cycle count is not a proper benchmark for performance on “modern” processors.</div><br/></div></div><div id="37550843" class="c"><input type="checkbox" id="c-37550843" checked=""/><div class="controls bullet"><span class="by">namibj</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549739">parent</a><span>|</span><a href="#37553400">prev</a><span>|</span><a href="#37552294">next</a><span>|</span><label class="collapse" for="c-37550843">[-]</label><label class="expand" for="c-37550843">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s neither the only metric of relevance, nor is that a good proxy for modern superscalar vector processor architectures.</div><br/></div></div><div id="37552294" class="c"><input type="checkbox" id="c-37552294" checked=""/><div class="controls bullet"><span class="by">Buttons840</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549739">parent</a><span>|</span><a href="#37550843">prev</a><span>|</span><a href="#37550280">next</a><span>|</span><label class="collapse" for="c-37552294">[-]</label><label class="expand" for="c-37552294">[1 more]</label></div><br/><div class="children"><div class="content">This is scooching into AlphaGo (or whatever the generic implementation is called) territory: mixing predictive AI with traditional optimization algorithms.</div><br/></div></div><div id="37550280" class="c"><input type="checkbox" id="c-37550280" checked=""/><div class="controls bullet"><span class="by">drug-freedom</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549739">parent</a><span>|</span><a href="#37552294">prev</a><span>|</span><a href="#37551262">next</a><span>|</span><label class="collapse" for="c-37550280">[-]</label><label class="expand" for="c-37550280">[5 more]</label></div><br/><div class="children"><div class="content">One example where a LLM might be better is which functions to inline.<p>Current compilers use a complex set of heuristics, a more holistic approach the kind neural networks do might outperform.</div><br/><div id="37550346" class="c"><input type="checkbox" id="c-37550346" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37550280">parent</a><span>|</span><a href="#37551262">next</a><span>|</span><label class="collapse" for="c-37550346">[-]</label><label class="expand" for="c-37550346">[4 more]</label></div><br/><div class="children"><div class="content">For function inlining specifically, I&#x27;m not sure LLMs are necessarily the right choice. The original MLGO paper [1] demonstrated a big code-size improvement with a ML model for making inlining decisions (7-20% code size wins), but they used tens of engineered features. Maybe a LLM could squeeze some additional size wins out, but maybe not [2].<p>Additionally, there are other factors to consider when productionizing these systems. Compile time is important (which LLMs will almost certainly explode), and anyone concerned about code size will probably be doing (Thin)LTO which would require feeding a lot more context into a LLM making inlining decisions.<p>1. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2101.04808" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2101.04808</a>
2. <a href="https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3503222.3507744" rel="nofollow noreferrer">https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;3503222.3507744</a></div><br/><div id="37552445" class="c"><input type="checkbox" id="c-37552445" checked=""/><div class="controls bullet"><span class="by">BruceEel</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37550346">parent</a><span>|</span><a href="#37551262">next</a><span>|</span><label class="collapse" for="c-37552445">[-]</label><label class="expand" for="c-37552445">[3 more]</label></div><br/><div class="children"><div class="content">I&#x27;m probably being very naive with this but, could mechanistic interpretability play a role here? Specifically, to experimentally short-list the LLM&#x27;s most effective optimizations, then try to peek inside the LLM and perhaps fish out some novel optimization algorithm that could be efficiently implemented <i>without</i> the LLM?</div><br/><div id="37552492" class="c"><input type="checkbox" id="c-37552492" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37552445">parent</a><span>|</span><a href="#37551262">next</a><span>|</span><label class="collapse" for="c-37552492">[-]</label><label class="expand" for="c-37552492">[2 more]</label></div><br/><div class="children"><div class="content">I did a bit of work on this last summer on (much) smaller models [1] and it was briefly discussed towards the end of last year&#x27;s MLGO panel [2]. For heuristic replacements specifically, you might be able to glean some things (or just use interpretable models like decision trees), but something like a neural network works fundamentally differently than the existing heuristics, so you probably wouldn&#x27;t see most of the performance gains. For just tuning heuristics, the usual practice is to make most of the parameters configurable and then use something like bayesian optimization to try and find an optimal set, and this is sometimes done as a baseline in pieces of ML-in-compiler research.<p>1. <a href="https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;ml-compiler-opt&#x2F;pull&#x2F;109">https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;ml-compiler-opt&#x2F;pull&#x2F;109</a>
2. <a href="https:&#x2F;&#x2F;youtu.be&#x2F;0uUKDQyn1Z4?si=PHrx9RICJIiA3E6C" rel="nofollow noreferrer">https:&#x2F;&#x2F;youtu.be&#x2F;0uUKDQyn1Z4?si=PHrx9RICJIiA3E6C</a></div><br/><div id="37552590" class="c"><input type="checkbox" id="c-37552590" checked=""/><div class="controls bullet"><span class="by">BruceEel</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37552492">parent</a><span>|</span><a href="#37551262">next</a><span>|</span><label class="collapse" for="c-37552590">[-]</label><label class="expand" for="c-37552590">[1 more]</label></div><br/><div class="children"><div class="content">Ah interesting. Hadn&#x27;t seen that presentation, thanks for sharing!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="37551262" class="c"><input type="checkbox" id="c-37551262" checked=""/><div class="controls bullet"><span class="by">nightski</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549642">parent</a><span>|</span><a href="#37549739">prev</a><span>|</span><a href="#37549681">next</a><span>|</span><label class="collapse" for="c-37551262">[-]</label><label class="expand" for="c-37551262">[1 more]</label></div><br/><div class="children"><div class="content">I thought so as well but then in the article it says that only like 91% of the code even compiles.</div><br/></div></div></div></div><div id="37549681" class="c"><input type="checkbox" id="c-37549681" checked=""/><div class="controls bullet"><span class="by">reic</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549571">parent</a><span>|</span><a href="#37549642">prev</a><span>|</span><a href="#37549636">next</a><span>|</span><label class="collapse" for="c-37549681">[-]</label><label class="expand" for="c-37549681">[3 more]</label></div><br/><div class="children"><div class="content">Quantification can be done by measuring in at least two dimensions: (1) the size of the synthesised code, and (2) how precisely the generated code matches the input (which means roughly: on what fraction of input do the two programs give different output). We have set up a challenge that <i>seeks</i> to entice the community to look into this problem domain more. And we&#x27;ve simplified the assumptions, so as to make it more tractable:<p>- Challenge: <a href="https:&#x2F;&#x2F;codalab.lisn.upsaclay.fr&#x2F;competitions&#x2F;15096" rel="nofollow noreferrer">https:&#x2F;&#x2F;codalab.lisn.upsaclay.fr&#x2F;competitions&#x2F;15096</a><p>- Paper describing the challenge: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.07899" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.07899</a><p>(I am one of the authors, AMA)</div><br/><div id="37550272" class="c"><input type="checkbox" id="c-37550272" checked=""/><div class="controls bullet"><span class="by">jebarker</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549681">parent</a><span>|</span><a href="#37549636">next</a><span>|</span><label class="collapse" for="c-37550272">[-]</label><label class="expand" for="c-37550272">[2 more]</label></div><br/><div class="children"><div class="content">How well does (2) really measure accuracy? It seems like a single output that doesn&#x27;t match the input code could indicate a fundamental floor in the optimized code, so it&#x27;s essentially 100% wrong even though it gets the correct answer almost all the time.<p>Good luck on the challenge though, this seems like an interesting and valuable area of research.</div><br/><div id="37550338" class="c"><input type="checkbox" id="c-37550338" checked=""/><div class="controls bullet"><span class="by">reic</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37550272">parent</a><span>|</span><a href="#37549636">next</a><span>|</span><label class="collapse" for="c-37550338">[-]</label><label class="expand" for="c-37550338">[1 more]</label></div><br/><div class="children"><div class="content">Of course (2) is not a perfect measure of accuracy, since it does not quantify how far wrong an output is, e.g. if 111111111111 is the correct output, then both
111111111110 and 829382934783 count as equally faulty. The main advantage of (2) is that it is natural, easy to understand, and easy to measure and compare. We have to start somewhere. I imagine that, in the future, it can be refined (e.g. taking the Hamming distance between desire and actual output). I expect that more refined quantification emerges  in response to the community better understanding exactly what is hard in the synthesis of programs.<p>Feel free to submit something! A simple submission is probably just a few lines of code.</div><br/></div></div></div></div></div></div><div id="37549636" class="c"><input type="checkbox" id="c-37549636" checked=""/><div class="controls bullet"><span class="by">foota</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549571">parent</a><span>|</span><a href="#37549681">prev</a><span>|</span><a href="#37549652">next</a><span>|</span><label class="collapse" for="c-37549636">[-]</label><label class="expand" for="c-37549636">[1 more]</label></div><br/><div class="children"><div class="content">The approach seems to focus on selecting optimizations to apply for LLVM (e.g., imagime: should this be inlined as an example), but the worst case is that the code is poorly optimized, you can&#x27;t select optimizations to apply and get a wrong result.<p>I agree that what you say is true of compilation as a whole, but that doesn&#x27;t seem to be the focus here (rather, it&#x27;s used as a sort of crutch to help the LLM learn)</div><br/></div></div><div id="37549652" class="c"><input type="checkbox" id="c-37549652" checked=""/><div class="controls bullet"><span class="by">armchairhacker</span><span>|</span><a href="#37549533">root</a><span>|</span><a href="#37549571">parent</a><span>|</span><a href="#37549636">prev</a><span>|</span><a href="#37549617">next</a><span>|</span><label class="collapse" for="c-37549652">[-]</label><label class="expand" for="c-37549652">[1 more]</label></div><br/><div class="children"><div class="content">The trick is finding a way to ensure that LLM produces something which is always correct. Like in this case, the LLM only changes compiler optimizations, not the assembly itself, so no matter what it outputs the code is correct, it just may be larger. Other possibilities: an LLM which applies semantics-preserving program transformations, or an LLM combined with a proof assistant to verify the output (more generally and for any domain, an LLM as an NP oracle).<p>But I agree, as of now I haven&#x27;t seen good uses where LLMs produce reliable output. Not only do you need that guarantee that whatever output always generates a correct program, you need something where an LLM is considerably better than a simple or random algorithm, and you need a lot of training data (severely restricting how creative you can be with the output).</div><br/></div></div></div></div></div></div><div id="37549617" class="c"><input type="checkbox" id="c-37549617" checked=""/><div class="controls bullet"><span class="by">wyldfire</span><span>|</span><a href="#37549533">prev</a><span>|</span><a href="#37550571">next</a><span>|</span><label class="collapse" for="c-37549617">[-]</label><label class="expand" for="c-37549617">[6 more]</label></div><br/><div class="children"><div class="content">&gt; understanding.
We evaluate on a large suite of test programs. Our approach achieves a 3.0% improvement in reducing instruction counts over the compiler,<p>3% code size reduction is really good.  The challenge will be having codegen like this that someone is willing to support. And for that they&#x27;d want to be able to reason about why the compiler made this decision or that one. IIUC that&#x27;s an outstanding problem for AI in general.</div><br/><div id="37549930" class="c"><input type="checkbox" id="c-37549930" checked=""/><div class="controls bullet"><span class="by">TheLoafOfBread</span><span>|</span><a href="#37549617">parent</a><span>|</span><a href="#37550571">next</a><span>|</span><label class="collapse" for="c-37549930">[-]</label><label class="expand" for="c-37549930">[5 more]</label></div><br/><div class="children"><div class="content">Also bugs from this approach are going to be funny - program compiled with compiler version X will work as expected and same program compiled with version X+1 will start crashing because AI under some circumstances decided that dereference of a specific pointer was unnecessary, so it won&#x27;t drop it into the assembly.<p>Good luck finding such a bug, because you will be looking on correct code, but computer will be executing invalid output.</div><br/><div id="37550305" class="c"><input type="checkbox" id="c-37550305" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37549617">root</a><span>|</span><a href="#37549930">parent</a><span>|</span><a href="#37550064">next</a><span>|</span><label class="collapse" for="c-37550305">[-]</label><label class="expand" for="c-37550305">[3 more]</label></div><br/><div class="children"><div class="content">The focus of this work is finding the optimal ordering of optimization passes to perform, not doing neural compilation. This guarantees correct code, assuming the underlying transformation passes are correct.<p>Most work in ML for compilers focuses on replacing heuristics and phase ordering precisely because they don&#x27;t impact correctness. There is some work being done on neural compilation [1], but I&#x27;m not sure that&#x27;s going to be a viable approach anytime soon.<p>1. <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;9926313" rel="nofollow noreferrer">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;9926313</a></div><br/><div id="37550841" class="c"><input type="checkbox" id="c-37550841" checked=""/><div class="controls bullet"><span class="by">wyldfire</span><span>|</span><a href="#37549617">root</a><span>|</span><a href="#37550305">parent</a><span>|</span><a href="#37550064">next</a><span>|</span><label class="collapse" for="c-37550841">[-]</label><label class="expand" for="c-37550841">[2 more]</label></div><br/><div class="children"><div class="content">&gt; phase ordering precisely because they don&#x27;t impact correctness.<p>lol let&#x27;s say they&#x27;re less likely to impact correctness than an arbitrary new optimization.</div><br/><div id="37553625" class="c"><input type="checkbox" id="c-37553625" checked=""/><div class="controls bullet"><span class="by">ncruces</span><span>|</span><a href="#37549617">root</a><span>|</span><a href="#37550841">parent</a><span>|</span><a href="#37550064">next</a><span>|</span><label class="collapse" for="c-37553625">[-]</label><label class="expand" for="c-37553625">[1 more]</label></div><br/><div class="children"><div class="content">If you find a bug, it&#x27;s in the optimization passes (that don&#x27;t reorder and should, if you decide to do this).<p>At this point this is like (usefully) fuzzing your optimizer, which long term is going to be great for correctness.</div><br/></div></div></div></div></div></div><div id="37550064" class="c"><input type="checkbox" id="c-37550064" checked=""/><div class="controls bullet"><span class="by">a_wild_dandan</span><span>|</span><a href="#37549617">root</a><span>|</span><a href="#37549930">parent</a><span>|</span><a href="#37550305">prev</a><span>|</span><a href="#37550571">next</a><span>|</span><label class="collapse" for="c-37550064">[-]</label><label class="expand" for="c-37550064">[1 more]</label></div><br/><div class="children"><div class="content">Damn. These things imitate humans too well. Guess we’ll need a giant test suite to feel stable. Sounds like work. Let’s train a GAN for that and put our feet up. Turtles all the way down, my dudes.</div><br/></div></div></div></div></div></div><div id="37550571" class="c"><input type="checkbox" id="c-37550571" checked=""/><div class="controls bullet"><span class="by">naveen99</span><span>|</span><a href="#37549617">prev</a><span>|</span><a href="#37551633">next</a><span>|</span><label class="collapse" for="c-37550571">[-]</label><label class="expand" for="c-37550571">[24 more]</label></div><br/><div class="children"><div class="content">Chatgpt4 can do source to source optimization which is pretty cool.  I got it to beat gcc at -03 on simple small toy problems.  and it can do similar things with python also.  But it threw its hands up when I gave it a longer piece of code to optimize.</div><br/><div id="37550995" class="c"><input type="checkbox" id="c-37550995" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#37550571">parent</a><span>|</span><a href="#37550725">next</a><span>|</span><label class="collapse" for="c-37550995">[-]</label><label class="expand" for="c-37550995">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a Kaze Emanuar video where he tries to have ChatGPT-4 optimize parts of his already well-optimized Mario 64 ROM hack: <a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=20s9hWDx0Io">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=20s9hWDx0Io</a></div><br/></div></div><div id="37550725" class="c"><input type="checkbox" id="c-37550725" checked=""/><div class="controls bullet"><span class="by">dwattttt</span><span>|</span><a href="#37550571">parent</a><span>|</span><a href="#37550995">prev</a><span>|</span><a href="#37553417">next</a><span>|</span><label class="collapse" for="c-37550725">[-]</label><label class="expand" for="c-37550725">[5 more]</label></div><br/><div class="children"><div class="content">It does make sense that ChatGPT can beat gcc (or any compiler really); the compiler is forced to optimise code so that it still appears to work as if it&#x27;s the source you wrote. Most importantly, if there are observable side-effects, compilers must preserve them, even though you know you don&#x27;t actually care about them. An AI is not bound to preserve those, and can semantically change what you wrote, so long as the one semantic you wanted preserved is still there.</div><br/><div id="37550914" class="c"><input type="checkbox" id="c-37550914" checked=""/><div class="controls bullet"><span class="by">esrauch</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37550725">parent</a><span>|</span><a href="#37553417">next</a><span>|</span><label class="collapse" for="c-37550914">[-]</label><label class="expand" for="c-37550914">[4 more]</label></div><br/><div class="children"><div class="content">It seems like compilers should have an interactive mode where it suggests code that is very similar but not technically perfectly the same that is more efficient and the can accept or decline the alternate version.</div><br/><div id="37550937" class="c"><input type="checkbox" id="c-37550937" checked=""/><div class="controls bullet"><span class="by">oldmanhorton</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37550914">parent</a><span>|</span><a href="#37551682">next</a><span>|</span><label class="collapse" for="c-37550937">[-]</label><label class="expand" for="c-37550937">[1 more]</label></div><br/><div class="children"><div class="content">This sounds like an extension of performance lint rules which many languages&#x2F;ecosystems already have.</div><br/></div></div><div id="37551682" class="c"><input type="checkbox" id="c-37551682" checked=""/><div class="controls bullet"><span class="by">insanitybit</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37550914">parent</a><span>|</span><a href="#37550937">prev</a><span>|</span><a href="#37550941">next</a><span>|</span><label class="collapse" for="c-37551682">[-]</label><label class="expand" for="c-37551682">[1 more]</label></div><br/><div class="children"><div class="content">A backend compiler is probably not in a good place to do that. Frontends could, however, and there are lots of tools already to make those suggestions for many languages.<p>clippy in rust, for example, will tell you about removing needless allocations, etc, which a backend compiler might have a harder time doing.</div><br/></div></div></div></div></div></div><div id="37553417" class="c"><input type="checkbox" id="c-37553417" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#37550571">parent</a><span>|</span><a href="#37550725">prev</a><span>|</span><a href="#37551260">next</a><span>|</span><label class="collapse" for="c-37553417">[-]</label><label class="expand" for="c-37553417">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think any of those examples would be materially different than finding a related problem on stackoverflow and applying the answer.<p>LLMs are just good at searching and transforming between representations, but they really are not good at logical inferences.</div><br/></div></div><div id="37551260" class="c"><input type="checkbox" id="c-37551260" checked=""/><div class="controls bullet"><span class="by">naveen99</span><span>|</span><a href="#37550571">parent</a><span>|</span><a href="#37553417">prev</a><span>|</span><a href="#37550595">next</a><span>|</span><label class="collapse" for="c-37551260">[-]</label><label class="expand" for="c-37551260">[6 more]</label></div><br/><div class="children"><div class="content">The toy example for those curious:<p><pre><code>  #include &lt;stdio.h&gt;
  int main(void) {
  int i; 
  int a[2000] ; 
  for(i = 0; i &lt; 2000; i++){
  a[i] = i ; 
  }
  printf(&quot;%d\n&quot;, a[5]);
  } 

</code></pre>
This program initializes an array `a` of size 2000, populates it with integers from 0 to 1999, and then prints the value at index 5, which is 5.<p>Just as with the Python program, we can optimize this program significantly. Given that we&#x27;re only interested in the sixth element (index 5) of the array, we don&#x27;t need to construct and populate the entire array.<p>Here&#x27;s an optimized version of the code:<p><pre><code>  #include &lt;stdio.h&gt;
  int main(void) {
  printf(&quot;%d\n&quot;, 5);
}</code></pre></div><br/><div id="37551564" class="c"><input type="checkbox" id="c-37551564" checked=""/><div class="controls bullet"><span class="by">Izkata</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37551260">parent</a><span>|</span><a href="#37551266">next</a><span>|</span><label class="collapse" for="c-37551564">[-]</label><label class="expand" for="c-37551564">[2 more]</label></div><br/><div class="children"><div class="content">Code indentation is 2 spaces on here, you have to do it to all the lines you want formatted that way.  That&#x27;s why the first one got a bunch of lines combined, it treated them as one paragraph instead of code.</div><br/><div id="37551767" class="c"><input type="checkbox" id="c-37551767" checked=""/><div class="controls bullet"><span class="by">naveen99</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37551564">parent</a><span>|</span><a href="#37551266">next</a><span>|</span><label class="collapse" for="c-37551767">[-]</label><label class="expand" for="c-37551767">[1 more]</label></div><br/><div class="children"><div class="content">thanks. fixed.</div><br/></div></div></div></div><div id="37551266" class="c"><input type="checkbox" id="c-37551266" checked=""/><div class="controls bullet"><span class="by">naveen99</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37551260">parent</a><span>|</span><a href="#37551564">prev</a><span>|</span><a href="#37552183">next</a><span>|</span><label class="collapse" for="c-37551266">[-]</label><label class="expand" for="c-37551266">[1 more]</label></div><br/><div class="children"><div class="content">But when I tried to get it to remove the dependency on studio.h, it said that’s too hard.  Might have gone further with a more reasonable request I guess.  Also not necessary as gcc does that anyway.</div><br/></div></div><div id="37552183" class="c"><input type="checkbox" id="c-37552183" checked=""/><div class="controls bullet"><span class="by">cypress66</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37551260">parent</a><span>|</span><a href="#37551266">prev</a><span>|</span><a href="#37550595">next</a><span>|</span><label class="collapse" for="c-37552183">[-]</label><label class="expand" for="c-37552183">[2 more]</label></div><br/><div class="children"><div class="content">Printf is horribly slow compared to puts</div><br/><div id="37552320" class="c"><input type="checkbox" id="c-37552320" checked=""/><div class="controls bullet"><span class="by">jmgao</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37552183">parent</a><span>|</span><a href="#37550595">next</a><span>|</span><label class="collapse" for="c-37552320">[-]</label><label class="expand" for="c-37552320">[1 more]</label></div><br/><div class="children"><div class="content">puts isn&#x27;t applicable here because you actually need to format the %d, but any compiler worth using (i.e. not MSVC: <a href="https:&#x2F;&#x2F;gcc.godbolt.org&#x2F;z&#x2F;zx74vY1za" rel="nofollow noreferrer">https:&#x2F;&#x2F;gcc.godbolt.org&#x2F;z&#x2F;zx74vY1za</a>) will optimize a printf of a constant string ending in a newline into a puts.</div><br/></div></div></div></div></div></div><div id="37550595" class="c"><input type="checkbox" id="c-37550595" checked=""/><div class="controls bullet"><span class="by">alex_lav</span><span>|</span><a href="#37550571">parent</a><span>|</span><a href="#37551260">prev</a><span>|</span><a href="#37551633">next</a><span>|</span><label class="collapse" for="c-37550595">[-]</label><label class="expand" for="c-37550595">[10 more]</label></div><br/><div class="children"><div class="content">At my company we have some &quot;loadbearing&quot; code that was written by a mad scientist that no longer works at our company. We have a total ban on AI for source code analysis (so chatgpt, copilot etc are all banned). I&#x27;ve really wanted to throw some of the grosser parts of that codebase into gpt-4 just to see if it could bring some small amount of sanity.</div><br/><div id="37550830" class="c"><input type="checkbox" id="c-37550830" checked=""/><div class="controls bullet"><span class="by">reidjs</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37550595">parent</a><span>|</span><a href="#37551633">next</a><span>|</span><label class="collapse" for="c-37550830">[-]</label><label class="expand" for="c-37550830">[9 more]</label></div><br/><div class="children"><div class="content">Do you know why that policy is in place? Is it fear that the llm provider will steal company trade knowledge?</div><br/><div id="37550920" class="c"><input type="checkbox" id="c-37550920" checked=""/><div class="controls bullet"><span class="by">esrauch</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37550830">parent</a><span>|</span><a href="#37551877">next</a><span>|</span><label class="collapse" for="c-37550920">[-]</label><label class="expand" for="c-37550920">[5 more]</label></div><br/><div class="children"><div class="content">It&#x27;s probably both that is leaking your source out and the risk of it being a copyright violation if it spits out some GPL source verbatim and you check it in.</div><br/><div id="37550974" class="c"><input type="checkbox" id="c-37550974" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37550920">parent</a><span>|</span><a href="#37551877">next</a><span>|</span><label class="collapse" for="c-37550974">[-]</label><label class="expand" for="c-37550974">[4 more]</label></div><br/><div class="children"><div class="content">&gt; if it spits out some GPL source verbatim<p>Does that ever actually happen? I&#x27;ve only heard of it happening to people who forced the AI&#x27;s hand by including the comments for said code in the prompt.</div><br/><div id="37551600" class="c"><input type="checkbox" id="c-37551600" checked=""/><div class="controls bullet"><span class="by">minhazm</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37550974">parent</a><span>|</span><a href="#37551095">next</a><span>|</span><label class="collapse" for="c-37551600">[-]</label><label class="expand" for="c-37551600">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a setting &quot;Suggestions matching public code&quot; that can be set to &quot;Block&quot; that I think is sufficient for most people&#x27;s usage. But many companies don&#x27;t want to involve themselves in any sort of liability.</div><br/></div></div><div id="37551095" class="c"><input type="checkbox" id="c-37551095" checked=""/><div class="controls bullet"><span class="by">callalex</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37550974">parent</a><span>|</span><a href="#37551600">prev</a><span>|</span><a href="#37551113">next</a><span>|</span><label class="collapse" for="c-37551095">[-]</label><label class="expand" for="c-37551095">[1 more]</label></div><br/><div class="children"><div class="content">While many software companies get away with an “it’ll be fine” attitude, that is not sufficient for all companies and industries. Sometimes things have to be provably correct.</div><br/></div></div><div id="37551113" class="c"><input type="checkbox" id="c-37551113" checked=""/><div class="controls bullet"><span class="by">pclmulqdq</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37550974">parent</a><span>|</span><a href="#37551095">prev</a><span>|</span><a href="#37551877">next</a><span>|</span><label class="collapse" for="c-37551113">[-]</label><label class="expand" for="c-37551113">[1 more]</label></div><br/><div class="children"><div class="content">This happens a lot, and you can easily walk into constructing such a prompt without knowing.</div><br/></div></div></div></div></div></div><div id="37551877" class="c"><input type="checkbox" id="c-37551877" checked=""/><div class="controls bullet"><span class="by">alex_lav</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37550830">parent</a><span>|</span><a href="#37550920">prev</a><span>|</span><a href="#37551633">next</a><span>|</span><label class="collapse" for="c-37551877">[-]</label><label class="expand" for="c-37551877">[3 more]</label></div><br/><div class="children"><div class="content">I work in a research facility, so the biggest fear is that our super top secret elite info will leak. The reality is it&#x27;d be used to refactor a lot of terrible code.</div><br/><div id="37552190" class="c"><input type="checkbox" id="c-37552190" checked=""/><div class="controls bullet"><span class="by">cypress66</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37551877">parent</a><span>|</span><a href="#37551633">next</a><span>|</span><label class="collapse" for="c-37552190">[-]</label><label class="expand" for="c-37552190">[2 more]</label></div><br/><div class="children"><div class="content">Use local models if you don&#x27;t want to send your data to OpenAI</div><br/><div id="37552458" class="c"><input type="checkbox" id="c-37552458" checked=""/><div class="controls bullet"><span class="by">alex_lav</span><span>|</span><a href="#37550571">root</a><span>|</span><a href="#37552190">parent</a><span>|</span><a href="#37551633">next</a><span>|</span><label class="collapse" for="c-37552458">[-]</label><label class="expand" for="c-37552458">[1 more]</label></div><br/><div class="children"><div class="content">&gt; We have a total ban on AI for source code analysis</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="37551633" class="c"><input type="checkbox" id="c-37551633" checked=""/><div class="controls bullet"><span class="by">CJefferson</span><span>|</span><a href="#37550571">prev</a><span>|</span><a href="#37552708">next</a><span>|</span><label class="collapse" for="c-37551633">[-]</label><label class="expand" for="c-37551633">[9 more]</label></div><br/><div class="children"><div class="content">While this isn&#x27;t optimization, is there any LLM systems that create &quot;provably correct&quot; transformations yet?<p>I have used ChatGPT on some fairly awful code, asking it to add comments, rename variables and functions, etc. I find the outputs useful, but a couple of times it&#x27;s broken the code. I imagine for many (not all) languages, you could ask the LLM to produce suggested changes, then use a code-rewriting tool to apply them in a way you could be 100% sure they weren&#x27;t going to change the behaviour of the progrma.</div><br/><div id="37552393" class="c"><input type="checkbox" id="c-37552393" checked=""/><div class="controls bullet"><span class="by">aureianimus</span><span>|</span><a href="#37551633">parent</a><span>|</span><a href="#37551677">next</a><span>|</span><label class="collapse" for="c-37552393">[-]</label><label class="expand" for="c-37552393">[2 more]</label></div><br/><div class="children"><div class="content">Not strictly what you&#x27;re looking for, but in Lean (functional language&#x2F;theorem prover), there&#x27;s some interesting work being done. Using the tool actually shows which suggestions will compile, which certifies correctness to some degree. <a href="https:&#x2F;&#x2F;leandojo.org&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;leandojo.org&#x2F;</a></div><br/><div id="37552637" class="c"><input type="checkbox" id="c-37552637" checked=""/><div class="controls bullet"><span class="by">isaacfung</span><span>|</span><a href="#37551633">root</a><span>|</span><a href="#37552393">parent</a><span>|</span><a href="#37551677">next</a><span>|</span><label class="collapse" for="c-37552637">[-]</label><label class="expand" for="c-37552637">[1 more]</label></div><br/><div class="children"><div class="content">Similar ideas<p>Certified Reasoning with Language Models  
<a href="https:&#x2F;&#x2F;github.com&#x2F;gpoesia&#x2F;certified-reasoning">https:&#x2F;&#x2F;github.com&#x2F;gpoesia&#x2F;certified-reasoning</a><p>It&#x27;s based on Peano, a theorem proving environment  
Peano: Learning Formal Mathematical Reasoning  
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.15864" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2211.15864</a><p>(<a href="https:&#x2F;&#x2F;github.com&#x2F;kyegomez&#x2F;LOGICGUIDE">https:&#x2F;&#x2F;github.com&#x2F;kyegomez&#x2F;LOGICGUIDE</a> claims to implement the same paper as the first repo but it is fake)</div><br/></div></div></div></div><div id="37551783" class="c"><input type="checkbox" id="c-37551783" checked=""/><div class="controls bullet"><span class="by">quickthrower2</span><span>|</span><a href="#37551633">parent</a><span>|</span><a href="#37551677">prev</a><span>|</span><a href="#37552126">next</a><span>|</span><label class="collapse" for="c-37551783">[-]</label><label class="expand" for="c-37551783">[1 more]</label></div><br/><div class="children"><div class="content">Sounds like TDD and langchain?<p>Where the T can be anything from Ruby unit tests to Coq proofs.</div><br/></div></div><div id="37552126" class="c"><input type="checkbox" id="c-37552126" checked=""/><div class="controls bullet"><span class="by">darksaints</span><span>|</span><a href="#37551633">parent</a><span>|</span><a href="#37551783">prev</a><span>|</span><a href="#37552116">next</a><span>|</span><label class="collapse" for="c-37552126">[-]</label><label class="expand" for="c-37552126">[2 more]</label></div><br/><div class="children"><div class="content">I can&#x27;t imagine there would be any success with an LLM that isn&#x27;t already known about via Satisfiability Modulo Theory.</div><br/><div id="37552745" class="c"><input type="checkbox" id="c-37552745" checked=""/><div class="controls bullet"><span class="by">CJefferson</span><span>|</span><a href="#37551633">root</a><span>|</span><a href="#37552126">parent</a><span>|</span><a href="#37552116">next</a><span>|</span><label class="collapse" for="c-37552745">[-]</label><label class="expand" for="c-37552745">[1 more]</label></div><br/><div class="children"><div class="content">I use SMT, but I can’t imagine how it would suggest good names for variables?</div><br/></div></div></div></div><div id="37552116" class="c"><input type="checkbox" id="c-37552116" checked=""/><div class="controls bullet"><span class="by">wrsh07</span><span>|</span><a href="#37551633">parent</a><span>|</span><a href="#37552126">prev</a><span>|</span><a href="#37552708">next</a><span>|</span><label class="collapse" for="c-37552116">[-]</label><label class="expand" for="c-37552116">[2 more]</label></div><br/><div class="children"><div class="content">Are you compiling the code or interpreting?</div><br/><div id="37552742" class="c"><input type="checkbox" id="c-37552742" checked=""/><div class="controls bullet"><span class="by">CJefferson</span><span>|</span><a href="#37551633">root</a><span>|</span><a href="#37552116">parent</a><span>|</span><a href="#37552708">next</a><span>|</span><label class="collapse" for="c-37552742">[-]</label><label class="expand" for="c-37552742">[1 more]</label></div><br/><div class="children"><div class="content">Compiling C++ code, which means there is a chance you could prove transformations correct, but I’m not going to try it myself :)</div><br/></div></div></div></div></div></div><div id="37552708" class="c"><input type="checkbox" id="c-37552708" checked=""/><div class="controls bullet"><span class="by">neonsunset</span><span>|</span><a href="#37551633">prev</a><span>|</span><a href="#37549606">next</a><span>|</span><label class="collapse" for="c-37552708">[-]</label><label class="expand" for="c-37552708">[3 more]</label></div><br/><div class="children"><div class="content">I was hoping to see a more ambitious language model based project.<p>Rather than just picking compiler arguments, an LLM could parse, and then transform AST into its more optimized form in a way that does not rely on a very formal way it is treated by compilers of today, apply guesstimate-based branch reordering and inlining heuristics not dissimilar to how a programmer would do so manually.<p>Once done, a compiler could perform final AST validation and either route it back to LLM to fix it or auto-fix most common cases.</div><br/><div id="37552865" class="c"><input type="checkbox" id="c-37552865" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37552708">parent</a><span>|</span><a href="#37552721">next</a><span>|</span><label class="collapse" for="c-37552865">[-]</label><label class="expand" for="c-37552865">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s the benefit of having an LLM do those things in a way that guesstimates? There are big wins to be had in code-size and some wins to be had in performance related to inlining [1][2], but I think the implementation in the references directly tied into the compiler&#x27;s inlining heuristic is a much better way to do that as it guarantees correctness. In addition, there&#x27;s a reason that compilers basically ignore the `inline` keyword these days.<p>For branch reordering, techniques like BOLT [5] are pretty effectively able to reorder code layout at the binary level for big performance gains by using profile information. ML models can sometimes synthesize that information [3], but if I recall correctly, the performance of those models wasn&#x27;t as good.<p>Neural compilation (like what you&#x27;re describing) has been tried with LLMs [4], but has a lot of correctness problems currently, and I don&#x27;t think it&#x27;s going to be feasible anytime soon to do reinforcement learning for performance&#x2F;code-size improvements.<p>1. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2101.04808" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2101.04808</a>
2. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2207.08389" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2207.08389</a>
3. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2112.14679" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2112.14679</a>
4. <a href="https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;9926313" rel="nofollow noreferrer">https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;9926313</a>
5. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1807.06735" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1807.06735</a></div><br/></div></div><div id="37552721" class="c"><input type="checkbox" id="c-37552721" checked=""/><div class="controls bullet"><span class="by">haltist</span><span>|</span><a href="#37552708">parent</a><span>|</span><a href="#37552865">prev</a><span>|</span><a href="#37549606">next</a><span>|</span><label class="collapse" for="c-37552721">[-]</label><label class="expand" for="c-37552721">[1 more]</label></div><br/><div class="children"><div class="content">How do you validate semantic equivalence?</div><br/></div></div></div></div><div id="37549606" class="c"><input type="checkbox" id="c-37549606" checked=""/><div class="controls bullet"><span class="by">CalChris</span><span>|</span><a href="#37552708">prev</a><span>|</span><a href="#37550736">next</a><span>|</span><label class="collapse" for="c-37549606">[-]</label><label class="expand" for="c-37549606">[4 more]</label></div><br/><div class="children"><div class="content">There&#x27;s a half day tutorial at the LLVM Developers Meeting on this, <i>ML-Guided Compiler Optimization in LLVM</i>. However, the authors of this paper aren&#x27;t giving that tutorial.</div><br/><div id="37550254" class="c"><input type="checkbox" id="c-37550254" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37549606">parent</a><span>|</span><a href="#37549661">next</a><span>|</span><label class="collapse" for="c-37550254">[-]</label><label class="expand" for="c-37550254">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s a workshop intended to facilitate discussion in the space. The lead author of this paper (Chris Cummins) will probably be there.<p><a href="https:&#x2F;&#x2F;discourse.llvm.org&#x2F;t&#x2F;pre-llvm-dev23-ml-guided-compiler-optimization-workshop&#x2F;71431" rel="nofollow noreferrer">https:&#x2F;&#x2F;discourse.llvm.org&#x2F;t&#x2F;pre-llvm-dev23-ml-guided-compil...</a></div><br/></div></div><div id="37549661" class="c"><input type="checkbox" id="c-37549661" checked=""/><div class="controls bullet"><span class="by">klohto</span><span>|</span><a href="#37549606">parent</a><span>|</span><a href="#37550254">prev</a><span>|</span><a href="#37550736">next</a><span>|</span><label class="collapse" for="c-37549661">[-]</label><label class="expand" for="c-37549661">[2 more]</label></div><br/><div class="children"><div class="content">MLGO uses RL</div><br/><div id="37549886" class="c"><input type="checkbox" id="c-37549886" checked=""/><div class="controls bullet"><span class="by">mathisfun123</span><span>|</span><a href="#37549606">root</a><span>|</span><a href="#37549661">parent</a><span>|</span><a href="#37550736">next</a><span>|</span><label class="collapse" for="c-37549886">[-]</label><label class="expand" for="c-37549886">[1 more]</label></div><br/><div class="children"><div class="content">maybe today but MLGO, the initiative, uses whatever. To wit: chris cummins (first author here) was on last year&#x27;s MLGO panel.</div><br/></div></div></div></div></div></div><div id="37550736" class="c"><input type="checkbox" id="c-37550736" checked=""/><div class="controls bullet"><span class="by">quadrature</span><span>|</span><a href="#37549606">prev</a><span>|</span><a href="#37550470">next</a><span>|</span><label class="collapse" for="c-37550736">[-]</label><label class="expand" for="c-37550736">[2 more]</label></div><br/><div class="children"><div class="content">I wonder if this requires a 7B parameter model.Assembly has a small grammar and is very constrained compared to natural language.</div><br/><div id="37553474" class="c"><input type="checkbox" id="c-37553474" checked=""/><div class="controls bullet"><span class="by">kaba0</span><span>|</span><a href="#37550736">parent</a><span>|</span><a href="#37550470">next</a><span>|</span><label class="collapse" for="c-37553474">[-]</label><label class="expand" for="c-37553474">[1 more]</label></div><br/><div class="children"><div class="content">I don’t see why would the output language’s complexity matter - that’s clearly not the hard part. You need plenty of “thinking” to do for outputting sensible assembly, let alone whole programs.<p>With that said, it is not doing neural compilation as others have mentioned, it’s only about ordering&#x2F;enabling different phases of the compiler based on ML, over the current, simpler heuristics.</div><br/></div></div></div></div><div id="37550470" class="c"><input type="checkbox" id="c-37550470" checked=""/><div class="controls bullet"><span class="by">sesuximo</span><span>|</span><a href="#37550736">prev</a><span>|</span><a href="#37550662">next</a><span>|</span><label class="collapse" for="c-37550470">[-]</label><label class="expand" for="c-37550470">[2 more]</label></div><br/><div class="children"><div class="content">I wonder if you could get a correct compiler (or 100% emulation in their terms) by allowing it to choose optimization pass order rather than doing more arbitrary things</div><br/><div id="37550532" class="c"><input type="checkbox" id="c-37550532" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37550470">parent</a><span>|</span><a href="#37550662">next</a><span>|</span><label class="collapse" for="c-37550532">[-]</label><label class="expand" for="c-37550532">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure a fully correct production optimizing compiler is that feasible. LLVM  gets multiple miscompilation reports per week (from what I&#x27;ve haphazardly seen observing the issue tracker).<p>Theoretically changing the order of the passes in the optimization pipeline shouldn&#x27;t cause any correctness issues, but the fact is that the ordering in the default compilation pipelines is the one that is most tested, so there will probably be bugs exposed when fuzzing the pass ordering.</div><br/></div></div></div></div><div id="37550662" class="c"><input type="checkbox" id="c-37550662" checked=""/><div class="controls bullet"><span class="by">kolbe</span><span>|</span><a href="#37550470">prev</a><span>|</span><a href="#37550045">next</a><span>|</span><label class="collapse" for="c-37550662">[-]</label><label class="expand" for="c-37550662">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Our approach achieves a 3.0% improvement in reducing instruction counts over the compiler, outperforming two state-of-the-art baselines that require thousands of compilations.<p>If that&#x27;s their target, then what&#x27;s the point? LLVM&#x27;s optimizations are not done to minimize instructions but to maximize performance. On modern processors, these can be very different things.</div><br/><div id="37550820" class="c"><input type="checkbox" id="c-37550820" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37550662">parent</a><span>|</span><a href="#37550045">next</a><span>|</span><label class="collapse" for="c-37550820">[-]</label><label class="expand" for="c-37550820">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re right that a decrease in code size doesn&#x27;t mean a performance increase (and oftentimes they can be inversely correlated like in inlining).<p>But LLVM targets both depending upon what optimization pipeline you select. (-Oz&#x2F;-Os are targeting minimum code size, -O1,-O2,-O3 are optimization focussed).<p>Code size reduction is critical in some use cases like embedded environments and mobile apps and it is a significant area of research.</div><br/></div></div></div></div><div id="37550045" class="c"><input type="checkbox" id="c-37550045" checked=""/><div class="controls bullet"><span class="by">haltist</span><span>|</span><a href="#37550662">prev</a><span>|</span><a href="#37551136">next</a><span>|</span><label class="collapse" for="c-37550045">[-]</label><label class="expand" for="c-37550045">[5 more]</label></div><br/><div class="children"><div class="content">Next step is to add verification for optimized code from the LLM with an SMT solver (like Z3) to remove &quot;hallucinations&quot;. If the input and output code can be verified to be equivalent then this would be a great addition to an optimization pipeline. Once that&#x27;s done the same can be applied to intermediate representations of GPU kernels in a recursive loop of AI optimizing AI code for faster execution times.</div><br/><div id="37550276" class="c"><input type="checkbox" id="c-37550276" checked=""/><div class="controls bullet"><span class="by">boomanaiden154</span><span>|</span><a href="#37550045">parent</a><span>|</span><a href="#37550209">next</a><span>|</span><label class="collapse" for="c-37550276">[-]</label><label class="expand" for="c-37550276">[2 more]</label></div><br/><div class="children"><div class="content">There&#x27;s already tooling available for using SMT to validate LLVM-IR transformations [1]. It&#x27;s designed for zero false positives however, so some things might slip through the cracks.<p>Additionally, this work focuses on phase ordering, which produces correct code regardless of what the LLM puts out, assuming there aren&#x27;t any bugs in the passes being used (which could crop up as random orderings aren&#x27;t as well tested as the standard orderings in the commonly used pipelines).<p>1. <a href="https:&#x2F;&#x2F;users.cs.utah.edu&#x2F;~regehr&#x2F;alive2-pldi21.pdf" rel="nofollow noreferrer">https:&#x2F;&#x2F;users.cs.utah.edu&#x2F;~regehr&#x2F;alive2-pldi21.pdf</a></div><br/><div id="37551766" class="c"><input type="checkbox" id="c-37551766" checked=""/><div class="controls bullet"><span class="by">haltist</span><span>|</span><a href="#37550045">root</a><span>|</span><a href="#37550276">parent</a><span>|</span><a href="#37550209">next</a><span>|</span><label class="collapse" for="c-37551766">[-]</label><label class="expand" for="c-37551766">[1 more]</label></div><br/><div class="children"><div class="content">Interesting. AI code has no loops so the problem they mention in the beginning about unrolling loops to a certain depth is a non-issue.</div><br/></div></div></div></div></div></div><div id="37551136" class="c"><input type="checkbox" id="c-37551136" checked=""/><div class="controls bullet"><span class="by">dhosek</span><span>|</span><a href="#37550045">prev</a><span>|</span><a href="#37551455">next</a><span>|</span><label class="collapse" for="c-37551136">[-]</label><label class="expand" for="c-37551136">[2 more]</label></div><br/><div class="children"><div class="content">“generating compilable code 91% of the time” which means that almost ten percent of the time, it doesn’t generate compilable code. Given the fact that ChatGPT has gotten worse at math over time,¹ I’m wondering if this too will get worse.<p>⸻<p>1. Although I also find myself thinking about my kids as they were developing language where they initially correctly conjugated some common irregular verbs, then they started conjugating them as if they were regular and then finally returned to correctly conjugating them, which might be what’s happening with ChatGPT and math.</div><br/></div></div><div id="37551455" class="c"><input type="checkbox" id="c-37551455" checked=""/><div class="controls bullet"><span class="by">primordialsoup</span><span>|</span><a href="#37551136">prev</a><span>|</span><a href="#37551508">next</a><span>|</span><label class="collapse" for="c-37551455">[-]</label><label class="expand" for="c-37551455">[2 more]</label></div><br/><div class="children"><div class="content">This is very interesting work, but it&#x27;s not really a LLM. It doesn&#x27;t have language abilities. They should have called it a seq2seq model, but I think that term is not in vogue these days :)</div><br/></div></div><div id="37551508" class="c"><input type="checkbox" id="c-37551508" checked=""/><div class="controls bullet"><span class="by">gamerpuppy</span><span>|</span><a href="#37551455">prev</a><span>|</span><label class="collapse" for="c-37551508">[-]</label><label class="expand" for="c-37551508">[3 more]</label></div><br/><div class="children"><div class="content">LLm&#x27;s are agi, you can use them for anything so posts like &quot;LLm&#x27;s for x&quot; are really so boring.</div><br/><div id="37551650" class="c"><input type="checkbox" id="c-37551650" checked=""/><div class="controls bullet"><span class="by">csjh</span><span>|</span><a href="#37551508">parent</a><span>|</span><a href="#37551521">next</a><span>|</span><label class="collapse" for="c-37551650">[-]</label><label class="expand" for="c-37551650">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are definitely not AGI</div><br/></div></div></div></div></div></div></div></div></div></body></html>