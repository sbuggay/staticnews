<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1700211657985" as="style"/><link rel="stylesheet" href="styles.css?v=1700211657985"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://www.airplane.dev/blog/migrating-to-opentelemetry">Migrating to OpenTelemetry</a> <span class="domain">(<a href="https://www.airplane.dev">www.airplane.dev</a>)</span></div><div class="subtext"><span>kkoppenhaver</span> | <span>59 comments</span></div><br/><div><div id="38294705" class="c"><input type="checkbox" id="c-38294705" checked=""/><div class="controls bullet"><span class="by">CSMastermind</span><span>|</span><a href="#38297679">next</a><span>|</span><label class="collapse" for="c-38294705">[-]</label><label class="expand" for="c-38294705">[17 more]</label></div><br/><div class="children"><div class="content">&gt; The data collected from these streams is sent to several vendors including Datadog (for application logs and metrics), Honeycomb (for traces), and Google Cloud Logging (for infrastructure logs).<p>It sounds like they were in a place that a lot of companies are in where they don&#x27;t have a single pane of glass for observability.  One of if not the main benefit I&#x27;ve gotten out of Datadog is having everything in Datadog so that it&#x27;s all connected and I can easily jump from a trace to logs for instance.<p>One of the terrible mistakes I see companies make with this tooling is fragmenting like this.  Everyone has their own personal preference for tool and ultimately the collective experience is significantly worse than the sum of its parts.</div><br/><div id="38296135" class="c"><input type="checkbox" id="c-38296135" checked=""/><div class="controls bullet"><span class="by">badloginagain</span><span>|</span><a href="#38294705">parent</a><span>|</span><a href="#38295505">next</a><span>|</span><label class="collapse" for="c-38296135">[-]</label><label class="expand" for="c-38296135">[3 more]</label></div><br/><div class="children"><div class="content">I feel we hold up single-observability-solution as the Holy Grail, and I can see the argument for it- one place to understand the health of your services.<p>But I&#x27;ve also been in terrible vendor lock-in situations, being bent over the barrel because switching to a better solution is so damn expensive.<p>At least now with OTel you have an open standard that allows you to switch easier, but even then I&#x27;d rather have 2 solutions that meet my exact observability requirements than a single solution that does everything OKish.</div><br/><div id="38297281" class="c"><input type="checkbox" id="c-38297281" checked=""/><div class="controls bullet"><span class="by">mikeshi42</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38296135">parent</a><span>|</span><a href="#38298649">next</a><span>|</span><label class="collapse" for="c-38297281">[-]</label><label class="expand" for="c-38297281">[1 more]</label></div><br/><div class="children"><div class="content">Biased as a founder in the space [1] but I think with OpenTelemetry + OSS extensible observability tooling, the holy grail of one tool is more realizable than ever.<p>Vendor lock in with Otel now is hopefully a thing of the past - but now that more obs solutions are going open source, hopefully it&#x27;s not necessarily true that one tool would be mediocre over all use cases (since DD and the likes are inherently limited by their own engineering teams, vs OSS products can have community&#x2F;customer contributions to improve the surface area over time on top of the core maintainer&#x27;s work).<p>[1] <a href="https:&#x2F;&#x2F;github.com&#x2F;hyperdxio&#x2F;hyperdx">https:&#x2F;&#x2F;github.com&#x2F;hyperdxio&#x2F;hyperdx</a></div><br/></div></div><div id="38298649" class="c"><input type="checkbox" id="c-38298649" checked=""/><div class="controls bullet"><span class="by">pranay01</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38296135">parent</a><span>|</span><a href="#38297281">prev</a><span>|</span><a href="#38295505">next</a><span>|</span><label class="collapse" for="c-38298649">[-]</label><label class="expand" for="c-38298649">[1 more]</label></div><br/><div class="children"><div class="content">I think that OpenTelemetry will solve this problem of vendor lock in. I am a founder building in this space[1] and we see many of our users switching to opentelemetry as that provides an easy way to switch if needed in future.<p>At SigNoz, we have metrics, traces and logs in a single application which helps you correlate across signals much more easily - and being natively based on opentelemetry makes this correlation much easier as it leverages the standard data format.<p>Though this might take sometime, as many teams have proprietary SDK in their code, which is not easy to rip out. Opentelemetry auto-instrumentation[2] makes it much easier, and I think that&#x27;s the path people will follow to get started<p>[1]<a href="https:&#x2F;&#x2F;github.com&#x2F;SigNoz&#x2F;signoz">https:&#x2F;&#x2F;github.com&#x2F;SigNoz&#x2F;signoz</a>
[2]<a href="https:&#x2F;&#x2F;opentelemetry.io&#x2F;docs&#x2F;instrumentation&#x2F;java&#x2F;automatic&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;opentelemetry.io&#x2F;docs&#x2F;instrumentation&#x2F;java&#x2F;automatic...</a></div><br/></div></div></div></div><div id="38295505" class="c"><input type="checkbox" id="c-38295505" checked=""/><div class="controls bullet"><span class="by">dexterdog</span><span>|</span><a href="#38294705">parent</a><span>|</span><a href="#38296135">prev</a><span>|</span><a href="#38295542">next</a><span>|</span><label class="collapse" for="c-38295505">[-]</label><label class="expand" for="c-38295505">[3 more]</label></div><br/><div class="children"><div class="content">Depending on your usage it can be prohibitively expensive to use datadog for everything like that. We have it for just our prod env because it&#x27;s just not worth what it brings to the table to put all of our logs into it.</div><br/><div id="38300142" class="c"><input type="checkbox" id="c-38300142" checked=""/><div class="controls bullet"><span class="by">shric</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38295505">parent</a><span>|</span><a href="#38297319">next</a><span>|</span><label class="collapse" for="c-38300142">[-]</label><label class="expand" for="c-38300142">[1 more]</label></div><br/><div class="children"><div class="content">I once worked out what it would cost to send our company&#x27;s prod logs to datadog. It was 1.5x our total AWS cost. The company ran entirely on AWS</div><br/></div></div><div id="38297319" class="c"><input type="checkbox" id="c-38297319" checked=""/><div class="controls bullet"><span class="by">dabeeeenster</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38295505">parent</a><span>|</span><a href="#38300142">prev</a><span>|</span><a href="#38295542">next</a><span>|</span><label class="collapse" for="c-38297319">[-]</label><label class="expand" for="c-38297319">[1 more]</label></div><br/><div class="children"><div class="content">Is prod not 99% of your logs?</div><br/></div></div></div></div><div id="38295542" class="c"><input type="checkbox" id="c-38295542" checked=""/><div class="controls bullet"><span class="by">maccard</span><span>|</span><a href="#38294705">parent</a><span>|</span><a href="#38295505">prev</a><span>|</span><a href="#38295248">next</a><span>|</span><label class="collapse" for="c-38295542">[-]</label><label class="expand" for="c-38295542">[7 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve spent a small amount of time in datadog, lots in grafana, and somewhere in between in honeycomb. Out applications are designed to emit traces, and comparing honeycomb with tracing to a traditional app with metrics and logs, I would choose tracing every time.<p>It annoys me that logs are overlooked in honeycomb, (and metrics are... fine). But, given the choice between a single pane of glass in grafana or having to do logs (and metrics sometimes) in cloudwatch but spending 95% of my time in honeycomb - I&#x27;d pick honeycomb every time</div><br/><div id="38296132" class="c"><input type="checkbox" id="c-38296132" checked=""/><div class="controls bullet"><span class="by">mdtusz</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38295542">parent</a><span>|</span><a href="#38299395">next</a><span>|</span><label class="collapse" for="c-38296132">[-]</label><label class="expand" for="c-38296132">[2 more]</label></div><br/><div class="children"><div class="content">Agreed - honeycomb has been a boon, however some improvements to metric displays and the ability to set the default &quot;board&quot; used in the home page would be very welcome. Also would be pretty happy if there was a way to drop events on the honeycomb side for a way to dynamically filter - e.g. &quot;don&#x27;t even bother storing this trace if it has a http.status_code &lt; 400&quot;. This is surprisingly painful to implement on the application side (at least in rust).<p>Hopefully someone that works there is reading this.</div><br/><div id="38296367" class="c"><input type="checkbox" id="c-38296367" checked=""/><div class="controls bullet"><span class="by">masterj</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38296132">parent</a><span>|</span><a href="#38299395">next</a><span>|</span><label class="collapse" for="c-38296367">[-]</label><label class="expand" for="c-38296367">[1 more]</label></div><br/><div class="children"><div class="content">It sounds like you should look into their tail-sampling Refinery tool <a href="https:&#x2F;&#x2F;docs.honeycomb.io&#x2F;manage-data-volume&#x2F;refinery&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;docs.honeycomb.io&#x2F;manage-data-volume&#x2F;refinery&#x2F;</a></div><br/></div></div></div></div><div id="38299395" class="c"><input type="checkbox" id="c-38299395" checked=""/><div class="controls bullet"><span class="by">serverlessmom</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38295542">parent</a><span>|</span><a href="#38296132">prev</a><span>|</span><a href="#38296766">next</a><span>|</span><label class="collapse" for="c-38299395">[-]</label><label class="expand" for="c-38299395">[1 more]</label></div><br/><div class="children"><div class="content">I think Honeycomb is perfect for one kind of user, who&#x27;s entirely concerned with traces and very long retention. For a more general OpenTelemetry-native solution, check out Signoz.</div><br/></div></div><div id="38296766" class="c"><input type="checkbox" id="c-38296766" checked=""/><div class="controls bullet"><span class="by">viraptor</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38295542">parent</a><span>|</span><a href="#38299395">prev</a><span>|</span><a href="#38299164">next</a><span>|</span><label class="collapse" for="c-38296766">[-]</label><label class="expand" for="c-38296766">[2 more]</label></div><br/><div class="children"><div class="content">Have you tried the traces in grafana&#x2F;tempo yet? <a href="https:&#x2F;&#x2F;grafana.com&#x2F;docs&#x2F;grafana&#x2F;latest&#x2F;panels-visualizations&#x2F;visualizations&#x2F;traces&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;grafana.com&#x2F;docs&#x2F;grafana&#x2F;latest&#x2F;panels-visualization...</a><p>It seems to miss some aggregation stuff, but also it&#x27;s improving every time I check. I wonder if anyone&#x27;s used it in anger yet and how far is it from replacing datadog or honeycomb.</div><br/><div id="38296837" class="c"><input type="checkbox" id="c-38296837" checked=""/><div class="controls bullet"><span class="by">arccy</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38296766">parent</a><span>|</span><a href="#38299164">next</a><span>|</span><label class="collapse" for="c-38296837">[-]</label><label class="expand" for="c-38296837">[1 more]</label></div><br/><div class="children"><div class="content">tempo still feels very much: look at a trace that you found from elsewhere (like logs).<p>with so much information in traces and the pure volume, the aggregation really is the key to actionable info out of a tracing setup if it&#x27;s going to be the primary entry point.</div><br/></div></div></div></div><div id="38299164" class="c"><input type="checkbox" id="c-38299164" checked=""/><div class="controls bullet"><span class="by">ankit01-oss</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38295542">parent</a><span>|</span><a href="#38296766">prev</a><span>|</span><a href="#38295248">next</a><span>|</span><label class="collapse" for="c-38299164">[-]</label><label class="expand" for="c-38299164">[1 more]</label></div><br/><div class="children"><div class="content">You can also check out SigNoz - <a href="https:&#x2F;&#x2F;github.com&#x2F;SigNoz&#x2F;signoz">https:&#x2F;&#x2F;github.com&#x2F;SigNoz&#x2F;signoz</a>. It has logs, metrics, and traces under a single pane. If you&#x27;re using otel libraries and otel collector you can do a lot of correlation between your logs and traces. I am a maintainer, and we have seen a lot of our users using signoz to have the ease of having three signals in a single pane.</div><br/></div></div></div></div><div id="38295248" class="c"><input type="checkbox" id="c-38295248" checked=""/><div class="controls bullet"><span class="by">devin</span><span>|</span><a href="#38294705">parent</a><span>|</span><a href="#38295542">prev</a><span>|</span><a href="#38296101">next</a><span>|</span><label class="collapse" for="c-38295248">[-]</label><label class="expand" for="c-38295248">[1 more]</label></div><br/><div class="children"><div class="content">Eh, personally I view honeycomb and datadog as different enough offerings that I can see why you&#x27;d choose to have both.</div><br/></div></div><div id="38296101" class="c"><input type="checkbox" id="c-38296101" checked=""/><div class="controls bullet"><span class="by">rewmie</span><span>|</span><a href="#38294705">parent</a><span>|</span><a href="#38295248">prev</a><span>|</span><a href="#38297679">next</a><span>|</span><label class="collapse" for="c-38296101">[-]</label><label class="expand" for="c-38296101">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It sounds like they were in a place that a lot of companies are in where they don&#x27;t have a single pane of glass for observability.<p>One of the biggest features of AWS which is very easy to take for granted and go unnoticed is Amazon CloudWatch. It supports metrics, logging, alarms, metrics from alarms, alarms from alarms, querying historical logs, trigger actions, etc etc etc. and it covers each and every single service provided by AWS including metaservices like AWS Config and Cloudtrail.<p>And you barely notice it. It&#x27;s just there, and you can see everything.<p>&gt; One of the terrible mistakes I see companies make with this tooling is fragmenting like this.<p>So much this. It&#x27;s not fun at all to have to go through logs and metrics on any application,and much less so if for some reason their maintainers scattered their metrics emission to the four winds. However, with AWS all roads lead to Cloudwatch, and everything is so much better.</div><br/><div id="38297359" class="c"><input type="checkbox" id="c-38297359" checked=""/><div class="controls bullet"><span class="by">yourapostasy</span><span>|</span><a href="#38294705">root</a><span>|</span><a href="#38296101">parent</a><span>|</span><a href="#38297679">next</a><span>|</span><label class="collapse" for="c-38297359">[-]</label><label class="expand" for="c-38297359">[1 more]</label></div><br/><div class="children"><div class="content"><i>&gt; ...with AWS all roads lead to Cloudwatch, and everything is so much better.</i><p>Most of my clients are not in the product-market fit for AWS CloudWatch, because most of their developers don&#x27;t have the development, testing and operational maturity&#x2F;discipline to use CloudWatch cost-effectively (this is at root an organization problem, but let&#x27;s not go off onto that giant tangent). So the only realistic tracing strategy we converged upon to recommend for them is &quot;grab everything, and retain it up to the point in time we won&#x27;t be blamed for not knowing root cause&quot; (which in some specific cases can be up to years!), while we undertake the long journey with them to upskill their teams.<p>This would make using CloudWatch everywhere rapidly climb up into the top three largest line item in the AWS bill, easily justifying spinning that tracing functionality in-house. So we wind up opting into self-managed tooling like Elastic Observability or Honeycomb where the pricing is friendlier to teams in unfortunate situations that need to start with everything for CYA, much as I would like to stay within CloudWatch.<p>Has anyone found a better solution to these use cases where the development maturity level is more prosaic, or is this really the best local maxima at the industry&#x27;s current SOTA?</div><br/></div></div></div></div></div></div><div id="38297679" class="c"><input type="checkbox" id="c-38297679" checked=""/><div class="controls bullet"><span class="by">Jedd</span><span>|</span><a href="#38294705">prev</a><span>|</span><a href="#38293172">next</a><span>|</span><label class="collapse" for="c-38297679">[-]</label><label class="expand" for="c-38297679">[4 more]</label></div><br/><div class="children"><div class="content">The killer feature of OpenTelemetry for us is brokering (with ETL).<p>Partly this lets us easily re-route &amp; duplicate telemetry, partly it means changes to backend products in the future won&#x27;t be a big disruption.<p>For metrics we&#x27;re a mostly telegraf-&gt;prometheus-&gt;grafana mimir shop - telegraf because its rock solid and feature-rich, prometheus because there&#x27;s no real competition in that tier, and mimir because of scale &amp; self-host options.<p>Our scale problem means most online pricing calculators generate overflow errors.<p>Our non-security log destination preference is Loki - for similar reasons to Mimir - though a SIEM it definitely is not.<p>Tracing to a vendor, but looking to bring that back to grafana Tempo.  Product maturity is a long way off commercial APM offerings, but it feels like the feature-set is about 70% there and converging rapidly. Off-the-shelf tracing products have an appealingly low cost of entry, which only briefly defers lock-in &amp; pricing shocks.</div><br/><div id="38299055" class="c"><input type="checkbox" id="c-38299055" checked=""/><div class="controls bullet"><span class="by">pranay01</span><span>|</span><a href="#38297679">parent</a><span>|</span><a href="#38293172">next</a><span>|</span><label class="collapse" for="c-38299055">[-]</label><label class="expand" for="c-38299055">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, the ability to send to multiple sources is quite powerful and most of this comes from the configurability of Otel Collector [1].<p>If you are looking for a open source backend for OpenTelemetry, then you can explore SigNoz[2] (I am one of the founders) We have a quite a decent product for APM&#x2F;tracing leveraging opentelemerty native data format and semantic convention.<p>[1]<a href="https:&#x2F;&#x2F;opentelemetry.io&#x2F;docs&#x2F;collector&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;opentelemetry.io&#x2F;docs&#x2F;collector&#x2F;</a>
[2]<a href="https:&#x2F;&#x2F;github.com&#x2F;SigNoz&#x2F;signoz">https:&#x2F;&#x2F;github.com&#x2F;SigNoz&#x2F;signoz</a></div><br/><div id="38299601" class="c"><input type="checkbox" id="c-38299601" checked=""/><div class="controls bullet"><span class="by">Jedd</span><span>|</span><a href="#38297679">root</a><span>|</span><a href="#38299055">parent</a><span>|</span><a href="#38293172">next</a><span>|</span><label class="collapse" for="c-38299601">[-]</label><label class="expand" for="c-38299601">[2 more]</label></div><br/><div class="children"><div class="content">Hi Pranay - actually I&#x27;ve had a signoz tab open for about 5 weeks - once I find time I&#x27;m meaning to run it up in my lab.</div><br/><div id="38299754" class="c"><input type="checkbox" id="c-38299754" checked=""/><div class="controls bullet"><span class="by">pranay01</span><span>|</span><a href="#38297679">root</a><span>|</span><a href="#38299601">parent</a><span>|</span><a href="#38293172">next</a><span>|</span><label class="collapse" for="c-38299754">[-]</label><label class="expand" for="c-38299754">[1 more]</label></div><br/><div class="children"><div class="content">Awesome! Do reach out to us in our slack community[1] if you have any questions or need any help on setting things up<p>[1] <a href="https:&#x2F;&#x2F;signoz.io&#x2F;slack">https:&#x2F;&#x2F;signoz.io&#x2F;slack</a></div><br/></div></div></div></div></div></div></div></div><div id="38293172" class="c"><input type="checkbox" id="c-38293172" checked=""/><div class="controls bullet"><span class="by">tapoxi</span><span>|</span><a href="#38297679">prev</a><span>|</span><a href="#38293124">next</a><span>|</span><label class="collapse" for="c-38293172">[-]</label><label class="expand" for="c-38293172">[5 more]</label></div><br/><div class="children"><div class="content">I made this switch very recently. For our Java apps it was as simple as loading the otel agent in place of the Datadog SDK, basically &quot;-javaagent:&#x2F;opt&#x2F;otel&#x2F;opentelemetry-javaagent.jar&quot; in our args.<p>The collector (which processes and ships metrics) can be installed in K8S through Helm or an operator, and we just added a variable to our charts so the agent can be pointed at the collector. The collector speaks OTLP which is the fancy combined metrics&#x2F;traces&#x2F;logs protocol the OTEL SDKs&#x2F;agents use, but it also speaks Prometheus, Zipkin, etc to give you an easy migration path. We currently ship to Datadog as well as an internal service, with the end goal being migrating off of Datadog gradually.</div><br/><div id="38293326" class="c"><input type="checkbox" id="c-38293326" checked=""/><div class="controls bullet"><span class="by">andrewstuart2</span><span>|</span><a href="#38293172">parent</a><span>|</span><a href="#38293124">next</a><span>|</span><label class="collapse" for="c-38293326">[-]</label><label class="expand" for="c-38293326">[4 more]</label></div><br/><div class="children"><div class="content">We tried this about a year and a half ago and ended up going somewhat backwards into DD entrenchment, because they&#x27;ve decided that anything not an official DD metric (that is, collected by their agent typically) is custom and then becomes substantially more expensive. We wanted a nice migration path from any vendor to any other vendor but they have a fairly effective strategy for making gradual migrations more expensive for heavy telemetry users. At least our instrumentation these days is otel, but it&#x27;s the metrics we expected to just scrape from prometheus that we had to dial back and start using more official DD agent metrics and configs to get, lest our bill balloon by 10x. It&#x27;s a frustrating place to be. Especially since it&#x27;s still not remotely cheap, just that it could be way worse.<p>I know this isn&#x27;t a DataDog post, and I&#x27;m a bit off topic, but I try to do my best to warn against DD these days.</div><br/><div id="38294128" class="c"><input type="checkbox" id="c-38294128" checked=""/><div class="controls bullet"><span class="by">shawnb576</span><span>|</span><a href="#38293172">root</a><span>|</span><a href="#38293326">parent</a><span>|</span><a href="#38294556">next</a><span>|</span><label class="collapse" for="c-38294128">[-]</label><label class="expand" for="c-38294128">[2 more]</label></div><br/><div class="children"><div class="content">This has been a concern for me too. But the agent is just a statsd receiver with some extra magic, so this seems like a thing that could be solved with the collector sending traffic to an agent rather than the HTTP APIs?<p>I looked at the OTel DD stuff and did not see any support for this, fwiw, maybe it doesn&#x27;t work b&#x2F;c the agent expects more context from the pod (e.g. app and label?)</div><br/><div id="38294574" class="c"><input type="checkbox" id="c-38294574" checked=""/><div class="controls bullet"><span class="by">andrewstuart2</span><span>|</span><a href="#38293172">root</a><span>|</span><a href="#38294128">parent</a><span>|</span><a href="#38294556">next</a><span>|</span><label class="collapse" for="c-38294574">[-]</label><label class="expand" for="c-38294574">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, the DD agent and the otel-collector DD exporter actually use the same code paths for the most part. The relevant difference tends to be in metrics, where the official path involves the DD agent doing collection directly, for example, collecting redis metrics by giving the agent your redis database hostname and creds. It can then pack those into the specific shape that DD knows about and they get sent with the right name, values, etc so that DD calls them regular metrics.<p>If you instead went the more flexible route of using many of the de-facto standard prometheus exporters like the one for redis, or built-in prometheus metrics from something like istio, and forward those to your agent or configure your agent to poll those prometheus metrics, it won&#x27;t do any reshaping (which I can see the arguments for, kinda, knowing a bit about their backend) and they just end up in the DD backend as custom metrics, and charge you at $0.10&#x2F;mo per 100 time series. If you&#x27;ve used prometheus before for any realistic deployments with enrichment etc, you can probably see this gets expensive ridiculously fast.<p>What I wish they&#x27;d do instead is have some form of adapter from those de facto standards, so I can still collect metrics 99% my own way, in a portable fashion, and then add DD as my backend without ending up as custom everything, costing significantly more.</div><br/></div></div></div></div><div id="38294556" class="c"><input type="checkbox" id="c-38294556" checked=""/><div class="controls bullet"><span class="by">xyst</span><span>|</span><a href="#38293172">root</a><span>|</span><a href="#38293326">parent</a><span>|</span><a href="#38294128">prev</a><span>|</span><a href="#38293124">next</a><span>|</span><label class="collapse" for="c-38294556">[-]</label><label class="expand" for="c-38294556">[1 more]</label></div><br/><div class="children"><div class="content">&gt; somewhat backwards into DD entrenchment, because they&#x27;ve decided that anything not an official DD metric (that is, collected by their agent typically) is custom and then becomes substantially more expensive.<p>It a vendor pulled shit like this on me. That’s when I would counsel them. Of course most big orgs would rather not do the leg work to actually become portable, migrate off vendor. So of course they will just pay the bill.<p>Vendors love the custom shit they build because they know once it’s infiltrated the stack then it’s basically like gangrene (have to cut off the appendage to save the host)</div><br/></div></div></div></div></div></div><div id="38293124" class="c"><input type="checkbox" id="c-38293124" checked=""/><div class="controls bullet"><span class="by">MajimasEyepatch</span><span>|</span><a href="#38293172">prev</a><span>|</span><a href="#38300522">next</a><span>|</span><label class="collapse" for="c-38293124">[-]</label><label class="expand" for="c-38293124">[7 more]</label></div><br/><div class="children"><div class="content">It&#x27;s interesting that you&#x27;re using both Honeycomb and Datadog. With everything migrated to OTel, would there be advantages to consolidating on just Honeycomb (or Datadog)? Have you found they&#x27;re useful for different things, or is there enough overlap that you could use just one or the other?</div><br/><div id="38293562" class="c"><input type="checkbox" id="c-38293562" checked=""/><div class="controls bullet"><span class="by">bhyolken</span><span>|</span><a href="#38293124">parent</a><span>|</span><a href="#38300522">next</a><span>|</span><label class="collapse" for="c-38293562">[-]</label><label class="expand" for="c-38293562">[6 more]</label></div><br/><div class="children"><div class="content">Author here, thanks for the question! The current split developed from the personal preferences of the engineers who initially set up our observability systems, based on what they had used (and liked) at previous jobs.<p>We&#x27;re definitely open to doing more consolidation in the future, especially if we can save money by doing that, but from a usability standpoint we&#x27;ve been pretty happy with Honeycomb for traces and Datadog for everything else so far. And, that seems to be aligned with what each vendor is best at at the moment.</div><br/><div id="38293837" class="c"><input type="checkbox" id="c-38293837" checked=""/><div class="controls bullet"><span class="by">MuffinFlavored</span><span>|</span><a href="#38293124">root</a><span>|</span><a href="#38293562">parent</a><span>|</span><a href="#38300522">next</a><span>|</span><label class="collapse" for="c-38293837">[-]</label><label class="expand" for="c-38293837">[5 more]</label></div><br/><div class="children"><div class="content">&gt;  from the personal preferences of the engineers<p><a href="https:&#x2F;&#x2F;www.honeycomb.io&#x2F;pricing" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.honeycomb.io&#x2F;pricing</a><p><a href="https:&#x2F;&#x2F;www.datadoghq.com&#x2F;pricing&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.datadoghq.com&#x2F;pricing&#x2F;</a><p>Am I wrong to say... having 2 is &quot;expensive&quot;? Maybe not if 50% of your stuff is going to Honeycomb and 50% going to DataDog. Could you save money&#x2F;complexity (less places to look for things) having just DataDog or just Honeycomb?</div><br/><div id="38293961" class="c"><input type="checkbox" id="c-38293961" checked=""/><div class="controls bullet"><span class="by">bhyolken</span><span>|</span><a href="#38293124">root</a><span>|</span><a href="#38293837">parent</a><span>|</span><a href="#38300522">next</a><span>|</span><label class="collapse" for="c-38293961">[-]</label><label class="expand" for="c-38293961">[4 more]</label></div><br/><div class="children"><div class="content">Right now, there isn&#x27;t much duplication of what we&#x27;re sending to each vendor, so I don&#x27;t think we&#x27;d save a ton by consolidating, at least based on list prices. We could maybe negotiate better prices based on higher volumes, but I&#x27;m not sure if Airplane is spending enough at this point to get massive discounts there.<p>Another potential benefit would definitely be reduced complexity and better integration for the engineering team. So, for instance, you could look at a log and then more easily navigate to the UI for the associated trace. Currently, we do this by putting Honeycomb URLs in our Datadog log events, which works but isn&#x27;t quite as seamless. But, given that our team is pretty small at this point and that we&#x27;re not spending a ton of our time on performance optimizations, we don&#x27;t feel an urgent need to consolidate (yet).</div><br/><div id="38294714" class="c"><input type="checkbox" id="c-38294714" checked=""/><div class="controls bullet"><span class="by">MuffinFlavored</span><span>|</span><a href="#38293124">root</a><span>|</span><a href="#38293961">parent</a><span>|</span><a href="#38300522">next</a><span>|</span><label class="collapse" for="c-38294714">[-]</label><label class="expand" for="c-38294714">[3 more]</label></div><br/><div class="children"><div class="content">When you say DataDog for everything else (as in not traces), besides logs, what else do you mean?</div><br/><div id="38294799" class="c"><input type="checkbox" id="c-38294799" checked=""/><div class="controls bullet"><span class="by">claytonjy</span><span>|</span><a href="#38293124">root</a><span>|</span><a href="#38294714">parent</a><span>|</span><a href="#38300522">next</a><span>|</span><label class="collapse" for="c-38294799">[-]</label><label class="expand" for="c-38294799">[2 more]</label></div><br/><div class="children"><div class="content">Metrics, probably? The article calls out logs, metrics, and traces as the 3 pillars of observability.</div><br/><div id="38295029" class="c"><input type="checkbox" id="c-38295029" checked=""/><div class="controls bullet"><span class="by">bhyolken</span><span>|</span><a href="#38293124">root</a><span>|</span><a href="#38294799">parent</a><span>|</span><a href="#38300522">next</a><span>|</span><label class="collapse" for="c-38295029">[-]</label><label class="expand" for="c-38295029">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, metrics and logs, plus a few other things that depend on these (alerts, SLOs, metric-based dashboards, etc.).</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="38300522" class="c"><input type="checkbox" id="c-38300522" checked=""/><div class="controls bullet"><span class="by">nullify88</span><span>|</span><a href="#38293124">prev</a><span>|</span><a href="#38295511">next</a><span>|</span><label class="collapse" for="c-38300522">[-]</label><label class="expand" for="c-38300522">[1 more]</label></div><br/><div class="children"><div class="content">One thing that&#x27;s slightly off putting about OpenTelemetry is how resource attributes don&#x27;t get included as prometheus labels for metrics, instead they are on an info metric which requires a join to enrich the metric you are interested in.<p>Luckily the prometheus exporters have a switch to enable this behaviour, but there&#x27;s talk of removing this functionality because it breaks the spec. If you were to use the OpenTelemetry protocol in to something like Mimir, you don&#x27;t have the option  of enabling that behaviour unless you use prometheus remote write.<p>Our developers aren&#x27;t a fan of that.<p><a href="https:&#x2F;&#x2F;opentelemetry.io&#x2F;docs&#x2F;specs&#x2F;otel&#x2F;compatibility&#x2F;prometheus_and_openmetrics&#x2F;#resource-attributes-1" rel="nofollow noreferrer">https:&#x2F;&#x2F;opentelemetry.io&#x2F;docs&#x2F;specs&#x2F;otel&#x2F;compatibility&#x2F;prome...</a></div><br/></div></div><div id="38295511" class="c"><input type="checkbox" id="c-38295511" checked=""/><div class="controls bullet"><span class="by">nevon</span><span>|</span><a href="#38300522">prev</a><span>|</span><a href="#38294409">next</a><span>|</span><label class="collapse" for="c-38295511">[-]</label><label class="expand" for="c-38295511">[4 more]</label></div><br/><div class="children"><div class="content">I would love to save a few hundred thousands a year by running Otel collector over Datadog agents, just on the cost-per-host alone. Unfortunately that would also mean giving up Datatog APM and NPM, as far as I can tell, which have been really valuable. Going back to just metrics and traces would feel like quite the step backwards and be a hard sell.</div><br/><div id="38296821" class="c"><input type="checkbox" id="c-38296821" checked=""/><div class="controls bullet"><span class="by">arccy</span><span>|</span><a href="#38295511">parent</a><span>|</span><a href="#38294409">next</a><span>|</span><label class="collapse" for="c-38296821">[-]</label><label class="expand" for="c-38296821">[3 more]</label></div><br/><div class="children"><div class="content">you can submit opentelemetry traces to datadog which should be the equivalent of apm&#x2F;npm, though maybe with a less polished integration.</div><br/><div id="38300103" class="c"><input type="checkbox" id="c-38300103" checked=""/><div class="controls bullet"><span class="by">nevon</span><span>|</span><a href="#38295511">root</a><span>|</span><a href="#38296821">parent</a><span>|</span><a href="#38294409">next</a><span>|</span><label class="collapse" for="c-38300103">[-]</label><label class="expand" for="c-38300103">[2 more]</label></div><br/><div class="children"><div class="content">Just traces are a long way off from APM and NPM. APM gives me the ability to debug memory leaks from continuous heap snapshots, or performance issues through CPU profiling. NPM is almost like having tcpdump running constantly, showing me where there&#x27;s packet loss or other forms of connectivity issues.</div><br/><div id="38300534" class="c"><input type="checkbox" id="c-38300534" checked=""/><div class="controls bullet"><span class="by">porker</span><span>|</span><a href="#38295511">root</a><span>|</span><a href="#38300103">parent</a><span>|</span><a href="#38294409">next</a><span>|</span><label class="collapse" for="c-38300534">[-]</label><label class="expand" for="c-38300534">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for sharing this, I&#x27;ve had &quot;look at tracing&quot; on my to do list for months and assumed it was identical to APM. It seems it won&#x27;t be a direct substitute, which helps explain the cost difference.</div><br/></div></div></div></div></div></div></div></div><div id="38294409" class="c"><input type="checkbox" id="c-38294409" checked=""/><div class="controls bullet"><span class="by">roskilli</span><span>|</span><a href="#38295511">prev</a><span>|</span><a href="#38293056">next</a><span>|</span><label class="collapse" for="c-38294409">[-]</label><label class="expand" for="c-38294409">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Moreover, we encountered some rough edges in the metrics-related functionality of the Go SDK referenced above. Ultimately, we had to write a conversion layer on top of the OTel metrics API that allowed for simple, Prometheus-like counters, gauges, and histograms.<p>Have encountered this a lot from teams attempting to use the metrics SDK.<p>Are you open to comment on specifics here and also what kind of shim you had to put in front of the SDK? It would be great to continue to retrieve feedback so that we can as a community have a good idea of what remains before it&#x27;s possible to use the SDK for real world production use cases in anger. Just wiring up the setup in your app used to be fairly painful but that has gotten somewhat better over the last 12-24 months, I&#x27;d love to also hear what is currently causing compatibility issues w&#x2F; the metric types themselves using the SDK which requires a shim and what the shim is doing to achieve compatibility.</div><br/><div id="38294981" class="c"><input type="checkbox" id="c-38294981" checked=""/><div class="controls bullet"><span class="by">bhyolken</span><span>|</span><a href="#38294409">parent</a><span>|</span><a href="#38293056">next</a><span>|</span><label class="collapse" for="c-38294981">[-]</label><label class="expand" for="c-38294981">[3 more]</label></div><br/><div class="children"><div class="content">Sure, happy to provide more specifics!<p>Our main issue was the lack of a synchronous gauge. The officially supported asynchronous API of registering a callback function to report a gauge metric is very different from how we were doing things before, and would have required lots of refactoring of our code. Instead, we wrote a wrapper that exposes a synchronous-like API: <a href="https:&#x2F;&#x2F;gist.github.com&#x2F;yolken-airplane&#x2F;027867b753840f7d15d622be793f57bb" rel="nofollow noreferrer">https:&#x2F;&#x2F;gist.github.com&#x2F;yolken-airplane&#x2F;027867b753840f7d15d6...</a>.<p>It seems like this is a common feature request across many of the SDKs, and it&#x27;s in the process of being fixed in some of them (<a href="https:&#x2F;&#x2F;github.com&#x2F;open-telemetry&#x2F;opentelemetry-specification&#x2F;issues&#x2F;2318">https:&#x2F;&#x2F;github.com&#x2F;open-telemetry&#x2F;opentelemetry-specificatio...</a>)? I&#x27;m not sure what the plans are for the golang SDK specifically.<p>Another, more minor issue, is the lack of support for &quot;constant&quot; attributes that are applied to all observations of a metric. We use these to identify the app, among other use cases, so we added wrappers around the various &quot;Add&quot;, &quot;Record&quot;, &quot;Observe&quot;, etc. calls that automatically add these. (It&#x27;s totally possible that this is supported and I missed it, in which case please let me know.)<p>Overall, the SDK was generally well-written and well-documented, we just needed some extra work to make the interfaces more similar to the ones we were using before.</div><br/><div id="38298658" class="c"><input type="checkbox" id="c-38298658" checked=""/><div class="controls bullet"><span class="by">roskilli</span><span>|</span><a href="#38294409">root</a><span>|</span><a href="#38294981">parent</a><span>|</span><a href="#38296725">next</a><span>|</span><label class="collapse" for="c-38298658">[-]</label><label class="expand" for="c-38298658">[1 more]</label></div><br/><div class="children"><div class="content">Thanks for the detailed response.<p>I am surprised there is no gauge update API yet (instead of callback only), this is a common use case and I don&#x27;t think folks should be expected to implement their own. Especially since it will lead to potentially allocation heavy bespoke implementations, depending on use case given mutex+callback+other structures that likely need to be heap allocated (vs a simple int64 wrapper with atomic update&#x2F;load APIs).<p>Also I would just say that the fact the APIs differ a lot to more common popular Prometheus client libraries does beg the question of do we need more complicated APIs that folks have a harder time using. Now is the time to modernize these before everyone is instrumented with some generation of a client library that would need to change&#x2F;evolve. The whole idea of an OTel SDK is instrument once and then avoid needing to re-instrument again when making changes to your observability pipeline and where it&#x27;s pointed. This becomes a hard sell if OTel SDK needs to shift fairly significantly to support more popular &amp; common use cases with more typical APIs and by doing so leaves a whole bunch of OTel instrumented code that needs to be modernized to a different looking API.</div><br/></div></div><div id="38296725" class="c"><input type="checkbox" id="c-38296725" checked=""/><div class="controls bullet"><span class="by">arccy</span><span>|</span><a href="#38294409">root</a><span>|</span><a href="#38294981">parent</a><span>|</span><a href="#38298658">prev</a><span>|</span><a href="#38293056">next</a><span>|</span><label class="collapse" for="c-38296725">[-]</label><label class="expand" for="c-38296725">[1 more]</label></div><br/><div class="children"><div class="content">the official SDKs will only support an api once there&#x27;s a spec that allows it.<p>for const attributes, generally these should be defined at the resource &#x2F; provider level: <a href="https:&#x2F;&#x2F;pkg.go.dev&#x2F;go.opentelemetry.io&#x2F;otel&#x2F;sdk&#x2F;metric#WithResource" rel="nofollow noreferrer">https:&#x2F;&#x2F;pkg.go.dev&#x2F;go.opentelemetry.io&#x2F;otel&#x2F;sdk&#x2F;metric#WithR...</a></div><br/></div></div></div></div></div></div><div id="38293056" class="c"><input type="checkbox" id="c-38293056" checked=""/><div class="controls bullet"><span class="by">caust1c</span><span>|</span><a href="#38294409">prev</a><span>|</span><a href="#38296565">next</a><span>|</span><label class="collapse" for="c-38293056">[-]</label><label class="expand" for="c-38293056">[3 more]</label></div><br/><div class="children"><div class="content">Curious about the code implemented for logs!  Hopefully that&#x27;s something that can be shared at some point.  Also curious if it integrates with `log&#x2F;slog` :-)<p>Congrats too!  As I understand it from stories I&#x27;ve heard from others, migrating to OTel is no easy undertaking.</div><br/><div id="38293763" class="c"><input type="checkbox" id="c-38293763" checked=""/><div class="controls bullet"><span class="by">bhyolken</span><span>|</span><a href="#38293056">parent</a><span>|</span><a href="#38296565">next</a><span>|</span><label class="collapse" for="c-38293763">[-]</label><label class="expand" for="c-38293763">[2 more]</label></div><br/><div class="children"><div class="content">Thanks! For logs, we actually use github.com&#x2F;segmentio&#x2F;events and just implemented a handler for that library that batches logs and periodically flushes them out to our collector using the underlying protocol buffer interface. We plan on migrating to log&#x2F;slog soon, and once we do that we&#x27;ll adapt our handler and can share the code.</div><br/><div id="38293877" class="c"><input type="checkbox" id="c-38293877" checked=""/><div class="controls bullet"><span class="by">caust1c</span><span>|</span><a href="#38293056">root</a><span>|</span><a href="#38293763">parent</a><span>|</span><a href="#38296565">next</a><span>|</span><label class="collapse" for="c-38293877">[-]</label><label class="expand" for="c-38293877">[1 more]</label></div><br/><div class="children"><div class="content">Awesome!  Great work and thanks for sharing your experience!</div><br/></div></div></div></div></div></div><div id="38296565" class="c"><input type="checkbox" id="c-38296565" checked=""/><div class="controls bullet"><span class="by">shoelessone</span><span>|</span><a href="#38293056">prev</a><span>|</span><a href="#38296485">next</a><span>|</span><label class="collapse" for="c-38296565">[-]</label><label class="expand" for="c-38296565">[3 more]</label></div><br/><div class="children"><div class="content">I really really want to use OTel for a small project but have always had a really tough time finding a path that is cheap or free for a personal project.<p>In theory you can send telemetry data with OTel to Cloud Watch, but I&#x27;ve struggle to connect the dots with the front end application (e.g. React&#x2F;Next.js).</div><br/><div id="38296796" class="c"><input type="checkbox" id="c-38296796" checked=""/><div class="controls bullet"><span class="by">arccy</span><span>|</span><a href="#38296565">parent</a><span>|</span><a href="#38297411">next</a><span>|</span><label class="collapse" for="c-38296796">[-]</label><label class="expand" for="c-38296796">[1 more]</label></div><br/><div class="children"><div class="content">grafana cloud, honeycomb, etc have free tiers, though you&#x27;ll have to watch how much data you send them.
or you can self host something like signoz or the elastic stack.
frontend will typically go to an instance of opentelemetry collector to filter&#x2F;convert to the protocol for the storage backend.</div><br/></div></div><div id="38297411" class="c"><input type="checkbox" id="c-38297411" checked=""/><div class="controls bullet"><span class="by">yourapostasy</span><span>|</span><a href="#38296565">parent</a><span>|</span><a href="#38296796">prev</a><span>|</span><a href="#38296485">next</a><span>|</span><label class="collapse" for="c-38297411">[-]</label><label class="expand" for="c-38297411">[1 more]</label></div><br/><div class="children"><div class="content">Have you checked out Jaeger [1]? It is lightweight enough for a personal project, open source, and featureful enough to really help &quot;turn on the lightbulb&quot; with other engineers to show them the difference between logging&#x2F;monitoring and tracing.<p>[1] <a href="https:&#x2F;&#x2F;www.jaegertracing.io&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;www.jaegertracing.io&#x2F;</a></div><br/></div></div></div></div><div id="38296485" class="c"><input type="checkbox" id="c-38296485" checked=""/><div class="controls bullet"><span class="by">throwaway084t95</span><span>|</span><a href="#38296565">prev</a><span>|</span><a href="#38294396">next</a><span>|</span><label class="collapse" for="c-38296485">[-]</label><label class="expand" for="c-38296485">[2 more]</label></div><br/><div class="children"><div class="content">What is the &quot;first principles&quot; argument that observability decomposes into logs, metrics, and tracing?  I see this dogma accepted everywhere, but I&#x27;m inquisitive about it</div><br/><div id="38296692" class="c"><input type="checkbox" id="c-38296692" checked=""/><div class="controls bullet"><span class="by">yannyu</span><span>|</span><a href="#38296485">parent</a><span>|</span><a href="#38294396">next</a><span>|</span><label class="collapse" for="c-38296692">[-]</label><label class="expand" for="c-38296692">[1 more]</label></div><br/><div class="children"><div class="content">First you had logs. Everyone uses logs because it&#x27;s easy. Logs are great, but suddenly you&#x27;re spending a crapton of time or money maintaining terabytes or petabytes of storage and ingest of logs. And even worse, in some cases for these logs, you don&#x27;t actually care about 99% of the log line and simply want a single number, such as CPU utilization or the value of the shopping cart or latency.<p>So, someone says, &quot;let&#x27;s make something smaller and more portable than logs. We need to track numerical data over time more easily, so that we can see pretty charts of when these values are outside of where they should be.&quot; This ends up being metrics and a time-series database (TSDB), built to handle not arbitrary lines of text but instead meant to parse out metadata and append numerical data to existing time-series based on that metadata.<p>Between metrics and logs, you end up with a good idea of what&#x27;s going on with your infrastructure, but logs are still too verbose to understand what&#x27;s happening with your applications past a certain point. If you have an application crashing repeatedly, or if you&#x27;ve got applications running slowly, metrics and logs can&#x27;t really help you there. So companies built out Application Performance Monitoring, meant to tap directly into the processes running on the box and spit out all sorts of interesting runtime metrics and events about not just the applications, but the specific methods and calls those applications are utilizing within their stack&#x2F;code.<p>Initially, this works great if you&#x27;re running these APM tools on a single box within monolithic stacks, but as the world moved toward Cloud Service Providers and containerized&#x2F;ephemeral infrastructure, APM stopped being as effective. When a transaction starts to go through multiple machines and microservices, APM deployed on those boxes individually can&#x27;t give you the context of how these disparate calls relate to a holistic transaction.<p>So someone says, &quot;hey, what if we include transaction IDs in these service calls, so that we can post-hoc stitch together these individual transaction lines into a whole transaction, end-to-end?&quot; Which is how you end up with the concept of spans and traces, taking what worked well with Application Performance Monitoring and generalizing that out into the modern microservices architectures that are more common today.</div><br/></div></div></div></div><div id="38294396" class="c"><input type="checkbox" id="c-38294396" checked=""/><div class="controls bullet"><span class="by">tsamba</span><span>|</span><a href="#38296485">prev</a><span>|</span><a href="#38293308">next</a><span>|</span><label class="collapse" for="c-38294396">[-]</label><label class="expand" for="c-38294396">[3 more]</label></div><br/><div class="children"><div class="content">Interesting read. What did you find easier about using GCP&#x27;s log tooling for your internal system logs, rather than the OTel collector?</div><br/><div id="38298216" class="c"><input type="checkbox" id="c-38298216" checked=""/><div class="controls bullet"><span class="by">bhyolken</span><span>|</span><a href="#38294396">parent</a><span>|</span><a href="#38297876">next</a><span>|</span><label class="collapse" for="c-38298216">[-]</label><label class="expand" for="c-38298216">[1 more]</label></div><br/><div class="children"><div class="content">Author here. This decision was more about ease of implementation than anything else. Our internal application logs were already being scooped up by GCP because we run our services in GKE, and we already had a GCP-&gt;Datadog log syncer [1] for some other GCP infra logs, so re-using the GCP-based pipeline was the easiest way
to handle our application logs once we removed the Datadog agent.<p>In the future, we&#x27;ll probably switch these logs to also go through our collector, and it shouldn&#x27;t be super hard (because we already implemented a golang OTel log handler for the external case), but we just haven&#x27;t gotten around to it yet.<p>[1] <a href="https:&#x2F;&#x2F;docs.datadoghq.com&#x2F;integrations&#x2F;google_cloud_platform&#x2F;#log-collection" rel="nofollow noreferrer">https:&#x2F;&#x2F;docs.datadoghq.com&#x2F;integrations&#x2F;google_cloud_platfor...</a></div><br/></div></div><div id="38297876" class="c"><input type="checkbox" id="c-38297876" checked=""/><div class="controls bullet"><span class="by">clintonb</span><span>|</span><a href="#38294396">parent</a><span>|</span><a href="#38298216">prev</a><span>|</span><a href="#38293308">next</a><span>|</span><label class="collapse" for="c-38297876">[-]</label><label class="expand" for="c-38297876">[1 more]</label></div><br/><div class="children"><div class="content">Their collector is used to send infrastructure logs to GCP (instead of Datadog).<p>My guess is this is to save on costs. GCP logging is probably cheaper than Datadog, and infrastructure logs may not be needed as frequently as application logs.</div><br/></div></div></div></div><div id="38293308" class="c"><input type="checkbox" id="c-38293308" checked=""/><div class="controls bullet"><span class="by">k__</span><span>|</span><a href="#38294396">prev</a><span>|</span><label class="collapse" for="c-38293308">[-]</label><label class="expand" for="c-38293308">[5 more]</label></div><br/><div class="children"><div class="content">I had the impression, logs and metrics are a pre-observability thing.</div><br/><div id="38293911" class="c"><input type="checkbox" id="c-38293911" checked=""/><div class="controls bullet"><span class="by">SteveNuts</span><span>|</span><a href="#38293308">parent</a><span>|</span><a href="#38294856">next</a><span>|</span><label class="collapse" for="c-38293911">[-]</label><label class="expand" for="c-38293911">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never heard the term &quot;pre-observability&quot;, what does that mean?</div><br/><div id="38294166" class="c"><input type="checkbox" id="c-38294166" checked=""/><div class="controls bullet"><span class="by">renegade-otter</span><span>|</span><a href="#38293308">root</a><span>|</span><a href="#38293911">parent</a><span>|</span><a href="#38294856">next</a><span>|</span><label class="collapse" for="c-38294166">[-]</label><label class="expand" for="c-38294166">[1 more]</label></div><br/><div class="children"><div class="content">The era when &quot;debugging in production&quot; wasn&#x27;t standard.</div><br/></div></div></div></div><div id="38294856" class="c"><input type="checkbox" id="c-38294856" checked=""/><div class="controls bullet"><span class="by">marcosdumay</span><span>|</span><a href="#38293308">parent</a><span>|</span><a href="#38293911">prev</a><span>|</span><label class="collapse" for="c-38294856">[-]</label><label class="expand" for="c-38294856">[2 more]</label></div><br/><div class="children"><div class="content">Observability is about logs and metrics, and pre-observability (I guess you mean the high-level-only records simpler environments keep) is also about logs and metrics.<p>Anything you register to keep track of your environment has the form of either logs or metrics. The difference is about the contents of such logs and metrics.</div><br/><div id="38301078" class="c"><input type="checkbox" id="c-38301078" checked=""/><div class="controls bullet"><span class="by">k__</span><span>|</span><a href="#38293308">root</a><span>|</span><a href="#38294856">parent</a><span>|</span><label class="collapse" for="c-38301078">[-]</label><label class="expand" for="c-38301078">[1 more]</label></div><br/><div class="children"><div class="content">When I read Observability Engineering, I got the impression it was about long events and tracing, and metrics and logs were a thing of the past people gave up on since the rise of Microservices.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>