<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1703754056152" as="style"/><link rel="stylesheet" href="styles.css?v=1703754056152"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://arstechnica.com/tech-policy/2023/12/ny-times-sues-open-ai-microsoft-over-copyright-infringement/">NY Times copyright suit wants OpenAI to delete all GPT instances</a> <span class="domain">(<a href="https://arstechnica.com">arstechnica.com</a>)</span></div><div class="subtext"><span>justinc8687</span> | <span>159 comments</span></div><br/><div><div id="38791211" class="c"><input type="checkbox" id="c-38791211" checked=""/><div class="controls bullet"><span class="by">rich_sasha</span><span>|</span><a href="#38790737">next</a><span>|</span><label class="collapse" for="c-38791211">[-]</label><label class="expand" for="c-38791211">[10 more]</label></div><br/><div class="children"><div class="content">If you forget about the LLM aspect, and simply build a product out of (legally) scraped NYT articles, is that fair use?<p>Let&#x27;s say I host these, offer some indexing on it, and rewrite articles. Something like, summarise all articles on US-UK relationships over past 5 years. I charge money for it, and all I pay NYT is a monthly subscription fee. To keep things simple, let&#x27;s say I never regurgitate chunks of verbatim NYT articles, maybe quite short snippets.<p>Is that fair use? IANAL, but doesn&#x27;t sound like it. Typically I can&#x27;t take a personal &quot;tier&quot; of a product and charge 3rd parties for derivatives of it. Say like VS Code.<p>A sibling comment mentions search engines. I think there&#x27;s a big difference. A search engine doesn&#x27;t replace the source, not at all. Rather it points me at it, and offers me the opportunity to pay for the article. Whereas either this or an LLM uses NYT content as an alternative to actually paying for an NYT subscription.<p>But then what do I know...</div><br/><div id="38791376" class="c"><input type="checkbox" id="c-38791376" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#38791211">parent</a><span>|</span><a href="#38791295">next</a><span>|</span><label class="collapse" for="c-38791376">[-]</label><label class="expand" for="c-38791376">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Typically I can&#x27;t take a personal &quot;tier&quot; of a product and charge 3rd parties for derivatives of it. Say like VS Code.</i><p>Can&#x27;t you, though? I&#x27;d thought in general, it&#x27;s a very important for the market to be able to do just that, otherwise everything gets gummed up in webs of exclusive contractual dependencies between established companies.</div><br/><div id="38791444" class="c"><input type="checkbox" id="c-38791444" checked=""/><div class="controls bullet"><span class="by">rich_sasha</span><span>|</span><a href="#38791211">root</a><span>|</span><a href="#38791376">parent</a><span>|</span><a href="#38791295">next</a><span>|</span><label class="collapse" for="c-38791444">[-]</label><label class="expand" for="c-38791444">[1 more]</label></div><br/><div class="children"><div class="content">As I say, I don&#x27;t really know. But then, this is exactly how SaaS licensing works. There may even be a free personal tier, where you can&#x27;t sell products based on it, and a professional tier which may be very expensive indeed.<p>Typically providers of online databases go to some effort to stop people from sharing logins. Even from that point or view, I can imagine scraping articles and providing paraphrases of it for a fee is fishy.<p>All I&#x27;m saying, to some people it&#x27;s obvious that the whole LLM on scraped Internet is fair use, to me it is not obvious.</div><br/></div></div></div></div><div id="38791295" class="c"><input type="checkbox" id="c-38791295" checked=""/><div class="controls bullet"><span class="by">heavyset_go</span><span>|</span><a href="#38791211">parent</a><span>|</span><a href="#38791376">prev</a><span>|</span><a href="#38791407">next</a><span>|</span><label class="collapse" for="c-38791295">[-]</label><label class="expand" for="c-38791295">[3 more]</label></div><br/><div class="children"><div class="content">Another factor to consider is that neural nets can function as lossy compression, which becomes extremely evident when using models that are overfit.<p>Sometimes they&#x27;re so overfit that the compression isn&#x27;t even lossy, and the data is encoded verbatim in the NN.</div><br/><div id="38791347" class="c"><input type="checkbox" id="c-38791347" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#38791211">root</a><span>|</span><a href="#38791295">parent</a><span>|</span><a href="#38791407">next</a><span>|</span><label class="collapse" for="c-38791347">[-]</label><label class="expand" for="c-38791347">[2 more]</label></div><br/><div class="children"><div class="content">Yes, but this then hits against learning&#x2F;understanding and compression being <i>fundamentally the same thing</i>. I can&#x27;t think of a better way to argue in favor of &quot;it&#x27;s fine if human does it, therefore it&#x27;s fine if LLM does it&quot;, than from the &quot;lossy compression&quot; angle.</div><br/><div id="38791467" class="c"><input type="checkbox" id="c-38791467" checked=""/><div class="controls bullet"><span class="by">RandomLensman</span><span>|</span><a href="#38791211">root</a><span>|</span><a href="#38791347">parent</a><span>|</span><a href="#38791407">next</a><span>|</span><label class="collapse" for="c-38791467">[-]</label><label class="expand" for="c-38791467">[1 more]</label></div><br/><div class="children"><div class="content">We can have different rules for humans than for machines. In fact, that happens all the time.</div><br/></div></div></div></div></div></div><div id="38791407" class="c"><input type="checkbox" id="c-38791407" checked=""/><div class="controls bullet"><span class="by">px43</span><span>|</span><a href="#38791211">parent</a><span>|</span><a href="#38791295">prev</a><span>|</span><a href="#38791225">next</a><span>|</span><label class="collapse" for="c-38791407">[-]</label><label class="expand" for="c-38791407">[2 more]</label></div><br/><div class="children"><div class="content">From what I can tell, this has nothing to do with LLMs at all. In the example in the article, the user is asking Bing to go fetch the contents of an article directly from the website, and print it out, which it dutifully does.<p>Seems like the &quot;problem&quot; is that NYT etc gives privileged access to search engines for indexing their content, but then get upset when snippets of the indexed content is being shown to users without the users having to fight the paywall or whatever.<p>This article also claims that the screenshot is coming from ChatGPT when it clearly is not.</div><br/><div id="38791455" class="c"><input type="checkbox" id="c-38791455" checked=""/><div class="controls bullet"><span class="by">rich_sasha</span><span>|</span><a href="#38791211">root</a><span>|</span><a href="#38791407">parent</a><span>|</span><a href="#38791225">next</a><span>|</span><label class="collapse" for="c-38791455">[-]</label><label class="expand" for="c-38791455">[1 more]</label></div><br/><div class="children"><div class="content">I suppose that&#x27;s a relatively easy thing to fix, technically. It proves, however, that th underlying LLM is trained on copyrighted data.<p>I&#x27;m not sure the problem goes away simply if the LLM in question (or any other one) gets some &quot;no verbose regurgitation&quot; filter.</div><br/></div></div></div></div><div id="38791225" class="c"><input type="checkbox" id="c-38791225" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#38791211">parent</a><span>|</span><a href="#38791407">prev</a><span>|</span><a href="#38790737">next</a><span>|</span><label class="collapse" for="c-38791225">[-]</label><label class="expand" for="c-38791225">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Something like, summarise all articles on US-UK relationships over past 5 years. I charge money for it, and all I pay NYT is a monthly subscription fee.<p>&gt;Is that fair use? IANAL, but doesn&#x27;t sound like it.<p>If you pay someone to do the summarisation for you, then you publish the content and charge a fee for it, you&#x27;re the one liable, not the person you paid to summarise it for you. Similarly if you ask GPT to do it for you, then publish it, you&#x27;re liable for what you publish; GPT is just a summarisation tool.</div><br/><div id="38791305" class="c"><input type="checkbox" id="c-38791305" checked=""/><div class="controls bullet"><span class="by">rich_sasha</span><span>|</span><a href="#38791211">root</a><span>|</span><a href="#38791225">parent</a><span>|</span><a href="#38790737">next</a><span>|</span><label class="collapse" for="c-38791305">[-]</label><label class="expand" for="c-38791305">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not the example. Here I proactively scrape NYT, summarise articles for a fee and sell that as a service. It&#x27;s not people coming to me with some articles to summarise, and maybe then publishing it online.<p>At some level it becomes a subversion of NYTs fees. First, say I subscribe and simply host the articles verbatim, for a fee. Clearly, that&#x27;s not right.<p>Suppose I change some spelling or word order, or use a synonym or two. That&#x27;s still not ok.<p>And if I substantially paraphrase the articles? I guess this is the relevant case. This is kind of what LLMs do. And also feels like not fair use.</div><br/></div></div></div></div></div></div><div id="38790737" class="c"><input type="checkbox" id="c-38790737" checked=""/><div class="controls bullet"><span class="by">groceryheist</span><span>|</span><a href="#38791211">prev</a><span>|</span><a href="#38790608">next</a><span>|</span><label class="collapse" for="c-38790737">[-]</label><label class="expand" for="c-38790737">[26 more]</label></div><br/><div class="children"><div class="content">The suit demonstrates instances where ChatGTP &#x2F; Bing Copilot copy from the NYT verbatim.  I think it is hard to argue that such copying constitutes &quot;fair use&quot;.  
However, OAI&#x2F;MS should be able to fix this within the current paradigm: Just learn to recognize and punish plagiarism via RLHF.<p>However, the suit goes far beyond claiming that such copying violates their copyright: &quot;Unauthorized copying of Times Works without payment to train LLMs is a substitutive use that is not justified by any transformative purpose.&quot;<p>This is a strong claim that just downloading articles into training data is what violates the copyright. That GTP outputs verbatim copies is a red herring. Hopefully the judge(s) will notice and direct focus on the interesting, high-stakes, and murky legal issues raised when we ask: What about a model can (or can&#x27;t) be &quot;transformative&quot;?</div><br/><div id="38791026" class="c"><input type="checkbox" id="c-38791026" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38790737">parent</a><span>|</span><a href="#38791203">next</a><span>|</span><label class="collapse" for="c-38791026">[-]</label><label class="expand" for="c-38791026">[9 more]</label></div><br/><div class="children"><div class="content">&gt; Just learn to recognize and punish plagiarism via RLHF.<p>This is not a RLHF problem. What I was expecting them to do is to keep a bloom filter of ngrams for known copyrighted content, such as enumerating all sets of n=7 consecutive words in an article, and validate against it. The model would only output at maximum n-1 words that look verbatim from the source.<p>But this will blow up in their face. Let&#x27;s see:<p>- AI companies will start investing much more in content attribution<p>- The new content attribution tools will be applied on all human written articles as well, because anyone could be using GPT in secret<p>- Then people will start seeing a chilling effect on creativity<p>- We must also check NYT against all the other sources, not everything the write is original</div><br/><div id="38791088" class="c"><input type="checkbox" id="c-38791088" checked=""/><div class="controls bullet"><span class="by">groceryheist</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791026">parent</a><span>|</span><a href="#38791203">next</a><span>|</span><label class="collapse" for="c-38791088">[-]</label><label class="expand" for="c-38791088">[8 more]</label></div><br/><div class="children"><div class="content">Maybe the bloom filter solution is enough, but I wonder.<p>- Paraphrasing n=7 words (and quite a few more) within a sentence can easily be fair use.<p>- As n gets big, the bloom filter has to also.<p>If&#x2F;when attribution is solved for LLMs (and not fake attribution like from Bing or Perplexity) then creators can be compensated when their works are used in AI outputs.  If compensation is high enough this can greatly incentivize creativity, perhaps to the point of realizing &quot;free culture&quot; visions from the late 90s.</div><br/><div id="38791302" class="c"><input type="checkbox" id="c-38791302" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791088">parent</a><span>|</span><a href="#38791156">next</a><span>|</span><label class="collapse" for="c-38791302">[-]</label><label class="expand" for="c-38791302">[3 more]</label></div><br/><div class="children"><div class="content">&gt; if compensation is high enough<p>Who pays the compensation?
If it&#x27;s the user, why wouldn&#x27;t they just buy the authors work directly? Why go through the LLM middleman?</div><br/><div id="38791468" class="c"><input type="checkbox" id="c-38791468" checked=""/><div class="controls bullet"><span class="by">starttoaster</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791302">parent</a><span>|</span><a href="#38791321">next</a><span>|</span><label class="collapse" for="c-38791468">[-]</label><label class="expand" for="c-38791468">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If it&#x27;s the user, why wouldn&#x27;t they just buy the authors work directly? Why go through the LLM middleman?<p>If it&#x27;s the user, why wouldn&#x27;t they just buy the DVDs directly? Why go through the Netflix middleman?</div><br/></div></div><div id="38791321" class="c"><input type="checkbox" id="c-38791321" checked=""/><div class="controls bullet"><span class="by">groceryheist</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791302">parent</a><span>|</span><a href="#38791468">prev</a><span>|</span><a href="#38791156">next</a><span>|</span><label class="collapse" for="c-38791321">[-]</label><label class="expand" for="c-38791321">[1 more]</label></div><br/><div class="children"><div class="content">The LLM users&#x2F;middlemen pay.  The user probably pays less than they would have to pay the author.  The LMM provides information retrieval &#x2F; discovery.</div><br/></div></div></div></div><div id="38791156" class="c"><input type="checkbox" id="c-38791156" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791088">parent</a><span>|</span><a href="#38791302">prev</a><span>|</span><a href="#38791203">next</a><span>|</span><label class="collapse" for="c-38791156">[-]</label><label class="expand" for="c-38791156">[4 more]</label></div><br/><div class="children"><div class="content">As n-gram length grows, we are still going to have the same number of ngrams, they go through a hashing function and indexed in the bloom filter as usual. The number of n-grams size n in a text is text_length - ngram_length + 1.</div><br/><div id="38791281" class="c"><input type="checkbox" id="c-38791281" checked=""/><div class="controls bullet"><span class="by">groceryheist</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791156">parent</a><span>|</span><a href="#38791203">next</a><span>|</span><label class="collapse" for="c-38791281">[-]</label><label class="expand" for="c-38791281">[3 more]</label></div><br/><div class="children"><div class="content">The number of <i>unique</i> values in the bloom filter will go up ~exponentially with n. So to control the false positive rate the bloom filter has to grow.</div><br/><div id="38791335" class="c"><input type="checkbox" id="c-38791335" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791281">parent</a><span>|</span><a href="#38791203">next</a><span>|</span><label class="collapse" for="c-38791335">[-]</label><label class="expand" for="c-38791335">[2 more]</label></div><br/><div class="children"><div class="content">At large enough ngram size there would be very few collisions. You can take for example this text and try in Google with quotes, it won&#x27;t find anything matching exactly.<p>I tested this 6-gram &quot;it won&#x27;t find anything matching exactly&quot;, no match. Almost anything we write has never been said exactly like that before.</div><br/><div id="38791408" class="c"><input type="checkbox" id="c-38791408" checked=""/><div class="controls bullet"><span class="by">groceryheist</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791335">parent</a><span>|</span><a href="#38791203">next</a><span>|</span><label class="collapse" for="c-38791408">[-]</label><label class="expand" for="c-38791408">[1 more]</label></div><br/><div class="children"><div class="content">Yes and the fact that the number of unique phrases grows so quickly with n is why the bloom filter needs to grow so that hashed n-grams don&#x27;t collide.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="38791203" class="c"><input type="checkbox" id="c-38791203" checked=""/><div class="controls bullet"><span class="by">JumpCrisscross</span><span>|</span><a href="#38790737">parent</a><span>|</span><a href="#38791026">prev</a><span>|</span><a href="#38791093">next</a><span>|</span><label class="collapse" for="c-38791203">[-]</label><label class="expand" for="c-38791203">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>Just learn to recognize and punish plagiarism via RLHF</i><p>OpenAI has created a $100bn company on this transfer. The <i>Times</i> may have an interest in a material fraction of that wealth.</div><br/></div></div><div id="38791093" class="c"><input type="checkbox" id="c-38791093" checked=""/><div class="controls bullet"><span class="by">jahewson</span><span>|</span><a href="#38790737">parent</a><span>|</span><a href="#38791203">prev</a><span>|</span><a href="#38791154">next</a><span>|</span><label class="collapse" for="c-38791093">[-]</label><label class="expand" for="c-38791093">[5 more]</label></div><br/><div class="children"><div class="content">Many instances of fair use involve verbatim copying. The important questions surround the situation in which that happens - not so much the copying. NYT is in uncharted territory here.</div><br/><div id="38791153" class="c"><input type="checkbox" id="c-38791153" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791093">parent</a><span>|</span><a href="#38791154">next</a><span>|</span><label class="collapse" for="c-38791153">[-]</label><label class="expand" for="c-38791153">[4 more]</label></div><br/><div class="children"><div class="content">in the same way that machines are not able to claim copyright, they aren&#x27;t allowed to claim other legal rights either, like &quot;fair use&quot;.<p>The entity which owns ChatGPT is apparently maintaining a copy of the entirety of the New York Times archive within the ChatGPT knowledge base. That they extract some fair use snippets (they would claim) from it would still be fruit of a poisoned tree, no?<p>(disclaimer: I&#x27;m pro AI, anti copyright, especially anti elitist NY Times; but pro rule of law)</div><br/><div id="38791234" class="c"><input type="checkbox" id="c-38791234" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791153">parent</a><span>|</span><a href="#38791196">next</a><span>|</span><label class="collapse" for="c-38791234">[-]</label><label class="expand" for="c-38791234">[1 more]</label></div><br/><div class="children"><div class="content">There is another fix, but it will have to wait for GPT-5. They could reword articles, summarize in different words and analyze their contents, creating sufficiently different variants. The ideas would be kept, but original expression stripped. Then train GPT5 on this data. The model can&#x27;t possibly regurgitate copyrighted content if they never saw it during training.<p>This can be further coupled with search - use GPT to look at multiple sources at once, and report. It&#x27;s what humans do as well, we read the same news in different sources to get a more balanced take. Maybe they have contradictions, maybe they have inaccuracies, biases. We could keep that analysis for training models. This would also improve the training set.</div><br/></div></div><div id="38791196" class="c"><input type="checkbox" id="c-38791196" checked=""/><div class="controls bullet"><span class="by">colechristensen</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791153">parent</a><span>|</span><a href="#38791234">prev</a><span>|</span><a href="#38791154">next</a><span>|</span><label class="collapse" for="c-38791196">[-]</label><label class="expand" for="c-38791196">[2 more]</label></div><br/><div class="children"><div class="content">I think there is some point between fifty years ago and last week in which the copyright for the content of newspapers should be public domain.  That part of copyright needs to be fixed.<p>Your creative work does deserve at least some period of exclusive rights for you.  Definitely not so much that your grandchildren get to quibble about it well into retirement.  But also whatever the number 3 or 4 most valuable company in the world doesn’t get to scrape your content daily to repackage and sell as intelligent systems.</div><br/><div id="38791431" class="c"><input type="checkbox" id="c-38791431" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791196">parent</a><span>|</span><a href="#38791154">next</a><span>|</span><label class="collapse" for="c-38791431">[-]</label><label class="expand" for="c-38791431">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>But also whatever the number 3 or 4 most valuable company in the world doesn’t get to scrape your content daily to repackage and sell as intelligent systems.</i><p>Here&#x27;s a thing though: for 99%+ of that content, being turned into feedstock for ML model training is about <i>the only valuable thing that came of its existence</i>.<p>If it were not for world-ending danger of too smart an AI being developed too quickly, I&#x27;d vote for exempting ML training from copyright altogether, today - it&#x27;s hard to overstate just how much more useful any copyrighted content is for society as LLM training data, than as whatever it was created for originally.</div><br/></div></div></div></div></div></div></div></div><div id="38791154" class="c"><input type="checkbox" id="c-38791154" checked=""/><div class="controls bullet"><span class="by">colechristensen</span><span>|</span><a href="#38790737">parent</a><span>|</span><a href="#38791093">prev</a><span>|</span><a href="#38790949">next</a><span>|</span><label class="collapse" for="c-38791154">[-]</label><label class="expand" for="c-38791154">[2 more]</label></div><br/><div class="children"><div class="content">I think NYT is going to win.<p>LLMs are arguably compressed data archives with weird algorithms.  The fact that they will regularly regurgitate verbatim quotes of training data is evidence of this, as are the guardrails that try to prevent this.<p>The second piece of evidence is this paper explained here <a href="https:&#x2F;&#x2F;www.hendrik-erz.de&#x2F;post&#x2F;why-gzip-just-beat-a-large-language-model" rel="nofollow">https:&#x2F;&#x2F;www.hendrik-erz.de&#x2F;post&#x2F;why-gzip-just-beat-a-large-l...</a> where instead of an LLM researchers used gzip compressed data as a model and it even beat trained LLMs.<p>AI is a bit of a black box, but that doesn’t protect the operators of black boxes from rights violation suits.  You can’t make a database of scraped copyrighted data and patented that querying that data is fair use.<p>There needs to be law made here and the law just isn’t going to be “everybody can copy everything for free as long as it’s for model training”.<p>Licensing will have to be worked out, actual laws and not just case law needs to be written.  I have a lot of sympathy for lots of leeway for the open source researchers and hackers doing things… but not so much for Microsoft and Microsoft sponsored openai.</div><br/></div></div><div id="38790949" class="c"><input type="checkbox" id="c-38790949" checked=""/><div class="controls bullet"><span class="by">peyton</span><span>|</span><a href="#38790737">parent</a><span>|</span><a href="#38791154">prev</a><span>|</span><a href="#38790895">next</a><span>|</span><label class="collapse" for="c-38790949">[-]</label><label class="expand" for="c-38790949">[5 more]</label></div><br/><div class="children"><div class="content">Well yeah, copying a work and using it for its original expressive purpose isn’t fair use, no? You have to use it for a transformative purpose.<p>Suppose I’m selling subscriptions to the New Jersey Times, a site which simply downloads New York Times articles and passes them through an autoencoder with some random noise. It serves the exact same purpose as the New York Times website, except I make the money. Is that fair use?</div><br/><div id="38791189" class="c"><input type="checkbox" id="c-38791189" checked=""/><div class="controls bullet"><span class="by">cornel_io</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38790949">parent</a><span>|</span><a href="#38790976">next</a><span>|</span><label class="collapse" for="c-38791189">[-]</label><label class="expand" for="c-38791189">[2 more]</label></div><br/><div class="children"><div class="content">If they could find a single person who in natural use (e.g. not as they were trying to gather data for this lawsuit) has ever <i>actually</i> used ChatGPT as a direct substitution for a NYT subscription, I&#x27;d support this lawsuit.<p>But nobody would do that, because ChatGPT is a really shitty way to read NYT articles (it&#x27;s stale, it can&#x27;t reliably reproduce them, etc.). All that is valuable about it is the way that it transforms and operates on that data in conjunction with all the other data that it has.<p>The real world use of ChatGPT is very transformative, even if you can trick it into behaving in ways that are not. If the courts act intelligently they should at least weigh that as part of their decision.</div><br/><div id="38791443" class="c"><input type="checkbox" id="c-38791443" checked=""/><div class="controls bullet"><span class="by">peyton</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38791189">parent</a><span>|</span><a href="#38790976">next</a><span>|</span><label class="collapse" for="c-38791443">[-]</label><label class="expand" for="c-38791443">[1 more]</label></div><br/><div class="children"><div class="content">It’s more of a thought experiment. Here’s another with more commercial applications:<p>Suppose I start a service called “EastlawAI” by downloading the Westlaw database and hiring a team of comedians to write very funny lawyer jokes.<p>I take Westlaw cases and lawyer jokes and feed them to my autoencoder. I also learn a mapping from user queries to decoder inputs.<p>I sell an API and advertise it to startups as capable of answering any legal question in a funny way. Another company comes along with an API to make the output less funny.<p>Have I created a competitor to Westlaw by copying Westlaw’s works for their original expressive purpose and exposing it as an intermediary? Or have I simply trained the world’s most informative lawyer joke generator that some of my customers happen to use for legal analysis by layering other tools atop my output?<p>Did I need to download Westlaw cases to make my lawyer joke generator? Are the jokes a fair-use smokescreen for repackaging commercially valuable copyrighted data? Does my joke generator impact Westlaw in the market? Depends, right?</div><br/></div></div></div></div><div id="38790976" class="c"><input type="checkbox" id="c-38790976" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38790949">parent</a><span>|</span><a href="#38791189">prev</a><span>|</span><a href="#38790895">next</a><span>|</span><label class="collapse" for="c-38790976">[-]</label><label class="expand" for="c-38790976">[2 more]</label></div><br/><div class="children"><div class="content">&gt;  Well yeah, copying a work and using it for its original expressive purpose isn’t fair use, no? You have to use it for a transformative purpose.<p>They transformed the weights.<p>Just like reading the article transforms <i>yours</i>.<p>As for verbatim reproduction, I&#x27;m pretty sure brains are capable of reproducing song lyrics, musical melodies, common symbols (&quot;cool S&quot;), and lots of other things verbatim too.<p>Those quotes from Dr. King&#x27;s speech that you remember are copyrighted, you know?</div><br/><div id="38791103" class="c"><input type="checkbox" id="c-38791103" checked=""/><div class="controls bullet"><span class="by">JambalayaJim</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38790976">parent</a><span>|</span><a href="#38790895">next</a><span>|</span><label class="collapse" for="c-38791103">[-]</label><label class="expand" for="c-38791103">[1 more]</label></div><br/><div class="children"><div class="content">This comment is just blatant anthropomorphizing of ML models. You have no idea if reading an article “transforms weights” in a human mind, and regardless, they aren’t legally the same thing anyway.</div><br/></div></div></div></div></div></div><div id="38790895" class="c"><input type="checkbox" id="c-38790895" checked=""/><div class="controls bullet"><span class="by">spacecadet</span><span>|</span><a href="#38790737">parent</a><span>|</span><a href="#38790949">prev</a><span>|</span><a href="#38790608">next</a><span>|</span><label class="collapse" for="c-38790895">[-]</label><label class="expand" for="c-38790895">[3 more]</label></div><br/><div class="children"><div class="content">Transformations are happening. Maybe if the output is verbatim afterwards, than that says something about the outputs originality all along... or am I a troll?</div><br/><div id="38791159" class="c"><input type="checkbox" id="c-38791159" checked=""/><div class="controls bullet"><span class="by">dathery</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38790895">parent</a><span>|</span><a href="#38790957">next</a><span>|</span><label class="collapse" for="c-38791159">[-]</label><label class="expand" for="c-38791159">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re talking about transformative with regard to copyright law where it is an important part of determining fair use, not the dictionary definition you&#x27;re using here.<p>I can&#x27;t take NY Times articles, translate them into Spanish, and then sell the translations under fair use, even though clearly I&#x27;ve transformed the original article content.</div><br/></div></div><div id="38790957" class="c"><input type="checkbox" id="c-38790957" checked=""/><div class="controls bullet"><span class="by">jarrell_mark</span><span>|</span><a href="#38790737">root</a><span>|</span><a href="#38790895">parent</a><span>|</span><a href="#38791159">prev</a><span>|</span><a href="#38790608">next</a><span>|</span><label class="collapse" for="c-38790957">[-]</label><label class="expand" for="c-38790957">[1 more]</label></div><br/><div class="children"><div class="content">Anything + 2 and then minus two is back to the original thing. This says more about the transformations than the source material.</div><br/></div></div></div></div></div></div><div id="38790608" class="c"><input type="checkbox" id="c-38790608" checked=""/><div class="controls bullet"><span class="by">aurareturn</span><span>|</span><a href="#38790737">prev</a><span>|</span><a href="#38791089">next</a><span>|</span><label class="collapse" for="c-38790608">[-]</label><label class="expand" for="c-38790608">[14 more]</label></div><br/><div class="children"><div class="content">Companies that have content all see dollar signs.<p>NYT won&#x27;t mind if you use their content to train LLMs - as long as they get a commission. Reddit will shut down their free API and make you pay to get training content. Discord is going to be selling content for AI training too - if they haven&#x27;t already done so. Twitter is doing it.<p>They didn&#x27;t care before because LLMs were just experiments. Now we&#x27;re talking trillions of dollars of value.</div><br/><div id="38791273" class="c"><input type="checkbox" id="c-38791273" checked=""/><div class="controls bullet"><span class="by">mvdtnz</span><span>|</span><a href="#38790608">parent</a><span>|</span><a href="#38790668">next</a><span>|</span><label class="collapse" for="c-38791273">[-]</label><label class="expand" for="c-38791273">[1 more]</label></div><br/><div class="children"><div class="content">NYT do not &quot;have&quot; content, they create content. It&#x27;s their raison d&#x27;etre.</div><br/></div></div><div id="38790668" class="c"><input type="checkbox" id="c-38790668" checked=""/><div class="controls bullet"><span class="by">up2isomorphism</span><span>|</span><a href="#38790608">parent</a><span>|</span><a href="#38791273">prev</a><span>|</span><a href="#38790628">next</a><span>|</span><label class="collapse" for="c-38790668">[-]</label><label class="expand" for="c-38790668">[9 more]</label></div><br/><div class="children"><div class="content">&quot;They&quot; also include the people working there. Why someone work with full time writing articles should give the work for free just let someone to train it and make money out of it as a consequence?</div><br/><div id="38790696" class="c"><input type="checkbox" id="c-38790696" checked=""/><div class="controls bullet"><span class="by">tucnak</span><span>|</span><a href="#38790608">root</a><span>|</span><a href="#38790668">parent</a><span>|</span><a href="#38790889">next</a><span>|</span><label class="collapse" for="c-38790696">[-]</label><label class="expand" for="c-38790696">[5 more]</label></div><br/><div class="children"><div class="content">&gt;Why someone work with full time writing articles should give the work for free<p>They are not giving it out &quot;for free&quot;, in fact they&#x27;re being paid by their employer to write these articles. Moreover, the writers themselves stand noth&#x27; to gain from their past writings financially as they don&#x27;t belong to the ownership structure of the business.</div><br/><div id="38790774" class="c"><input type="checkbox" id="c-38790774" checked=""/><div class="controls bullet"><span class="by">bloppe</span><span>|</span><a href="#38790608">root</a><span>|</span><a href="#38790696">parent</a><span>|</span><a href="#38790988">next</a><span>|</span><label class="collapse" for="c-38790774">[-]</label><label class="expand" for="c-38790774">[1 more]</label></div><br/><div class="children"><div class="content">&gt; the writers themselves stand noth&#x27; to gain from their past writings financially as they don&#x27;t belong to the ownership structure of the business.<p>This is a dumb argument. We&#x27;re not just talking about ancient articles. We&#x27;re talking about new content, including content that is yet to be written.</div><br/></div></div><div id="38790988" class="c"><input type="checkbox" id="c-38790988" checked=""/><div class="controls bullet"><span class="by">MisterBastahrd</span><span>|</span><a href="#38790608">root</a><span>|</span><a href="#38790696">parent</a><span>|</span><a href="#38790774">prev</a><span>|</span><a href="#38790889">next</a><span>|</span><label class="collapse" for="c-38790988">[-]</label><label class="expand" for="c-38790988">[3 more]</label></div><br/><div class="children"><div class="content">Their ability to make money in the future is directly tied to their employers&#x27; ability to make money with their content. This is a closed financial loop. If OpenAI or any other AI company wants in, they should pay a licensing fee or get the laws changed, not just assume that they can take what they want and pretend like there are no negative consequences for the creator or the rights-holder.</div><br/><div id="38791310" class="c"><input type="checkbox" id="c-38791310" checked=""/><div class="controls bullet"><span class="by">TeMPOraL</span><span>|</span><a href="#38790608">root</a><span>|</span><a href="#38790988">parent</a><span>|</span><a href="#38791289">next</a><span>|</span><label class="collapse" for="c-38791310">[-]</label><label class="expand" for="c-38791310">[1 more]</label></div><br/><div class="children"><div class="content">No one is pretending there are no &quot;there are no negative consequences for the creator or the rights-holder&quot;. Of course there are. But this is a story of rights-holders, who&#x27;ve already outgrown their usefulness, wanting to tap themselves into money stream they are not entitled to.<p><i>ChatGPT isn&#x27;t competing with NYT on a core competency</i>. No one uses LLMs for original news reporting. They&#x27;re obviously incapable of doing that, by virtue of not being there on the scene or able to independently research a topic, maintain relationships with sources, etc. What ChatGPT can do is quote&#x2F;reproduce some parts of past articles, <i>and reason from them</i>. Or at least produce new text that&#x27;s somewhat related to the old text.<p>The threat to NYT is this: ChatGPT is much better bullshitter than they are, so it reduces NYT to its core competency: providing original information. Which is all it should be doing in the first place. But instead, NYT wants to not only keep the bullshitting part of its revenue, but also take a cut or destroy the much greater and <i>much more useful</i> part of where this all feeds a general-purpose language model.</div><br/></div></div><div id="38791289" class="c"><input type="checkbox" id="c-38791289" checked=""/><div class="controls bullet"><span class="by">malwrar</span><span>|</span><a href="#38790608">root</a><span>|</span><a href="#38790988">parent</a><span>|</span><a href="#38791310">prev</a><span>|</span><a href="#38790889">next</a><span>|</span><label class="collapse" for="c-38791289">[-]</label><label class="expand" for="c-38791289">[1 more]</label></div><br/><div class="children"><div class="content">In this limited example, are there such consequences? Are people dropping NYT subscriptions because they trust chatgpt to inform them of current events? I don’t buy it.</div><br/></div></div></div></div></div></div><div id="38790889" class="c"><input type="checkbox" id="c-38790889" checked=""/><div class="controls bullet"><span class="by">amadvance</span><span>|</span><a href="#38790608">root</a><span>|</span><a href="#38790668">parent</a><span>|</span><a href="#38790696">prev</a><span>|</span><a href="#38790628">next</a><span>|</span><label class="collapse" for="c-38790889">[-]</label><label class="expand" for="c-38790889">[3 more]</label></div><br/><div class="children"><div class="content">&gt; Why someone work with full time writing articles should give the work for free<p>OpenSource developers did that ;)</div><br/><div id="38790935" class="c"><input type="checkbox" id="c-38790935" checked=""/><div class="controls bullet"><span class="by">KETHERCORTEX</span><span>|</span><a href="#38790608">root</a><span>|</span><a href="#38790889">parent</a><span>|</span><a href="#38790628">next</a><span>|</span><label class="collapse" for="c-38790935">[-]</label><label class="expand" for="c-38790935">[2 more]</label></div><br/><div class="children"><div class="content">When open source developers do that, they also include an explicit licensing information that lists cases when the usage is allowed and restricted. So even if the code is open source and licensed under GPL, its usage in a closed source product like ChatGPT is not allowed.</div><br/><div id="38791230" class="c"><input type="checkbox" id="c-38791230" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38790608">root</a><span>|</span><a href="#38790935">parent</a><span>|</span><a href="#38790628">next</a><span>|</span><label class="collapse" for="c-38791230">[-]</label><label class="expand" for="c-38791230">[1 more]</label></div><br/><div class="children"><div class="content">GPL code usage in closed source ChatGPT is allowed &quot;for internal use&quot;; it just would not be allowed to distribute binaries of ChatGPT that are closed source without making source available; also a GPL3 license violation to allow online access to a ChatGPT program that used GPL3 code without making source available.</div><br/></div></div></div></div></div></div></div></div><div id="38790628" class="c"><input type="checkbox" id="c-38790628" checked=""/><div class="controls bullet"><span class="by">MuffinFlavored</span><span>|</span><a href="#38790608">parent</a><span>|</span><a href="#38790668">prev</a><span>|</span><a href="#38791089">next</a><span>|</span><label class="collapse" for="c-38790628">[-]</label><label class="expand" for="c-38790628">[3 more]</label></div><br/><div class="children"><div class="content">&gt; They didn&#x27;t care before because LLMs were just experiments. Now we&#x27;re talking trillions of dollars of value.<p>Can you make the argument this was their fault for not having forward vision&#x2F;being asleep at the wheel and &quot;accidentally, in hindsight&quot; letting OpenAI&#x2F;others have free, open, unlimited access to their content?</div><br/><div id="38790761" class="c"><input type="checkbox" id="c-38790761" checked=""/><div class="controls bullet"><span class="by">bloppe</span><span>|</span><a href="#38790608">root</a><span>|</span><a href="#38790628">parent</a><span>|</span><a href="#38790810">next</a><span>|</span><label class="collapse" for="c-38790761">[-]</label><label class="expand" for="c-38790761">[1 more]</label></div><br/><div class="children"><div class="content">Basically none of the training material for GPT was used under an &quot;unlimited&quot; license. There are very important legal limitations. GPT just doesn&#x27;t care much about them.</div><br/></div></div><div id="38790810" class="c"><input type="checkbox" id="c-38790810" checked=""/><div class="controls bullet"><span class="by">aurareturn</span><span>|</span><a href="#38790608">root</a><span>|</span><a href="#38790628">parent</a><span>|</span><a href="#38790761">prev</a><span>|</span><a href="#38791089">next</a><span>|</span><label class="collapse" for="c-38790810">[-]</label><label class="expand" for="c-38790810">[1 more]</label></div><br/><div class="children"><div class="content">No, I can&#x27;t. It&#x27;s just an observation with no personal opinion.</div><br/></div></div></div></div></div></div><div id="38791089" class="c"><input type="checkbox" id="c-38791089" checked=""/><div class="controls bullet"><span class="by">throwaway4good</span><span>|</span><a href="#38790608">prev</a><span>|</span><a href="#38791243">next</a><span>|</span><label class="collapse" for="c-38791089">[-]</label><label class="expand" for="c-38791089">[1 more]</label></div><br/><div class="children"><div class="content">The lawsuit itself (which arstechnica links to):<p><a href="https:&#x2F;&#x2F;nytco-assets.nytimes.com&#x2F;2023&#x2F;12&#x2F;NYT_Complaint_Dec2023.pdf" rel="nofollow">https:&#x2F;&#x2F;nytco-assets.nytimes.com&#x2F;2023&#x2F;12&#x2F;NYT_Complaint_Dec20...</a><p>From page 30 and onwards has some fairly clear examples on how ChatGPT has an (internal) copy of copyrighted material which it will recite verbatim.<p>Essentially if you copy a lot of copyrighted material into a blob and then apply some sort of destructive compression to it. How destructive would that compression have to be for the copyright no longer to hold? My guess it would have to be a lot.<p>As I see it the closeness of OpenAI may be what saves it. OpenAI could filter and block copyrighted material from the LLM from leaving the web interface using some straight forward matching mechanism against the copyrighted part of the data set ChatGPT has been trained on. Whereas open source projects trained on the same data set would be left with the much harder task of removing the copyrighted material from the LLM itself.</div><br/></div></div><div id="38791243" class="c"><input type="checkbox" id="c-38791243" checked=""/><div class="controls bullet"><span class="by">logicchains</span><span>|</span><a href="#38791089">prev</a><span>|</span><a href="#38791292">next</a><span>|</span><label class="collapse" for="c-38791243">[-]</label><label class="expand" for="c-38791243">[3 more]</label></div><br/><div class="children"><div class="content">NYT&#x27;s perspective is going to look so stupid in future when we put LLMs into mechanical bodies with the ability to interact with the physical world, and to learn&#x2F;update their weights live. It would make it completely illegal for such a robot to read&#x2F;watch&#x2F;listen to any copyrighted material; no watching TV, no reading library books, no browsing the internet, because in doing so it could memorise some copyrighted content.</div><br/><div id="38791290" class="c"><input type="checkbox" id="c-38791290" checked=""/><div class="controls bullet"><span class="by">type_Ben_struct</span><span>|</span><a href="#38791243">parent</a><span>|</span><a href="#38791271">next</a><span>|</span><label class="collapse" for="c-38791290">[-]</label><label class="expand" for="c-38791290">[1 more]</label></div><br/><div class="children"><div class="content">I disagree. The verbatim part is the problem. You’re drawing a comparison to how humans operate except we’re not allowed to operate like that.<p>While harder to do as a human, if  memorised a copyrighted book and then did a live reading on TV, or produced replicas from memory and sold them (the most comparable example), I’d be sued.<p>Humans produce derivative work all the time, and it’s fine for LLM’s to do that, but you can’t do it verbatim.</div><br/></div></div><div id="38791271" class="c"><input type="checkbox" id="c-38791271" checked=""/><div class="controls bullet"><span class="by">ramraj07</span><span>|</span><a href="#38791243">parent</a><span>|</span><a href="#38791290">prev</a><span>|</span><a href="#38791292">next</a><span>|</span><label class="collapse" for="c-38791271">[-]</label><label class="expand" for="c-38791271">[1 more]</label></div><br/><div class="children"><div class="content">Will it? If the LLM in the body is allowed to read nytimes on a tablet I&#x27;m sure they wouldn&#x27;t care.</div><br/></div></div></div></div><div id="38791292" class="c"><input type="checkbox" id="c-38791292" checked=""/><div class="controls bullet"><span class="by">jrockway</span><span>|</span><a href="#38791243">prev</a><span>|</span><a href="#38790610">next</a><span>|</span><label class="collapse" for="c-38791292">[-]</label><label class="expand" for="c-38791292">[5 more]</label></div><br/><div class="children"><div class="content">I read about this in the Times today (and am surprised that it wasn&#x27;t on HN already).<p>My guess is that the court will likely find in the Times favor, because the legal system won&#x27;t be able to understand how training works and because people are &quot;scared&quot; of AI.  To me, reading a book, putting it in some storage system, and then recalling it to form future thoughts is fair use.  It&#x27;s what we all do all the time, and I think that&#x27;s exactly what training is.  I might say something like &quot;I, for one, welcome our new LLM overlords&quot;.  Am I infringing the copyright of The Simpsons?  No.<p>I am guessing some technicality like a terms-of-use violation of the website (avoidable if you go to the library and type in back issues of the Times), or storing the text between training sessions is what will do OpenAI in here.  The legal system has never been particularly comfortable with how computers work; for example, the only reason EULAs work is because you &quot;copy&quot; software when your OS reads the program off of disk into memory (and from memory into cache, and from cache into registers).  That would be copyright infringement according to courts, so you have to agree to a license to get that permission.<p>I think the precedent on copyright law is way off base, granting too much power to authors and too little to user.  But because it&#x27;s so favorable towards &quot;rightsholders&quot;, I expect the Times to prevail here.</div><br/><div id="38791329" class="c"><input type="checkbox" id="c-38791329" checked=""/><div class="controls bullet"><span class="by">pests</span><span>|</span><a href="#38791292">parent</a><span>|</span><a href="#38791328">next</a><span>|</span><label class="collapse" for="c-38791329">[-]</label><label class="expand" for="c-38791329">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t agree that an LLM is doing what we are doing.<p>&quot;Its what we do all the time&quot; is a major assumption</div><br/></div></div><div id="38791328" class="c"><input type="checkbox" id="c-38791328" checked=""/><div class="controls bullet"><span class="by">hsbauauvhabzb</span><span>|</span><a href="#38791292">parent</a><span>|</span><a href="#38791329">prev</a><span>|</span><a href="#38790610">next</a><span>|</span><label class="collapse" for="c-38791328">[-]</label><label class="expand" for="c-38791328">[3 more]</label></div><br/><div class="children"><div class="content">My hard drive can - bit for bit - recall video files. If I serve them to other people on the internet without permission of the copyright holder, that’s called piracy.</div><br/><div id="38791415" class="c"><input type="checkbox" id="c-38791415" checked=""/><div class="controls bullet"><span class="by">jrockway</span><span>|</span><a href="#38791292">root</a><span>|</span><a href="#38791328">parent</a><span>|</span><a href="#38791381">next</a><span>|</span><label class="collapse" for="c-38791415">[-]</label><label class="expand" for="c-38791415">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, but the LLMs can&#x27;t.  They aren&#x27;t big enough to contain every byte of every NYT article, even with the best-known compression algorithms.  Rather, they pick up and remember the same patterns that humans do when they write.  Authors of the articles also did that, and so the two algorithms (human writer, LLM inference) end up with the same result.  (That doesn&#x27;t preclude large chunks of text that are actually remembered, though.  We humans have large chunks of verbatim text floating around in our brains.  Passwords, phone numbers, &quot;I pledge allegiance to the flag...&quot;, etc.)<p>Anyway, like I said, I don&#x27;t think OpenAI will win this.  Someone will produce one verbatim article and the court will make OpenAI pay a bunch of money as though every article could be reproduced verbatim, and AI in the US will be set back that many billion dollars.  It probably doesn&#x27;t matter in the long run; it preserves the status quo for as long as the judge is judging and the newspaper exec is newspaper exec-ing.  That&#x27;s all they need.  The next generation will have to figure out how to deal with AI-induced job loss... and climate change.  Have fun, next generation!</div><br/></div></div><div id="38791381" class="c"><input type="checkbox" id="c-38791381" checked=""/><div class="controls bullet"><span class="by">ninjinxo</span><span>|</span><a href="#38791292">root</a><span>|</span><a href="#38791328">parent</a><span>|</span><a href="#38791415">prev</a><span>|</span><a href="#38790610">next</a><span>|</span><label class="collapse" for="c-38791381">[-]</label><label class="expand" for="c-38791381">[1 more]</label></div><br/><div class="children"><div class="content">But is it still piracy if you compress them and serve only a likeness of the original?</div><br/></div></div></div></div></div></div><div id="38790610" class="c"><input type="checkbox" id="c-38790610" checked=""/><div class="controls bullet"><span class="by">fasterik</span><span>|</span><a href="#38791292">prev</a><span>|</span><a href="#38790790">next</a><span>|</span><label class="collapse" for="c-38790610">[-]</label><label class="expand" for="c-38790610">[18 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve been arguing since ChatGPT came out that LLMs should fall under fair use as a &quot;transformative work&quot;. I&#x27;m not a lawyer and this is just my non-expert opinion, but it will be interesting to see what the legal system has to say about this.</div><br/><div id="38790866" class="c"><input type="checkbox" id="c-38790866" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#38790610">parent</a><span>|</span><a href="#38790665">next</a><span>|</span><label class="collapse" for="c-38790866">[-]</label><label class="expand" for="c-38790866">[1 more]</label></div><br/><div class="children"><div class="content">This seems like a reasonable opinion when you think about the training data size and imagine that any given output is some kind of interpolation of some unknown large number of training examples all from different people. If it’s borrowing snippets from tens or hundreds or thousands of sources, then who’s copyrights are being violated? Remixing in music seems to be withstanding some amount of legal scrutiny, as long as the remix is borrowing from multiple sources and the music is clearly different and original.<p>It gets harder to stand behind a blanket claim that LLMs or any AI we’ve got falls under fair use when they keep repeatedly reproducing complete and identifiable individual works and clearly violating copyright laws in specific instances. The models might be remixing and&#x2F;or transformative most of the time, but we have proof that they don’t do that every time nor all the time… yet. Maybe the lawsuits will be the impetus we need to fix the AIs so they don’t reproduce specific works, and thus make the fair use claim solid and actually defensible?</div><br/></div></div><div id="38790665" class="c"><input type="checkbox" id="c-38790665" checked=""/><div class="controls bullet"><span class="by">mynegation</span><span>|</span><a href="#38790610">parent</a><span>|</span><a href="#38790866">prev</a><span>|</span><a href="#38791013">next</a><span>|</span><label class="collapse" for="c-38790665">[-]</label><label class="expand" for="c-38790665">[12 more]</label></div><br/><div class="children"><div class="content">Suit claims that GPT reproduced passages from NYT almost verbatim.</div><br/><div id="38791062" class="c"><input type="checkbox" id="c-38791062" checked=""/><div class="controls bullet"><span class="by">lodovic</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790665">parent</a><span>|</span><a href="#38790760">next</a><span>|</span><label class="collapse" for="c-38791062">[-]</label><label class="expand" for="c-38791062">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m sure the NYT uses dictionaries, encyclopaedias and style books verbatim as well. And they don&#x27;t invent the facts they write about. As journalists they are compiling and passing along other knowledge. You usually don&#x27;t get a piece of their income when a journalist quotes you verbatim (people usually don&#x27;t get paid for interviews).</div><br/></div></div><div id="38790760" class="c"><input type="checkbox" id="c-38790760" checked=""/><div class="controls bullet"><span class="by">dahart</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790665">parent</a><span>|</span><a href="#38791062">prev</a><span>|</span><a href="#38790690">next</a><span>|</span><label class="collapse" for="c-38790760">[-]</label><label class="expand" for="c-38790760">[2 more]</label></div><br/><div class="children"><div class="content">I don’t doubt it does. It’s easy to get it to spit out long answers from Stack Overflow verbatim, I’ve done it. Maybe some of the “transformative” nature of the LLM output is the removal of any authorship, copyright, license, and edit history information. ;) The point here is to supplant Google as the portal of information, right? It doesn’t have new information, but it’s pretty good at remixing the words from multiple sources, when it has multiple sources. One possible reason for their legal woes wrt copyright is that it’s also great at memorizing things that only have one source. My college Markov-chain text predictor would do the same thing and easily get stuck in local regions if it couldn’t match something else.</div><br/><div id="38791055" class="c"><input type="checkbox" id="c-38791055" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790760">parent</a><span>|</span><a href="#38790690">next</a><span>|</span><label class="collapse" for="c-38791055">[-]</label><label class="expand" for="c-38791055">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think these can replace search engines.</div><br/></div></div></div></div><div id="38790690" class="c"><input type="checkbox" id="c-38790690" checked=""/><div class="controls bullet"><span class="by">rvz</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790665">parent</a><span>|</span><a href="#38790760">prev</a><span>|</span><a href="#38791013">next</a><span>|</span><label class="collapse" for="c-38790690">[-]</label><label class="expand" for="c-38790690">[8 more]</label></div><br/><div class="children"><div class="content">Precisely.<p>This tired <i>&#x27;fair use&#x27;</i> excuses from AI bros whilst the GPT has reproduced the article text verbatim, word for word and it being monetized without the permission from the copyright holder and source (NYT) is an obvious copyright violation 101. Full stop.<p>Again, just like Getty v. Stability, this copyright lawsuit will end in a licensing deal. Apple played it smart with their choice with licensing deals to train their GPT [0]. But this time, OpenAI knew they could get a license to train on NYT articles but <i>chose</i> not to.<p>[0] <a href="https:&#x2F;&#x2F;9to5mac.com&#x2F;2023&#x2F;12&#x2F;22&#x2F;apple-wants-to-train-its-ai-with-50-million-worth-of-licensed-news-articles&#x2F;" rel="nofollow">https:&#x2F;&#x2F;9to5mac.com&#x2F;2023&#x2F;12&#x2F;22&#x2F;apple-wants-to-train-its-ai-w...</a></div><br/><div id="38790720" class="c"><input type="checkbox" id="c-38790720" checked=""/><div class="controls bullet"><span class="by">throwup238</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790690">parent</a><span>|</span><a href="#38790743">next</a><span>|</span><label class="collapse" for="c-38790720">[-]</label><label class="expand" for="c-38790720">[1 more]</label></div><br/><div class="children"><div class="content">The four factors considered in a fair use test:<p><pre><code>    the purpose and character of the use
    the nature of the copyrighted work
    the amount and substantiality of the portion taken
    the effect of the use upon the potential market.
</code></pre>
Literally every single one of these factors has very complicated precedent and each one is an open question when it comes to AI. Since fair use is a balancing test this could go any way.<p>Stability took the easy way out because they didn&#x27;t have billions of dollars to play around with and Microsoft to back them. Let&#x27;s see what OpenAI does but calling everyone who disagrees with your naive interpretation of fair use &quot;AI bros&quot; is doing everyone a disservice.</div><br/></div></div><div id="38790743" class="c"><input type="checkbox" id="c-38790743" checked=""/><div class="controls bullet"><span class="by">chatmasta</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790690">parent</a><span>|</span><a href="#38790720">prev</a><span>|</span><a href="#38791013">next</a><span>|</span><label class="collapse" for="c-38790743">[-]</label><label class="expand" for="c-38790743">[6 more]</label></div><br/><div class="children"><div class="content">&gt; AI bros<p>What (or whom) do you consider  to be an &quot;AI bro?&quot;<p>This sort of ad hominem generalization usually accompanies a weak argument.</div><br/><div id="38790916" class="c"><input type="checkbox" id="c-38790916" checked=""/><div class="controls bullet"><span class="by">beau_g</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790743">parent</a><span>|</span><a href="#38790939">next</a><span>|</span><label class="collapse" for="c-38790916">[-]</label><label class="expand" for="c-38790916">[2 more]</label></div><br/><div class="children"><div class="content">Young males that wear Tensorflow branded muscle tank tops and drive Mitsubishi Eclipse convertibles with the vanity plate OVERFIT. They are everywhere these days.</div><br/><div id="38791019" class="c"><input type="checkbox" id="c-38791019" checked=""/><div class="controls bullet"><span class="by">jakderrida</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790916">parent</a><span>|</span><a href="#38790939">next</a><span>|</span><label class="collapse" for="c-38791019">[-]</label><label class="expand" for="c-38791019">[1 more]</label></div><br/><div class="children"><div class="content">Thank you for the absurd visual. The vanity plate, especially, was worth saving for last. Somehow, the car is well suited, also. Love how they prefer Tensorflow over Pytorch, too.</div><br/></div></div></div></div><div id="38790939" class="c"><input type="checkbox" id="c-38790939" checked=""/><div class="controls bullet"><span class="by">vidarh</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790743">parent</a><span>|</span><a href="#38790916">prev</a><span>|</span><a href="#38790756">next</a><span>|</span><label class="collapse" for="c-38790939">[-]</label><label class="expand" for="c-38790939">[1 more]</label></div><br/><div class="children"><div class="content">I generally tend to downvote comments that use &quot;x bros&quot; for pretty much any x on sight for that reason. It&#x27;s exceedingly rare for such a comment to be much more than a thinly veiled insult with little substance. Sometimes I might even agree with the insult, but it&#x27;s still rarely appropriate here.</div><br/></div></div><div id="38790756" class="c"><input type="checkbox" id="c-38790756" checked=""/><div class="controls bullet"><span class="by">satvikpendem</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790743">parent</a><span>|</span><a href="#38790939">prev</a><span>|</span><a href="#38790768">next</a><span>|</span><label class="collapse" for="c-38790756">[-]</label><label class="expand" for="c-38790756">[1 more]</label></div><br/><div class="children"><div class="content">It seems to be used by people who&#x27;ve previously used the term &quot;tech bro.&quot;</div><br/></div></div><div id="38790768" class="c"><input type="checkbox" id="c-38790768" checked=""/><div class="controls bullet"><span class="by">irq</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790743">parent</a><span>|</span><a href="#38790756">prev</a><span>|</span><a href="#38791013">next</a><span>|</span><label class="collapse" for="c-38790768">[-]</label><label class="expand" for="c-38790768">[1 more]</label></div><br/><div class="children"><div class="content">Not saying I agree with this labeling, but it means approximately the same thing as “crypto bro”, but for AI</div><br/></div></div></div></div></div></div></div></div><div id="38791013" class="c"><input type="checkbox" id="c-38791013" checked=""/><div class="controls bullet"><span class="by">agentgumshoe</span><span>|</span><a href="#38790610">parent</a><span>|</span><a href="#38790665">prev</a><span>|</span><a href="#38790710">next</a><span>|</span><label class="collapse" for="c-38791013">[-]</label><label class="expand" for="c-38791013">[2 more]</label></div><br/><div class="children"><div class="content">What if I ask ChatGPT to print the article verbatim as sourced, from its own dataset?</div><br/><div id="38791428" class="c"><input type="checkbox" id="c-38791428" checked=""/><div class="controls bullet"><span class="by">cjbprime</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38791013">parent</a><span>|</span><a href="#38790710">next</a><span>|</span><label class="collapse" for="c-38791428">[-]</label><label class="expand" for="c-38791428">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t have database access to its own training dataset; it only has access to the weights it lossily-compressed that training dataset into.</div><br/></div></div></div></div><div id="38790710" class="c"><input type="checkbox" id="c-38790710" checked=""/><div class="controls bullet"><span class="by">ramesh31</span><span>|</span><a href="#38790610">parent</a><span>|</span><a href="#38791013">prev</a><span>|</span><a href="#38790790">next</a><span>|</span><label class="collapse" for="c-38790710">[-]</label><label class="expand" for="c-38790710">[2 more]</label></div><br/><div class="children"><div class="content">It&#x27;s inevitable that this question ends up at the supreme court. And the sooner the better IMO. It&#x27;s clearly fair use. Generative agents will be seen legally as no different than a human artist leveraging the summation of their influences to create a new work.</div><br/><div id="38791024" class="c"><input type="checkbox" id="c-38791024" checked=""/><div class="controls bullet"><span class="by">agentgumshoe</span><span>|</span><a href="#38790610">root</a><span>|</span><a href="#38790710">parent</a><span>|</span><a href="#38790790">next</a><span>|</span><label class="collapse" for="c-38791024">[-]</label><label class="expand" for="c-38791024">[1 more]</label></div><br/><div class="children"><div class="content">Clearly fair use?  What if I pay ChatGPT to give me the NYT article it sourced verbatim as stored (i.e. without referring me to the NYT source)?</div><br/></div></div></div></div></div></div><div id="38790790" class="c"><input type="checkbox" id="c-38790790" checked=""/><div class="controls bullet"><span class="by">altals2023</span><span>|</span><a href="#38790610">prev</a><span>|</span><a href="#38791306">next</a><span>|</span><label class="collapse" for="c-38790790">[-]</label><label class="expand" for="c-38790790">[18 more]</label></div><br/><div class="children"><div class="content">Won&#x27;t hold in court. GPT is a platform mainly providing answer to private individuals asking. Is like you ask a professor a question and he answered verbatim what copyrighted materials available (due to photographic memory) word for word back to you. Now if you take this answer and write a book or publish enmass on blogs for example, then you are the one should be sued by NYT. If GPT use the exact same wordings and publish it out to evetyone visiting their page, then that is on OpenAI.</div><br/><div id="38791317" class="c"><input type="checkbox" id="c-38791317" checked=""/><div class="controls bullet"><span class="by">heavyset_go</span><span>|</span><a href="#38790790">parent</a><span>|</span><a href="#38791367">next</a><span>|</span><label class="collapse" for="c-38791317">[-]</label><label class="expand" for="c-38791317">[1 more]</label></div><br/><div class="children"><div class="content">Professors and schools get into legal problems when professors pirate and&#x2F;or otherwise distribute content they don&#x27;t have licenses for.</div><br/></div></div><div id="38791367" class="c"><input type="checkbox" id="c-38791367" checked=""/><div class="controls bullet"><span class="by">thinkingemote</span><span>|</span><a href="#38790790">parent</a><span>|</span><a href="#38791317">prev</a><span>|</span><a href="#38790871">next</a><span>|</span><label class="collapse" for="c-38791367">[-]</label><label class="expand" for="c-38791367">[1 more]</label></div><br/><div class="children"><div class="content">The professor having been trained in academia would state the sources of the verbatim quotes. In writing papers he would use references and explicit quotes. There&#x27;s nothing hidden going on with the professor.</div><br/></div></div><div id="38790871" class="c"><input type="checkbox" id="c-38790871" checked=""/><div class="controls bullet"><span class="by">Vegenoid</span><span>|</span><a href="#38790790">parent</a><span>|</span><a href="#38791367">prev</a><span>|</span><a href="#38791244">next</a><span>|</span><label class="collapse" for="c-38790871">[-]</label><label class="expand" for="c-38790871">[9 more]</label></div><br/><div class="children"><div class="content">If said professor offered a service where anyone could ask them for information that is behind a paywall, and they provided it without significant transformation, this would certainly be copyright infringement that the copyright holder would have every right and motivation to take action against.</div><br/><div id="38790930" class="c"><input type="checkbox" id="c-38790930" checked=""/><div class="controls bullet"><span class="by">elashri</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38790871">parent</a><span>|</span><a href="#38790970">next</a><span>|</span><label class="collapse" for="c-38790930">[-]</label><label class="expand" for="c-38790930">[4 more]</label></div><br/><div class="children"><div class="content">I think the scale only matters here (probably). Because I will find it hard that a teacher&#x2F;professor will not be allowed to setup a service where they will teach and provide their knowledge for others. That is basically the concept of teaching. Of course until LLM, we never had this scale before. Millions of potential learners vs the normal hundreds in a classroom session. So that makes the new case interesting</div><br/><div id="38791006" class="c"><input type="checkbox" id="c-38791006" checked=""/><div class="controls bullet"><span class="by">toyg</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38790930">parent</a><span>|</span><a href="#38790970">next</a><span>|</span><label class="collapse" for="c-38791006">[-]</label><label class="expand" for="c-38791006">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Teaching&quot; by copying source books word for word, would be copyright infringement; see, for example, the well-known issues around photocopying books or even excerpts.<p>Also lying on source materials (e.g. telling students that some respected historian denies the Holocaust happened, when it&#x27;s obviously not the case) is not &quot;teaching&quot; - it&#x27;s defamation, and the NYT is absolutely right to pursue that angle too.<p>Using LLMs as general-purpose search engines is a minefield, I would not be surprised if the practice disappeared in the next 20 years. Obviously the tech is here to stay, there is no problem when it&#x27;s applied to augmenting niche work; but as a Google replacement, it has so many issues</div><br/><div id="38791121" class="c"><input type="checkbox" id="c-38791121" checked=""/><div class="controls bullet"><span class="by">shkkmo</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38791006">parent</a><span>|</span><a href="#38790970">next</a><span>|</span><label class="collapse" for="c-38791121">[-]</label><label class="expand" for="c-38791121">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Teaching&quot; by copying source books word for word, would be copyright infringement; see, for example, the well-known issues around photocopying books or even excerpts.<p>Incorrect. Educational use helps satisfy one of tests for fair use. Teachers can, in many cases, photocopy copyrighted work without infringing on that copyright.</div><br/><div id="38791344" class="c"><input type="checkbox" id="c-38791344" checked=""/><div class="controls bullet"><span class="by">heavyset_go</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38791121">parent</a><span>|</span><a href="#38790970">next</a><span>|</span><label class="collapse" for="c-38791344">[-]</label><label class="expand" for="c-38791344">[1 more]</label></div><br/><div class="children"><div class="content">Educational use is just one of the many factors used to determine whether an instance of copyright infringement is fair use or not, but it is not carte blanche for educators to ignore IP laws just because they&#x27;re educating.</div><br/></div></div></div></div></div></div></div></div><div id="38790970" class="c"><input type="checkbox" id="c-38790970" checked=""/><div class="controls bullet"><span class="by">unsupp0rted</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38790871">parent</a><span>|</span><a href="#38790930">prev</a><span>|</span><a href="#38790926">next</a><span>|</span><label class="collapse" for="c-38790970">[-]</label><label class="expand" for="c-38790970">[3 more]</label></div><br/><div class="children"><div class="content">Would parroting back article content perfectly from memory certainly be copyright infringement?</div><br/><div id="38791007" class="c"><input type="checkbox" id="c-38791007" checked=""/><div class="controls bullet"><span class="by">verve_rat</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38790970">parent</a><span>|</span><a href="#38790926">next</a><span>|</span><label class="collapse" for="c-38791007">[-]</label><label class="expand" for="c-38791007">[2 more]</label></div><br/><div class="children"><div class="content">Go perform a song in a public place without a licencing arrangement and let us know.</div><br/><div id="38791359" class="c"><input type="checkbox" id="c-38791359" checked=""/><div class="controls bullet"><span class="by">infinityio</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38791007">parent</a><span>|</span><a href="#38790926">next</a><span>|</span><label class="collapse" for="c-38791359">[-]</label><label class="expand" for="c-38791359">[1 more]</label></div><br/><div class="children"><div class="content">scale is important here - maybe a better analogy is setting up a paid Spotify clone with all the music sourced from torrents with some slight distortion effect added</div><br/></div></div></div></div></div></div><div id="38790926" class="c"><input type="checkbox" id="c-38790926" checked=""/><div class="controls bullet"><span class="by">gedy</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38790871">parent</a><span>|</span><a href="#38790970">prev</a><span>|</span><a href="#38791244">next</a><span>|</span><label class="collapse" for="c-38790926">[-]</label><label class="expand" for="c-38790926">[1 more]</label></div><br/><div class="children"><div class="content">Professors are largely behind a paywall</div><br/></div></div></div></div><div id="38791033" class="c"><input type="checkbox" id="c-38791033" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38790790">parent</a><span>|</span><a href="#38791244">prev</a><span>|</span><a href="#38791306">next</a><span>|</span><label class="collapse" for="c-38791033">[-]</label><label class="expand" for="c-38791033">[5 more]</label></div><br/><div class="children"><div class="content">I hope people start calling out the &quot;well it&#x27;s fine if a human does it&quot; arguments out for the rat fuck thinking it is. These are computational systems operating at very large scales run by some of the wealthiest companies in the world.<p>If I go fishing, the regulations I have to comply with are very light because the effect I have on the environment is minimal. The regulations for an industrial fishing barge are rightfully very different, even if the end result is the same fish on your plate.</div><br/><div id="38791391" class="c"><input type="checkbox" id="c-38791391" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38791033">parent</a><span>|</span><a href="#38791082">next</a><span>|</span><label class="collapse" for="c-38791391">[-]</label><label class="expand" for="c-38791391">[1 more]</label></div><br/><div class="children"><div class="content">GPT is like a fleet of small fishing boats, each user driving their boat in another direction, not a fishing barge. For every token written by the model there must be a human who prompted, and then consumed it. It is manual, and personal, and deliberate.<p>In fact all the demonstrations in the lawsuit PDF were intentionally angling for reproducing copyrighted content. They had to push the model to do it. That won&#x27;t happen unless users deliberately ask for it. It won&#x27;t happen en-masse.</div><br/></div></div><div id="38791082" class="c"><input type="checkbox" id="c-38791082" checked=""/><div class="controls bullet"><span class="by">Garrrrrr</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38791033">parent</a><span>|</span><a href="#38791391">prev</a><span>|</span><a href="#38791306">next</a><span>|</span><label class="collapse" for="c-38791082">[-]</label><label class="expand" for="c-38791082">[3 more]</label></div><br/><div class="children"><div class="content">unfortunately that&#x27;s not the crowd of people here. 80% of the comments under this thread (right now, 2:52est) are making similar arguments and *continue* to act like LLMs are doing something unique&#x2F;creative... instead of just generating sentences, from algorithms, from virtually pirated content in the form of data mining</div><br/><div id="38791256" class="c"><input type="checkbox" id="c-38791256" checked=""/><div class="controls bullet"><span class="by">kriro9jdjfif</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38791082">parent</a><span>|</span><a href="#38791268">next</a><span>|</span><label class="collapse" for="c-38791256">[-]</label><label class="expand" for="c-38791256">[1 more]</label></div><br/><div class="children"><div class="content">“It is difficult to get a man to understand something, when his salary depends on his not understanding it.”<p><a href="https:&#x2F;&#x2F;www.goodreads.com&#x2F;quotes&#x2F;21810-it-is-difficult-to-get-a-man-to-understand-something" rel="nofollow">https:&#x2F;&#x2F;www.goodreads.com&#x2F;quotes&#x2F;21810-it-is-difficult-to-ge...</a></div><br/></div></div><div id="38791268" class="c"><input type="checkbox" id="c-38791268" checked=""/><div class="controls bullet"><span class="by">c1b</span><span>|</span><a href="#38790790">root</a><span>|</span><a href="#38791082">parent</a><span>|</span><a href="#38791256">prev</a><span>|</span><a href="#38791306">next</a><span>|</span><label class="collapse" for="c-38791268">[-]</label><label class="expand" for="c-38791268">[1 more]</label></div><br/><div class="children"><div class="content">“As if LLMs are doing something creative and aren’t just algorithms”<p>You have no idea what you’re talking about huh?</div><br/></div></div></div></div></div></div></div></div><div id="38791306" class="c"><input type="checkbox" id="c-38791306" checked=""/><div class="controls bullet"><span class="by">chmod600</span><span>|</span><a href="#38790790">prev</a><span>|</span><a href="#38790733">next</a><span>|</span><label class="collapse" for="c-38791306">[-]</label><label class="expand" for="c-38791306">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t copyright tethered somehow to a notion of &quot;expression&quot;? That is, the same ideas and facts expressed differently are a different work?<p>Sure, when something is clearly derived, or just expressed in a new medium, then I&#x27;m sure it&#x27;s still covered. But if it goes through an LLM and the result bears little resemblance, how can that still fall under copyright?</div><br/><div id="38791371" class="c"><input type="checkbox" id="c-38791371" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38791306">parent</a><span>|</span><a href="#38790733">next</a><span>|</span><label class="collapse" for="c-38791371">[-]</label><label class="expand" for="c-38791371">[1 more]</label></div><br/><div class="children"><div class="content">As you said AI can rewrite articles, obtaining a clean cut separation between ideas and expression. Keep the ideas, write a new text. And if you got multiple sources, the more sources you use the better, it would make the output be even more different. This approach could also check consistency and bias between sources.</div><br/></div></div></div></div><div id="38790733" class="c"><input type="checkbox" id="c-38790733" checked=""/><div class="controls bullet"><span class="by">kragen</span><span>|</span><a href="#38791306">prev</a><span>|</span><a href="#38790985">next</a><span>|</span><label class="collapse" for="c-38790733">[-]</label><label class="expand" for="c-38790733">[1 more]</label></div><br/><div class="children"><div class="content">this was predicted in the very influential epic 2014 video in 02004<p><a href="https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eUHBPuHS-7s" rel="nofollow">https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eUHBPuHS-7s</a> (the original is flash and has thus been consigned to the memory hole, so we are left with this poor-quality conversion)<p>36&quot;: &#x27;however, the press as you know it has ceased to exist&#x27;<p>40&quot;: &#x27;20th-century news organizations are an afterthought; a lonely remnant of a not-too-distant past&#x27;<p>2&#x27;11&quot;: &#x27;also in 2002, google launches google news, a news portal.  news organizations cry foul.  google news is edited entirely by computers&#x27;<p>5&#x27;13&quot;: &#x27;the news wars of 2010 are notable for the fact that no actual news organizations take part.  googlezon finally checkmates microsoft with a feature the software giant cannot match: using a new algorithm, googlezon&#x27;s computers construct new stories, dynamically stripping sentences and facts from all content sources, and recombining them.  the computer writes a new story for every user&#x27;<p>5&#x27;55&quot;: &#x27;in 2011 the slumbering fourth estate awakes to make its first and final stand.  the new york times company sues googlezon, claiming that the company&#x27;s fact-stripping robots are a violation of copyright law.  the case goes all the way to the supreme court&#x27;<p>they didn&#x27;t get the details exactly right, but overall the accuracy is astounding<p>however, that may be a hyperstition artifact in this timeline<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;EPIC_2014" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;EPIC_2014</a> (i thought epic 2014 might be the only flash video to hae a wikipedia article about it, but then i looked and found five others)</div><br/></div></div><div id="38790985" class="c"><input type="checkbox" id="c-38790985" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#38790733">prev</a><span>|</span><a href="#38791304">next</a><span>|</span><label class="collapse" for="c-38790985">[-]</label><label class="expand" for="c-38790985">[8 more]</label></div><br/><div class="children"><div class="content">Would be funny if NT Times won this and all commercial LLMs were shut down.<p>Then LLMs would be distributed only via torrents, like most copyright infringing media.</div><br/><div id="38791043" class="c"><input type="checkbox" id="c-38791043" checked=""/><div class="controls bullet"><span class="by">realusername</span><span>|</span><a href="#38790985">parent</a><span>|</span><a href="#38791035">next</a><span>|</span><label class="collapse" for="c-38791043">[-]</label><label class="expand" for="c-38791043">[1 more]</label></div><br/><div class="children"><div class="content">They would still thrive but in other countries with other legal frameworks. The concept is way too valuable to disappear.</div><br/></div></div><div id="38791035" class="c"><input type="checkbox" id="c-38791035" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#38790985">parent</a><span>|</span><a href="#38791043">prev</a><span>|</span><a href="#38791304">next</a><span>|</span><label class="collapse" for="c-38791035">[-]</label><label class="expand" for="c-38791035">[6 more]</label></div><br/><div class="children"><div class="content">Making these things anathema to commercial interests and making training them at scale legally perilous would be a huge win.</div><br/><div id="38791173" class="c"><input type="checkbox" id="c-38791173" checked=""/><div class="controls bullet"><span class="by">StableAlkyne</span><span>|</span><a href="#38790985">root</a><span>|</span><a href="#38791035">parent</a><span>|</span><a href="#38791124">next</a><span>|</span><label class="collapse" for="c-38791173">[-]</label><label class="expand" for="c-38791173">[2 more]</label></div><br/><div class="children"><div class="content">A huge win for countries with lax copyright laws. These things aren&#x27;t going away, the worst case scenario would be exactly that scenario playing out - then China (or some other peer to the US&#x27;s tech sector) just continues developing them to achieve an economic advantage. All in addition to the obvious political implications of AI chatbots being controlled by them.<p>The LLM genie is out of the bottle: an unfavorable court ruling in a single country isn&#x27;t going to stuff it back in.</div><br/><div id="38791477" class="c"><input type="checkbox" id="c-38791477" checked=""/><div class="controls bullet"><span class="by">geysersam</span><span>|</span><a href="#38790985">root</a><span>|</span><a href="#38791173">parent</a><span>|</span><a href="#38791124">next</a><span>|</span><label class="collapse" for="c-38791477">[-]</label><label class="expand" for="c-38791477">[1 more]</label></div><br/><div class="children"><div class="content">Do LLM really give an economic advantage though? I&#x27;ve mostly seen them used to write quirky poems and bad code. People are scrambling to find use-cases but it&#x27;s not very convincing so far.<p>On the other hand, if LLM are used to &quot;launder&quot; copyright content and, accepting the premises of copyright law, this has the effect of reducing incentives to do creative work, that has obvious huge implications for economic productivity.</div><br/></div></div></div></div><div id="38791124" class="c"><input type="checkbox" id="c-38791124" checked=""/><div class="controls bullet"><span class="by">mdekkers</span><span>|</span><a href="#38790985">root</a><span>|</span><a href="#38791035">parent</a><span>|</span><a href="#38791173">prev</a><span>|</span><a href="#38791283">next</a><span>|</span><label class="collapse" for="c-38791124">[-]</label><label class="expand" for="c-38791124">[2 more]</label></div><br/><div class="children"><div class="content">&gt; making training them at scale legally perilous would be a huge win.<p>Why?</div><br/><div id="38791183" class="c"><input type="checkbox" id="c-38791183" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38790985">root</a><span>|</span><a href="#38791124">parent</a><span>|</span><a href="#38791283">next</a><span>|</span><label class="collapse" for="c-38791183">[-]</label><label class="expand" for="c-38791183">[1 more]</label></div><br/><div class="children"><div class="content">I have no idea what he&#x27;s thinking, but if everybody in the community here had an LLM in their pocket and large orgs did not, it would at least be kind of fun.</div><br/></div></div></div></div><div id="38791283" class="c"><input type="checkbox" id="c-38791283" checked=""/><div class="controls bullet"><span class="by">Dalewyn</span><span>|</span><a href="#38790985">root</a><span>|</span><a href="#38791035">parent</a><span>|</span><a href="#38791124">prev</a><span>|</span><a href="#38791304">next</a><span>|</span><label class="collapse" for="c-38791283">[-]</label><label class="expand" for="c-38791283">[1 more]</label></div><br/><div class="children"><div class="content">&gt;making training them at scale legally perilous<p>Loading data to which you have no rights over into your software is legally perilous, yes.<p>It&#x27;s as easy as simply asking for and receiving permission from the data&#x27;s rightsholders (which might require exchange of coin) to make it not legally perilous.</div><br/></div></div></div></div></div></div><div id="38791304" class="c"><input type="checkbox" id="c-38791304" checked=""/><div class="controls bullet"><span class="by">kazinator</span><span>|</span><a href="#38790985">prev</a><span>|</span><a href="#38791399">next</a><span>|</span><label class="collapse" for="c-38791304">[-]</label><label class="expand" for="c-38791304">[1 more]</label></div><br/><div class="children"><div class="content">Should be: &quot;NY Times wants OpenÄI to delete all GPT instances&quot;. You wouldn&#x27;t want the hapless rabble misreading it as an &quot;aiii&quot; diphthong.</div><br/></div></div><div id="38791399" class="c"><input type="checkbox" id="c-38791399" checked=""/><div class="controls bullet"><span class="by">cynicalsecurity</span><span>|</span><a href="#38791304">prev</a><span>|</span><a href="#38791209">next</a><span>|</span><label class="collapse" for="c-38791399">[-]</label><label class="expand" for="c-38791399">[1 more]</label></div><br/><div class="children"><div class="content">Nothing will come out of it. NY times will lose.</div><br/></div></div><div id="38791209" class="c"><input type="checkbox" id="c-38791209" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38791399">prev</a><span>|</span><a href="#38790305">next</a><span>|</span><label class="collapse" for="c-38791209">[-]</label><label class="expand" for="c-38791209">[4 more]</label></div><br/><div class="children"><div class="content">in my head I like to think of web crawler search engines&#x2F;search engine databases and LLMs as being somewhat similar. Search engines are ok if they just provide snippets with citations (urls), and they would be unacceptable if they provided large block quotes that removed the need to go to the original source to read the original expression of more complex ideas.<p>A web-crawled LLM that lived within the same constraints would be a search engine under another name, with a slightly different presentation style. If it starts spitting out entire articles without citation, that&#x27;s not acceptable.</div><br/><div id="38791280" class="c"><input type="checkbox" id="c-38791280" checked=""/><div class="controls bullet"><span class="by">aurareturn</span><span>|</span><a href="#38791209">parent</a><span>|</span><a href="#38790305">next</a><span>|</span><label class="collapse" for="c-38791280">[-]</label><label class="expand" for="c-38791280">[3 more]</label></div><br/><div class="children"><div class="content">I think it&#x27;s different. LLMs can solve problems. Part of that problem-solving ability comes from training completely unrelated content such as NYT articles. GPT4 doesn&#x27;t have to spit out NYT articles verbatim to have benefited from NYT articles. It uses NYT articles for every query.</div><br/><div id="38791436" class="c"><input type="checkbox" id="c-38791436" checked=""/><div class="controls bullet"><span class="by">fsckboy</span><span>|</span><a href="#38791209">root</a><span>|</span><a href="#38791280">parent</a><span>|</span><a href="#38790305">next</a><span>|</span><label class="collapse" for="c-38791436">[-]</label><label class="expand" for="c-38791436">[2 more]</label></div><br/><div class="children"><div class="content">Let&#x27;s say I&#x27;m an academic; if my research, note-taking, and paper writing skills lead to fair-use, cited quotations where applicable, general knowledge not identified, and the creative aspects and unique conclusions creating the intriguing part of my work, that&#x27;s copacetic. If I spit out (from memory, mind you) verbatim quotes and light rewordings of NY Times articles, that&#x27;s not; &quot;I don&#x27;t remember where I got that material&quot; doesn&#x27;t cut it. My reading the NY Times every day for years because I judge it to be more literate and accurate than other sources, undoubtedly it has informed my thinking and style, but I don&#x27;t need to acknowledge that.<p>If I use ChatGPT as a research tool, as long as it lives within the same parameters that I have to live within, I don&#x27;t see a problem with its education&#x2F;learning.<p>I understand that the NYTimes would like a slice of anything that comes out of the GPT but I&#x27;m talking about what seems reasonable. People who share their copyrighted material do not own all of the thinking that comes out of it; they own that expression of it, that is all.</div><br/><div id="38791465" class="c"><input type="checkbox" id="c-38791465" checked=""/><div class="controls bullet"><span class="by">aurareturn</span><span>|</span><a href="#38791209">root</a><span>|</span><a href="#38791436">parent</a><span>|</span><a href="#38790305">next</a><span>|</span><label class="collapse" for="c-38791465">[-]</label><label class="expand" for="c-38791465">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re not replicating yourself millions of times and selling yourself for $20&#x2F;month. If you are, then NYT might sue you too.<p>I&#x27;m not saying LLMs are by default, illegal. All I&#x27;m saying is that there is some merit to why NYT and content companies want a piece of the pie and think they deserve it.</div><br/></div></div></div></div></div></div></div></div><div id="38790305" class="c"><input type="checkbox" id="c-38790305" checked=""/><div class="controls bullet"><span class="by">biglyburrito</span><span>|</span><a href="#38791209">prev</a><span>|</span><a href="#38790454">next</a><span>|</span><label class="collapse" for="c-38790305">[-]</label><label class="expand" for="c-38790305">[9 more]</label></div><br/><div class="children"><div class="content">TLDR:<p>&quot;The suit seeks nothing less than the erasure of both any GPT instances that the parties have trained using material from the Times, as well as the destruction of the datasets that were used for the training. It also asks for a permanent injunction to prevent similar conduct in the future. The Times also wants money, lots and lots of money: &quot;statutory damages, compensatory damages, restitution, disgorgement, and any other relief that may be permitted by law or equity.&quot;&quot;</div><br/><div id="38790558" class="c"><input type="checkbox" id="c-38790558" checked=""/><div class="controls bullet"><span class="by">chongli</span><span>|</span><a href="#38790305">parent</a><span>|</span><a href="#38790393">next</a><span>|</span><label class="collapse" for="c-38790558">[-]</label><label class="expand" for="c-38790558">[2 more]</label></div><br/><div class="children"><div class="content">This is what lawyers are paid for. They ask for the max because there’s no harm in doing so. Everyone knows there’s little meaning to that.</div><br/><div id="38790578" class="c"><input type="checkbox" id="c-38790578" checked=""/><div class="controls bullet"><span class="by">greggsy</span><span>|</span><a href="#38790305">root</a><span>|</span><a href="#38790558">parent</a><span>|</span><a href="#38790393">next</a><span>|</span><label class="collapse" for="c-38790578">[-]</label><label class="expand" for="c-38790578">[1 more]</label></div><br/><div class="children"><div class="content">They always go for the max, knowing that they will settle somewhere closer to the expected rate.</div><br/></div></div></div></div><div id="38790393" class="c"><input type="checkbox" id="c-38790393" checked=""/><div class="controls bullet"><span class="by">downWidOutaFite</span><span>|</span><a href="#38790305">parent</a><span>|</span><a href="#38790558">prev</a><span>|</span><a href="#38790454">next</a><span>|</span><label class="collapse" for="c-38790393">[-]</label><label class="expand" for="c-38790393">[6 more]</label></div><br/><div class="children"><div class="content">Wow they want to kill it. I wonder if we&#x27;ve just lived through the golden Napster era of LLMs.</div><br/><div id="38790482" class="c"><input type="checkbox" id="c-38790482" checked=""/><div class="controls bullet"><span class="by">suby</span><span>|</span><a href="#38790305">root</a><span>|</span><a href="#38790393">parent</a><span>|</span><a href="#38790398">next</a><span>|</span><label class="collapse" for="c-38790482">[-]</label><label class="expand" for="c-38790482">[2 more]</label></div><br/><div class="children"><div class="content">They may just want a licensing deal.</div><br/><div id="38790579" class="c"><input type="checkbox" id="c-38790579" checked=""/><div class="controls bullet"><span class="by">weikju</span><span>|</span><a href="#38790305">root</a><span>|</span><a href="#38790482">parent</a><span>|</span><a href="#38790398">next</a><span>|</span><label class="collapse" for="c-38790579">[-]</label><label class="expand" for="c-38790579">[1 more]</label></div><br/><div class="children"><div class="content">They&#x27;re already working on it with Apple (see my other reply in this discussion), so I wouldn&#x27;t doubt that this is another salvo in the same battle.</div><br/></div></div></div></div><div id="38790398" class="c"><input type="checkbox" id="c-38790398" checked=""/><div class="controls bullet"><span class="by">readthenotes1</span><span>|</span><a href="#38790305">root</a><span>|</span><a href="#38790393">parent</a><span>|</span><a href="#38790482">prev</a><span>|</span><a href="#38790454">next</a><span>|</span><label class="collapse" for="c-38790398">[-]</label><label class="expand" for="c-38790398">[3 more]</label></div><br/><div class="children"><div class="content">Just train on NYT articles no longer in copyright. We may be better for it.</div><br/><div id="38791003" class="c"><input type="checkbox" id="c-38791003" checked=""/><div class="controls bullet"><span class="by">vidarh</span><span>|</span><a href="#38790305">root</a><span>|</span><a href="#38790398">parent</a><span>|</span><a href="#38790688">next</a><span>|</span><label class="collapse" for="c-38791003">[-]</label><label class="expand" for="c-38791003">[1 more]</label></div><br/><div class="children"><div class="content">Or buy them. OpenAI market cap is many times NYT.<p>If we see court judgements start to go copyright owners way, we will also see a scramble from AI companies to buy the few publishers with enough data to be worth buying, and to create works for hire to replace the rest.<p>In the long run a copyright ruling like that will be a boon for OpenAI and all other players with deep enough pockets to do so, and massively harm everyone else who will suddenly find it far harder to build models legally.</div><br/></div></div><div id="38790688" class="c"><input type="checkbox" id="c-38790688" checked=""/><div class="controls bullet"><span class="by">mynegation</span><span>|</span><a href="#38790305">root</a><span>|</span><a href="#38790398">parent</a><span>|</span><a href="#38791003">prev</a><span>|</span><a href="#38790454">next</a><span>|</span><label class="collapse" for="c-38790688">[-]</label><label class="expand" for="c-38790688">[1 more]</label></div><br/><div class="children"><div class="content">Next thing you know ChatGPT gives you the best way to crank your automobile and take good care of your crinoline.</div><br/></div></div></div></div></div></div></div></div><div id="38790454" class="c"><input type="checkbox" id="c-38790454" checked=""/><div class="controls bullet"><span class="by">strangus</span><span>|</span><a href="#38790305">prev</a><span>|</span><a href="#38790348">next</a><span>|</span><label class="collapse" for="c-38790454">[-]</label><label class="expand" for="c-38790454">[3 more]</label></div><br/><div class="children"><div class="content">Next up, Microsoft acquires the New York Times forming MSNYT</div><br/><div id="38790571" class="c"><input type="checkbox" id="c-38790571" checked=""/><div class="controls bullet"><span class="by">playingalong</span><span>|</span><a href="#38790454">parent</a><span>|</span><a href="#38790981">next</a><span>|</span><label class="collapse" for="c-38790571">[-]</label><label class="expand" for="c-38790571">[1 more]</label></div><br/><div class="children"><div class="content">... New Roman</div><br/></div></div><div id="38790981" class="c"><input type="checkbox" id="c-38790981" checked=""/><div class="controls bullet"><span class="by">unsupp0rted</span><span>|</span><a href="#38790454">parent</a><span>|</span><a href="#38790571">prev</a><span>|</span><a href="#38790348">next</a><span>|</span><label class="collapse" for="c-38790981">[-]</label><label class="expand" for="c-38790981">[1 more]</label></div><br/><div class="children"><div class="content">This is not impossible, and perhaps not even unlikely</div><br/></div></div></div></div><div id="38790348" class="c"><input type="checkbox" id="c-38790348" checked=""/><div class="controls bullet"><span class="by">weikju</span><span>|</span><a href="#38790454">prev</a><span>|</span><a href="#38790475">next</a><span>|</span><label class="collapse" for="c-38790348">[-]</label><label class="expand" for="c-38790348">[1 more]</label></div><br/><div class="children"><div class="content">Probably has something to do with impending deals between NYT and major companies, e.g.<p>[0] <a href="https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;12&#x2F;22&#x2F;technology&#x2F;apple-ai-news-publishers.html" rel="nofollow">https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;12&#x2F;22&#x2F;technology&#x2F;apple-ai-news-...</a><p>[1] <a href="https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;12&#x2F;22&#x2F;24012730&#x2F;apple-ai-models-news-publishers" rel="nofollow">https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;12&#x2F;22&#x2F;24012730&#x2F;apple-ai-models...</a></div><br/></div></div><div id="38790475" class="c"><input type="checkbox" id="c-38790475" checked=""/><div class="controls bullet"><span class="by">sackfield</span><span>|</span><a href="#38790348">prev</a><span>|</span><a href="#38790891">next</a><span>|</span><label class="collapse" for="c-38790475">[-]</label><label class="expand" for="c-38790475">[1 more]</label></div><br/><div class="children"><div class="content">Something I have wondered about LLMs and training data is the idea that the biggest content producers on the internet now have their world view and tone echoed disproportionately as part of the next big wave of technology. This is incredibly impactful (although admittedly I don&#x27;t know how to turn that into a profit). Is there some long term impact of removing the New York Times from training data that means it won&#x27;t be part of the LLMs corpus going forward that is unforeseen?</div><br/></div></div><div id="38790891" class="c"><input type="checkbox" id="c-38790891" checked=""/><div class="controls bullet"><span class="by">ChrisArchitect</span><span>|</span><a href="#38790475">prev</a><span>|</span><a href="#38791206">next</a><span>|</span><label class="collapse" for="c-38790891">[-]</label><label class="expand" for="c-38790891">[2 more]</label></div><br/><div class="children"><div class="content">[dupe]<p>Discussion here: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38781941">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38781941</a></div><br/><div id="38791152" class="c"><input type="checkbox" id="c-38791152" checked=""/><div class="controls bullet"><span class="by">kristianp</span><span>|</span><a href="#38790891">parent</a><span>|</span><a href="#38791206">next</a><span>|</span><label class="collapse" for="c-38791152">[-]</label><label class="expand" for="c-38791152">[1 more]</label></div><br/><div class="children"><div class="content">True, the Verge article was posted here earlier.</div><br/></div></div></div></div><div id="38791206" class="c"><input type="checkbox" id="c-38791206" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#38790891">prev</a><span>|</span><a href="#38790420">next</a><span>|</span><label class="collapse" for="c-38791206">[-]</label><label class="expand" for="c-38791206">[1 more]</label></div><br/><div class="children"><div class="content">Wondering who tf reads old NYT articles? News become old really fast. chatGPT is months or years behind.</div><br/></div></div><div id="38790420" class="c"><input type="checkbox" id="c-38790420" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#38791206">prev</a><span>|</span><a href="#38790600">next</a><span>|</span><label class="collapse" for="c-38790420">[-]</label><label class="expand" for="c-38790420">[10 more]</label></div><br/><div class="children"><div class="content">It&#x27;s obviously a frivolous suit that will only net at best a ceremonial victory for NYTimes: 8 figure max payout and a promise to not use NYtimes material in the future.<p>The trajectory and value to society of OpenAI vs NYtimes could not be greater. They have won no favors in the court of public opinion with their frequent misinformation. It&#x27;s all just a big waste of time, the last of the old guard flailing against the march of progress.<p>And even hypothetially if they managed to get OpenAI to delete ChatGPT they&#x27;d be hated forever.</div><br/><div id="38790865" class="c"><input type="checkbox" id="c-38790865" checked=""/><div class="controls bullet"><span class="by">faeriechangling</span><span>|</span><a href="#38790420">parent</a><span>|</span><a href="#38790497">next</a><span>|</span><label class="collapse" for="c-38790865">[-]</label><label class="expand" for="c-38790865">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;ve never really known The New York Times to file frivolous lawsuits.</div><br/></div></div><div id="38790497" class="c"><input type="checkbox" id="c-38790497" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#38790420">parent</a><span>|</span><a href="#38790865">prev</a><span>|</span><a href="#38790465">next</a><span>|</span><label class="collapse" for="c-38790497">[-]</label><label class="expand" for="c-38790497">[1 more]</label></div><br/><div class="children"><div class="content">Nobody is looking at this suit as applying to the Times exclusively – and neither will the courts.</div><br/></div></div><div id="38790456" class="c"><input type="checkbox" id="c-38790456" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38790420">parent</a><span>|</span><a href="#38790465">prev</a><span>|</span><a href="#38790600">next</a><span>|</span><label class="collapse" for="c-38790456">[-]</label><label class="expand" for="c-38790456">[6 more]</label></div><br/><div class="children"><div class="content">&gt; They have won no favors in the court of public opinion with their frequent misinformation.<p>You mean GPT here, right?</div><br/><div id="38790468" class="c"><input type="checkbox" id="c-38790468" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#38790420">root</a><span>|</span><a href="#38790456">parent</a><span>|</span><a href="#38790600">next</a><span>|</span><label class="collapse" for="c-38790468">[-]</label><label class="expand" for="c-38790468">[5 more]</label></div><br/><div class="children"><div class="content">ChatGPT only advertises itself as a fancy autocomplete. There is a disclaimer that it may produce output that appears correct but isn&#x27;t. NYtimes written material purports itself to be the truth, thus shouldn&#x27;t be held to the same standards as a generative AI obviously.</div><br/><div id="38790505" class="c"><input type="checkbox" id="c-38790505" checked=""/><div class="controls bullet"><span class="by">15457345234</span><span>|</span><a href="#38790420">root</a><span>|</span><a href="#38790468">parent</a><span>|</span><a href="#38790600">next</a><span>|</span><label class="collapse" for="c-38790505">[-]</label><label class="expand" for="c-38790505">[4 more]</label></div><br/><div class="children"><div class="content">I think what we should focus on is the volume of misinformation in general, not the provenance of it.<p>The NYT may produce misinformation but it aims not to, and its staff of human writers are limited in the quantity that they can produce. They also publish corrections.<p>GPT enables anyone who can pay to generate a virtually unlimited volume of misinformation, launder it into &#x27;articles&#x27; with fake bylines and saturate the internet with garbage.<p>I think we need to focus on the damage done.</div><br/><div id="38790515" class="c"><input type="checkbox" id="c-38790515" checked=""/><div class="controls bullet"><span class="by">atleastoptimal</span><span>|</span><a href="#38790420">root</a><span>|</span><a href="#38790505">parent</a><span>|</span><a href="#38791004">next</a><span>|</span><label class="collapse" for="c-38790515">[-]</label><label class="expand" for="c-38790515">[1 more]</label></div><br/><div class="children"><div class="content">Well that&#x27;s true for any large language model. As long as they exist there will be a deluge of bot written text producible for any purpose. At this point there is no getting the cat back into the bag.<p>In that case the bigger danger is Open source LLM&#x27;s. OpenAI at least monitors the use of their endpoints for obvious harm.</div><br/></div></div><div id="38791004" class="c"><input type="checkbox" id="c-38791004" checked=""/><div class="controls bullet"><span class="by">realusername</span><span>|</span><a href="#38790420">root</a><span>|</span><a href="#38790505">parent</a><span>|</span><a href="#38790515">prev</a><span>|</span><a href="#38790557">next</a><span>|</span><label class="collapse" for="c-38791004">[-]</label><label class="expand" for="c-38791004">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The NYT may produce misinformation but it aims not to, and its staff of human writers are limited in the quantity that they can produce. They also publish corrections.<p>Except when it affects their bottom line of course, they publicly lied on how meta tags work during the lawsuits against Google to get more money (like most newspapers did). And I have no doubt that they will extensively lie once again on how LLM really work.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="38790600" class="c"><input type="checkbox" id="c-38790600" checked=""/><div class="controls bullet"><span class="by">cycrutchfield</span><span>|</span><a href="#38790420">prev</a><span>|</span><a href="#38791095">next</a><span>|</span><label class="collapse" for="c-38790600">[-]</label><label class="expand" for="c-38790600">[9 more]</label></div><br/><div class="children"><div class="content">I read a NYT article and publish a summary of facts that I learned: totally legit.<p>Train a model on NYT text that outputs a summary of facts that it learned: OMG literally murder.</div><br/><div id="38790832" class="c"><input type="checkbox" id="c-38790832" checked=""/><div class="controls bullet"><span class="by">bloppe</span><span>|</span><a href="#38790600">parent</a><span>|</span><a href="#38790679">next</a><span>|</span><label class="collapse" for="c-38790832">[-]</label><label class="expand" for="c-38790832">[4 more]</label></div><br/><div class="children"><div class="content">Sounds like you didn&#x27;t read the article. Here&#x27;s a better synoposis:<p>I read a NYT article and publish an exact copy of that article on my website: copyright infringement.<p>Train a model on NYT text and it outputs an exact copy of that text: also copyright infringement.</div><br/><div id="38790937" class="c"><input type="checkbox" id="c-38790937" checked=""/><div class="controls bullet"><span class="by">slyall</span><span>|</span><a href="#38790600">root</a><span>|</span><a href="#38790832">parent</a><span>|</span><a href="#38790877">next</a><span>|</span><label class="collapse" for="c-38790937">[-]</label><label class="expand" for="c-38790937">[1 more]</label></div><br/><div class="children"><div class="content">A small number of outputs of ChatGPT are close enough to training articles to be (probably) copyright infringement.<p>What does that mean?<p>Look up &quot;substantial non-infringing use&quot; and this little court case:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sony_Corp._of_America_v._Universal_City_Studios,_Inc" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sony_Corp._of_America_v._Unive...</a>.<p>Now spend a few million on lawyers and roll your dice.</div><br/></div></div><div id="38790877" class="c"><input type="checkbox" id="c-38790877" checked=""/><div class="controls bullet"><span class="by">cycrutchfield</span><span>|</span><a href="#38790600">root</a><span>|</span><a href="#38790832">parent</a><span>|</span><a href="#38790937">prev</a><span>|</span><a href="#38790679">next</a><span>|</span><label class="collapse" for="c-38790877">[-]</label><label class="expand" for="c-38790877">[2 more]</label></div><br/><div class="children"><div class="content">So presumably when they fix that issue (which, if the text matches exactly, should be trivially easy) then would you accept that as a sufficient remedy?</div><br/><div id="38790961" class="c"><input type="checkbox" id="c-38790961" checked=""/><div class="controls bullet"><span class="by">tarruda</span><span>|</span><a href="#38790600">root</a><span>|</span><a href="#38790877">parent</a><span>|</span><a href="#38790679">next</a><span>|</span><label class="collapse" for="c-38790961">[-]</label><label class="expand" for="c-38790961">[1 more]</label></div><br/><div class="children"><div class="content">&gt; then would you accept that as a sufficient remedy?<p>Probably not until they pay him a hefty copyright fee.</div><br/></div></div></div></div></div></div><div id="38790679" class="c"><input type="checkbox" id="c-38790679" checked=""/><div class="controls bullet"><span class="by">up2isomorphism</span><span>|</span><a href="#38790600">parent</a><span>|</span><a href="#38790832">prev</a><span>|</span><a href="#38790723">next</a><span>|</span><label class="collapse" for="c-38790679">[-]</label><label class="expand" for="c-38790679">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s why there will be a legalization of the fair use. Just let your intellectual to be used for free training material is not sustainable.<p>Also remember copyright laws was not there in the first place.</div><br/></div></div><div id="38790723" class="c"><input type="checkbox" id="c-38790723" checked=""/><div class="controls bullet"><span class="by">bad_user</span><span>|</span><a href="#38790600">parent</a><span>|</span><a href="#38790679">prev</a><span>|</span><a href="#38790697">next</a><span>|</span><label class="collapse" for="c-38790723">[-]</label><label class="expand" for="c-38790723">[2 more]</label></div><br/><div class="children"><div class="content">Fair use is intended for humans, much like copyright in general.<p>If you can&#x27;t copyright AI-generated pieces, then why would fair use apply to LLMs?</div><br/><div id="38791142" class="c"><input type="checkbox" id="c-38791142" checked=""/><div class="controls bullet"><span class="by">mdekkers</span><span>|</span><a href="#38790600">root</a><span>|</span><a href="#38790723">parent</a><span>|</span><a href="#38790697">next</a><span>|</span><label class="collapse" for="c-38791142">[-]</label><label class="expand" for="c-38791142">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Fair use is intended for humans.<p>Is it? Can you quote relevant legislation or case law?</div><br/></div></div></div></div><div id="38790697" class="c"><input type="checkbox" id="c-38790697" checked=""/><div class="controls bullet"><span class="by">zozbot234</span><span>|</span><a href="#38790600">parent</a><span>|</span><a href="#38790723">prev</a><span>|</span><a href="#38791095">next</a><span>|</span><label class="collapse" for="c-38790697">[-]</label><label class="expand" for="c-38790697">[1 more]</label></div><br/><div class="children"><div class="content">Because it&#x27;s not just summarizing the bare facts.  It&#x27;s a parrot.</div><br/></div></div></div></div><div id="38790382" class="c"><input type="checkbox" id="c-38790382" checked=""/><div class="controls bullet"><span class="by">outside1234</span><span>|</span><a href="#38791095">prev</a><span>|</span><label class="collapse" for="c-38790382">[-]</label><label class="expand" for="c-38790382">[9 more]</label></div><br/><div class="children"><div class="content">Seems reasonable - they probably broke the TOS of the site</div><br/><div id="38790769" class="c"><input type="checkbox" id="c-38790769" checked=""/><div class="controls bullet"><span class="by">yjftsjthsd-h</span><span>|</span><a href="#38790382">parent</a><span>|</span><a href="#38791023">next</a><span>|</span><label class="collapse" for="c-38790769">[-]</label><label class="expand" for="c-38790769">[1 more]</label></div><br/><div class="children"><div class="content">Did OpenAI agree to those ToS? If not, I think (IANAL) LinkedIn was kind enough to give precedent that it&#x27;s irrelevant.<p>( <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;HiQ_Labs_v._LinkedIn" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;HiQ_Labs_v._LinkedIn</a> )</div><br/></div></div><div id="38791023" class="c"><input type="checkbox" id="c-38791023" checked=""/><div class="controls bullet"><span class="by">KETHERCORTEX</span><span>|</span><a href="#38790382">parent</a><span>|</span><a href="#38790769">prev</a><span>|</span><a href="#38790502">next</a><span>|</span><label class="collapse" for="c-38791023">[-]</label><label class="expand" for="c-38791023">[2 more]</label></div><br/><div class="children"><div class="content">On the other hand, NYT website willingly gave out all the information without imposing limitations. Seeing terms of service requires visiting a separate page, they aren&#x27;t seen immediately upon visiting the website. Understanding and accepting the terms also requires a human interaction.<p>robots.txt on nytimes.com now disallows indexing by GPTBot, so there&#x27;s an argument against automated information acquisition starting from some moment, but before some moment they weren&#x27;t explicitly against that.</div><br/><div id="38791054" class="c"><input type="checkbox" id="c-38791054" checked=""/><div class="controls bullet"><span class="by">arrrg</span><span>|</span><a href="#38790382">root</a><span>|</span><a href="#38791023">parent</a><span>|</span><a href="#38790502">next</a><span>|</span><label class="collapse" for="c-38791054">[-]</label><label class="expand" for="c-38791054">[1 more]</label></div><br/><div class="children"><div class="content">Seems weird to argue that you have to speak up if you don’t want something done to you or else you consent to everything.<p>I do think that’s the case for some things but especially for new things that doesn’t seem like a common sense understanding of the world.</div><br/></div></div></div></div><div id="38790502" class="c"><input type="checkbox" id="c-38790502" checked=""/><div class="controls bullet"><span class="by">thallium205</span><span>|</span><a href="#38790382">parent</a><span>|</span><a href="#38791023">prev</a><span>|</span><label class="collapse" for="c-38790502">[-]</label><label class="expand" for="c-38790502">[5 more]</label></div><br/><div class="children"><div class="content">What if they OCR’d the newspapers?  No ToS there.</div><br/><div id="38790651" class="c"><input type="checkbox" id="c-38790651" checked=""/><div class="controls bullet"><span class="by">steve1977</span><span>|</span><a href="#38790382">root</a><span>|</span><a href="#38790502">parent</a><span>|</span><a href="#38790583">next</a><span>|</span><label class="collapse" for="c-38790651">[-]</label><label class="expand" for="c-38790651">[3 more]</label></div><br/><div class="children"><div class="content">I’m pretty sure there is still a copyright also for the physical newspaper.</div><br/><div id="38790707" class="c"><input type="checkbox" id="c-38790707" checked=""/><div class="controls bullet"><span class="by">pyuser583</span><span>|</span><a href="#38790382">root</a><span>|</span><a href="#38790651">parent</a><span>|</span><a href="#38790583">next</a><span>|</span><label class="collapse" for="c-38790707">[-]</label><label class="expand" for="c-38790707">[2 more]</label></div><br/><div class="children"><div class="content">For the paper or the author? What exactly was the licensing agreement for Op-Ed authors in 1962?</div><br/><div id="38790807" class="c"><input type="checkbox" id="c-38790807" checked=""/><div class="controls bullet"><span class="by">bloppe</span><span>|</span><a href="#38790382">root</a><span>|</span><a href="#38790707">parent</a><span>|</span><a href="#38790583">next</a><span>|</span><label class="collapse" for="c-38790807">[-]</label><label class="expand" for="c-38790807">[1 more]</label></div><br/><div class="children"><div class="content">Read the article. It&#x27;s not difficult to get ChatGPT to regurgitate recent, obviously copyrighted articles, verbatim.</div><br/></div></div></div></div></div></div><div id="38790583" class="c"><input type="checkbox" id="c-38790583" checked=""/><div class="controls bullet"><span class="by">product-render</span><span>|</span><a href="#38790382">root</a><span>|</span><a href="#38790502">parent</a><span>|</span><a href="#38790651">prev</a><span>|</span><label class="collapse" for="c-38790583">[-]</label><label class="expand" for="c-38790583">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s at least partially a copyright claim, isn&#x27;t it? So the method -- OCR or scraping -- doesn&#x27;t matter, I  think.</div><br/></div></div></div></div></div></div></div></div></div></div></div></body></html>