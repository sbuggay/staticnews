<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1695114058970" as="style"/><link rel="stylesheet" href="styles.css?v=1695114058970"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://ai.meta.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/">Self-supervised learning: The dark matter of intelligence (2021)</a> <span class="domain">(<a href="https://ai.meta.com">ai.meta.com</a>)</span></div><div class="subtext"><span>reqo</span> | <span>22 comments</span></div><br/><div><div id="37560751" class="c"><input type="checkbox" id="c-37560751" checked=""/><div class="controls bullet"><span class="by">neonate</span><span>|</span><a href="#37560724">next</a><span>|</span><label class="collapse" for="c-37560751">[-]</label><label class="expand" for="c-37560751">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230816163400&#x2F;https:&#x2F;&#x2F;ai.meta.com&#x2F;blog&#x2F;self-supervised-learning-the-dark-matter-of-intelligence&#x2F;" rel="nofollow noreferrer">https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230816163400&#x2F;https:&#x2F;&#x2F;ai.meta.c...</a></div><br/></div></div><div id="37560724" class="c"><input type="checkbox" id="c-37560724" checked=""/><div class="controls bullet"><span class="by">dang</span><span>|</span><a href="#37560751">prev</a><span>|</span><a href="#37565156">next</a><span>|</span><label class="collapse" for="c-37560724">[-]</label><label class="expand" for="c-37560724">[10 more]</label></div><br/><div class="children"><div class="content">Discussed at the time:<p><i>Self-supervised learning: The dark matter of intelligence</i> - <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26431507">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26431507</a> - March 2021 (74 comments)</div><br/><div id="37562686" class="c"><input type="checkbox" id="c-37562686" checked=""/><div class="controls bullet"><span class="by">3abiton</span><span>|</span><a href="#37560724">parent</a><span>|</span><a href="#37562062">next</a><span>|</span><label class="collapse" for="c-37562686">[-]</label><label class="expand" for="c-37562686">[8 more]</label></div><br/><div class="children"><div class="content">In light of LLMs it seems relevant.</div><br/><div id="37565396" class="c"><input type="checkbox" id="c-37565396" checked=""/><div class="controls bullet"><span class="by">isaacfung</span><span>|</span><a href="#37560724">root</a><span>|</span><a href="#37562686">parent</a><span>|</span><a href="#37562780">next</a><span>|</span><label class="collapse" for="c-37565396">[-]</label><label class="expand" for="c-37565396">[3 more]</label></div><br/><div class="children"><div class="content">This article was written in 2021 when masked language models have been successfully applied in nlp(Bert, word2vec, glove, etc). However at the time, it was unclear how the same technique could be applied to vision tasks because unlike language which has a limited vocab, you can&#x27;t explicitly assign a probability to every possible image. Since then researchers have already made significant progress with techniques like contrastive learning(simclr), self distillation (BYOL, DINO), masked image models, etc. A cookbook of self-supervised learning is a good source to learn more about this topic.  
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.12210" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.12210</a></div><br/><div id="37565673" class="c"><input type="checkbox" id="c-37565673" checked=""/><div class="controls bullet"><span class="by">imjonse</span><span>|</span><a href="#37560724">root</a><span>|</span><a href="#37565396">parent</a><span>|</span><a href="#37562780">next</a><span>|</span><label class="collapse" for="c-37565673">[-]</label><label class="expand" for="c-37565673">[2 more]</label></div><br/><div class="children"><div class="content">SimCLR and others are older than 2021, BYOL is even mentioned in the blogpost. But your link indeed points to a more comprehensive overview.</div><br/><div id="37566016" class="c"><input type="checkbox" id="c-37566016" checked=""/><div class="controls bullet"><span class="by">isaacfung</span><span>|</span><a href="#37560724">root</a><span>|</span><a href="#37565673">parent</a><span>|</span><a href="#37562780">next</a><span>|</span><label class="collapse" for="c-37566016">[-]</label><label class="expand" for="c-37566016">[1 more]</label></div><br/><div class="children"><div class="content">You are correct that SimCLR and BYOL were released one year earlier. Sorry I worded it poorly. By &quot;at the time&quot;, I meant the period of time when masked language models just found success in NLP.</div><br/></div></div></div></div></div></div><div id="37562780" class="c"><input type="checkbox" id="c-37562780" checked=""/><div class="controls bullet"><span class="by">thelastparadise</span><span>|</span><a href="#37560724">root</a><span>|</span><a href="#37562686">parent</a><span>|</span><a href="#37565396">prev</a><span>|</span><a href="#37562062">next</a><span>|</span><label class="collapse" for="c-37562780">[-]</label><label class="expand" for="c-37562780">[4 more]</label></div><br/><div class="children"><div class="content">Especially in light of the releases of LLaMA and v2.</div><br/><div id="37564455" class="c"><input type="checkbox" id="c-37564455" checked=""/><div class="controls bullet"><span class="by">p1esk</span><span>|</span><a href="#37560724">root</a><span>|</span><a href="#37562780">parent</a><span>|</span><a href="#37562062">next</a><span>|</span><label class="collapse" for="c-37564455">[-]</label><label class="expand" for="c-37564455">[3 more]</label></div><br/><div class="children"><div class="content">I have no idea what you mean. The article is mainly about dealing with uncertainty when trying to predict visual information. LLMs have no such problem.</div><br/><div id="37564826" class="c"><input type="checkbox" id="c-37564826" checked=""/><div class="controls bullet"><span class="by">lukeinator42</span><span>|</span><a href="#37560724">root</a><span>|</span><a href="#37564455">parent</a><span>|</span><a href="#37564817">next</a><span>|</span><label class="collapse" for="c-37564826">[-]</label><label class="expand" for="c-37564826">[1 more]</label></div><br/><div class="children"><div class="content">LLMs are using self-supervised learning and the article talks about uncertainty when trying to predict missing information in the NLP domain and how it compares to the visual domain (and why it works so well for the NLP domain).</div><br/></div></div></div></div></div></div></div></div></div></div><div id="37565156" class="c"><input type="checkbox" id="c-37565156" checked=""/><div class="controls bullet"><span class="by">lukeplato</span><span>|</span><a href="#37560724">prev</a><span>|</span><a href="#37565643">next</a><span>|</span><label class="collapse" for="c-37565156">[-]</label><label class="expand" for="c-37565156">[2 more]</label></div><br/><div class="children"><div class="content">I recommend watching the Hinton talk on dark knowledge on YouTube</div><br/><div id="37566233" class="c"><input type="checkbox" id="c-37566233" checked=""/><div class="controls bullet"><span class="by">killjoywashere</span><span>|</span><a href="#37565156">parent</a><span>|</span><a href="#37565643">next</a><span>|</span><label class="collapse" for="c-37566233">[-]</label><label class="expand" for="c-37566233">[1 more]</label></div><br/><div class="children"><div class="content">tl;dw?</div><br/></div></div></div></div><div id="37565643" class="c"><input type="checkbox" id="c-37565643" checked=""/><div class="controls bullet"><span class="by">colordrops</span><span>|</span><a href="#37565156">prev</a><span>|</span><a href="#37565418">next</a><span>|</span><label class="collapse" for="c-37565643">[-]</label><label class="expand" for="c-37565643">[2 more]</label></div><br/><div class="children"><div class="content">We are giving more credit to humans than is due.  We aren&#x27;t capable of solving any arbitrary problem thrown our way. There are classes of problems we are good at solving due to us just being human and evolving to solve them, just as certain classes of problems are solveable by dogs.  As referred to in this article, &quot;common sense&quot; is not some yet to be determined skill set, but rather the set of classes of problems humans are capable of solving that AI has not yet tackled.<p>Perhaps it&#x27;s a matter of the AI connectome not being vast enough. Perhaps it&#x27;s a deeper issue of AI architecture.  Anyway it seems that that in this sense, &quot;common sense&quot; and &quot;dark matter&quot; are indeed analogous, in that it&#x27;s just a place holder for yet to be understood (or at least emulated) phenomena.  Perhaps that was intentional by the author, I can&#x27;t tell.</div><br/><div id="37566048" class="c"><input type="checkbox" id="c-37566048" checked=""/><div class="controls bullet"><span class="by">jewelry</span><span>|</span><a href="#37565643">parent</a><span>|</span><a href="#37565418">next</a><span>|</span><label class="collapse" for="c-37566048">[-]</label><label class="expand" for="c-37566048">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. And this study did a good job exploring it philosophically. <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1911.01547" rel="nofollow noreferrer">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1911.01547</a></div><br/></div></div></div></div><div id="37565418" class="c"><input type="checkbox" id="c-37565418" checked=""/><div class="controls bullet"><span class="by">psuedo_uuh</span><span>|</span><a href="#37565643">prev</a><span>|</span><a href="#37559843">next</a><span>|</span><label class="collapse" for="c-37565418">[-]</label><label class="expand" for="c-37565418">[1 more]</label></div><br/><div class="children"><div class="content">Dark matter of intelligence. Do we think it’s going to prove that we live in a simulation? Ive always felt like the tech industry things too highly of ourselves and the naming of things hits at that. Artificial intelligence is a good example. Would using the word statistics in the name be more accurate with what’s going on?</div><br/></div></div><div id="37559843" class="c"><input type="checkbox" id="c-37559843" checked=""/><div class="controls bullet"><span class="by">phreeza</span><span>|</span><a href="#37565418">prev</a><span>|</span><a href="#37559888">next</a><span>|</span><label class="collapse" for="c-37559843">[-]</label><label class="expand" for="c-37559843">[2 more]</label></div><br/><div class="children"><div class="content">(2021)</div><br/></div></div></div></div></div></div></div></body></html>