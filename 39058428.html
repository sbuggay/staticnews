<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1705914075868" as="style"/><link rel="stylesheet" href="styles.css?v=1705914075868"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://nightshade.cs.uchicago.edu/whatis.html">Nightshade: An offensive tool for artists against AI art generators</a> <span class="domain">(<a href="https://nightshade.cs.uchicago.edu">nightshade.cs.uchicago.edu</a>)</span></div><div class="subtext"><span>ink404</span> | <span>281 comments</span></div><br/><div><div id="39058569" class="c"><input type="checkbox" id="c-39058569" checked=""/><div class="controls bullet"><span class="by">ink404</span><span>|</span><a href="#39068620">next</a><span>|</span><label class="collapse" for="c-39058569">[-]</label><label class="expand" for="c-39058569">[1 more]</label></div><br/><div class="children"><div class="content">Paper is here: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.13828" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.13828</a></div><br/></div></div><div id="39068620" class="c"><input type="checkbox" id="c-39068620" checked=""/><div class="controls bullet"><span class="by">542458</span><span>|</span><a href="#39058569">prev</a><span>|</span><a href="#39071577">next</a><span>|</span><label class="collapse" for="c-39068620">[-]</label><label class="expand" for="c-39068620">[53 more]</label></div><br/><div class="children"><div class="content">This seems to introduce levels of artifacts that many artists would find unacceptable: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;sini4ka111&#x2F;status&#x2F;1748378223291912567" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;sini4ka111&#x2F;status&#x2F;1748378223291912567</a><p>The rumblings I&#x27;m hearing are that this a) barely works with last-gen training processes b) does not work at all with more modern training processes (GPT-4V, LLaVA, even BLIP2 labelling [1]) and c) would not be especially challenging to mitigate against even should it become more effective and popular. The Authors&#x27; previous work, Glaze, also does not seem to be very effective despite dramatic proclamations to the contrary, so I think this might be a case of overhyping an academically interesting but real-world-impractical result.<p>[1]: Courtesy of &#x2F;u&#x2F;b3sn0w on Reddit: <a href="https:&#x2F;&#x2F;imgur.com&#x2F;cI7RLAq" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;cI7RLAq</a> <a href="https:&#x2F;&#x2F;imgur.com&#x2F;eqe3Dyn" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;eqe3Dyn</a> <a href="https:&#x2F;&#x2F;imgur.com&#x2F;1BMASL4" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;1BMASL4</a></div><br/><div id="39073648" class="c"><input type="checkbox" id="c-39073648" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39070858">next</a><span>|</span><label class="collapse" for="c-39073648">[-]</label><label class="expand" for="c-39073648">[15 more]</label></div><br/><div class="children"><div class="content">The screenshots you sent in [1] are inference, not training. You need to get a Nightshaded image into the training set of an image generator in order for this to have any effect. When you give an image to GPT-4V, Stable Diffusion img2img, or anything else, you&#x27;re not training the AI - the model is completely frozen and does not change at all[0].<p>I don&#x27;t know if anyone else is still scraping <i>new</i> images into the generators. I&#x27;ve heard somewhere that OpenAI stopped scraping around 2021 because they&#x27;re worried about training on the output of their own models[1]. Adobe Firefly claims to have been trained on Adobe Stock images, but we don&#x27;t know if Adobe has any particular cutoffs of their own[2].<p>If you want an image that screws up inference - i.e. one that GPT-4V or Stable Diffusion will choke on - you want an adversarial image. I don&#x27;t know if you can adversarially train on a model you don&#x27;t have weights for, though I&#x27;ve heard you can generalize adversarial training against multiple independent models to <i>really</i> screw shit up[3].<p>[0] All learning capability of text generators come from the fact that they have a context window; but that only provides a short term memory of 2048 tokens. They have no other memory capability.<p>[1] The scenario of what happens when you do this is fancifully called Habsburg AI. The model learns from it&#x27;s own biases, reinforcing them into stronger biases, while forgetting everything else.<p>[2] It&#x27;d be particularly ironic if the only thing Nightshade harms is the one AI generator that tried to be even slightly ethical.<p>[3] At the extremes, these adversarial images fool humans. Though, the study that did this intentionally only showed the images for a small period of time, the idea being that short exposures are akin to a feed-forward neural network with no recurrent computation pathways. If you look at them longer, it&#x27;s obvious that it&#x27;s a picture of one thing edited to look like another.</div><br/><div id="39075721" class="c"><input type="checkbox" id="c-39075721" checked=""/><div class="controls bullet"><span class="by">scheeseman486</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075848">next</a><span>|</span><label class="collapse" for="c-39075721">[-]</label><label class="expand" for="c-39075721">[7 more]</label></div><br/><div class="children"><div class="content">Hey you know what might not be AI generated post-2021? Almost everything run through Nightshade. So given it&#x27;s defeated, which is pretty likely, artists have effectively tagged their own work for inclusion.</div><br/><div id="39080480" class="c"><input type="checkbox" id="c-39080480" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39075721">parent</a><span>|</span><a href="#39076023">next</a><span>|</span><label class="collapse" for="c-39080480">[-]</label><label class="expand" for="c-39080480">[2 more]</label></div><br/><div class="children"><div class="content">Modern generative image models are trained on curated data, not raw internet data. Sometimes the captions are regenerated to fit the image better. Only high quality images with high quality descriptions.</div><br/><div id="39086137" class="c"><input type="checkbox" id="c-39086137" checked=""/><div class="controls bullet"><span class="by">og_kalu</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39080480">parent</a><span>|</span><a href="#39076023">next</a><span>|</span><label class="collapse" for="c-39086137">[-]</label><label class="expand" for="c-39086137">[1 more]</label></div><br/><div class="children"><div class="content">I wouldn&#x27;t call what Stable Diffusion et al are trained on &quot;high quality&quot;. You need only look through the likes of LAION to see the kind of captions and images they get trained on.<p>It&#x27;s not random but it&#x27;s not particularly curated either. Most of the time, any curation is done afterwards.</div><br/></div></div></div></div><div id="39076023" class="c"><input type="checkbox" id="c-39076023" checked=""/><div class="controls bullet"><span class="by">hkt</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39075721">parent</a><span>|</span><a href="#39080480">prev</a><span>|</span><a href="#39080814">next</a><span>|</span><label class="collapse" for="c-39076023">[-]</label><label class="expand" for="c-39076023">[3 more]</label></div><br/><div class="children"><div class="content">It is a great shame that we have come to a no-win situation for artists when VCs are virtually unable to lose.</div><br/><div id="39079474" class="c"><input type="checkbox" id="c-39079474" checked=""/><div class="controls bullet"><span class="by">ToucanLoucan</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39076023">parent</a><span>|</span><a href="#39080814">next</a><span>|</span><label class="collapse" for="c-39079474">[-]</label><label class="expand" for="c-39079474">[2 more]</label></div><br/><div class="children"><div class="content">I mean that&#x27;s more or less status quo isn&#x27;t it? Big business does what it wants, common people can get fucked if they don&#x27;t like it. Same as it ever was.</div><br/><div id="39082095" class="c"><input type="checkbox" id="c-39082095" checked=""/><div class="controls bullet"><span class="by">hkt</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39079474">parent</a><span>|</span><a href="#39080814">next</a><span>|</span><label class="collapse" for="c-39082095">[-]</label><label class="expand" for="c-39082095">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s exactly right. It is just the variety of new ways in which common people get fucked that is dispiriting, with seemingly nothing capable of moving in the opposite direction.</div><br/></div></div></div></div></div></div><div id="39080814" class="c"><input type="checkbox" id="c-39080814" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39075721">parent</a><span>|</span><a href="#39076023">prev</a><span>|</span><a href="#39075848">next</a><span>|</span><label class="collapse" for="c-39080814">[-]</label><label class="expand" for="c-39080814">[1 more]</label></div><br/><div class="children"><div class="content">Why wouldn&#x27;t an artist just generate AI spam and Nightshade it?</div><br/></div></div></div></div><div id="39075848" class="c"><input type="checkbox" id="c-39075848" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075721">prev</a><span>|</span><a href="#39075732">next</a><span>|</span><label class="collapse" for="c-39075848">[-]</label><label class="expand" for="c-39075848">[2 more]</label></div><br/><div class="children"><div class="content">Correct me if I&#x27;m wrong but I understand image generators as relying on auto-labeled images to understand what means what, and the point of this attack to make the auto-labelers mislabel the image, but as the top-level comment said it&#x27;s seemingly not tricking newer auto-labelers.</div><br/><div id="39077114" class="c"><input type="checkbox" id="c-39077114" checked=""/><div class="controls bullet"><span class="by">michaelbrave</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39075848">parent</a><span>|</span><a href="#39075732">next</a><span>|</span><label class="collapse" for="c-39077114">[-]</label><label class="expand" for="c-39077114">[1 more]</label></div><br/><div class="children"><div class="content">not all are auto labelled, some are hand labelled, some are initially labelled with something like clip&#x2F;blip&#x2F;booru and then corrected a bit by hand. The newest thing though is using llm&#x27;s with image support like GPT4 to label the images, which kind of does a much better job most of the time.<p>Your understanding of the attack was the same as mine, it injects just the right kinds of pixels to throw off the auto-labellers to misdirect what they are directing causing the tags to get shuffled around.<p>Also on reddit today some of the Stable Diffusion users are already starting to train using Nightshade so they can implement it as a negative model, which might or might not work, will have to see.</div><br/></div></div></div></div><div id="39075732" class="c"><input type="checkbox" id="c-39075732" checked=""/><div class="controls bullet"><span class="by">webmaven</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075848">prev</a><span>|</span><a href="#39075705">next</a><span>|</span><label class="collapse" for="c-39075732">[-]</label><label class="expand" for="c-39075732">[1 more]</label></div><br/><div class="children"><div class="content">Even if no new images are being scraped to train the foundation text-to-image models, you can be certain that there is a small horde of folk still scraping to create datasets for training fine-tuned models, LoRAs, Textual Inversions, and all the new hotness training methods still being created each day.</div><br/></div></div><div id="39075705" class="c"><input type="checkbox" id="c-39075705" checked=""/><div class="controls bullet"><span class="by">ptdn</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075732">prev</a><span>|</span><a href="#39075343">next</a><span>|</span><label class="collapse" for="c-39075705">[-]</label><label class="expand" for="c-39075705">[1 more]</label></div><br/><div class="children"><div class="content">The context windows of LLMs are now significantly larger than 2048 tokens, and there are clever ways to autopopulate context window to remind it of things.</div><br/></div></div><div id="39075343" class="c"><input type="checkbox" id="c-39075343" checked=""/><div class="controls bullet"><span class="by">jerbear4328</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075705">prev</a><span>|</span><a href="#39076141">next</a><span>|</span><label class="collapse" for="c-39075343">[-]</label><label class="expand" for="c-39075343">[2 more]</label></div><br/><div class="children"><div class="content">[3] sounds really interesting - do you have a link?</div><br/><div id="39075646" class="c"><input type="checkbox" id="c-39075646" checked=""/><div class="controls bullet"><span class="by">ittseta</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39075343">parent</a><span>|</span><a href="#39076141">next</a><span>|</span><label class="collapse" for="c-39075646">[-]</label><label class="expand" for="c-39075646">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41467-023-40499-0" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41467-023-40499-0</a>
<a href="https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;images-altered-to-trick-machine-vision-can-influence-humans-too&#x2F;" rel="nofollow">https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;images-altered-to-tric...</a><p>Study on the Influence of Adversarial Images on Human Perception</div><br/></div></div></div></div><div id="39076141" class="c"><input type="checkbox" id="c-39076141" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075343">prev</a><span>|</span><a href="#39070858">next</a><span>|</span><label class="collapse" for="c-39076141">[-]</label><label class="expand" for="c-39076141">[1 more]</label></div><br/><div class="children"><div class="content">If it doesn&#x27;t work during inference I really doubt it will have any intended effect during training, there is simply too much signal and the added adversarial noise works on the frozen and small proxy model they used (CLIP image encoder I think) but it doesn&#x27;t work on a larger model and trained on a different dataset, if there is any effect during training it will probably just be the model learning that it can&#x27;t take shortcuts (the artifacts working on the proxy model showcase gaps in its visual knowledge).<p>Generative models like text-to-image have an encoder part (it could be explicit or not) that extract the semantic from the noised image, if the auto-labelers can correctly label the samples then the encoded trained on both actual and adversarial images will learn to not take the same shortcuts that the proxy model has taken making the model more robust, I cannot see an argument where this should be a negative thing for the model.</div><br/></div></div></div></div><div id="39070858" class="c"><input type="checkbox" id="c-39070858" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39073648">prev</a><span>|</span><a href="#39071249">next</a><span>|</span><label class="collapse" for="c-39070858">[-]</label><label class="expand" for="c-39070858">[2 more]</label></div><br/><div class="children"><div class="content">Yeah. At worst a simple img2img diffusion step would mitigate this, but just eyeballing the examples, traditional denoisers would probably do the job?<p>Denoising is probably a good preprocessing step anyway.</div><br/><div id="39081180" class="c"><input type="checkbox" id="c-39081180" checked=""/><div class="controls bullet"><span class="by">achileas</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39070858">parent</a><span>|</span><a href="#39071249">next</a><span>|</span><label class="collapse" for="c-39081180">[-]</label><label class="expand" for="c-39081180">[1 more]</label></div><br/><div class="children"><div class="content">It’s a common preprocessing step and I believe that’s how glaze (this lab’s previous work) was defeated.</div><br/></div></div></div></div><div id="39071249" class="c"><input type="checkbox" id="c-39071249" checked=""/><div class="controls bullet"><span class="by">pimlottc</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39070858">prev</a><span>|</span><a href="#39084388">next</a><span>|</span><label class="collapse" for="c-39071249">[-]</label><label class="expand" for="c-39071249">[20 more]</label></div><br/><div class="children"><div class="content">I can’t really see any difference in those images on the Twitter example when viewing it on mobile</div><br/><div id="39071623" class="c"><input type="checkbox" id="c-39071623" checked=""/><div class="controls bullet"><span class="by">vhcr</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39075606">next</a><span>|</span><label class="collapse" for="c-39071623">[-]</label><label class="expand" for="c-39071623">[5 more]</label></div><br/><div class="children"><div class="content">The animation when you change images makes it harder to see the difference, I opened the three images each in its own tab and the differences are more apparent when you change between each other instantly.</div><br/><div id="39074431" class="c"><input type="checkbox" id="c-39074431" checked=""/><div class="controls bullet"><span class="by">SirMaster</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071623">parent</a><span>|</span><a href="#39071959">next</a><span>|</span><label class="collapse" for="c-39074431">[-]</label><label class="expand" for="c-39074431">[3 more]</label></div><br/><div class="children"><div class="content">But that’s not realistic?<p>If you have to have both and instantly toggle between them to notice the difference, then it sounds like it’s doing its job well and is hard to notice the difference.</div><br/><div id="39076753" class="c"><input type="checkbox" id="c-39076753" checked=""/><div class="controls bullet"><span class="by">bowsamic</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39074431">parent</a><span>|</span><a href="#39075766">next</a><span>|</span><label class="collapse" for="c-39076753">[-]</label><label class="expand" for="c-39076753">[1 more]</label></div><br/><div class="children"><div class="content">What kind of artist is not going to be bothered with seeing huge artifacting on their work? Btw for me it was immediately noticeable even on mobile</div><br/></div></div><div id="39075766" class="c"><input type="checkbox" id="c-39075766" checked=""/><div class="controls bullet"><span class="by">battles</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39074431">parent</a><span>|</span><a href="#39076753">prev</a><span>|</span><a href="#39071959">next</a><span>|</span><label class="collapse" for="c-39075766">[-]</label><label class="expand" for="c-39075766">[1 more]</label></div><br/><div class="children"><div class="content">The person who drew it would definitely notice.</div><br/></div></div></div></div><div id="39071959" class="c"><input type="checkbox" id="c-39071959" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071623">parent</a><span>|</span><a href="#39074431">prev</a><span>|</span><a href="#39075606">next</a><span>|</span><label class="collapse" for="c-39071959">[-]</label><label class="expand" for="c-39071959">[1 more]</label></div><br/><div class="children"><div class="content">One of the few times a &#x27;blink comparator&#x27; feature in image viewers would be useful!</div><br/></div></div></div></div><div id="39075606" class="c"><input type="checkbox" id="c-39075606" checked=""/><div class="controls bullet"><span class="by">fenomas</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39071623">prev</a><span>|</span><a href="#39073127">next</a><span>|</span><label class="collapse" for="c-39075606">[-]</label><label class="expand" for="c-39075606">[6 more]</label></div><br/><div class="children"><div class="content">At full size it&#x27;s <i>super</i> obvious - I made a side-by-side:<p><a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;I6EQ05g.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;I6EQ05g.png</a></div><br/><div id="39076191" class="c"><input type="checkbox" id="c-39076191" checked=""/><div class="controls bullet"><span class="by">trimethylpurine</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39075606">parent</a><span>|</span><a href="#39073127">next</a><span>|</span><label class="collapse" for="c-39076191">[-]</label><label class="expand" for="c-39076191">[5 more]</label></div><br/><div class="children"><div class="content">I still don&#x27;t see a difference. (Mobile)</div><br/><div id="39077884" class="c"><input type="checkbox" id="c-39077884" checked=""/><div class="controls bullet"><span class="by">Rewrap3643</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39076191">parent</a><span>|</span><a href="#39076271">next</a><span>|</span><label class="collapse" for="c-39077884">[-]</label><label class="expand" for="c-39077884">[1 more]</label></div><br/><div class="children"><div class="content">Have you done a color blindness test before? Red-green is the most common type and the differences here are mostly shades of green.</div><br/></div></div><div id="39076271" class="c"><input type="checkbox" id="c-39076271" checked=""/><div class="controls bullet"><span class="by">fenomas</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39076191">parent</a><span>|</span><a href="#39077884">prev</a><span>|</span><a href="#39083634">next</a><span>|</span><label class="collapse" for="c-39076271">[-]</label><label class="expand" for="c-39076271">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a maybe more mobile friendly comparison:<p><a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;zUVn8rt.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;zUVn8rt.png</a><p>But now that I double-check, I was comparing with the images zoomed to 200%. On desktop the artifacts are also noticeable at 100%, but not nearly as bad as in my previous comment.</div><br/></div></div><div id="39083634" class="c"><input type="checkbox" id="c-39083634" checked=""/><div class="controls bullet"><span class="by">Detrytus</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39076191">parent</a><span>|</span><a href="#39076271">prev</a><span>|</span><a href="#39076758">next</a><span>|</span><label class="collapse" for="c-39083634">[-]</label><label class="expand" for="c-39083634">[1 more]</label></div><br/><div class="children"><div class="content">Second picture looks like you were looking at it through a dirty window, there&#x27;s lot of pale white stains, or light reflections, it&#x27;s really blurry.</div><br/></div></div><div id="39076758" class="c"><input type="checkbox" id="c-39076758" checked=""/><div class="controls bullet"><span class="by">bowsamic</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39076191">parent</a><span>|</span><a href="#39083634">prev</a><span>|</span><a href="#39073127">next</a><span>|</span><label class="collapse" for="c-39076758">[-]</label><label class="expand" for="c-39076758">[1 more]</label></div><br/><div class="children"><div class="content">What phone are you using? It’s extremely obvious on my iPhone</div><br/></div></div></div></div></div></div><div id="39073127" class="c"><input type="checkbox" id="c-39073127" checked=""/><div class="controls bullet"><span class="by">josefx</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39075606">prev</a><span>|</span><a href="#39071467">next</a><span>|</span><label class="collapse" for="c-39073127">[-]</label><label class="expand" for="c-39073127">[1 more]</label></div><br/><div class="children"><div class="content">Something similar to jpeg artifacts on any surface with a normally smooth color gradient, in some cases rather significant.</div><br/></div></div><div id="39071467" class="c"><input type="checkbox" id="c-39071467" checked=""/><div class="controls bullet"><span class="by">0xcde4c3db</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39073127">prev</a><span>|</span><a href="#39071419">next</a><span>|</span><label class="collapse" for="c-39071467">[-]</label><label class="expand" for="c-39071467">[1 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t see it immediately either, but there&#x27;s a <i>ton</i> of added noise. The most noticeable bit for me was near the standing person&#x27;s bent elbow, but there&#x27;s a lot more that becomes obvious when flipping back and forth between browser tabs instead of swiping on Twitter.</div><br/></div></div><div id="39071419" class="c"><input type="checkbox" id="c-39071419" checked=""/><div class="controls bullet"><span class="by">Keyframe</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39071467">prev</a><span>|</span><a href="#39071402">next</a><span>|</span><label class="collapse" for="c-39071419">[-]</label><label class="expand" for="c-39071419">[1 more]</label></div><br/><div class="children"><div class="content">look at the green drapes to the right, or any large uniform colored space. It looks similar to bad JPEG artifacts.</div><br/></div></div><div id="39071402" class="c"><input type="checkbox" id="c-39071402" checked=""/><div class="controls bullet"><span class="by">pxc</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39071419">prev</a><span>|</span><a href="#39075463">next</a><span>|</span><label class="collapse" for="c-39071402">[-]</label><label class="expand" for="c-39071402">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have great vision, but me neither. They&#x27;re indistinguishable to me (likewise on mobile).</div><br/><div id="39075183" class="c"><input type="checkbox" id="c-39075183" checked=""/><div class="controls bullet"><span class="by">Gigachad</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071402">parent</a><span>|</span><a href="#39075463">next</a><span>|</span><label class="collapse" for="c-39075183">[-]</label><label class="expand" for="c-39075183">[1 more]</label></div><br/><div class="children"><div class="content">I was on desktop and it looks like pretty heavy jpeg compression. Doesn&#x27;t completely destroy the image, but it&#x27;s pretty noticeable when blown up large enough.</div><br/></div></div></div></div><div id="39075463" class="c"><input type="checkbox" id="c-39075463" checked=""/><div class="controls bullet"><span class="by">jquery</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39071402">prev</a><span>|</span><a href="#39071870">next</a><span>|</span><label class="collapse" for="c-39075463">[-]</label><label class="expand" for="c-39075463">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s really noticeable on desktop, like compressing an 800kb jpeg to 50kb. Maybe on mobile you won&#x27;t notice, but on desktop the image looks blown out.</div><br/></div></div><div id="39071870" class="c"><input type="checkbox" id="c-39071870" checked=""/><div class="controls bullet"><span class="by">charcircuit</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39075463">prev</a><span>|</span><a href="#39071417">next</a><span>|</span><label class="collapse" for="c-39071870">[-]</label><label class="expand" for="c-39071870">[1 more]</label></div><br/><div class="children"><div class="content">The gradient on the bat has blocks in it instead of being smooth.</div><br/></div></div><div id="39071417" class="c"><input type="checkbox" id="c-39071417" checked=""/><div class="controls bullet"><span class="by">milsorgen</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39071870">prev</a><span>|</span><a href="#39084388">next</a><span>|</span><label class="collapse" for="c-39071417">[-]</label><label class="expand" for="c-39071417">[1 more]</label></div><br/><div class="children"><div class="content">It took me a minute too but on the fast you can see some blocky artifacting by the elbow and a few spots elsewhere like curtain upper left.</div><br/></div></div></div></div><div id="39084388" class="c"><input type="checkbox" id="c-39084388" checked=""/><div class="controls bullet"><span class="by">kjs3</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39071249">prev</a><span>|</span><a href="#39071063">next</a><span>|</span><label class="collapse" for="c-39084388">[-]</label><label class="expand" for="c-39084388">[1 more]</label></div><br/><div class="children"><div class="content">Seems obvious that the people stealing would be adjusting their process to negate these kinds of countermeasures all the time.  I don&#x27;t see this as an arms race the artists are going to win.  Not like the LLM folks can consider actually paying their way...the business plan pretty much has &quot;...by stealing everything we can get our hands on...&quot; in the executive summary.</div><br/></div></div><div id="39071063" class="c"><input type="checkbox" id="c-39071063" checked=""/><div class="controls bullet"><span class="by">gedy</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39084388">prev</a><span>|</span><a href="#39074931">next</a><span>|</span><label class="collapse" for="c-39071063">[-]</label><label class="expand" for="c-39071063">[3 more]</label></div><br/><div class="children"><div class="content">Maybe it&#x27;s more about &quot;protecting&quot; images that artists want to publicly share to advertise work, but it&#x27;s not appropriate for final digital media, etc.</div><br/><div id="39071234" class="c"><input type="checkbox" id="c-39071234" checked=""/><div class="controls bullet"><span class="by">sesm</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071063">parent</a><span>|</span><a href="#39074931">next</a><span>|</span><label class="collapse" for="c-39071234">[-]</label><label class="expand" for="c-39071234">[2 more]</label></div><br/><div class="children"><div class="content">In short, anti-AI watermark.</div><br/><div id="39073507" class="c"><input type="checkbox" id="c-39073507" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071234">parent</a><span>|</span><a href="#39074931">next</a><span>|</span><label class="collapse" for="c-39073507">[-]</label><label class="expand" for="c-39073507">[1 more]</label></div><br/><div class="children"><div class="content">Yeah. It may mess with the artist&#x27;s vision but the impact is still way more subtle than other methods used to protect against these unwanted actions.<p>Of course I&#x27;m assuming it works to begin with. Sounds like a game of cat and mouse. And AI has a lot of rich cats.</div><br/></div></div></div></div></div></div><div id="39074931" class="c"><input type="checkbox" id="c-39074931" checked=""/><div class="controls bullet"><span class="by">h0p3</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39071063">prev</a><span>|</span><a href="#39071545">next</a><span>|</span><label class="collapse" for="c-39074931">[-]</label><label class="expand" for="c-39074931">[1 more]</label></div><br/><div class="children"><div class="content">Sir &#x2F;u&#x2F;b3nsn0w is courteous, `&#x2F;nod`.</div><br/></div></div><div id="39071545" class="c"><input type="checkbox" id="c-39071545" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39074931">prev</a><span>|</span><a href="#39071577">next</a><span>|</span><label class="collapse" for="c-39071545">[-]</label><label class="expand" for="c-39071545">[10 more]</label></div><br/><div class="children"><div class="content">The artifacts are a non-issue. It&#x27;s intended images with nightshade are intended to be silently scrapped and avoid human filtering.</div><br/><div id="39071803" class="c"><input type="checkbox" id="c-39071803" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071545">parent</a><span>|</span><a href="#39072858">next</a><span>|</span><label class="collapse" for="c-39071803">[-]</label><label class="expand" for="c-39071803">[6 more]</label></div><br/><div class="children"><div class="content">The artifacts are extremely an issue for artists who don&#x27;t want their images damaged for the possibility of them not being trained by AI.<p>It&#x27;s a bad tradeoff.</div><br/><div id="39071865" class="c"><input type="checkbox" id="c-39071865" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071803">parent</a><span>|</span><a href="#39072858">next</a><span>|</span><label class="collapse" for="c-39071865">[-]</label><label class="expand" for="c-39071865">[5 more]</label></div><br/><div class="children"><div class="content">Nightshaded images aren&#x27;t intended for portfolios. They&#x27;re mean to be uploaded enmasse and scraped later.</div><br/><div id="39072416" class="c"><input type="checkbox" id="c-39072416" checked=""/><div class="controls bullet"><span class="by">AJ007</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071865">parent</a><span>|</span><a href="#39072858">next</a><span>|</span><label class="collapse" for="c-39072416">[-]</label><label class="expand" for="c-39072416">[4 more]</label></div><br/><div class="children"><div class="content">To where? A place no one sees them and they aren&#x27;t scraped?</div><br/><div id="39072560" class="c"><input type="checkbox" id="c-39072560" checked=""/><div class="controls bullet"><span class="by">filleduchaos</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39072416">parent</a><span>|</span><a href="#39072796">next</a><span>|</span><label class="collapse" for="c-39072560">[-]</label><label class="expand" for="c-39072560">[1 more]</label></div><br/><div class="children"><div class="content">I think the point is that they&#x27;re akin to a watermark.<p>Even before the current AI boom, plenty of artists have wanted to <i>showcase</i> their work&#x2F;prove that it exists without necessarily making the highest quality original file public.</div><br/></div></div><div id="39072796" class="c"><input type="checkbox" id="c-39072796" checked=""/><div class="controls bullet"><span class="by">Diti</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39072416">parent</a><span>|</span><a href="#39072560">prev</a><span>|</span><a href="#39072925">next</a><span>|</span><label class="collapse" for="c-39072796">[-]</label><label class="expand" for="c-39072796">[1 more]</label></div><br/><div class="children"><div class="content">Most serious artists I know (at least in my community) release their high-quality images on Patreon or similar.</div><br/></div></div><div id="39072925" class="c"><input type="checkbox" id="c-39072925" checked=""/><div class="controls bullet"><span class="by">pgeorgi</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39072416">parent</a><span>|</span><a href="#39072796">prev</a><span>|</span><a href="#39072858">next</a><span>|</span><label class="collapse" for="c-39072925">[-]</label><label class="expand" for="c-39072925">[1 more]</label></div><br/><div class="children"><div class="content">For example in accounts on image sites that are exposed to suspected scrapers but not to others. Scrapers will still see the real data, but they&#x27;ll also run into stuff designed to mix up the training process.</div><br/></div></div></div></div></div></div></div></div><div id="39072858" class="c"><input type="checkbox" id="c-39072858" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071545">parent</a><span>|</span><a href="#39071803">prev</a><span>|</span><a href="#39074946">next</a><span>|</span><label class="collapse" for="c-39072858">[-]</label><label class="expand" for="c-39072858">[2 more]</label></div><br/><div class="children"><div class="content">do you mean scrapped or scraped?</div><br/><div id="39073155" class="c"><input type="checkbox" id="c-39073155" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39072858">parent</a><span>|</span><a href="#39074946">next</a><span>|</span><label class="collapse" for="c-39073155">[-]</label><label class="expand" for="c-39073155">[1 more]</label></div><br/><div class="children"><div class="content">scraped</div><br/></div></div></div></div><div id="39074946" class="c"><input type="checkbox" id="c-39074946" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071545">parent</a><span>|</span><a href="#39072858">prev</a><span>|</span><a href="#39071577">next</a><span>|</span><label class="collapse" for="c-39074946">[-]</label><label class="expand" for="c-39074946">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The artifacts are a non-issue.<p>According to which authority?</div><br/></div></div></div></div></div></div><div id="39071577" class="c"><input type="checkbox" id="c-39071577" checked=""/><div class="controls bullet"><span class="by">gfodor</span><span>|</span><a href="#39068620">prev</a><span>|</span><a href="#39071676">next</a><span>|</span><label class="collapse" for="c-39071577">[-]</label><label class="expand" for="c-39071577">[36 more]</label></div><br/><div class="children"><div class="content">Huge market for snake oil here. There is no way that such tools will ever win, given the requirements the art remain viewable to human perception, so even if you made something that worked (which this sounds like it doesn’t) from first principles it will be worked around immediately.<p>The only real way for artists or anyone really to try to hold back models from training on human outputs is through the law, ie, leveraging state backed violence to deter the things they don’t want. This too won’t be a perfect solution, if anything it will just put more incentives for people to develop decentralized training networks that “launder” the copyright violations that would allow for prosecutions.<p>All in all it’s a losing battle at a minimum and a stupid battle at worst. We know these models can be created easily and so they will, eventually, since you can’t prevent a computer from observing images you want humans to be able to observe freely.</div><br/><div id="39072466" class="c"><input type="checkbox" id="c-39072466" checked=""/><div class="controls bullet"><span class="by">AJ007</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39072800">next</a><span>|</span><label class="collapse" for="c-39072466">[-]</label><label class="expand" for="c-39072466">[14 more]</label></div><br/><div class="children"><div class="content">The level of claims accompanied by enthusiastic reception from a technically illiterate audience make it sound, smell, and sound like snake oil without much deep investigation.<p>There is another alternative to the law. Provide your art for private viewing only, and ensure your in person audience does not bring recording devices with them. That may sound absurd, but it&#x27;s a common practice during activities like having sex.</div><br/><div id="39075451" class="c"><input type="checkbox" id="c-39075451" checked=""/><div class="controls bullet"><span class="by">Gormo</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39072466">parent</a><span>|</span><a href="#39074637">next</a><span>|</span><label class="collapse" for="c-39075451">[-]</label><label class="expand" for="c-39075451">[1 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t sound like a viable business model.  There seems to be a non-trivial bootstrap problem involved -- how do you become well-known enough to attract audiences to private venues in sufficient volume to make a living? -- and would in no way diminish demand for AI-generated artwork which would still continue to draw attention away from you.</div><br/></div></div><div id="39074637" class="c"><input type="checkbox" id="c-39074637" checked=""/><div class="controls bullet"><span class="by">Art9681</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39072466">parent</a><span>|</span><a href="#39075451">prev</a><span>|</span><a href="#39076073">next</a><span>|</span><label class="collapse" for="c-39074637">[-]</label><label class="expand" for="c-39074637">[4 more]</label></div><br/><div class="children"><div class="content">This would just create a new market for art paparazzis who would find any and all means to inflitrate such private viewings with futuristic miniature cameras and other sensors and selling it for a premium. Less than 24 hours later the files end up on hundreds or thousands of centralized and decentralized servers.<p>I&#x27;m not defending it. Just acknowledging the reality. The next TMZ for private art gatherings is percolating in someone&#x27;s garage at the moment.</div><br/><div id="39077366" class="c"><input type="checkbox" id="c-39077366" checked=""/><div class="controls bullet"><span class="by">jurassic</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39074637">parent</a><span>|</span><a href="#39074734">next</a><span>|</span><label class="collapse" for="c-39077366">[-]</label><label class="expand" for="c-39077366">[2 more]</label></div><br/><div class="children"><div class="content">I find this difficult to believe; no matter how small your camera is, photography is about light. Art reproduction photography is surprisingly hard to do if you care about the quality of the end result. Unless you can surreptitiously smuggle in a studio lighting setup, tripod, and color checker card… sure you can take an image in secret, but not one that is a good representation of the real thing.</div><br/><div id="39086793" class="c"><input type="checkbox" id="c-39086793" checked=""/><div class="controls bullet"><span class="by">Robotbeat</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39077366">parent</a><span>|</span><a href="#39074734">next</a><span>|</span><label class="collapse" for="c-39086793">[-]</label><label class="expand" for="c-39086793">[1 more]</label></div><br/><div class="children"><div class="content">It’s about number of photons and aperture. In principle this could be very hard to detect, especially once people get good at multiple distributed apertures that are coherent with one another.</div><br/></div></div></div></div></div></div><div id="39076073" class="c"><input type="checkbox" id="c-39076073" checked=""/><div class="controls bullet"><span class="by">wraptile</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39072466">parent</a><span>|</span><a href="#39074637">prev</a><span>|</span><a href="#39072586">next</a><span>|</span><label class="collapse" for="c-39076073">[-]</label><label class="expand" for="c-39076073">[7 more]</label></div><br/><div class="children"><div class="content">The thing is people want the benefits of having their stuff public but not bear the costs. Scraping has been mostly a solved problem especially when it comes to broad crawling. Put it under a login, there, no more AI &quot;stealing&quot; your work.</div><br/><div id="39076780" class="c"><input type="checkbox" id="c-39076780" checked=""/><div class="controls bullet"><span class="by">csydas</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076073">parent</a><span>|</span><a href="#39076724">next</a><span>|</span><label class="collapse" for="c-39076780">[-]</label><label class="expand" for="c-39076780">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s true at all. Images and text get reposted with or without consent, often without attribution. It wouldn&#x27;t make it right for the AI companies to scrape when the original author doesn&#x27;t want that but someone else has ignored their wishes and requirements. Basically, what good is putting your stuff behind login or some other restrictive viewing method if someone just saves the image&#x2F;text? I think it&#x27;s still a relatively serious problem for people creating things. And without some form of easy access to viewing, the people creating things don&#x27;t get the visibility and exposure they need to get an audience&#x2F;clients.<p>This is one the AI companies should offer the olive branch on IMO, there must be a way to use stenography to transparently embed a &quot;don&#x27;t process for AI&quot; code into an image or text or music or any other creative work that won&#x27;t be noticeable by humans, but the AI would see if it tried to process the content for training. I think it would be a very convenient answer and probably not be detrimental to the AI companies, but I also imagine that the AI companies would not be very eager to spend the resources implementing this. I do think they&#x27;re the best source for such protections for artists though.<p>Ideally, without a previous written agreement for a dataset from the original creators, the AI companies probably shouldn&#x27;t be using it for training at all, but I doubt that will happen -- the system I mention above should be _opt-in_, that is, you must tag such content that is free to be AI trained in order for AI to be trained on it, but I have 0 faith that the AI companies would agree to such a self-limitation.<p>edit: added mention to music and other creative works in second paragraph 1st sentence<p>edit 2: Added final paragraph as I do think this should be opt-in, but don&#x27;t believe AI companies would ever accept this, even though they should by all means in my opinion.</div><br/><div id="39077815" class="c"><input type="checkbox" id="c-39077815" checked=""/><div class="controls bullet"><span class="by">amlib</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076780">parent</a><span>|</span><a href="#39076724">next</a><span>|</span><label class="collapse" for="c-39077815">[-]</label><label class="expand" for="c-39077815">[1 more]</label></div><br/><div class="children"><div class="content">Here are my 2 cents, I think we will need some laws specifying two types of AI models, ones trained with full consent (opt-in) for its training material and ones without. The first one would be like Adobe&#x27;s firefly model where they allegedly own everything they trained it with, or something where you go around asking for consent for each thing in your training corpus (probably unfeasible for large models). Maybe things in the public domain would be ok to train with. In this case there are no restrictions and the output from such models can even be copyrighted.<p>Now for the second type, representing models such as Stable Difusion and Chat GPT, it would be required to have their trained model freely available to anyone and any resulting output would not be copyrightable. It may be a more fairer way of allowing anyone to harness the power of AI models that contain essentially the knowledge of all man kind, but without giving any party an unfair monopoly on it.<p>This should be easily enforceable for big corporations, else it would be too obvious if they are trying to pass one type model as another or even keep the truth about their model from leaking. It might not be as easy to keep small groups or individuals from breaking those rules, but hey, at least it evens the playing field.</div><br/></div></div></div></div><div id="39076724" class="c"><input type="checkbox" id="c-39076724" checked=""/><div class="controls bullet"><span class="by">946789987649</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076073">parent</a><span>|</span><a href="#39076780">prev</a><span>|</span><a href="#39072586">next</a><span>|</span><label class="collapse" for="c-39076724">[-]</label><label class="expand" for="c-39076724">[4 more]</label></div><br/><div class="children"><div class="content">Is that login statement strictly true? Unless the login is paid, there&#x27;s no reason we can&#x27;t get to (if not already there) the point where the AI scraper can just create a login first.</div><br/><div id="39077740" class="c"><input type="checkbox" id="c-39077740" checked=""/><div class="controls bullet"><span class="by">wraptile</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076724">parent</a><span>|</span><a href="#39076786">next</a><span>|</span><label class="collapse" for="c-39077740">[-]</label><label class="expand" for="c-39077740">[1 more]</label></div><br/><div class="children"><div class="content">No, eforcing click-wrap legal agreements is actually possible. With basic KYC the scraper would instantly open up itself for litigation and no internet art piece is frankly worth this sort of trouble.</div><br/></div></div><div id="39076786" class="c"><input type="checkbox" id="c-39076786" checked=""/><div class="controls bullet"><span class="by">Tade0</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076724">parent</a><span>|</span><a href="#39077740">prev</a><span>|</span><a href="#39072586">next</a><span>|</span><label class="collapse" for="c-39076786">[-]</label><label class="expand" for="c-39076786">[2 more]</label></div><br/><div class="children"><div class="content">But then you can rate-limit to a point where scraping everything will take a considerable amount of time.<p>Of course the workaround would be to have multiple accounts, but that in turn can be made unscalable with a &quot;prove you&#x27;re human&quot; box.</div><br/><div id="39076832" class="c"><input type="checkbox" id="c-39076832" checked=""/><div class="controls bullet"><span class="by">csydas</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076786">parent</a><span>|</span><a href="#39072586">next</a><span>|</span><label class="collapse" for="c-39076832">[-]</label><label class="expand" for="c-39076832">[1 more]</label></div><br/><div class="children"><div class="content">you are not incorrect that this would help mitigate, but it still misses a few key points I think regarding why artists are upset about AI generation<p>- This is still vulnerable to stuff like mturk or even just normal users who did get past the anti-bot things pulling and re-uploading the content elsewhere that is easier for the AI companies to use<p>- The artists&#x27; main contention is that the AI companies shouldn&#x27;t be allowed to just use whatever they find without confirm they have a license to use the content in this way<p>- If someone&#x27;s content _does_ get into an AI model and it&#x27;s determined somehow (I think there is a case with a news paper and chatGPT over this very issue?), the legal system doesn&#x27;t really have a good framework for this situation right now -- is it copyright infringement? (arguably not? it&#x27;s not clear) is it plagiarism? (arguably yes, but plagiarism in US court system is very hard to proof&#x2F;get action on) is it license violation? (for those who use licenses for their art, probably yes, but it&#x27;s the same issue as plagiarism -- how to prove it effectively?)<p>Really what this comes down to is that the AI companies use the premise that they have a right to use someone else&#x27;s works without consent for the AI training. While your suggestions are technically correct, it puts the impetus on the artists that they must do something different because the AI companies are allowed to train their models as they currently do without recourse for the original artist. Maybe that will be ruled true in the future I don&#x27;t know, but I can absolutely get why artists are upset about this premise shaping the discussion on AI training, as such a premise negates their rights as an artist and many artists have 0 path for recourse. I&#x27;m pretty sure that OpenAI wouldn&#x27;t think about scraping a Disney movie from a video upload site just because it&#x27;s open access since Disney likely can fight in a more meaningful way. I would agree with artists who are complaining that they shouldn&#x27;t need to wait for a big corporation to decide that this behavior is undesirable before real action is taken, but it seems that is going to be what is needed. It might be reality, but it&#x27;s a very sad reality that people want changed.</div><br/></div></div></div></div></div></div></div></div><div id="39072586" class="c"><input type="checkbox" id="c-39072586" checked=""/><div class="controls bullet"><span class="by">gfodor</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39072466">parent</a><span>|</span><a href="#39076073">prev</a><span>|</span><a href="#39072800">next</a><span>|</span><label class="collapse" for="c-39072586">[-]</label><label class="expand" for="c-39072586">[1 more]</label></div><br/><div class="children"><div class="content">True I can imagine that kind of thing becoming popular.</div><br/></div></div></div></div><div id="39072800" class="c"><input type="checkbox" id="c-39072800" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39072466">prev</a><span>|</span><a href="#39074285">next</a><span>|</span><label class="collapse" for="c-39072800">[-]</label><label class="expand" for="c-39072800">[1 more]</label></div><br/><div class="children"><div class="content">&gt;There is no way that such tools will ever win, given the requirements the art remain viewable to human perception<p>On the other hand, the adversarial environment might push models towards a representation more aligned with human perception, which is neat.</div><br/></div></div><div id="39074285" class="c"><input type="checkbox" id="c-39074285" checked=""/><div class="controls bullet"><span class="by">aqfamnzc</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39072800">prev</a><span>|</span><a href="#39074368">next</a><span>|</span><label class="collapse" for="c-39074285">[-]</label><label class="expand" for="c-39074285">[1 more]</label></div><br/><div class="children"><div class="content">The ol&#x27; Analog Gap. <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Analog_hole" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Analog_hole</a></div><br/></div></div><div id="39074368" class="c"><input type="checkbox" id="c-39074368" checked=""/><div class="controls bullet"><span class="by">Reubend</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39074285">prev</a><span>|</span><a href="#39076330">next</a><span>|</span><label class="collapse" for="c-39074368">[-]</label><label class="expand" for="c-39074368">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Huge market for snake oil here.<p>This tool is free, and as far as I can tell it runs locally. If you&#x27;re not selling anything, and there&#x27;s no profit motive, then I don&#x27;t think you can reasonably call it &quot;snake oil&quot;.<p>At worst, it&#x27;s a waste of time. But nobody&#x27;s being deceived into purchasing it.</div><br/><div id="39076000" class="c"><input type="checkbox" id="c-39076000" checked=""/><div class="controls bullet"><span class="by">autoexec</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39074368">parent</a><span>|</span><a href="#39077584">next</a><span>|</span><label class="collapse" for="c-39076000">[-]</label><label class="expand" for="c-39076000">[1 more]</label></div><br/><div class="children"><div class="content">If this is a danger from &quot;snake oil&quot; of this type, it&#x27;d be from the other side, where artists are intentionally tricked into believing that tools like this mean that AI isn&#x27;t or won&#x27;t be a threat to their copyrights in order to get them to stop opposing it so strongly, when in fact the tool does nothing to prevent their copyrights from being violated.<p>I don&#x27;t think that&#x27;s the intention of Nightshade, but I wouldn&#x27;t put past someone to try it.</div><br/></div></div><div id="39077584" class="c"><input type="checkbox" id="c-39077584" checked=""/><div class="controls bullet"><span class="by">Biganon</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39074368">parent</a><span>|</span><a href="#39076000">prev</a><span>|</span><a href="#39078751">next</a><span>|</span><label class="collapse" for="c-39077584">[-]</label><label class="expand" for="c-39077584">[1 more]</label></div><br/><div class="children"><div class="content">There&#x27;s an academic paper being published.<p>Snake oil for the sake of getting published is a very real problem that does exist.</div><br/></div></div><div id="39078751" class="c"><input type="checkbox" id="c-39078751" checked=""/><div class="controls bullet"><span class="by">golol</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39074368">parent</a><span>|</span><a href="#39077584">prev</a><span>|</span><a href="#39076330">next</a><span>|</span><label class="collapse" for="c-39078751">[-]</label><label class="expand" for="c-39078751">[2 more]</label></div><br/><div class="children"><div class="content">Religion is also deceptive and snake-oil even if it does not involve profit driven motivations.</div><br/><div id="39083832" class="c"><input type="checkbox" id="c-39083832" checked=""/><div class="controls bullet"><span class="by">NoahKAndrews</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39078751">parent</a><span>|</span><a href="#39076330">next</a><span>|</span><label class="collapse" for="c-39083832">[-]</label><label class="expand" for="c-39083832">[1 more]</label></div><br/><div class="children"><div class="content">It very often does involve such motivations, though I agree with your larger point.</div><br/></div></div></div></div></div></div><div id="39076330" class="c"><input type="checkbox" id="c-39076330" checked=""/><div class="controls bullet"><span class="by">spaceman_2020</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39074368">prev</a><span>|</span><a href="#39084550">next</a><span>|</span><label class="collapse" for="c-39076330">[-]</label><label class="expand" for="c-39076330">[6 more]</label></div><br/><div class="children"><div class="content">This is the hard reality. There is no putting this genie back in the bottle.<p>The only way to be an artist now is to have a unique style of your own, and to never make it online.</div><br/><div id="39076716" class="c"><input type="checkbox" id="c-39076716" checked=""/><div class="controls bullet"><span class="by">hutzlibu</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076330">parent</a><span>|</span><a href="#39076441">next</a><span>|</span><label class="collapse" for="c-39076716">[-]</label><label class="expand" for="c-39076716">[4 more]</label></div><br/><div class="children"><div class="content">&quot;and to never make it online.&quot;<p>So then of course, you also cannot sell your work, as those might put it online. And you cannot show your art to big crowds, as some will make pictures and put it online. So ... you can become a literal underground artists, where only some may see your work. I think only some will like that.<p>But I actually disagree, there are plenty of ways to be an artist now - but most should probably think about including AI as a tool, if they still want to make money. But with the exception of some superstars, most artists are famously low on money - and AI did not introduce this. (all the professional artists I know, those who went to art school - do not make their income with their art)</div><br/><div id="39078239" class="c"><input type="checkbox" id="c-39078239" checked=""/><div class="controls bullet"><span class="by">BeFlatXIII</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076716">parent</a><span>|</span><a href="#39077252">next</a><span>|</span><label class="collapse" for="c-39078239">[-]</label><label class="expand" for="c-39078239">[1 more]</label></div><br/><div class="children"><div class="content">GP almost certainly mean &quot;make physical art.&quot;  Pictures of that can get online, but it&#x27;s not the real thing.</div><br/></div></div><div id="39077252" class="c"><input type="checkbox" id="c-39077252" checked=""/><div class="controls bullet"><span class="by">sabedevops</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076716">parent</a><span>|</span><a href="#39078239">prev</a><span>|</span><a href="#39076441">next</a><span>|</span><label class="collapse" for="c-39077252">[-]</label><label class="expand" for="c-39077252">[2 more]</label></div><br/><div class="children"><div class="content">Can you elaborate on how they supplement their income?</div><br/><div id="39078414" class="c"><input type="checkbox" id="c-39078414" checked=""/><div class="controls bullet"><span class="by">hutzlibu</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39077252">parent</a><span>|</span><a href="#39076441">next</a><span>|</span><label class="collapse" for="c-39078414">[-]</label><label class="expand" for="c-39078414">[1 more]</label></div><br/><div class="children"><div class="content">Every other source of income? So other, art-unrelated jobs.</div><br/></div></div></div></div></div></div></div></div><div id="39084550" class="c"><input type="checkbox" id="c-39084550" checked=""/><div class="controls bullet"><span class="by">elzbardico</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39076330">prev</a><span>|</span><a href="#39075787">next</a><span>|</span><label class="collapse" for="c-39084550">[-]</label><label class="expand" for="c-39084550">[1 more]</label></div><br/><div class="children"><div class="content">You don’t need it to visible. You only need it to be scrapped to poison the models. I think that’s the idea.</div><br/></div></div><div id="39075787" class="c"><input type="checkbox" id="c-39075787" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39084550">prev</a><span>|</span><a href="#39081417">next</a><span>|</span><label class="collapse" for="c-39075787">[-]</label><label class="expand" for="c-39075787">[1 more]</label></div><br/><div class="children"><div class="content">Everything old is new again.  It&#x27;s the same thing with any DRM that happens on the client side.  As long as it&#x27;s viewable by humans, someone will figure out a way to feed that into a machine.</div><br/></div></div><div id="39081417" class="c"><input type="checkbox" id="c-39081417" checked=""/><div class="controls bullet"><span class="by">vmirnv</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39075787">prev</a><span>|</span><a href="#39075946">next</a><span>|</span><label class="collapse" for="c-39081417">[-]</label><label class="expand" for="c-39081417">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m thinking — is it possible to create something on a global level similar to what they did in Snapchat: some sort of image flickering that would be difficult to parse, but still acceptable for humans?</div><br/></div></div><div id="39075946" class="c"><input type="checkbox" id="c-39075946" checked=""/><div class="controls bullet"><span class="by">AlfeG</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39081417">prev</a><span>|</span><a href="#39081563">next</a><span>|</span><label class="collapse" for="c-39075946">[-]</label><label class="expand" for="c-39075946">[2 more]</label></div><br/><div class="children"><div class="content">My guess. Is that at some poi t of time You will not be able to use any generated image or video in commercial. Because of 100% copyright claim for using parts of copyrighted image. Like YouTube those days. When some random beeps matches with someone music...</div><br/><div id="39076078" class="c"><input type="checkbox" id="c-39076078" checked=""/><div class="controls bullet"><span class="by">abrarsami</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39075946">parent</a><span>|</span><a href="#39081563">next</a><span>|</span><label class="collapse" for="c-39076078">[-]</label><label class="expand" for="c-39076078">[1 more]</label></div><br/><div class="children"><div class="content">It should be like that. I agree</div><br/></div></div></div></div><div id="39081563" class="c"><input type="checkbox" id="c-39081563" checked=""/><div class="controls bullet"><span class="by">honkycat</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39075946">prev</a><span>|</span><a href="#39080162">next</a><span>|</span><label class="collapse" for="c-39081563">[-]</label><label class="expand" for="c-39081563">[2 more]</label></div><br/><div class="children"><div class="content">&quot;A law, ie, leveraging state backed violence to deter the things they don’t want.&quot;<p>We all know what a law is you don&#x27;t need to clarify. It makes your prose less readable.</div><br/><div id="39084239" class="c"><input type="checkbox" id="c-39084239" checked=""/><div class="controls bullet"><span class="by">gfodor</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39081563">parent</a><span>|</span><a href="#39080162">next</a><span>|</span><label class="collapse" for="c-39084239">[-]</label><label class="expand" for="c-39084239">[1 more]</label></div><br/><div class="children"><div class="content">Other people pointed out they appreciated this prose. It’s easy to forget what exactly people are asking for when they talk about regulating the training of machine learning models.</div><br/></div></div></div></div><div id="39080162" class="c"><input type="checkbox" id="c-39080162" checked=""/><div class="controls bullet"><span class="by">jMyles</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39081563">prev</a><span>|</span><a href="#39071676">next</a><span>|</span><label class="collapse" for="c-39080162">[-]</label><label class="expand" for="c-39080162">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  leveraging state backed violence to deter the things they don’t want<p>I just want to say: I really appreciate the stark terms in which you&#x27;ve put this.<p>The thing that has come to be called &quot;intellectual property&quot; is actually just a threat of violence against people who arrange bytes in a way that challenges power structures.</div><br/></div></div></div></div><div id="39071676" class="c"><input type="checkbox" id="c-39071676" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39071577">prev</a><span>|</span><a href="#39073118">next</a><span>|</span><label class="collapse" for="c-39071676">[-]</label><label class="expand" for="c-39071676">[1 more]</label></div><br/><div class="children"><div class="content">A few months ago I made a proof-of-concept on how finetuning Stable Diffusion XL on known bad&#x2F;incoherent images can actually allow it to output &quot;better&quot; images if those images are used as a negative prompt, i.e. specifying a high-dimensional area of the latent space that model generation should stay away from: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37211519">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37211519</a><p>There&#x27;s a nonzero chance that encouraging the creation of a large dataset of known tampered data can ironically <i>improve</i> generative AI art models by allowing the model to recognize tampered data and allow the training process to work around it.</div><br/></div></div><div id="39073118" class="c"><input type="checkbox" id="c-39073118" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#39071676">prev</a><span>|</span><a href="#39071378">next</a><span>|</span><label class="collapse" for="c-39073118">[-]</label><label class="expand" for="c-39073118">[6 more]</label></div><br/><div class="children"><div class="content">This seems like a pretty pointless &quot;arms race&quot; or &quot;cat and mouse game&quot;. People who want to train generative image models and who don&#x27;t care about what artists think about it at all can just do some basic post-processing on the images that is just enough to destroy the very carefully tuned changes this Nightshade algorithm makes. Something like resampling it to slightly lower resolution and then using another super-resolution model on it to upsample it again would probably be able to destroy these subtle tweaks without making a big difference to a human observer.<p>In the future, my guess is that courts will generally be on the side of artists because of societal pressures, and artists will be able to challenge any image they find and have it sent to yet another ML model that can quickly adjudicate whether the generated image is &quot;too similar&quot; to the artist&#x27;s style (which would also need to be dissimilar enough from everyone else&#x27;s style to give a reasonable legal claim in the first place).<p>Or maybe artists will just give up on trying to monetize the images themselves and focus only on creating physical artifacts, similar to how independent musicians make most of their money nowadays from touring and selling merchandise at shows (plus Patreon). Who knows? It&#x27;s hard to predict the future when there are such huge fundamental changes that happen so quickly!</div><br/><div id="39073735" class="c"><input type="checkbox" id="c-39073735" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#39073118">parent</a><span>|</span><a href="#39075640">next</a><span>|</span><label class="collapse" for="c-39073735">[-]</label><label class="expand" for="c-39073735">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Or maybe artists will just give up on trying to monetize the images themselves and focus only on creating physical artifacts, similar to how independent musicians make most of their money nowadays from touring and selling merchandise at shows (plus Patreon).<p>As is, art already isn&#x27;t a sustainable career for most people who can&#x27;t get a job in industry. The most common monetization is either commissions or hiding extra content behind a pay wall.<p>To be honest I can see more proverbial &quot;Furry artists&quot; sprouting up in a cynical timeline. I imagine like every other big tech that the 18+ side of this will be clamped down hard by the various powers that be. Which means NSFW stuff will be shielded a bit by the advancement and you either need to find underground training models or go back to an artist. .</div><br/><div id="39075209" class="c"><input type="checkbox" id="c-39075209" checked=""/><div class="controls bullet"><span class="by">Gigachad</span><span>|</span><a href="#39073118">root</a><span>|</span><a href="#39073735">parent</a><span>|</span><a href="#39075640">next</a><span>|</span><label class="collapse" for="c-39075209">[-]</label><label class="expand" for="c-39075209">[1 more]</label></div><br/><div class="children"><div class="content">&gt;need to find underground training models<p>It&#x27;s not particularly that hard. The furry nsfw models are already the most well developed and available models you can get right now. And they are spitting out stuff that is almost indistinguishable from regular art.</div><br/></div></div></div></div><div id="39075640" class="c"><input type="checkbox" id="c-39075640" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#39073118">parent</a><span>|</span><a href="#39073735">prev</a><span>|</span><a href="#39080187">next</a><span>|</span><label class="collapse" for="c-39075640">[-]</label><label class="expand" for="c-39075640">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This seems like a pretty pointless &quot;arms race&quot; or &quot;cat and mouse game&quot;.<p>If there is any &quot;point&quot; of this, it&#x27;s that&#x27;s going to push the AI models to become <i>better</i> at capturing how humans see things.</div><br/></div></div><div id="39080187" class="c"><input type="checkbox" id="c-39080187" checked=""/><div class="controls bullet"><span class="by">jMyles</span><span>|</span><a href="#39073118">parent</a><span>|</span><a href="#39075640">prev</a><span>|</span><a href="#39073164">next</a><span>|</span><label class="collapse" for="c-39080187">[-]</label><label class="expand" for="c-39080187">[1 more]</label></div><br/><div class="children"><div class="content">&gt; musicians make most of their money nowadays from touring and selling merchandise at shows<p>Be reminded that this is - and has always been - the mainstream model of the lineages of what have come to be called &quot;traditional&quot; and &quot;Americana&quot; and &quot;Appalachian&quot; music.<p>The Grateful Dead implemented this model with great finesse, sometimes going out of their way to eschew intellectual property claims over their work, in the belief that such claims only hindered their success (and of course, they eventually formalized this advocacy and named it &quot;The Electronic Frontier Foundation&quot; - it&#x27;s no coincidence that EFF sprung from deadhead culture).</div><br/></div></div><div id="39073164" class="c"><input type="checkbox" id="c-39073164" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#39073118">parent</a><span>|</span><a href="#39080187">prev</a><span>|</span><a href="#39071378">next</a><span>|</span><label class="collapse" for="c-39073164">[-]</label><label class="expand" for="c-39073164">[1 more]</label></div><br/><div class="children"><div class="content">the point is you could circumvent one nightshade, but as long as the cat and mouse game continues there can be more</div><br/></div></div></div></div><div id="39071378" class="c"><input type="checkbox" id="c-39071378" checked=""/><div class="controls bullet"><span class="by">marcinzm</span><span>|</span><a href="#39073118">prev</a><span>|</span><a href="#39072007">next</a><span>|</span><label class="collapse" for="c-39071378">[-]</label><label class="expand" for="c-39071378">[1 more]</label></div><br/><div class="children"><div class="content">This feels like it&#x27;ll actually help make AI models better versus worse once they train on these images. Artists are basically, for free, creating training data that conveys what types of noise does not change the intended meaning of the image to the artist themselves.</div><br/></div></div><div id="39072007" class="c"><input type="checkbox" id="c-39072007" checked=""/><div class="controls bullet"><span class="by">chris-orgmenta</span><span>|</span><a href="#39071378">prev</a><span>|</span><a href="#39071494">next</a><span>|</span><label class="collapse" for="c-39072007">[-]</label><label class="expand" for="c-39072007">[4 more]</label></div><br/><div class="children"><div class="content">I want <i>progressive fees</i> on copyright&#x2F;IP&#x2F;patent usage, and worldwide gov cooperation&#x2F;legislation (and perhaps even worldwide ability to use works without obtaining initial permission, although let&#x27;s not go into that outlandish stuff)<p>I want a scaling license fee to apply (e.g. % pegged to revenue. This still has an indirect problem with different industries having different profit margins, but still seems the fairest).<p>And I want the world (or EU, then others to follow suit) to slowly reduce copyright to 0 years* after artists death if owned by a person, and 20-30 years max if owned by a corporation.<p>And I want the penalties for not declaring usage** &#x2F; not paying fees, to be incredibly high for corporations... 50% gross (harder) &#x2F; net (easier) profit margin for the year? Something that isn&#x27;t a slap on the wrist and can&#x27;t be wriggled out of <i>quite</i> so easily, and is actually an incentive not to steal in the first place.)<p>[*]or whatever society deems appropriate.<p>[**]Until auto-detection (for better or worse) gets good enough.<p>IMO that would allow personal use, encourages new entrants to market, encourages innovation, incentivises better behaviour from OpenAI et al.</div><br/><div id="39074752" class="c"><input type="checkbox" id="c-39074752" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#39072007">parent</a><span>|</span><a href="#39076132">next</a><span>|</span><label class="collapse" for="c-39074752">[-]</label><label class="expand" for="c-39074752">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And I want the world (or EU, then others to follow suit) to slowly reduce copyright to 0 years* after artists death if owned by a person, and 20-30 years max if owned by a corporation.<p>Why death at all?<p>It&#x27;s icky to trigger soon after death, it&#x27;s bad to have copyright vary so much based on author age, and it&#x27;s bad for many works to still have huge copyright lengths.<p>It&#x27;s perfectly fine to let copyright expire during the author&#x27;s life.  20-30 years for everything.</div><br/></div></div><div id="39076132" class="c"><input type="checkbox" id="c-39076132" checked=""/><div class="controls bullet"><span class="by">wraptile</span><span>|</span><a href="#39072007">parent</a><span>|</span><a href="#39074752">prev</a><span>|</span><a href="#39071494">next</a><span>|</span><label class="collapse" for="c-39076132">[-]</label><label class="expand" for="c-39076132">[2 more]</label></div><br/><div class="children"><div class="content">Extremely naive to think that any of this could be enforced to any adequate level. Copyright is fundamentally broken and putting some plasters on it is not going to do much especially when these plasters are several decades too late.</div><br/></div></div></div></div><div id="39071494" class="c"><input type="checkbox" id="c-39071494" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#39072007">prev</a><span>|</span><a href="#39070676">next</a><span>|</span><label class="collapse" for="c-39071494">[-]</label><label class="expand" for="c-39071494">[47 more]</label></div><br/><div class="children"><div class="content">The number of people who are going to be able to produce high fidelity art with off the shelf tools in the near future is unbelievable.<p>It’s pretty exciting.<p>Being able to find a mix of styles you like and apply them to new subjects to make your own unique, personalized, artwork sounds like a wickedly cool power to give to billions of people.</div><br/><div id="39072915" class="c"><input type="checkbox" id="c-39072915" checked=""/><div class="controls bullet"><span class="by">kredd</span><span>|</span><a href="#39071494">parent</a><span>|</span><a href="#39073148">next</a><span>|</span><label class="collapse" for="c-39072915">[-]</label><label class="expand" for="c-39072915">[28 more]</label></div><br/><div class="children"><div class="content">In terms of art, population tends to put value not on the result, but origin and process. People will just look down on any art that’s AI generated in a couple of years when it becomes ubiquitous.</div><br/><div id="39073186" class="c"><input type="checkbox" id="c-39073186" checked=""/><div class="controls bullet"><span class="by">redwall_hp</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072915">parent</a><span>|</span><a href="#39075447">next</a><span>|</span><label class="collapse" for="c-39073186">[-]</label><label class="expand" for="c-39073186">[4 more]</label></div><br/><div class="children"><div class="content">This is already the case. Art is a process, a form of human expression, not an end result.<p>I&#x27;m sure OpenAI&#x27;s models can shit out an approximation of a new Terry Pratchett or Douglas Adams novel, but nobody with any level of literary appreciation would give a damn unless fraud was committed to trick readers into buying it. It&#x27;s not the author&#x27;s work, and there&#x27;s no human message behind it.</div><br/><div id="39075467" class="c"><input type="checkbox" id="c-39075467" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073186">parent</a><span>|</span><a href="#39075534">next</a><span>|</span><label class="collapse" for="c-39075467">[-]</label><label class="expand" for="c-39075467">[1 more]</label></div><br/><div class="children"><div class="content">Novels aren&#x27;t about a message. They&#x27;re entertainment. If the novel is entertaining then it&#x27;s irrelevant whether there is or isn&#x27;t a message in it. Besides, literature enthusiasts will invent a message for a popular story even if there never was one.<p>Also, I&#x27;m sure that you can eventually just prompt the model with the message you want to put into the story, if you can&#x27;t already do that.</div><br/></div></div><div id="39075534" class="c"><input type="checkbox" id="c-39075534" checked=""/><div class="controls bullet"><span class="by">portaouflop</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073186">parent</a><span>|</span><a href="#39075467">prev</a><span>|</span><a href="#39077592">next</a><span>|</span><label class="collapse" for="c-39075534">[-]</label><label class="expand" for="c-39075534">[1 more]</label></div><br/><div class="children"><div class="content">I haven’t read anything “shit out” by any LLM that even nearly approaches the level of quality by the authors you named — would very much like to see something like that - do you have any evidence for your claims?<p>AFAICT current text generation is something approaching bad mimicry at best and downright abysmal in general. 
I think you still need a very skilled author and meaty brain with a story to tell to make use of an LLM for storytelling. 
Sure it’s a useful tool that will make authors more effective but we are far from the point where you tell the LLM “write a story set in Pratchetts Discworld” and something acceptable or even entertaining will be spit out - if such a thing can even be achieved.</div><br/></div></div><div id="39077592" class="c"><input type="checkbox" id="c-39077592" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073186">parent</a><span>|</span><a href="#39075534">prev</a><span>|</span><a href="#39075447">next</a><span>|</span><label class="collapse" for="c-39077592">[-]</label><label class="expand" for="c-39077592">[1 more]</label></div><br/><div class="children"><div class="content">Thing is there are way more <i>good</i> books written, than any single person can consume in their lifetimes. An average person like me, reading a mixed diet of classics, obscure recommendations and what&#x27;s popular right now, I still don&#x27;t feel like I&#x27;m making a dent in the pile of high quality written content.<p>Given all that, the purpose of LLMs should be to create tailor made content to everyone&#x27;s tastes. However, it seems the hardcore guardrails put into GPT4 and Claude prevent it from generating anything enjoyable. It seems, even the plot of the average Star Wars movie is too spicy for modern LLM sensibilities, never mind something like Stephen King.</div><br/></div></div></div></div><div id="39075447" class="c"><input type="checkbox" id="c-39075447" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072915">parent</a><span>|</span><a href="#39073186">prev</a><span>|</span><a href="#39074768">next</a><span>|</span><label class="collapse" for="c-39075447">[-]</label><label class="expand" for="c-39075447">[4 more]</label></div><br/><div class="children"><div class="content">I disagree. I definitely value modern digital art more than most historical art, because it just looks better. If AI art looks better (and in some cases it does) then I&#x27;ll prefer that.</div><br/><div id="39076090" class="c"><input type="checkbox" id="c-39076090" checked=""/><div class="controls bullet"><span class="by">kredd</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075447">parent</a><span>|</span><a href="#39074768">next</a><span>|</span><label class="collapse" for="c-39076090">[-]</label><label class="expand" for="c-39076090">[3 more]</label></div><br/><div class="children"><div class="content">That’s totally fine, everyone’s definition of art is subjective. But general value of an art as a piece will just still be zero for AI generated ones, just like any IKEA &#x2F; Amazon print piece. You just pay for the “looks pretty”, frame and paper.</div><br/><div id="39076759" class="c"><input type="checkbox" id="c-39076759" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39076090">parent</a><span>|</span><a href="#39074768">next</a><span>|</span><label class="collapse" for="c-39076759">[-]</label><label class="expand" for="c-39076759">[2 more]</label></div><br/><div class="children"><div class="content">&gt;<i>You just pay for the “looks pretty”, frame and paper.</i><p>But you pay that for any piece of art though? You appreciate it because you like what it looks like. The utility of it is in how good it looks, it&#x27;s not how much effort was put into it.<p>If you need a ditch you&#x27;re not going to value the ditch more if the worker dug it by hand instead of using an excavator. You value it based on the utility it provides you.</div><br/><div id="39079264" class="c"><input type="checkbox" id="c-39079264" checked=""/><div class="controls bullet"><span class="by">kredd</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39076759">parent</a><span>|</span><a href="#39074768">next</a><span>|</span><label class="collapse" for="c-39079264">[-]</label><label class="expand" for="c-39079264">[1 more]</label></div><br/><div class="children"><div class="content">That analogy doesn’t work for art, since worker’s ditch is result based. There are no feelings like “i like this ditch”, “experience of a ditch” or “i’m curious how this ditch was dug”.<p>Again, i’m not saying buying a mass made AI art will be wrong. Just personally speaking, it will never evoke any feelings other than “looks neat” for me. So its inherent “art value” is close to 0 as I can guess its history is basically someone put in a prompt and sent it to print (which I can do myself on my phone too!). It’s the same as looking at cool building pics on my phone (0 art value) versus actually seeing them in person (non-0), mostly because the feelings I get from it. That being said, if it makes others happy, it’s not my place to judge.</div><br/></div></div></div></div></div></div></div></div><div id="39074768" class="c"><input type="checkbox" id="c-39074768" checked=""/><div class="controls bullet"><span class="by">petesergeant</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072915">parent</a><span>|</span><a href="#39075447">prev</a><span>|</span><a href="#39075103">next</a><span>|</span><label class="collapse" for="c-39074768">[-]</label><label class="expand" for="c-39074768">[1 more]</label></div><br/><div class="children"><div class="content">&gt; population tends to put value not on the result, but origin and process<p>I think population tends to value &quot;looks pretty&quot;, and it&#x27;s other artists, connoisseurs, and art critics who value origin and process. Exit Through the Gift Shop sums this up nicely</div><br/></div></div><div id="39075103" class="c"><input type="checkbox" id="c-39075103" checked=""/><div class="controls bullet"><span class="by">Theodores</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072915">parent</a><span>|</span><a href="#39074768">prev</a><span>|</span><a href="#39073074">next</a><span>|</span><label class="collapse" for="c-39075103">[-]</label><label class="expand" for="c-39075103">[5 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Labor_theory_of_value" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Labor_theory_of_value</a><p>According to Marx, value is only created with human labour. This is not just a Marxist theory, it is an observation.<p>There may be lots of over-priced junk that makes you want to question this idea. But let&#x27;s not nit-pick on that.<p>In two years time people will not see any value in AI art, quite correctly because there is not much human labour in creating it.</div><br/><div id="39075286" class="c"><input type="checkbox" id="c-39075286" checked=""/><div class="controls bullet"><span class="by">mesh</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075103">parent</a><span>|</span><a href="#39075479">next</a><span>|</span><label class="collapse" for="c-39075286">[-]</label><label class="expand" for="c-39075286">[1 more]</label></div><br/><div class="children"><div class="content">In two years time, no one will know what was created with AI, what was created by humans, or what was created by both.</div><br/></div></div><div id="39075479" class="c"><input type="checkbox" id="c-39075479" checked=""/><div class="controls bullet"><span class="by">Gormo</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075103">parent</a><span>|</span><a href="#39075286">prev</a><span>|</span><a href="#39075555">next</a><span>|</span><label class="collapse" for="c-39075479">[-]</label><label class="expand" for="c-39075479">[1 more]</label></div><br/><div class="children"><div class="content">&gt; According to Marx, value is only created with human labour. This is not just a Marxist theory, it is an observation.<p>And yet it&#x27;s completely and absolutely wrong.  Value is created by the subjective utility offered to the consumer, irrespective of what inputs created the thing conveying that utility.</div><br/></div></div><div id="39075555" class="c"><input type="checkbox" id="c-39075555" checked=""/><div class="controls bullet"><span class="by">jquery</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075103">parent</a><span>|</span><a href="#39075479">prev</a><span>|</span><a href="#39075780">next</a><span>|</span><label class="collapse" for="c-39075555">[-]</label><label class="expand" for="c-39075555">[1 more]</label></div><br/><div class="children"><div class="content">Labor theory of value is quite controversial, many economists call it tautological or even metaphysical. I also don&#x27;t really see what LTV has to say about AI art, if anything, except that the economic value generated by AI art should be distributed to everybody and not just funneled to a few capitalists at the top. I would agree with that. It&#x27;s true that more jobs get created even as jobs are destroyed, but it&#x27;s also true that just as our ancestors fought for a 40 hour work week and a social safety net, we should be able to ask for more as computers become ever so productive.</div><br/></div></div><div id="39075780" class="c"><input type="checkbox" id="c-39075780" checked=""/><div class="controls bullet"><span class="by">petesergeant</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075103">parent</a><span>|</span><a href="#39075555">prev</a><span>|</span><a href="#39073074">next</a><span>|</span><label class="collapse" for="c-39075780">[-]</label><label class="expand" for="c-39075780">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is not just a Marxist theory, it is an observation.<p>Yeah? Well, you know, that&#x27;s just like uh, your opinion, man</div><br/></div></div></div></div><div id="39073074" class="c"><input type="checkbox" id="c-39073074" checked=""/><div class="controls bullet"><span class="by">MacsHeadroom</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072915">parent</a><span>|</span><a href="#39075103">prev</a><span>|</span><a href="#39073148">next</a><span>|</span><label class="collapse" for="c-39073074">[-]</label><label class="expand" for="c-39073074">[13 more]</label></div><br/><div class="children"><div class="content">Nope, but I already look down on artists who refuse to integrate generative AI into their processes.</div><br/><div id="39073163" class="c"><input type="checkbox" id="c-39073163" checked=""/><div class="controls bullet"><span class="by">mplewis</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073074">parent</a><span>|</span><a href="#39073185">next</a><span>|</span><label class="collapse" for="c-39073163">[-]</label><label class="expand" for="c-39073163">[1 more]</label></div><br/><div class="children"><div class="content">Can you share some of the art you’ve made with generative AI?</div><br/></div></div><div id="39073185" class="c"><input type="checkbox" id="c-39073185" checked=""/><div class="controls bullet"><span class="by">jurynulifcation</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073074">parent</a><span>|</span><a href="#39073163">prev</a><span>|</span><a href="#39073327">next</a><span>|</span><label class="collapse" for="c-39073185">[-]</label><label class="expand" for="c-39073185">[1 more]</label></div><br/><div class="children"><div class="content">Cool, who are you?</div><br/></div></div><div id="39073327" class="c"><input type="checkbox" id="c-39073327" checked=""/><div class="controls bullet"><span class="by">MisterBastahrd</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073074">parent</a><span>|</span><a href="#39073185">prev</a><span>|</span><a href="#39073148">next</a><span>|</span><label class="collapse" for="c-39073327">[-]</label><label class="expand" for="c-39073327">[10 more]</label></div><br/><div class="children"><div class="content">People who use generative AI in their processes are not artists.</div><br/><div id="39073829" class="c"><input type="checkbox" id="c-39073829" checked=""/><div class="controls bullet"><span class="by">blacklion</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073327">parent</a><span>|</span><a href="#39075625">next</a><span>|</span><label class="collapse" for="c-39073829">[-]</label><label class="expand" for="c-39073829">[2 more]</label></div><br/><div class="children"><div class="content">And people who use Photoshop are?<p>There is somewhat famous digital artist from Russia - Alexey Andreev. Google it, he has very distinctive style of realistic technique and surrealistic situations, like landing big manta ray on the deck of aircraft carrier. Or you can see his old works in his 5-years-not-updates LJ [1].<p>Now he uses generative AI as one of his tools. As Photoshop, as different (unrealistic!) brushes in Photoshop, as other digital tools. His style is still 100% recognizable and his works don&#x27;t become worse or more &quot;generic&quot;. Is he still artist? I think so.<p>Where will you draw the line?<p>[1] - <a href="https:&#x2F;&#x2F;alexandreev.livejournal.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;alexandreev.livejournal.com&#x2F;</a></div><br/></div></div><div id="39075625" class="c"><input type="checkbox" id="c-39075625" checked=""/><div class="controls bullet"><span class="by">smackeyacky</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073327">parent</a><span>|</span><a href="#39073829">prev</a><span>|</span><a href="#39074963">next</a><span>|</span><label class="collapse" for="c-39075625">[-]</label><label class="expand" for="c-39075625">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think this is quite right.  I think paraphrasing The Incredibles has a better take:<p><i>When everybody is an artist, then nobody will be one.</i></div><br/></div></div><div id="39074963" class="c"><input type="checkbox" id="c-39074963" checked=""/><div class="controls bullet"><span class="by">davely</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073327">parent</a><span>|</span><a href="#39075625">prev</a><span>|</span><a href="#39073608">next</a><span>|</span><label class="collapse" for="c-39074963">[-]</label><label class="expand" for="c-39074963">[1 more]</label></div><br/><div class="children"><div class="content">I use generative AI to rubber duck and help improve my code.<p>Am I no longer a software engineer?</div><br/></div></div><div id="39073608" class="c"><input type="checkbox" id="c-39073608" checked=""/><div class="controls bullet"><span class="by">password54321</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073327">parent</a><span>|</span><a href="#39074963">prev</a><span>|</span><a href="#39073148">next</a><span>|</span><label class="collapse" for="c-39073608">[-]</label><label class="expand" for="c-39073608">[5 more]</label></div><br/><div class="children"><div class="content">This is true. They are just taking a sample from a generated latent space, just like taking a photo of something doesn&#x27;t make you an artist.</div><br/><div id="39073839" class="c"><input type="checkbox" id="c-39073839" checked=""/><div class="controls bullet"><span class="by">blacklion</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073608">parent</a><span>|</span><a href="#39073148">next</a><span>|</span><label class="collapse" for="c-39073839">[-]</label><label class="expand" for="c-39073839">[4 more]</label></div><br/><div class="children"><div class="content">So, there is no artists in, for example, street photography? Picture must be altered to become art, or staged?<p>Was it irony? :)</div><br/><div id="39073908" class="c"><input type="checkbox" id="c-39073908" checked=""/><div class="controls bullet"><span class="by">password54321</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073839">parent</a><span>|</span><a href="#39073874">next</a><span>|</span><label class="collapse" for="c-39073908">[-]</label><label class="expand" for="c-39073908">[1 more]</label></div><br/><div class="children"><div class="content">They are photographers. Here is the definition of an artist so you can have better clarity on what an artist is:<p>&quot;A person who creates art (such as painting, sculpture, music, or writing) using conscious skill and creative imagination&quot;</div><br/></div></div><div id="39075428" class="c"><input type="checkbox" id="c-39075428" checked=""/><div class="controls bullet"><span class="by">aqfamnzc</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073839">parent</a><span>|</span><a href="#39073874">prev</a><span>|</span><a href="#39073148">next</a><span>|</span><label class="collapse" for="c-39075428">[-]</label><label class="expand" for="c-39075428">[1 more]</label></div><br/><div class="children"><div class="content">I took gp as satire. But maybe not haha.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39073148" class="c"><input type="checkbox" id="c-39073148" checked=""/><div class="controls bullet"><span class="by">falcolas</span><span>|</span><a href="#39071494">parent</a><span>|</span><a href="#39072915">prev</a><span>|</span><a href="#39072108">next</a><span>|</span><label class="collapse" for="c-39073148">[-]</label><label class="expand" for="c-39073148">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Being able to find a mix of styles you like and apply them to new subjects to make your own unique, personalized, artwork sounds like a wickedly cool power to give to billions of people.<p>And in the process, they will obviate the need for Nightshade and similar tools.<p>AI models ingesting AI generated content does the work of destroying the models all by itself. Have a look at &quot;Model Collapse&quot; in relation to generative AI.</div><br/></div></div><div id="39072108" class="c"><input type="checkbox" id="c-39072108" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#39071494">parent</a><span>|</span><a href="#39073148">prev</a><span>|</span><a href="#39071744">next</a><span>|</span><label class="collapse" for="c-39072108">[-]</label><label class="expand" for="c-39072108">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;ll be about as wickedly tool as the ability to get on the internet, e.g. commoditized, transactional, and boring.</div><br/><div id="39072905" class="c"><input type="checkbox" id="c-39072905" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072108">parent</a><span>|</span><a href="#39071744">next</a><span>|</span><label class="collapse" for="c-39072905">[-]</label><label class="expand" for="c-39072905">[3 more]</label></div><br/><div class="children"><div class="content">I know this is an unpopular thing to say these days, but I still think the internet is amazing.<p>I have more access to information now than the most powerful people in the world did 40 years ago. I can learn about quantum field theory, about which pop star is allegedly fucking which other pop star, etc.<p>If I don&#x27;t care about the law I can read any of 25 million books or 100 million scientific papers all available on Anna&#x27;s Archive for free in seconds.</div><br/><div id="39074751" class="c"><input type="checkbox" id="c-39074751" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072905">parent</a><span>|</span><a href="#39073413">next</a><span>|</span><label class="collapse" for="c-39074751">[-]</label><label class="expand" for="c-39074751">[1 more]</label></div><br/><div class="children"><div class="content">As Jeff Bezos recently said on the Lex podcast: one of the greatest compliments you can give an inventor is that they’re invention will be taken for granted by future generations.<p>“It won’t be any more wickedly cool than the internet” - saying something won’t be any more wickedly cool than the most profound and impactful pieces of infrastructure human civilization has erected is a pretty high compliment.</div><br/></div></div></div></div></div></div><div id="39071744" class="c"><input type="checkbox" id="c-39071744" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#39071494">parent</a><span>|</span><a href="#39072108">prev</a><span>|</span><a href="#39073553">next</a><span>|</span><label class="collapse" for="c-39071744">[-]</label><label class="expand" for="c-39071744">[9 more]</label></div><br/><div class="children"><div class="content">And we only had to alienate millions of people from their labor to do it.</div><br/><div id="39072010" class="c"><input type="checkbox" id="c-39072010" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39071744">parent</a><span>|</span><a href="#39071879">next</a><span>|</span><label class="collapse" for="c-39072010">[-]</label><label class="expand" for="c-39072010">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely agree we should allow people to accumulate equity through effective allocation of their labor.<p>And I also agree that we shouldn’t build systems that alienate people from that accumulated equity.</div><br/></div></div><div id="39071879" class="c"><input type="checkbox" id="c-39071879" checked=""/><div class="controls bullet"><span class="by">DennisAleynikov</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39071744">parent</a><span>|</span><a href="#39072010">prev</a><span>|</span><a href="#39078278">next</a><span>|</span><label class="collapse" for="c-39071879">[-]</label><label class="expand" for="c-39071879">[5 more]</label></div><br/><div class="children"><div class="content">Yeah, sadly those millions of people don’t matter in the grand scheme of things and were never going to profit off their work long term</div><br/><div id="39087616" class="c"><input type="checkbox" id="c-39087616" checked=""/><div class="controls bullet"><span class="by">easyThrowaway</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39071879">parent</a><span>|</span><a href="#39072092">next</a><span>|</span><label class="collapse" for="c-39087616">[-]</label><label class="expand" for="c-39087616">[1 more]</label></div><br/><div class="children"><div class="content">Where the &quot;grand scheme of things&quot; are the quarter reports of a few AI-invested companies?</div><br/></div></div><div id="39072092" class="c"><input type="checkbox" id="c-39072092" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39071879">parent</a><span>|</span><a href="#39087616">prev</a><span>|</span><a href="#39078278">next</a><span>|</span><label class="collapse" for="c-39072092">[-]</label><label class="expand" for="c-39072092">[3 more]</label></div><br/><div class="children"><div class="content">What a bummer of a thing to say.<p>Those millions&#x2F;billions of people matter a great deal.</div><br/><div id="39074892" class="c"><input type="checkbox" id="c-39074892" checked=""/><div class="controls bullet"><span class="by">DennisAleynikov</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072092">parent</a><span>|</span><a href="#39078278">next</a><span>|</span><label class="collapse" for="c-39074892">[-]</label><label class="expand" for="c-39074892">[2 more]</label></div><br/><div class="children"><div class="content">They matter but not under the current system. Artists are a rarely paid profession, and there are professional artists out there but there’s now a huge amount of people that will never contact an artist for work that used to only be human powered. It’s not personal for me. I understand that desire to resist the inevitable but it’s here now.<p>For what it’s worth I never use midjourney or dalle or any of the commercial closed systems that steal from artists but I know I can’t stop the masses from going there and inputting “give me pretty picture in style x”</div><br/><div id="39077754" class="c"><input type="checkbox" id="c-39077754" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39074892">parent</a><span>|</span><a href="#39078278">next</a><span>|</span><label class="collapse" for="c-39077754">[-]</label><label class="expand" for="c-39077754">[1 more]</label></div><br/><div class="children"><div class="content">Resistance is important imo. If this happens and we, who work in this industry, say nothing, what good are we. It&#x27;s only inevitable if it&#x27;s socially acceptable.</div><br/></div></div></div></div></div></div></div></div><div id="39078278" class="c"><input type="checkbox" id="c-39078278" checked=""/><div class="controls bullet"><span class="by">BeFlatXIII</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39071744">parent</a><span>|</span><a href="#39071879">prev</a><span>|</span><a href="#39071884">next</a><span>|</span><label class="collapse" for="c-39078278">[-]</label><label class="expand" for="c-39078278">[1 more]</label></div><br/><div class="children"><div class="content">Worth it.</div><br/></div></div><div id="39071884" class="c"><input type="checkbox" id="c-39071884" checked=""/><div class="controls bullet"><span class="by">mensetmanusman</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39071744">parent</a><span>|</span><a href="#39078278">prev</a><span>|</span><a href="#39073553">next</a><span>|</span><label class="collapse" for="c-39071884">[-]</label><label class="expand" for="c-39071884">[1 more]</label></div><br/><div class="children"><div class="content">Is this utilitarianism?</div><br/></div></div></div></div><div id="39073553" class="c"><input type="checkbox" id="c-39073553" checked=""/><div class="controls bullet"><span class="by">password54321</span><span>|</span><a href="#39071494">parent</a><span>|</span><a href="#39071744">prev</a><span>|</span><a href="#39070676">next</a><span>|</span><label class="collapse" for="c-39073553">[-]</label><label class="expand" for="c-39073553">[4 more]</label></div><br/><div class="children"><div class="content">Not really. There is a reason why we find realistic painting to be more fascinating than a photo and why some still practice it. The effort put in by another artist does affect our enjoyment.</div><br/><div id="39075495" class="c"><input type="checkbox" id="c-39075495" checked=""/><div class="controls bullet"><span class="by">wruza</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073553">parent</a><span>|</span><a href="#39075777">next</a><span>|</span><label class="collapse" for="c-39075495">[-]</label><label class="expand" for="c-39075495">[1 more]</label></div><br/><div class="children"><div class="content">For me it doesn’t. I’m generating images, realistic, 2.5d, 2d and I like them as much. I don’t feel (or miss) what you described. Or what any other arts guy describes, for that matter. Arts people are different, because they were trained to feel something a normal person wouldn’t. And that’s okay, a normal person without training wouldn’t see how much beauty and effort there is in an algorithm or a legal contract as well.</div><br/></div></div><div id="39075777" class="c"><input type="checkbox" id="c-39075777" checked=""/><div class="controls bullet"><span class="by">dartharva</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073553">parent</a><span>|</span><a href="#39075495">prev</a><span>|</span><a href="#39070676">next</a><span>|</span><label class="collapse" for="c-39075777">[-]</label><label class="expand" for="c-39075777">[2 more]</label></div><br/><div class="children"><div class="content">The word &quot;we&quot; is doing a lot of heavy lifting here. A large majority of consumers can&#x27;t even tell apart AI-generated from handmade, let alone care who or what made the thing.</div><br/><div id="39077983" class="c"><input type="checkbox" id="c-39077983" checked=""/><div class="controls bullet"><span class="by">password54321</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075777">parent</a><span>|</span><a href="#39070676">next</a><span>|</span><label class="collapse" for="c-39077983">[-]</label><label class="expand" for="c-39077983">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, that&#x27;s just information you made up on the spot.</div><br/></div></div></div></div></div></div></div></div><div id="39070676" class="c"><input type="checkbox" id="c-39070676" checked=""/><div class="controls bullet"><span class="by">alentred</span><span>|</span><a href="#39071494">prev</a><span>|</span><a href="#39068525">next</a><span>|</span><label class="collapse" for="c-39070676">[-]</label><label class="expand" for="c-39070676">[7 more]</label></div><br/><div class="children"><div class="content">With this &quot;solution&quot; it looks like the world of art enters the cat-and-mouse game the ad blockers were playing for the last decade or two.</div><br/><div id="39070816" class="c"><input type="checkbox" id="c-39070816" checked=""/><div class="controls bullet"><span class="by">isodev</span><span>|</span><a href="#39070676">parent</a><span>|</span><a href="#39070883">next</a><span>|</span><label class="collapse" for="c-39070816">[-]</label><label class="expand" for="c-39070816">[4 more]</label></div><br/><div class="children"><div class="content">I just tested it with Azure AI image classification and it worked - so this cat is yet to adapt to the mouse’s latest idea.<p>I still feel it is absolutely wrong to roam around the internet and scrape images (without consent) in order to power one’s cash cow AI. I hope more methods to protect artworks (including audio and other formats) become more accessible.</div><br/><div id="39074680" class="c"><input type="checkbox" id="c-39074680" checked=""/><div class="controls bullet"><span class="by">HKH2</span><span>|</span><a href="#39070676">root</a><span>|</span><a href="#39070816">parent</a><span>|</span><a href="#39070883">next</a><span>|</span><label class="collapse" for="c-39074680">[-]</label><label class="expand" for="c-39074680">[3 more]</label></div><br/><div class="children"><div class="content">Artists copy from each other all the time. Arguably, culture exists because of copying (folk stories by necessity); copyright makes culture top-down and stagnant, and you can&#x27;t avoid it because they have the money to shove it right in your face. Who wants trickle-down culture?</div><br/><div id="39075165" class="c"><input type="checkbox" id="c-39075165" checked=""/><div class="controls bullet"><span class="by">blibble</span><span>|</span><a href="#39070676">root</a><span>|</span><a href="#39074680">parent</a><span>|</span><a href="#39070883">next</a><span>|</span><label class="collapse" for="c-39075165">[-]</label><label class="expand" for="c-39075165">[2 more]</label></div><br/><div class="children"><div class="content">it&#x27;s not an artist, it&#x27;s a piece of software<p>in the same way bittorrent or gzip is</div><br/><div id="39077990" class="c"><input type="checkbox" id="c-39077990" checked=""/><div class="controls bullet"><span class="by">HKH2</span><span>|</span><a href="#39070676">root</a><span>|</span><a href="#39075165">parent</a><span>|</span><a href="#39070883">next</a><span>|</span><label class="collapse" for="c-39077990">[-]</label><label class="expand" for="c-39077990">[1 more]</label></div><br/><div class="children"><div class="content">Sure. The person using it has intent. Now we have come to a point in which intent alone is art. Let there be light.</div><br/></div></div></div></div></div></div></div></div><div id="39070883" class="c"><input type="checkbox" id="c-39070883" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#39070676">parent</a><span>|</span><a href="#39070816">prev</a><span>|</span><a href="#39068525">next</a><span>|</span><label class="collapse" for="c-39070883">[-]</label><label class="expand" for="c-39070883">[2 more]</label></div><br/><div class="children"><div class="content">I might be missing something because I don&#x27;t know much about the architecture of either Nightshade or AI art generators, but I wonder if you could try to have a GAN-like architecture (an extra model trying to trick the model) for the part of the generator that labels images to build resistance to Nightshade-like filters.</div><br/><div id="39071288" class="c"><input type="checkbox" id="c-39071288" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#39070676">root</a><span>|</span><a href="#39070883">parent</a><span>|</span><a href="#39068525">next</a><span>|</span><label class="collapse" for="c-39071288">[-]</label><label class="expand" for="c-39071288">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t even have to be a full GAN, you only need to train the discriminator side to filter out the data. Clean reference images + Nightshade would be the generator side.</div><br/></div></div></div></div></div></div><div id="39068525" class="c"><input type="checkbox" id="c-39068525" checked=""/><div class="controls bullet"><span class="by">jamesu</span><span>|</span><a href="#39070676">prev</a><span>|</span><a href="#39070835">next</a><span>|</span><label class="collapse" for="c-39068525">[-]</label><label class="expand" for="c-39068525">[7 more]</label></div><br/><div class="children"><div class="content">Long-term I think the real problem for artists will be corporations generating their own high quality targeted datasets from a cheap labor pool, completely outcompeting them by a landslide.</div><br/><div id="39072226" class="c"><input type="checkbox" id="c-39072226" checked=""/><div class="controls bullet"><span class="by">jdietrich</span><span>|</span><a href="#39068525">parent</a><span>|</span><a href="#39071476">next</a><span>|</span><label class="collapse" for="c-39072226">[-]</label><label class="expand" for="c-39072226">[1 more]</label></div><br/><div class="children"><div class="content">In the short-to-medium term, we&#x27;re seeing huge improvements in the data efficiency of generative models. We haven&#x27;t really started to see self-training in diffusion models, which could improve data efficiency by orders of magnitude. Current models are good at generalisation and are getting better at an incredible pace, so any efforts to limit the progress of AI by restricting access to training data is a speedbump rather than a roadblock.</div><br/></div></div><div id="39071778" class="c"><input type="checkbox" id="c-39071778" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068525">parent</a><span>|</span><a href="#39071476">prev</a><span>|</span><a href="#39070835">next</a><span>|</span><label class="collapse" for="c-39071778">[-]</label><label class="expand" for="c-39071778">[4 more]</label></div><br/><div class="children"><div class="content">It will democratize art.</div><br/><div id="39076690" class="c"><input type="checkbox" id="c-39076690" checked=""/><div class="controls bullet"><span class="by">sussmannbaka</span><span>|</span><a href="#39068525">root</a><span>|</span><a href="#39071778">parent</a><span>|</span><a href="#39072152">next</a><span>|</span><label class="collapse" for="c-39076690">[-]</label><label class="expand" for="c-39076690">[1 more]</label></div><br/><div class="children"><div class="content">Art is already democratized. It has been for decades. Everyone can pick it up at zero cost. Even you!<p>The poorest people have historically produced great art. Training a model, however? Expensive. Running it locally? Expensive. Paying the sub? Expensive.<p>Nothing is being democratized, the only thing this does is devaluing the blood and sweat people have put into their work so FAANG can sell it to lazy suckers.</div><br/></div></div><div id="39072152" class="c"><input type="checkbox" id="c-39072152" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#39068525">root</a><span>|</span><a href="#39071778">parent</a><span>|</span><a href="#39076690">prev</a><span>|</span><a href="#39070835">next</a><span>|</span><label class="collapse" for="c-39072152">[-]</label><label class="expand" for="c-39072152">[2 more]</label></div><br/><div class="children"><div class="content">then it won&#x27;t be art anymore, it&#x27;ll just be mountains of shit<p>sorta like what the laptop did for writing</div><br/><div id="39074447" class="c"><input type="checkbox" id="c-39074447" checked=""/><div class="controls bullet"><span class="by">jrflowers</span><span>|</span><a href="#39068525">root</a><span>|</span><a href="#39072152">parent</a><span>|</span><a href="#39070835">next</a><span>|</span><label class="collapse" for="c-39074447">[-]</label><label class="expand" for="c-39074447">[1 more]</label></div><br/><div class="children"><div class="content">This is a good point. There hasn’t been any writing since the release of the Gateway Solo in 1995</div><br/></div></div></div></div></div></div></div></div><div id="39070835" class="c"><input type="checkbox" id="c-39070835" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39068525">prev</a><span>|</span><a href="#39068302">next</a><span>|</span><label class="collapse" for="c-39070835">[-]</label><label class="expand" for="c-39070835">[7 more]</label></div><br/><div class="children"><div class="content">What the article doesn&#x27;t illustrate is that it destroys fine detail in the image, even in the thumbnails of the reference paper:
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.13828.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.13828.pdf</a><p>Also... Maybe I am naive, but it seems rather trivial to work around with a quick prefilter? I don&#x27;t know if tradition denoising would be enough, but worst case you could run img2img diffusion.<p>reply</div><br/><div id="39071269" class="c"><input type="checkbox" id="c-39071269" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39070835">parent</a><span>|</span><a href="#39068302">next</a><span>|</span><label class="collapse" for="c-39071269">[-]</label><label class="expand" for="c-39071269">[6 more]</label></div><br/><div class="children"><div class="content">The poisoned images aren&#x27;t intended to be viewed, rather scraped and pass a basic human screen. You wouldn&#x27;t be able to denoise as you&#x27;d have to denoise the entire dataset, the entire point is that these are virtually undetectable from typical training set examples, but they can push prompt frequencies around at will with a small number of poisoned examples.</div><br/><div id="39071603" class="c"><input type="checkbox" id="c-39071603" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39070835">root</a><span>|</span><a href="#39071269">parent</a><span>|</span><a href="#39068302">next</a><span>|</span><label class="collapse" for="c-39071603">[-]</label><label class="expand" for="c-39071603">[5 more]</label></div><br/><div class="children"><div class="content">&gt; You wouldn&#x27;t be able to denoise as you&#x27;d have to denoise the entire dataset<p>Doing that requires much less compute than training a large generative image model.</div><br/><div id="39071907" class="c"><input type="checkbox" id="c-39071907" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39070835">root</a><span>|</span><a href="#39071603">parent</a><span>|</span><a href="#39071898">next</a><span>|</span><label class="collapse" for="c-39071907">[-]</label><label class="expand" for="c-39071907">[3 more]</label></div><br/><div class="children"><div class="content">I guess the idea is that the model trainers are ignorant of this and wouldn&#x27;t know to preprocess&#x2F;wouldn&#x27;t bother?<p>That&#x27;s actually quite plausible.</div><br/><div id="39075025" class="c"><input type="checkbox" id="c-39075025" checked=""/><div class="controls bullet"><span class="by">BugsJustFindMe</span><span>|</span><a href="#39070835">root</a><span>|</span><a href="#39071907">parent</a><span>|</span><a href="#39071898">next</a><span>|</span><label class="collapse" for="c-39075025">[-]</label><label class="expand" for="c-39075025">[2 more]</label></div><br/><div class="children"><div class="content">&gt; <i>I guess the idea is that the model trainers are ignorant of this</i><p>Maybe they&#x27;re ignorant of it right up until you announce it, but then they&#x27;re no longer ignorant of it.</div><br/><div id="39081379" class="c"><input type="checkbox" id="c-39081379" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39070835">root</a><span>|</span><a href="#39075025">parent</a><span>|</span><a href="#39071898">next</a><span>|</span><label class="collapse" for="c-39081379">[-]</label><label class="expand" for="c-39081379">[1 more]</label></div><br/><div class="children"><div class="content">Right, but they aren&#x27;t necessarily paying attention to this.<p>I am not trying to belittle foundational model trainers, but <i>a lot</i> goes on in ML land. Even groups can&#x27;t track every development.</div><br/></div></div></div></div></div></div><div id="39071898" class="c"><input type="checkbox" id="c-39071898" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39070835">root</a><span>|</span><a href="#39071603">parent</a><span>|</span><a href="#39071907">prev</a><span>|</span><a href="#39068302">next</a><span>|</span><label class="collapse" for="c-39071898">[-]</label><label class="expand" for="c-39071898">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  the entire point is that these are virtually undetectable from typical training set examples<p>I&#x27;ll repeat this point for clarity. After going over the paper again, denoising shouldn&#x27;t affect this attack, it&#x27;s the ability of plausible images to not be detected by human or AI discriminators (yet)</div><br/></div></div></div></div></div></div></div></div><div id="39068302" class="c"><input type="checkbox" id="c-39068302" checked=""/><div class="controls bullet"><span class="by">Quanttek</span><span>|</span><a href="#39070835">prev</a><span>|</span><a href="#39068570">next</a><span>|</span><label class="collapse" for="c-39068302">[-]</label><label class="expand" for="c-39068302">[27 more]</label></div><br/><div class="children"><div class="content">This is fantastic. If companies want to create AI models, they should license the content they use for the training data. As long as there are not sufficient legal protections and the EU&#x2F;Congress do not act, tools like these can serve as a stopgap and maybe help increase pressure on policymakers</div><br/><div id="39068494" class="c"><input type="checkbox" id="c-39068494" checked=""/><div class="controls bullet"><span class="by">popohauer</span><span>|</span><a href="#39068302">parent</a><span>|</span><a href="#39068328">next</a><span>|</span><label class="collapse" for="c-39068494">[-]</label><label class="expand" for="c-39068494">[8 more]</label></div><br/><div class="children"><div class="content">It&#x27;s going to be interesting to see how the lawsuits against OpenAI by content creators plays out. If the courts rule that AI generated content is a derivative work of all the content it was trained on it could really flip the entire gen AI movement on its head.</div><br/><div id="39068583" class="c"><input type="checkbox" id="c-39068583" checked=""/><div class="controls bullet"><span class="by">luma</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068494">parent</a><span>|</span><a href="#39077651">next</a><span>|</span><label class="collapse" for="c-39068583">[-]</label><label class="expand" for="c-39068583">[5 more]</label></div><br/><div class="children"><div class="content">If it were a derivative work[1] (and sufficiently transformational) then it&#x27;s allowed under current copyright law and might not be the slam dunk ruling you were hoping for.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Derivative_work" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Derivative_work</a></div><br/><div id="39071806" class="c"><input type="checkbox" id="c-39071806" checked=""/><div class="controls bullet"><span class="by">popohauer</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068583">parent</a><span>|</span><a href="#39071947">next</a><span>|</span><label class="collapse" for="c-39071806">[-]</label><label class="expand" for="c-39071806">[1 more]</label></div><br/><div class="children"><div class="content">Oh, interesting, I didn&#x27;t realize that&#x27;s how it worked. Thanks for the additional context around this. Guess it&#x27;s not as upending as I thought it could be.</div><br/></div></div><div id="39071947" class="c"><input type="checkbox" id="c-39071947" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068583">parent</a><span>|</span><a href="#39071806">prev</a><span>|</span><a href="#39068618">next</a><span>|</span><label class="collapse" for="c-39071947">[-]</label><label class="expand" for="c-39071947">[1 more]</label></div><br/><div class="children"><div class="content">Not if it is AI generated. So far only humans can be original enough to warrant copyrights, at least in the US .<p>BTW, the right to prepare derivative works belongs to the copyright holder of the reference work.<p>I doubt that many AI works are in fact derivative works. Sure, some bear enough similarity, but a gross majority likely doesn&#x27;t.</div><br/></div></div><div id="39068618" class="c"><input type="checkbox" id="c-39068618" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068583">parent</a><span>|</span><a href="#39071947">prev</a><span>|</span><a href="#39077651">next</a><span>|</span><label class="collapse" for="c-39068618">[-]</label><label class="expand" for="c-39068618">[2 more]</label></div><br/><div class="children"><div class="content">&quot;sufficiently transformational&quot; is carrying a lot of water here. At minimum it would cloud the issue and might expose anyone using AI to lawsuits where they&#x27;d potentially have to defend each generated image.</div><br/><div id="39071964" class="c"><input type="checkbox" id="c-39071964" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068618">parent</a><span>|</span><a href="#39077651">next</a><span>|</span><label class="collapse" for="c-39071964">[-]</label><label class="expand" for="c-39071964">[1 more]</label></div><br/><div class="children"><div class="content">Sufficiently transformational only applies to copyrightability, but AI works are not copyrightable under current US law, so it&#x27;s a non-issue.</div><br/></div></div></div></div></div></div><div id="39077651" class="c"><input type="checkbox" id="c-39077651" checked=""/><div class="controls bullet"><span class="by">torginus</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068494">parent</a><span>|</span><a href="#39068583">prev</a><span>|</span><a href="#39078293">next</a><span>|</span><label class="collapse" for="c-39077651">[-]</label><label class="expand" for="c-39077651">[1 more]</label></div><br/><div class="children"><div class="content">My biggest fear is that the big players will drop a few billion dollars to silence the copyright holders with power go away, and new rules are put in place that will make open-source models that can&#x27;t do the same essentially illegal.</div><br/></div></div><div id="39078293" class="c"><input type="checkbox" id="c-39078293" checked=""/><div class="controls bullet"><span class="by">BeFlatXIII</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068494">parent</a><span>|</span><a href="#39077651">prev</a><span>|</span><a href="#39068328">next</a><span>|</span><label class="collapse" for="c-39078293">[-]</label><label class="expand" for="c-39078293">[1 more]</label></div><br/><div class="children"><div class="content">…then I&#x27;ll keep enjoying my Stable Diffusion and pirated models.</div><br/></div></div></div></div><div id="39068328" class="c"><input type="checkbox" id="c-39068328" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#39068302">parent</a><span>|</span><a href="#39068494">prev</a><span>|</span><a href="#39068570">next</a><span>|</span><label class="collapse" for="c-39068328">[-]</label><label class="expand" for="c-39068328">[18 more]</label></div><br/><div class="children"><div class="content">&gt;  they should license the content they use for the training data<p>You mean like OpenAI and Adobe ?<p>Only the free and open source models didn&#x27;t licensed any content for the training data.</div><br/><div id="39068399" class="c"><input type="checkbox" id="c-39068399" checked=""/><div class="controls bullet"><span class="by">galleywest200</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068328">parent</a><span>|</span><a href="#39068452">next</a><span>|</span><label class="collapse" for="c-39068399">[-]</label><label class="expand" for="c-39068399">[15 more]</label></div><br/><div class="children"><div class="content">Adobe is training off of images stored in their cloud systems, per their Terms of Service.<p>OpenAI has provided no such documentation or legal guarantees, and it is still quite possible they scraped all sorts of copyright materials.</div><br/><div id="39068613" class="c"><input type="checkbox" id="c-39068613" checked=""/><div class="controls bullet"><span class="by">luma</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068399">parent</a><span>|</span><a href="#39075068">next</a><span>|</span><label class="collapse" for="c-39068613">[-]</label><label class="expand" for="c-39068613">[11 more]</label></div><br/><div class="children"><div class="content">Google scrapes copyrighted material every day and then presents that material to users in the form of excerpts, images, and entire book pages.  This has been ruled OK by the courts.  Scraping copyrighted information is not illegal or we couldn&#x27;t have search engines.</div><br/><div id="39071990" class="c"><input type="checkbox" id="c-39071990" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068613">parent</a><span>|</span><a href="#39068628">next</a><span>|</span><label class="collapse" for="c-39071990">[-]</label><label class="expand" for="c-39071990">[2 more]</label></div><br/><div class="children"><div class="content">Scraping is only legal if it&#x27;s temporary and transformational. If Google started selling the scrapped images it would be a different story.</div><br/><div id="39074032" class="c"><input type="checkbox" id="c-39074032" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39071990">parent</a><span>|</span><a href="#39068628">next</a><span>|</span><label class="collapse" for="c-39074032">[-]</label><label class="expand" for="c-39074032">[1 more]</label></div><br/><div class="children"><div class="content">What is not transformational for generative AI ?</div><br/></div></div></div></div><div id="39068628" class="c"><input type="checkbox" id="c-39068628" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068613">parent</a><span>|</span><a href="#39071990">prev</a><span>|</span><a href="#39075068">next</a><span>|</span><label class="collapse" for="c-39068628">[-]</label><label class="expand" for="c-39068628">[8 more]</label></div><br/><div class="children"><div class="content">Google is not presently selling &quot;we trained an AI on people&#x27;s art without permission, and you can type their name in along with a prompt to generate a knockoff of their art, and we charge you money for this&quot;. So it&#x27;s not really a 1:1 comparison, since there are companies selling the thing I described right now.</div><br/><div id="39070190" class="c"><input type="checkbox" id="c-39070190" checked=""/><div class="controls bullet"><span class="by">luma</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068628">parent</a><span>|</span><a href="#39075068">next</a><span>|</span><label class="collapse" for="c-39070190">[-]</label><label class="expand" for="c-39070190">[7 more]</label></div><br/><div class="children"><div class="content">That pretty clearly would fall under transformative work.  It is not illegal for a human to paint a painting in the style of, say, Banksy, and then sell the resulting painting.</div><br/><div id="39070426" class="c"><input type="checkbox" id="c-39070426" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070190">parent</a><span>|</span><a href="#39075068">next</a><span>|</span><label class="collapse" for="c-39070426">[-]</label><label class="expand" for="c-39070426">[6 more]</label></div><br/><div class="children"><div class="content">Humans and AI are not the same thing, legally or physically. The law does not currently grant AI rights of any kind.</div><br/><div id="39070751" class="c"><input type="checkbox" id="c-39070751" checked=""/><div class="controls bullet"><span class="by">luma</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070426">parent</a><span>|</span><a href="#39072003">next</a><span>|</span><label class="collapse" for="c-39070751">[-]</label><label class="expand" for="c-39070751">[4 more]</label></div><br/><div class="children"><div class="content">If a human isn&#x27;t violating the law when doing that thing, then how is the machine violating the law when it cannot even hold copyright itself?</div><br/><div id="39071341" class="c"><input type="checkbox" id="c-39071341" checked=""/><div class="controls bullet"><span class="by">estebank</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070751">parent</a><span>|</span><a href="#39070757">next</a><span>|</span><label class="collapse" for="c-39071341">[-]</label><label class="expand" for="c-39071341">[1 more]</label></div><br/><div class="children"><div class="content">In some locales sitting on the street writing down a list of people coming and going is legal, but leaving a camera pointed at the street isn&#x27;t. Legislation like that makes a distinction between an action by a person (which has bounds on scalability) and mechanized actions (that do not).</div><br/></div></div><div id="39070757" class="c"><input type="checkbox" id="c-39070757" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070751">parent</a><span>|</span><a href="#39071341">prev</a><span>|</span><a href="#39072003">next</a><span>|</span><label class="collapse" for="c-39070757">[-]</label><label class="expand" for="c-39070757">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure how to explain this any clearer: Humans and machines are legally distinct. Machines don&#x27;t have the rights that humans have.</div><br/><div id="39071609" class="c"><input type="checkbox" id="c-39071609" checked=""/><div class="controls bullet"><span class="by">Ukv</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070757">parent</a><span>|</span><a href="#39072003">next</a><span>|</span><label class="collapse" for="c-39071609">[-]</label><label class="expand" for="c-39071609">[1 more]</label></div><br/><div class="children"><div class="content">Fair Use is the relevant protection and is not specific to manual creation. Traditional algorithms (e.g: the snippets, caching, and thumbnailing done by search engines) are already covered by it.</div><br/></div></div></div></div></div></div><div id="39072003" class="c"><input type="checkbox" id="c-39072003" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070426">parent</a><span>|</span><a href="#39070751">prev</a><span>|</span><a href="#39075068">next</a><span>|</span><label class="collapse" for="c-39072003">[-]</label><label class="expand" for="c-39072003">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s not prohibited is allowed, at least in the US.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39075068" class="c"><input type="checkbox" id="c-39075068" checked=""/><div class="controls bullet"><span class="by">mesh</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068399">parent</a><span>|</span><a href="#39068613">prev</a><span>|</span><a href="#39068470">next</a><span>|</span><label class="collapse" for="c-39075068">[-]</label><label class="expand" for="c-39075068">[1 more]</label></div><br/><div class="children"><div class="content">No they are not. They train their models on Adobe Stock content. They do not train on user content.<p><a href="https:&#x2F;&#x2F;helpx.adobe.com&#x2F;manage-account&#x2F;using&#x2F;machine-learning-faq.html" rel="nofollow">https:&#x2F;&#x2F;helpx.adobe.com&#x2F;manage-account&#x2F;using&#x2F;machine-learnin...</a><p>&quot;The insights obtained through content analysis will not be used to re-create your content or lead to identifying any personal information.&quot;<p>&quot;For Adobe Firefly, the first model is trained on Adobe Stock images, openly licensed content, and public domain content where the copyright has expired.&quot;<p>(I work for Adobe)</div><br/></div></div><div id="39068470" class="c"><input type="checkbox" id="c-39068470" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068399">parent</a><span>|</span><a href="#39075068">prev</a><span>|</span><a href="#39068434">next</a><span>|</span><label class="collapse" for="c-39068470">[-]</label><label class="expand" for="c-39068470">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI has provided no such documentation<p>OpenAI and Shutterstocks publicly announced their collaboration, Shutterstocks sells AI generated images, generated with OpenAI models.</div><br/></div></div><div id="39068434" class="c"><input type="checkbox" id="c-39068434" checked=""/><div class="controls bullet"><span class="by">devmor</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068399">parent</a><span>|</span><a href="#39068470">prev</a><span>|</span><a href="#39068452">next</a><span>|</span><label class="collapse" for="c-39068434">[-]</label><label class="expand" for="c-39068434">[1 more]</label></div><br/><div class="children"><div class="content">There is in fact, an extreme amount of circumstantial evidence that they intentionally and knowingly violated copyright en mass. It’s been quite a popular subject in tech news the past couple weeks.</div><br/></div></div></div></div><div id="39068452" class="c"><input type="checkbox" id="c-39068452" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068328">parent</a><span>|</span><a href="#39068399">prev</a><span>|</span><a href="#39068578">next</a><span>|</span><label class="collapse" for="c-39068452">[-]</label><label class="expand" for="c-39068452">[1 more]</label></div><br/><div class="children"><div class="content">There is a small difference between any and all. OpenAI certainly didn&#x27;t licence all of the image they use for training.</div><br/></div></div><div id="39068578" class="c"><input type="checkbox" id="c-39068578" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068328">parent</a><span>|</span><a href="#39068452">prev</a><span>|</span><a href="#39068570">next</a><span>|</span><label class="collapse" for="c-39068578">[-]</label><label class="expand" for="c-39068578">[1 more]</label></div><br/><div class="children"><div class="content">source for OpenAI paying anyone a dime? don&#x27;t you think that would set a precedent that everyone else deserves their cut?</div><br/></div></div></div></div></div></div><div id="39068570" class="c"><input type="checkbox" id="c-39068570" checked=""/><div class="controls bullet"><span class="by">msp26</span><span>|</span><a href="#39068302">prev</a><span>|</span><a href="#39068368">next</a><span>|</span><label class="collapse" for="c-39068570">[-]</label><label class="expand" for="c-39068570">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Like Glaze, Nightshade is computed as a multi-objective optimization that minimizes visible changes to the original image.<p>It&#x27;s still noticeably visible.</div><br/><div id="39068608" class="c"><input type="checkbox" id="c-39068608" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#39068570">parent</a><span>|</span><a href="#39068368">next</a><span>|</span><label class="collapse" for="c-39068608">[-]</label><label class="expand" for="c-39068608">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I&#x27;ve seen multiple artists complain about how glazing reduces image quality. It&#x27;s very noticeable. That seems like an unavoidable problem given how AI is trained on images right now.</div><br/></div></div></div></div><div id="39068368" class="c"><input type="checkbox" id="c-39068368" checked=""/><div class="controls bullet"><span class="by">eddd-ddde</span><span>|</span><a href="#39068570">prev</a><span>|</span><a href="#39070808">next</a><span>|</span><label class="collapse" for="c-39068368">[-]</label><label class="expand" for="c-39068368">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this just teaching the models how to better understand pictures as humans do? As long as you feed them content that looks good to a human, wouldn&#x27;t they improve in creating such content?</div><br/><div id="39074784" class="c"><input type="checkbox" id="c-39074784" checked=""/><div class="controls bullet"><span class="by">lern_too_spel</span><span>|</span><a href="#39068368">parent</a><span>|</span><a href="#39070808">next</a><span>|</span><label class="collapse" for="c-39074784">[-]</label><label class="expand" for="c-39074784">[1 more]</label></div><br/><div class="children"><div class="content">You would think the economists at UChicago would have told these researchers that their tool would achieve the opposite effect of what they intended, but here we are.<p>In this case, the mechanism for how it would work is effectively useless. It doesn&#x27;t affect OpenAI or other companies building foundation models. It only works on people fine-tuning these foundation models, and only if the image is glazed to affect the same foundation model.</div><br/></div></div></div></div><div id="39070808" class="c"><input type="checkbox" id="c-39070808" checked=""/><div class="controls bullet"><span class="by">garg</span><span>|</span><a href="#39068368">prev</a><span>|</span><a href="#39068339">next</a><span>|</span><label class="collapse" for="c-39070808">[-]</label><label class="expand" for="c-39070808">[1 more]</label></div><br/><div class="children"><div class="content">Each time there is an update to training algorithms and in response poisoning algorithms, artists will have to re-glaze, re-mist, and re-nightshade all their images?<p>Eventually I assume the poisoning artifacts introduced in the images will be very visible to humans as well.</div><br/></div></div><div id="39068339" class="c"><input type="checkbox" id="c-39068339" checked=""/><div class="controls bullet"><span class="by">popohauer</span><span>|</span><a href="#39070808">prev</a><span>|</span><a href="#39071095">next</a><span>|</span><label class="collapse" for="c-39068339">[-]</label><label class="expand" for="c-39068339">[6 more]</label></div><br/><div class="children"><div class="content">I&#x27;m glad to see tools like Nightshade starting to pop up to protect the real life creativity of artists. I like AI art, but I do feel conflicted about its potential long term effects towards a society that no longer values authentic creativity.</div><br/><div id="39070992" class="c"><input type="checkbox" id="c-39070992" checked=""/><div class="controls bullet"><span class="by">Minor49er</span><span>|</span><a href="#39068339">parent</a><span>|</span><a href="#39071095">next</a><span>|</span><label class="collapse" for="c-39070992">[-]</label><label class="expand" for="c-39070992">[5 more]</label></div><br/><div class="children"><div class="content">Is the existence of the AI tool not itself a product of authentic creativity? Does eliminating barriers to image generation not facilitate authentic creativity?</div><br/><div id="39072142" class="c"><input type="checkbox" id="c-39072142" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#39068339">root</a><span>|</span><a href="#39070992">parent</a><span>|</span><a href="#39071095">next</a><span>|</span><label class="collapse" for="c-39072142">[-]</label><label class="expand" for="c-39072142">[4 more]</label></div><br/><div class="children"><div class="content">No, it facilitates commoditization. Art – real art – is fundamentally a human-to-human transaction. Once everyone can fire perfectly-rendered perfectly-unique pieces of &#x27;art&#x27; at each other, it&#x27;ll just become like the internet is today: filled with extremely low-value noise.<p>Enjoy the short term novelty while you can.</div><br/><div id="39073261" class="c"><input type="checkbox" id="c-39073261" checked=""/><div class="controls bullet"><span class="by">fulladder</span><span>|</span><a href="#39068339">root</a><span>|</span><a href="#39072142">parent</a><span>|</span><a href="#39078288">next</a><span>|</span><label class="collapse" for="c-39073261">[-]</label><label class="expand" for="c-39073261">[1 more]</label></div><br/><div class="children"><div class="content">This is the right prediction. Once machines can generate visual art, people will simply stop valuing it. We may see increased interest in other forms of art, e.g., live performance art like theater. It&#x27;s hard to predict exactly how it&#x27;ll play out, but once something becomes cheap to produce and widely available, it loses its luster for connoisseurs and then gradually loses its luster for everybody else too.</div><br/></div></div><div id="39078288" class="c"><input type="checkbox" id="c-39078288" checked=""/><div class="controls bullet"><span class="by">BeFlatXIII</span><span>|</span><a href="#39068339">root</a><span>|</span><a href="#39072142">parent</a><span>|</span><a href="#39073261">prev</a><span>|</span><a href="#39071095">next</a><span>|</span><label class="collapse" for="c-39078288">[-]</label><label class="expand" for="c-39078288">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Art – real art – is fundamentally a human-to-human transaction.<p>Why is this hippie nonsense so popular?</div><br/><div id="39079230" class="c"><input type="checkbox" id="c-39079230" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#39068339">root</a><span>|</span><a href="#39078288">parent</a><span>|</span><a href="#39071095">next</a><span>|</span><label class="collapse" for="c-39079230">[-]</label><label class="expand" for="c-39079230">[1 more]</label></div><br/><div class="children"><div class="content">Because some things are different than others, even though they might have the same word to describe them.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39071095" class="c"><input type="checkbox" id="c-39071095" checked=""/><div class="controls bullet"><span class="by">ang_cire</span><span>|</span><a href="#39068339">prev</a><span>|</span><a href="#39077106">next</a><span>|</span><label class="collapse" for="c-39071095">[-]</label><label class="expand" for="c-39071095">[13 more]</label></div><br/><div class="children"><div class="content">Setting aside the efficacy of this tool, I would be very interested in the legal implications of putting designs in your art that could corrupt ML models.<p>For instance, if I set traps in my home which hurt an intruder we are both guilty of crimes (traps are illegal and are never considered self defense, B&amp;E is illegal).<p>Would I be responsible for corrupting the AI operator&#x27;s data if I intentionally include adversarial artifacts to corrupt models, or is that just DRM to legally protect my art from infringement?<p>edit:<p>I replied to someone else, but this is probably good context:<p>DRM is legally allowed to disable or even corrupt the software or media that it is protecting, if it detects misuse.<p>If an adversarial-AI tool attacks the model, it then becomes a question of whether the model, having now incorporated my protected art, is now &quot;mine&quot; to disable&#x2F;corrupt, or whether it is in fact out of bounds of DRM.<p>So for instance, a court could say that the adversarial-AI methods could only actively prevent the training software from incorporating the protected media into a model, but could not corrupt the model itself.</div><br/><div id="39071133" class="c"><input type="checkbox" id="c-39071133" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39074455">next</a><span>|</span><label class="collapse" for="c-39071133">[-]</label><label class="expand" for="c-39071133">[5 more]</label></div><br/><div class="children"><div class="content">None whatsoever. There is no right to good data for model training, nor does any contractual relationship exist between you and and a model builder who scrapes your website.</div><br/><div id="39071597" class="c"><input type="checkbox" id="c-39071597" checked=""/><div class="controls bullet"><span class="by">ang_cire</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39071133">parent</a><span>|</span><a href="#39074455">next</a><span>|</span><label class="collapse" for="c-39071597">[-]</label><label class="expand" for="c-39071597">[4 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re assuming this is open-shut, you&#x27;re wrong. I asked this specifically as someone who works in security. A court is going to have to decide where the line is between DRM and malware in adversarial-AI tools.</div><br/><div id="39072770" class="c"><input type="checkbox" id="c-39072770" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39071597">parent</a><span>|</span><a href="#39071850">next</a><span>|</span><label class="collapse" for="c-39072770">[-]</label><label class="expand" for="c-39072770">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not. Malware is one thin, passive data poisoning is another. Mapmakers have long used such devices to detect&#x2F;deter unwanted copying. In the US such &#x27;trap streets&#x27; are not protected by copyright, but nor do they generate liability.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trap_street" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trap_street</a></div><br/><div id="39077771" class="c"><input type="checkbox" id="c-39077771" checked=""/><div class="controls bullet"><span class="by">ang_cire</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39072770">parent</a><span>|</span><a href="#39071850">next</a><span>|</span><label class="collapse" for="c-39077771">[-]</label><label class="expand" for="c-39077771">[1 more]</label></div><br/><div class="children"><div class="content">A trap street doesn&#x27;t damage other data. Not even remotely useful as an analogy. That&#x27;s to allow detection of copies, not to corrupt the copies from being useable.</div><br/></div></div></div></div><div id="39071850" class="c"><input type="checkbox" id="c-39071850" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39071597">parent</a><span>|</span><a href="#39072770">prev</a><span>|</span><a href="#39074455">next</a><span>|</span><label class="collapse" for="c-39071850">[-]</label><label class="expand" for="c-39071850">[1 more]</label></div><br/><div class="children"><div class="content">Worth trying but I doubt it unless we establish a right to train.</div><br/></div></div></div></div></div></div><div id="39074455" class="c"><input type="checkbox" id="c-39074455" checked=""/><div class="controls bullet"><span class="by">danShumway</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39071133">prev</a><span>|</span><a href="#39071261">next</a><span>|</span><label class="collapse" for="c-39074455">[-]</label><label class="expand" for="c-39074455">[1 more]</label></div><br/><div class="children"><div class="content">The way Nightshade works (assuming it does work) is by confusing the features of different tags with each other. To argue that this is illegal would be to argue that mistagging a piece of artwork on a gallery is illegal.<p>If you upload a picture of a dog to DeviantArt and you label it as a cat, and a model ingests that image and starts to think that cats look like dogs, would anybody claim that you are breaking a law? If you upload bad code to Github that has bugs, and an AI model consumes that code and then reproduces the bugs, would anyone argue that uploading badly written code to Github is a crime?<p>What if you uploaded some bad code to Github and then wrote a comment at the top of the code explaining what the error was, because you knew that the model would ignore that comment and would still look at the bad code. Then would you be committing a crime by putting that code on Github?<p>Even if it could be proven that your <i>intention</i> was for that code or that mistagged image to be unhelpful to training, it would still be a huge leap to say that either of those activities were criminal -- I would hope that the majority of HN would see that as a dangerous legal road to travel down.</div><br/></div></div><div id="39071261" class="c"><input type="checkbox" id="c-39071261" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39074455">prev</a><span>|</span><a href="#39073650">next</a><span>|</span><label class="collapse" for="c-39071261">[-]</label><label class="expand" for="c-39071261">[3 more]</label></div><br/><div class="children"><div class="content">That’s like asking if lying on a forum is illegal</div><br/><div id="39071583" class="c"><input type="checkbox" id="c-39071583" checked=""/><div class="controls bullet"><span class="by">ang_cire</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39071261">parent</a><span>|</span><a href="#39073650">next</a><span>|</span><label class="collapse" for="c-39071583">[-]</label><label class="expand" for="c-39071583">[2 more]</label></div><br/><div class="children"><div class="content">No, it&#x27;s much closer to (in fact, it is simply) asking if adversarial AI tools count as DRM or as malware. And a court is going to have to decide whether the model and or its output counts as separate software, which it is illegal for DRM to intentionally attack.<p>DRM can, for instance, disable its own parent tool (e.g. a video game) if it detects misuse, but it can&#x27;t attack the host computer or other software on that computer.<p>So is the model or its output, having been trained on my art, a byproduct of my art, in which case I have a legal right to &#x27;disable&#x27; it, or is it separate software that I don&#x27;t have a right to corrupt?</div><br/><div id="39074545" class="c"><input type="checkbox" id="c-39074545" checked=""/><div class="controls bullet"><span class="by">danShumway</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39071583">parent</a><span>|</span><a href="#39073650">next</a><span>|</span><label class="collapse" for="c-39074545">[-]</label><label class="expand" for="c-39074545">[1 more]</label></div><br/><div class="children"><div class="content">&gt; asking if adversarial AI tools count as DRM or as malware<p>Neither. Nightshade is not DRM or malware, it&#x27;s &quot;lying&quot; about the contents of an image.<p>Arguably, Nightshade does not corrupt or disable the model at all. It feeds it bad data that leads the model to generate incorrect conclusions or patterns about how to generate images. This is assuming it works, which we&#x27;ll have to wait and see, I&#x27;m not taking that as a given.<p>But the only &quot;corruption&quot; happening here is that the model is being fed data that it &quot;trusts&quot; without verifying that what the data is &quot;telling&quot; it is correct. It&#x27;s not disabling the model or crashing it, the model is forming incorrect conclusions and patterns about how to generate the image. If Google translate asked you to rate its performance on a task, and you gave it an incorrect rating from what you actually thought its performance was, is that DRM? Malware? Have you disabled Google translate by giving it bad feedback?<p>I don&#x27;t think the framing of this as either DRM or malware is correct. This is bad training data. Assuming it works, it works because it&#x27;s bad training data -- that&#x27;s why ingesting one or two images doesn&#x27;t affect models but ingesting a lot of images does, because training a model on bad data leads the model to perform worse if and only if there is enough of that bad data. And so what we&#x27;re really talking about here is not a question of DRM or malware, it&#x27;s a question of whether or not artists have a legal obligation to make their data useful for training -- and of course they don&#x27;t. The implications of saying that they did would be enormous, it would imply that any time you knowingly lied about a question that was being fed into an AI training set that doing so was illegal.</div><br/></div></div></div></div></div></div><div id="39073650" class="c"><input type="checkbox" id="c-39073650" checked=""/><div class="controls bullet"><span class="by">npteljes</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39071261">prev</a><span>|</span><a href="#39072593">next</a><span>|</span><label class="collapse" for="c-39073650">[-]</label><label class="expand" for="c-39073650">[1 more]</label></div><br/><div class="children"><div class="content">I see it as no different than mapmakers inventing a nonexistent alley, to check who copies their maps verbatim (&quot;trap street&quot;). Even if this caused, for example, a car crash because of an autonomous driver, the onus I think would be on the one that made the car and used the stolen map for navigation, and not on the one that created the original map.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trap_street" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trap_street</a></div><br/></div></div><div id="39072593" class="c"><input type="checkbox" id="c-39072593" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39073650">prev</a><span>|</span><a href="#39071279">next</a><span>|</span><label class="collapse" for="c-39072593">[-]</label><label class="expand" for="c-39072593">[1 more]</label></div><br/><div class="children"><div class="content">Japan is considering it, I think? <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38615280">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38615280</a></div><br/></div></div><div id="39071279" class="c"><input type="checkbox" id="c-39071279" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39072593">prev</a><span>|</span><a href="#39077106">next</a><span>|</span><label class="collapse" for="c-39071279">[-]</label><label class="expand" for="c-39071279">[1 more]</label></div><br/><div class="children"><div class="content">How would that situation be remotely related?</div><br/></div></div></div></div><div id="39077106" class="c"><input type="checkbox" id="c-39077106" checked=""/><div class="controls bullet"><span class="by">ThinkBeat</span><span>|</span><a href="#39071095">prev</a><span>|</span><a href="#39075808">next</a><span>|</span><label class="collapse" for="c-39077106">[-]</label><label class="expand" for="c-39077106">[2 more]</label></div><br/><div class="children"><div class="content">In so far as anger goes against AIs being trained on particular intellectual properties.<p>A made up scenario¹ is that a person who is training an AI, goes to the local
library and checks out 600 books on art. 
The person then lets the AI read all of them. 
After which they are returned to the library and another 600 books are borrowed<p>Then we can imagine the AI somehow visiting a lot of museums and galleries.<p>The AI will now have been trained on the style and looks of a lot
of art from different artists<p>All the material has been obtained in a legal manner.<p>Is this an acceptable use?<p>Or can an artist still assert that the AI was trained with their
IP without consent?<p>Clearly this is one of the ways a human would go about learning
about styles, techniques etc..<p>¹ Yes you probably cannot borrow 600 books at a time.
How does the AI read the books?   I dont know. Simplicity would be
that the researcher takes a photo of each page. 
This would be extremmly slow but for this hypothetical it is acceptable.</div><br/><div id="39077402" class="c"><input type="checkbox" id="c-39077402" checked=""/><div class="controls bullet"><span class="by">nanofus</span><span>|</span><a href="#39077106">parent</a><span>|</span><a href="#39075808">next</a><span>|</span><label class="collapse" for="c-39077402">[-]</label><label class="expand" for="c-39077402">[1 more]</label></div><br/><div class="children"><div class="content">I think the key difference here is that the most prominent image generation AIs are commercial and for-profit. The scenarios you describe are comparing a commercial AI to a private person. You cannot get a library card for a company, and you cannot bring a photography crew to a gallery without permission.</div><br/></div></div></div></div><div id="39075808" class="c"><input type="checkbox" id="c-39075808" checked=""/><div class="controls bullet"><span class="by">ngneer</span><span>|</span><a href="#39077106">prev</a><span>|</span><a href="#39071067">next</a><span>|</span><label class="collapse" for="c-39075808">[-]</label><label class="expand" for="c-39075808">[1 more]</label></div><br/><div class="children"><div class="content">I love it. This undermines the notion of ground truth. What separates correct information from incorrect information? Maybe nothing! I love how they acknowledge the never ending attack versus defense game. In  stark contrast to &quot;our AI will solve all your problems&quot;.</div><br/></div></div><div id="39071067" class="c"><input type="checkbox" id="c-39071067" checked=""/><div class="controls bullet"><span class="by">gweinberg</span><span>|</span><a href="#39075808">prev</a><span>|</span><a href="#39070921">next</a><span>|</span><label class="collapse" for="c-39071067">[-]</label><label class="expand" for="c-39071067">[1 more]</label></div><br/><div class="children"><div class="content">For this to work, wouldn&#x27;t you have to have an enormous number of artists collaborating on &quot;poisoning&quot; their images the same way (cow to handbag) while somehow keeping it secret form ai trainers that they were doing this?
It seems to me that even if the technology works perfectly as intended, you&#x27;re effectively just mislabeling a tiny fraction of the training data.</div><br/></div></div><div id="39070921" class="c"><input type="checkbox" id="c-39070921" checked=""/><div class="controls bullet"><span class="by">enord</span><span>|</span><a href="#39071067">prev</a><span>|</span><a href="#39071766">next</a><span>|</span><label class="collapse" for="c-39070921">[-]</label><label class="expand" for="c-39070921">[12 more]</label></div><br/><div class="children"><div class="content">I’m completely flabbergasted by the number of comments implying copyright concepts such as “fair use” or “derivative work” apply to trained ML models. Copyright is for _people_, as are the entailing rights, responsibilities and exemptions.
This has gone far beyond anthropomorphising and we need to like get it together, man!</div><br/><div id="39071386" class="c"><input type="checkbox" id="c-39071386" checked=""/><div class="controls bullet"><span class="by">ronsor</span><span>|</span><a href="#39070921">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39071386">[-]</label><label class="expand" for="c-39071386">[9 more]</label></div><br/><div class="children"><div class="content">You act like computers and ML models aren&#x27;t just tools used by people.</div><br/><div id="39074156" class="c"><input type="checkbox" id="c-39074156" checked=""/><div class="controls bullet"><span class="by">enord</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39071386">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39074156">[-]</label><label class="expand" for="c-39074156">[8 more]</label></div><br/><div class="children"><div class="content">What did I write to give you that impression?</div><br/><div id="39075051" class="c"><input type="checkbox" id="c-39075051" checked=""/><div class="controls bullet"><span class="by">Ukv</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39074156">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39075051">[-]</label><label class="expand" for="c-39075051">[7 more]</label></div><br/><div class="children"><div class="content">My initial interpretation was that you&#x27;re saying fair use is irrelevant to the situation because machine learning models aren&#x27;t themselves legal persons. But, fair use doesn&#x27;t solely apply to manual creation - use of traditional algorithms (e.g: the snippets, caching, and thumbnailing done by search engines) is still covered by fair use. To my understanding, that&#x27;s why ronsor pointed out that ML models are tools used by people (and those people can give a fair use defense).<p>Possibly you instead meant that fair use is relevant, but people are wording remarks in a way that suggests the model itself is giving a fair use defence to copyright infringement, rather than the persons training or using it?</div><br/><div id="39077899" class="c"><input type="checkbox" id="c-39077899" checked=""/><div class="controls bullet"><span class="by">enord</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39075051">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39077899">[-]</label><label class="expand" for="c-39077899">[6 more]</label></div><br/><div class="children"><div class="content">Well then I could have been much clearer because I meant something like the latter.<p>An ML model can neither have nor be in breach of copyright so any discussion about how it works, and how that relates to how people work or “learn” is besides the point.<p>What actually matters is firstly details about collation of source material, and later the particular legal details surrounding attribution. The last part involves breaking new ground legally speaking and IANAL so I will reserve judgement. The first part, collation of source material for training is emphatically <i>not</i> unexplored legal or moral territory. People are acting like none of the established processes apply in the case of LLMs and handwave about “learning” to defend it.</div><br/><div id="39078537" class="c"><input type="checkbox" id="c-39078537" checked=""/><div class="controls bullet"><span class="by">Ukv</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39077899">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39078537">[-]</label><label class="expand" for="c-39078537">[5 more]</label></div><br/><div class="children"><div class="content">&gt; and how that relates to how people work or “learn” is besides the point<p>It is important (for the training and generation stages) to distinguish between whether the model copies the original works or merely infers information from them - as copyright does not protect against the latter.<p>&gt; The first part, collation of source material for training is emphatically not unexplored legal or moral territory.<p>Similar to as in Authors Guild v. Google, Inc. where Google internally made entire copies of millions of in-copyright books:<p>&gt; &gt; While Google makes an unauthorized digital copy of the entire book, it does not reveal that digital copy to the public. The copy is made to enable the search functions to reveal limited, important information about the books. With respect to the search function, Google satisfies the third factor test<p>Or in the ongoing Thomson Reuters v. Ross Intelligence case where the latter used the former&#x27;s legal headnotes for training a language model:<p>&gt; &gt; verbatim intermediate copying has consistently been upheld as fair use if the copy is &quot;not reveal[ed] to the public.&quot;<p>That it&#x27;s an internal transient copy is not inherently a free pass, but it is something the courts take into consideration, as mentioned more explicitly in Sega v. Accolade:<p>&gt; &gt; Accolade, a commercial competitor of Sega, engaged in wholesale copying of Sega&#x27;s copyrighted code as a preliminary step in the development of a competing product [yet] where the ultimate (as opposed to direct) use is as limited as it was here, the factor is of very little weight<p>And, given training a machine learning model is a considerably different purpose than what the images were originally intended for, it&#x27;s likely to be considered transformative; as in Campbell v. Acuff-Rose Music:<p>&gt; &gt; The more transformative the new work, the less will be the significance of other factors</div><br/><div id="39081032" class="c"><input type="checkbox" id="c-39081032" checked=""/><div class="controls bullet"><span class="by">enord</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39078537">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39081032">[-]</label><label class="expand" for="c-39081032">[4 more]</label></div><br/><div class="children"><div class="content">Listen, most website and book-authors want to be indexed by google. It brings potential audience their way, so most don’t make use of their _right_ to be de-listed. For these models, there is no plausible benefit to the original creators, and so one has to argue they have _no_ such right to be “de-listed” in order to get any training data currently under copyright.</div><br/><div id="39081466" class="c"><input type="checkbox" id="c-39081466" checked=""/><div class="controls bullet"><span class="by">Ukv</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39081032">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39081466">[-]</label><label class="expand" for="c-39081466">[3 more]</label></div><br/><div class="children"><div class="content">&gt; It brings potential audience their way, so most don’t make use of their _right_ to be de-listed.<p>The Authors Guild lawsuit against Google Books ended in a 2015 ruling that Google Books is fair use and as such they <i>don&#x27;t</i> have a right to be de-listed. It&#x27;s not the case that they have a right to be de-listed but choose not to make use of it.<p>The same would apply if collation of data for machine learning datasets is found to be fair use.<p>&gt; one has to argue they have _no_ such right to be “de-listed” in order to get any training data currently under copyright.<p>Datasets I&#x27;m aware of already have respected machine-readable opt-outs, so if that were to be legally enforced (as it is by the EU&#x27;s DSM Directive for commercial data mining) I don&#x27;t think it&#x27;d be the end of the world.<p>There&#x27;s a lot of power in a default; the set of &quot;everything minus opted-out content&quot; will be significantly bigger than &quot;nothing plus opted-in content&quot; even with the same opinions.</div><br/><div id="39081919" class="c"><input type="checkbox" id="c-39081919" checked=""/><div class="controls bullet"><span class="by">enord</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39081466">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39081919">[-]</label><label class="expand" for="c-39081919">[2 more]</label></div><br/><div class="children"><div class="content">With the caveat that I was exactly wrong about the books de-listing, I feel you are making my point for me and retreating to a more pragmatic position about defaults.<p>The (quite entertaining) saga of Nightshade tells a story about what is going to be content creators “default position” going forward and everyone else will follow. You would be a fool not to, the AI companies are trying to end run you, using your own content, and make a profit without compensating you and leave you with no recourse.</div><br/><div id="39082444" class="c"><input type="checkbox" id="c-39082444" checked=""/><div class="controls bullet"><span class="by">Ukv</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39081919">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39082444">[-]</label><label class="expand" for="c-39082444">[1 more]</label></div><br/><div class="children"><div class="content">&gt; I feel you are making my point for me and retreating to a more pragmatic position about defaults<p>I&#x27;m unclear on what stance I&#x27;ve supposedly retreated from. My position is that an opt-out is not necessary under current US law, but that it wouldn&#x27;t be the worst-case outcome if new regulation were introduced to mandate it.<p>&gt; The (quite entertaining) saga of Nightshade tells a story about what is going to be content creators “default position” going forward and everyone else will follow<p>By &quot;default&quot; I refer not to the most common choice, but to the outcome that results from inaction. There&#x27;s a bias towards this default even if the majority of rightsholders do opt to use Nightshade (which I think is unlikely).</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39072640" class="c"><input type="checkbox" id="c-39072640" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#39070921">parent</a><span>|</span><a href="#39071386">prev</a><span>|</span><a href="#39071766">next</a><span>|</span><label class="collapse" for="c-39072640">[-]</label><label class="expand" for="c-39072640">[2 more]</label></div><br/><div class="children"><div class="content">No one is saying a model is the legal entity. The legal entities are still people and corporations.</div><br/><div id="39074131" class="c"><input type="checkbox" id="c-39074131" checked=""/><div class="controls bullet"><span class="by">enord</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39072640">parent</a><span>|</span><a href="#39071766">next</a><span>|</span><label class="collapse" for="c-39074131">[-]</label><label class="expand" for="c-39074131">[1 more]</label></div><br/><div class="children"><div class="content">Oh come on, you’re being insincere. Wether or not the model is learning from the work just like people is hotly debated <i>as if it would make a difference</i>. Fair use is even brought up. Fair use! Even if it applied, these training sets collate <i>all of everything</i><p>I feel like I’m taking crazy pills TBQH</div><br/></div></div></div></div></div></div><div id="39071766" class="c"><input type="checkbox" id="c-39071766" checked=""/><div class="controls bullet"><span class="by">squidbeak</span><span>|</span><a href="#39070921">prev</a><span>|</span><a href="#39080909">next</a><span>|</span><label class="collapse" for="c-39071766">[-]</label><label class="expand" for="c-39071766">[9 more]</label></div><br/><div class="children"><div class="content">I really don&#x27;t understand the anxiety of artists towards AI - as if creatives haven&#x27;t always borrowed and imitated. Every leading artist has had acolytes, and while it&#x27;s true no artist ever had an acolyte as prodigiously productive as AI will be, I don&#x27;t see anything different between a young artist looking to Picasso for cues and Stable Diffusion or DALL-E doing the same. Styles and methods haven&#x27;t ever been subject to copyright - and art would die the moment that changed.<p>The only explanation I can find for this backlash is that artists are actually worried just like the rest of us that pretty soon AI will produce higher quality more inventive work faster and more imaginatively than they can - which is very natural, but not a reason to inhibit an AI&#x27;s creative education.</div><br/><div id="39071892" class="c"><input type="checkbox" id="c-39071892" checked=""/><div class="controls bullet"><span class="by">beepbooptheory</span><span>|</span><a href="#39071766">parent</a><span>|</span><a href="#39072185">next</a><span>|</span><label class="collapse" for="c-39071892">[-]</label><label class="expand" for="c-39071892">[1 more]</label></div><br/><div class="children"><div class="content">This has been litigated over and over again, and there have been plenty of good points made and concerns raised over it by those who it actually affects.  It seems a little bit disingenuous (especially in this forum) to say that that conclusion is the &quot;only explanation&quot; you can come up with.  And just to avoid prompting you too much: trust me, we all know or can guess why you think AI art is a good thing regardless of any concerns one might bring up.</div><br/></div></div><div id="39072132" class="c"><input type="checkbox" id="c-39072132" checked=""/><div class="controls bullet"><span class="by">jwells89</span><span>|</span><a href="#39071766">parent</a><span>|</span><a href="#39072185">prev</a><span>|</span><a href="#39080909">next</a><span>|</span><label class="collapse" for="c-39072132">[-]</label><label class="expand" for="c-39072132">[1 more]</label></div><br/><div class="children"><div class="content">Imitation isn’t the problem so much as it is that ML generated images are composed of a mush of the images it was trained on. A human artist can abstract the concepts underpinning a style and mimic it by drawing all-new lineart, coloration, shading, composition, etc, while the ML model has to lean on blending training imagery together.<p>Furthermore there’s a sort of unavoidable “jitter” in human-produced art that varies between individuals that stems from vastly different ways of thinking, perception of the world, mental abstraction processes, life experiences, etc. This is why artists who start out imitating other artists almost always develop their imitations into a style all their own — the imitations were already appreciably different from the original due to the aforementioned biases and those distinctions only grow with time and experimentation.<p>There would be greatly reduced moral controversy surrounding ML models if they lacked that mincemeat&#x2F;pink slime aspect.</div><br/></div></div></div></div><div id="39080909" class="c"><input type="checkbox" id="c-39080909" checked=""/><div class="controls bullet"><span class="by">paulsutter</span><span>|</span><a href="#39071766">prev</a><span>|</span><a href="#39068272">next</a><span>|</span><label class="collapse" for="c-39080909">[-]</label><label class="expand" for="c-39080909">[1 more]</label></div><br/><div class="children"><div class="content">Cute. The effectiveness of any technique like this will be short-lived.<p>What we really need is clarification of the extent that copyright protection extends to similar works. Most likely from an AI analysis of case law.</div><br/></div></div><div id="39068272" class="c"><input type="checkbox" id="c-39068272" checked=""/><div class="controls bullet"><span class="by">gmerc</span><span>|</span><a href="#39080909">prev</a><span>|</span><a href="#39078006">next</a><span>|</span><label class="collapse" for="c-39068272">[-]</label><label class="expand" for="c-39068272">[6 more]</label></div><br/><div class="children"><div class="content">Doing the work to increase OpenAIs moat</div><br/><div id="39068317" class="c"><input type="checkbox" id="c-39068317" checked=""/><div class="controls bullet"><span class="by">Drakim</span><span>|</span><a href="#39068272">parent</a><span>|</span><a href="#39078006">next</a><span>|</span><label class="collapse" for="c-39068317">[-]</label><label class="expand" for="c-39068317">[5 more]</label></div><br/><div class="children"><div class="content">Obviously AIs can just train on images that aren&#x27;t poisoned.</div><br/><div id="39068442" class="c"><input type="checkbox" id="c-39068442" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#39068272">root</a><span>|</span><a href="#39068317">parent</a><span>|</span><a href="#39078006">next</a><span>|</span><label class="collapse" for="c-39068442">[-]</label><label class="expand" for="c-39068442">[4 more]</label></div><br/><div class="children"><div class="content">Is it possible to reliably detect whether an image is poisoned? If not then it achieves the goal of punishing entities which indiscriminately harvest data.</div><br/><div id="39068625" class="c"><input type="checkbox" id="c-39068625" checked=""/><div class="controls bullet"><span class="by">Kalium</span><span>|</span><a href="#39068272">root</a><span>|</span><a href="#39068442">parent</a><span>|</span><a href="#39068615">next</a><span>|</span><label class="collapse" for="c-39068625">[-]</label><label class="expand" for="c-39068625">[1 more]</label></div><br/><div class="children"><div class="content">You can use older images, collected from before the &quot;poisoning&quot; software was released. Then you don&#x27;t have to.<p>This, of course, assumes that &quot;poisoning&quot; actually works. Glaze and Nightshade and similar are very much akin to the various documented attacks on facial recognition systems. The attack does not exploit some fundamental flaw in how the systems work, but specific characteristics in a given implementation and version.<p>This matters because it means that later versions and models will inevitably not have the same vulnerabilities. The result is that any given defensive transformation should be expected to be only narrowly effective.</div><br/></div></div><div id="39068615" class="c"><input type="checkbox" id="c-39068615" checked=""/><div class="controls bullet"><span class="by">Drakim</span><span>|</span><a href="#39068272">root</a><span>|</span><a href="#39068442">parent</a><span>|</span><a href="#39068625">prev</a><span>|</span><a href="#39068664">next</a><span>|</span><label class="collapse" for="c-39068615">[-]</label><label class="expand" for="c-39068615">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s roughly in the same spot as reliably detecting if you have permission to use the image for your data training set in the first place.<p>If it doesn&#x27;t matter, then neither does the poisoning matter.</div><br/></div></div><div id="39068664" class="c"><input type="checkbox" id="c-39068664" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#39068272">root</a><span>|</span><a href="#39068442">parent</a><span>|</span><a href="#39068615">prev</a><span>|</span><a href="#39078006">next</a><span>|</span><label class="collapse" for="c-39068664">[-]</label><label class="expand" for="c-39068664">[1 more]</label></div><br/><div class="children"><div class="content">AI&#x27;s have learned much tougher things. You just need a small data set of poisoned images to learn it&#x27;s features.</div><br/></div></div></div></div></div></div></div></div><div id="39078006" class="c"><input type="checkbox" id="c-39078006" checked=""/><div class="controls bullet"><span class="by">drdrek</span><span>|</span><a href="#39068272">prev</a><span>|</span><a href="#39076888">next</a><span>|</span><label class="collapse" for="c-39078006">[-]</label><label class="expand" for="c-39078006">[1 more]</label></div><br/><div class="children"><div class="content">Only protection is adding giant gaping vaginas to your art, nothing less will deter scraping. If the Email spam community showed us something in the last 40 years is that no amount of defensive tech measures will work except financial disincentives.</div><br/></div></div><div id="39076888" class="c"><input type="checkbox" id="c-39076888" checked=""/><div class="controls bullet"><span class="by">nnevatie</span><span>|</span><a href="#39078006">prev</a><span>|</span><a href="#39076620">next</a><span>|</span><label class="collapse" for="c-39076888">[-]</label><label class="expand" for="c-39076888">[1 more]</label></div><br/><div class="children"><div class="content">The intention is good, from an AI-opponent&#x27;s perspective. I don&#x27;t think will work practically, though. The drawbacks for actual users of the image galleries, plus the level of complexity involved in poisoning the samples makes this unfeasible to implement at the scale required.</div><br/></div></div><div id="39076620" class="c"><input type="checkbox" id="c-39076620" checked=""/><div class="controls bullet"><span class="by">snerc</span><span>|</span><a href="#39076888">prev</a><span>|</span><a href="#39071407">next</a><span>|</span><label class="collapse" for="c-39076620">[-]</label><label class="expand" for="c-39076620">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if we know enough about any of these systems to make such claims. This is all predicated on the fact that this tool will be in widespread use. If it is somehow widely used beyond the folks who have seen it at the top of HN, won&#x27;t the big firms have countermeasures, ready to deploy?</div><br/></div></div><div id="39071407" class="c"><input type="checkbox" id="c-39071407" checked=""/><div class="controls bullet"><span class="by">zirgs</span><span>|</span><a href="#39076620">prev</a><span>|</span><a href="#39070744">next</a><span>|</span><label class="collapse" for="c-39071407">[-]</label><label class="expand" for="c-39071407">[1 more]</label></div><br/><div class="children"><div class="content">Does it survive AI upscaling or img2img? If not - then it&#x27;s useless. Nobody trains AI models without any preprocessing. This is basically a tool for 2022.</div><br/></div></div><div id="39070744" class="c"><input type="checkbox" id="c-39070744" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#39071407">prev</a><span>|</span><a href="#39071222">next</a><span>|</span><label class="collapse" for="c-39070744">[-]</label><label class="expand" for="c-39070744">[22 more]</label></div><br/><div class="children"><div class="content">Won&#x27;t a simple downsample-&gt;upsample be the antidote?</div><br/><div id="39071150" class="c"><input type="checkbox" id="c-39071150" checked=""/><div class="controls bullet"><span class="by">jdiff</span><span>|</span><a href="#39070744">parent</a><span>|</span><a href="#39070767">next</a><span>|</span><label class="collapse" for="c-39071150">[-]</label><label class="expand" for="c-39071150">[2 more]</label></div><br/><div class="children"><div class="content">No, it&#x27;s resistant to transformation. Rotation, cropping, scaling, the image remains poisonous. The only antidote known currently is active artist cooperation.</div><br/><div id="39072648" class="c"><input type="checkbox" id="c-39072648" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39071150">parent</a><span>|</span><a href="#39070767">next</a><span>|</span><label class="collapse" for="c-39072648">[-]</label><label class="expand" for="c-39072648">[1 more]</label></div><br/><div class="children"><div class="content">Or Img2Img.</div><br/></div></div></div></div><div id="39070767" class="c"><input type="checkbox" id="c-39070767" checked=""/><div class="controls bullet"><span class="by">wizzwizz4</span><span>|</span><a href="#39070744">parent</a><span>|</span><a href="#39071150">prev</a><span>|</span><a href="#39071222">next</a><span>|</span><label class="collapse" for="c-39070767">[-]</label><label class="expand" for="c-39070767">[19 more]</label></div><br/><div class="children"><div class="content">How do you train your upsampler? (Also: why are you seeking to provide an “antidote”?)</div><br/><div id="39070999" class="c"><input type="checkbox" id="c-39070999" checked=""/><div class="controls bullet"><span class="by">klyrs</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39070767">parent</a><span>|</span><a href="#39072165">next</a><span>|</span><label class="collapse" for="c-39070999">[-]</label><label class="expand" for="c-39070999">[3 more]</label></div><br/><div class="children"><div class="content">&gt; why are you seeking to provide an “antidote”<p>I think it&#x27;s worthwhile for such discussion to happen in the open.  If the tool can be defeated through simple means, it&#x27;s better for everybody to know that, right?</div><br/><div id="39071087" class="c"><input type="checkbox" id="c-39071087" checked=""/><div class="controls bullet"><span class="by">wizzwizz4</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39070999">parent</a><span>|</span><a href="#39072165">next</a><span>|</span><label class="collapse" for="c-39071087">[-]</label><label class="expand" for="c-39071087">[2 more]</label></div><br/><div class="children"><div class="content">It would be better for <i>artists</i> to know that. But Hacker News is not a forum of visual artists: it&#x27;s a forum of hackers, salaried programmers, and venture capitalists. Telling the bad guys about vulnerabilities isn&#x27;t responsible disclosure.<p>Causing car crashes isn&#x27;t hard (<a href="https:&#x2F;&#x2F;xkcd.com&#x2F;1958&#x2F;" rel="nofollow">https:&#x2F;&#x2F;xkcd.com&#x2F;1958&#x2F;</a>). That doesn&#x27;t mean Car Crash™ International®&#x27;s decision-makers know how to do it: they probably don&#x27;t even know what considerations go into traffic engineering, or how anyone can just buy road paint from that shop over there.<p>It&#x27;s everybody&#x27;s responsibility to keep Car Crash™ International® from existing; but failing that, it&#x27;s everybody&#x27;s responsibility to not tell them how to cause car crashes.</div><br/><div id="39073067" class="c"><input type="checkbox" id="c-39073067" checked=""/><div class="controls bullet"><span class="by">MrNeon</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39071087">parent</a><span>|</span><a href="#39072165">next</a><span>|</span><label class="collapse" for="c-39073067">[-]</label><label class="expand" for="c-39073067">[1 more]</label></div><br/><div class="children"><div class="content">The tears of artists and copyright evangelists is so sweet.</div><br/></div></div></div></div></div></div><div id="39072165" class="c"><input type="checkbox" id="c-39072165" checked=""/><div class="controls bullet"><span class="by">ukuina</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39070767">parent</a><span>|</span><a href="#39070999">prev</a><span>|</span><a href="#39070860">next</a><span>|</span><label class="collapse" for="c-39072165">[-]</label><label class="expand" for="c-39072165">[1 more]</label></div><br/><div class="children"><div class="content">I apologize. I was trying to respond to inflammatory language (&quot;poison&quot;) with similarly hyperbolic terms, and I should know better than to do that.<p>Let me rephrase: Would AI-powered upscaling&#x2F;downscaling (not a simple deterministic mathematical scaling) not defeat this at a conceptual level?</div><br/></div></div><div id="39070860" class="c"><input type="checkbox" id="c-39070860" checked=""/><div class="controls bullet"><span class="by">MrNeon</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39070767">parent</a><span>|</span><a href="#39072165">prev</a><span>|</span><a href="#39070790">next</a><span>|</span><label class="collapse" for="c-39070860">[-]</label><label class="expand" for="c-39070860">[13 more]</label></div><br/><div class="children"><div class="content">&gt;why are you seeking to provide an “antidote”<p>To train a model on the data.</div><br/><div id="39070879" class="c"><input type="checkbox" id="c-39070879" checked=""/><div class="controls bullet"><span class="by">krapp</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39070860">parent</a><span>|</span><a href="#39070790">next</a><span>|</span><label class="collapse" for="c-39070879">[-]</label><label class="expand" for="c-39070879">[12 more]</label></div><br/><div class="children"><div class="content">Get permission to use the data.</div><br/><div id="39071116" class="c"><input type="checkbox" id="c-39071116" checked=""/><div class="controls bullet"><span class="by">MrNeon</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39070879">parent</a><span>|</span><a href="#39070790">next</a><span>|</span><label class="collapse" for="c-39071116">[-]</label><label class="expand" for="c-39071116">[11 more]</label></div><br/><div class="children"><div class="content">Got all the permission I need when it was put on a publicly accessible server.</div><br/><div id="39072726" class="c"><input type="checkbox" id="c-39072726" checked=""/><div class="controls bullet"><span class="by">xigoi</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39071116">parent</a><span>|</span><a href="#39071188">next</a><span>|</span><label class="collapse" for="c-39072726">[-]</label><label class="expand" for="c-39072726">[6 more]</label></div><br/><div class="children"><div class="content">That’s not how copyright works.</div><br/><div id="39073055" class="c"><input type="checkbox" id="c-39073055" checked=""/><div class="controls bullet"><span class="by">MrNeon</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39072726">parent</a><span>|</span><a href="#39071188">next</a><span>|</span><label class="collapse" for="c-39073055">[-]</label><label class="expand" for="c-39073055">[5 more]</label></div><br/><div class="children"><div class="content">Tell me where it says training a model is infringing on copyright.</div><br/><div id="39073076" class="c"><input type="checkbox" id="c-39073076" checked=""/><div class="controls bullet"><span class="by">xigoi</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39073055">parent</a><span>|</span><a href="#39071188">next</a><span>|</span><label class="collapse" for="c-39073076">[-]</label><label class="expand" for="c-39073076">[4 more]</label></div><br/><div class="children"><div class="content">How is creating a derivative of someone’s work and selling it not copyright infringement?</div><br/><div id="39073251" class="c"><input type="checkbox" id="c-39073251" checked=""/><div class="controls bullet"><span class="by">MrNeon</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39073076">parent</a><span>|</span><a href="#39071188">next</a><span>|</span><label class="collapse" for="c-39073251">[-]</label><label class="expand" for="c-39073251">[3 more]</label></div><br/><div class="children"><div class="content">Who said anything about creating a derivative? Surely you don&#x27;t mean to say that any image created with a model trained on copyrighted data counts as a derivative of it. Edit: Or worse, that the model itself is derivative, something so different from an image must count as transformative work!.<p>Also who said anything about selling?</div><br/><div id="39073317" class="c"><input type="checkbox" id="c-39073317" checked=""/><div class="controls bullet"><span class="by">xigoi</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39073251">parent</a><span>|</span><a href="#39071188">next</a><span>|</span><label class="collapse" for="c-39073317">[-]</label><label class="expand" for="c-39073317">[2 more]</label></div><br/><div class="children"><div class="content">The model itself is a derivative. And it’s not really that transformative, it’s basically the input data compressed with highly lossy compression.<p>&gt; Also who said anything about selling?<p>All the corporations that are offering AI as a paid service?</div><br/><div id="39073590" class="c"><input type="checkbox" id="c-39073590" checked=""/><div class="controls bullet"><span class="by">MrNeon</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39073317">parent</a><span>|</span><a href="#39071188">next</a><span>|</span><label class="collapse" for="c-39073590">[-]</label><label class="expand" for="c-39073590">[1 more]</label></div><br/><div class="children"><div class="content">&gt; it’s basically the input data compressed with highly lossy compression.<p>Okay, extract the images from a Stable Diffusion checkpoint then. I&#x27;ll wait.<p>It&#x27;s not like lossy compression CAN&#x27;T be fair use or transformative. I&#x27;m sure you can imagine how that is possible given the many ways an image can be processed.<p>&gt; All the corporations that are offering AI as a paid service?<p>Am I them?</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39071188" class="c"><input type="checkbox" id="c-39071188" checked=""/><div class="controls bullet"><span class="by">wizzwizz4</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39071116">parent</a><span>|</span><a href="#39072726">prev</a><span>|</span><a href="#39070790">next</a><span>|</span><label class="collapse" for="c-39071188">[-]</label><label class="expand" for="c-39071188">[4 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not really how consent works.<p>I hope this is a special exception you&#x27;ve made, rather than your general approach towards interacting with your fellows.</div><br/><div id="39071540" class="c"><input type="checkbox" id="c-39071540" checked=""/><div class="controls bullet"><span class="by">MrNeon</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39071188">parent</a><span>|</span><a href="#39070790">next</a><span>|</span><label class="collapse" for="c-39071540">[-]</label><label class="expand" for="c-39071540">[3 more]</label></div><br/><div class="children"><div class="content">That is how consent works.</div><br/><div id="39081039" class="c"><input type="checkbox" id="c-39081039" checked=""/><div class="controls bullet"><span class="by">CatWChainsaw</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39071540">parent</a><span>|</span><a href="#39070790">next</a><span>|</span><label class="collapse" for="c-39081039">[-]</label><label class="expand" for="c-39081039">[2 more]</label></div><br/><div class="children"><div class="content">If my body is in a public space you have the right to force me to have sex with you, I guess?  That&#x27;s your logic after all.</div><br/><div id="39082417" class="c"><input type="checkbox" id="c-39082417" checked=""/><div class="controls bullet"><span class="by">MrNeon</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39081039">parent</a><span>|</span><a href="#39070790">next</a><span>|</span><label class="collapse" for="c-39082417">[-]</label><label class="expand" for="c-39082417">[1 more]</label></div><br/><div class="children"><div class="content">Data you put up on the internet is not your body.<p>Do I really have to explain this? You know I don&#x27;t. Do better.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39070790" class="c"><input type="checkbox" id="c-39070790" checked=""/><div class="controls bullet"><span class="by">spookie</span><span>|</span><a href="#39070744">root</a><span>|</span><a href="#39070767">parent</a><span>|</span><a href="#39070860">prev</a><span>|</span><a href="#39071222">next</a><span>|</span><label class="collapse" for="c-39070790">[-]</label><label class="expand" for="c-39070790">[1 more]</label></div><br/><div class="children"><div class="content">Why would you train one?</div><br/></div></div></div></div></div></div><div id="39071222" class="c"><input type="checkbox" id="c-39071222" checked=""/><div class="controls bullet"><span class="by">Duanemclemore</span><span>|</span><a href="#39070744">prev</a><span>|</span><label class="collapse" for="c-39071222">[-]</label><label class="expand" for="c-39071222">[1 more]</label></div><br/><div class="children"><div class="content">For visual artists who don&#x27;t want visible artifacting in the art they feature online, would it be possible to upload these alongside your un-poisoned art, but have them only hanging out in the background? So say having one proper copy and a hundred poisoned copies in the same server, but only showing the un-poisoned one?<p>Might this &quot;flood the zone&quot; approach also have -some- efficacy against human copycats?</div><br/></div></div></div></div></div></div></div></body></html>