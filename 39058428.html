<!DOCTYPE html><html lang="en"><head><title>Static News</title><meta charSet="utf-8"/><meta name="description" content="Static delayed Hacker News."/><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1d1f21"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><meta name="application-name" content="Static News"/><meta name="apple-mobile-web-app-title" content="Static News"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="#1d1f21"/><link rel="preload" href="styles.css?v=1705827653097" as="style"/><link rel="stylesheet" href="styles.css?v=1705827653097"/></head><body><div id="container"><div id="inner"><header><a href="/">Static News</a><a href="/about">about</a></header><div id="content"><div><div id="title"><a href="https://nightshade.cs.uchicago.edu/whatis.html">Nightshade: An offensive tool for artists against AI art generators</a> <span class="domain">(<a href="https://nightshade.cs.uchicago.edu">nightshade.cs.uchicago.edu</a>)</span></div><div class="subtext"><span>ink404</span> | <span>379 comments</span></div><br/><div><div id="39058569" class="c"><input type="checkbox" id="c-39058569" checked=""/><div class="controls bullet"><span class="by">ink404</span><span>|</span><a href="#39068620">next</a><span>|</span><label class="collapse" for="c-39058569">[-]</label><label class="expand" for="c-39058569">[1 more]</label></div><br/><div class="children"><div class="content">Paper is here: <a href="https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.13828" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.13828</a></div><br/></div></div><div id="39068620" class="c"><input type="checkbox" id="c-39068620" checked=""/><div class="controls bullet"><span class="by">542458</span><span>|</span><a href="#39058569">prev</a><span>|</span><a href="#39071577">next</a><span>|</span><label class="collapse" for="c-39068620">[-]</label><label class="expand" for="c-39068620">[43 more]</label></div><br/><div class="children"><div class="content">This seems to introduce levels of artifacts that many artists would find unacceptable: <a href="https:&#x2F;&#x2F;twitter.com&#x2F;sini4ka111&#x2F;status&#x2F;1748378223291912567" rel="nofollow">https:&#x2F;&#x2F;twitter.com&#x2F;sini4ka111&#x2F;status&#x2F;1748378223291912567</a><p>The rumblings I&#x27;m hearing are that this a) barely works with last-gen training processes b) does not work at all with more modern training processes (GPT-4V, LLaVA, even BLIP2 labelling [1]) and c) would not be especially challenging to mitigate against even should it become more effective and popular. The Authors&#x27; previous work, Glaze, also does not seem to be very effective despite dramatic proclamations to the contrary, so I think this might be a case of overhyping an academically interesting but real-world-impractical result.<p>[1]: Courtesy of &#x2F;u&#x2F;b3sn0w on Reddit: <a href="https:&#x2F;&#x2F;imgur.com&#x2F;cI7RLAq" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;cI7RLAq</a> <a href="https:&#x2F;&#x2F;imgur.com&#x2F;eqe3Dyn" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;eqe3Dyn</a> <a href="https:&#x2F;&#x2F;imgur.com&#x2F;1BMASL4" rel="nofollow">https:&#x2F;&#x2F;imgur.com&#x2F;1BMASL4</a></div><br/><div id="39073648" class="c"><input type="checkbox" id="c-39073648" checked=""/><div class="controls bullet"><span class="by">kmeisthax</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39070858">next</a><span>|</span><label class="collapse" for="c-39073648">[-]</label><label class="expand" for="c-39073648">[9 more]</label></div><br/><div class="children"><div class="content">The screenshots you sent in [1] are inference, not training. You need to get a Nightshaded image into the training set of an image generator in order for this to have any effect. When you give an image to GPT-4V, Stable Diffusion img2img, or anything else, you&#x27;re not training the AI - the model is completely frozen and does not change at all[0].<p>I don&#x27;t know if anyone else is still scraping <i>new</i> images into the generators. I&#x27;ve heard somewhere that OpenAI stopped scraping around 2021 because they&#x27;re worried about training on the output of their own models[1]. Adobe Firefly claims to have been trained on Adobe Stock images, but we don&#x27;t know if Adobe has any particular cutoffs of their own[2].<p>If you want an image that screws up inference - i.e. one that GPT-4V or Stable Diffusion will choke on - you want an adversarial image. I don&#x27;t know if you can adversarially train on a model you don&#x27;t have weights for, though I&#x27;ve heard you can generalize adversarial training against multiple independent models to <i>really</i> screw shit up[3].<p>[0] All learning capability of text generators come from the fact that they have a context window; but that only provides a short term memory of 2048 tokens. They have no other memory capability.<p>[1] The scenario of what happens when you do this is fancifully called Habsburg AI. The model learns from it&#x27;s own biases, reinforcing them into stronger biases, while forgetting everything else.<p>[2] It&#x27;d be particularly ironic if the only thing Nightshade harms is the one AI generator that tried to be even slightly ethical.<p>[3] At the extremes, these adversarial images fool humans. Though, the study that did this intentionally only showed the images for a small period of time, the idea being that short exposures are akin to a feed-forward neural network with no recurrent computation pathways. If you look at them longer, it&#x27;s obvious that it&#x27;s a picture of one thing edited to look like another.</div><br/><div id="39075721" class="c"><input type="checkbox" id="c-39075721" checked=""/><div class="controls bullet"><span class="by">scheeseman486</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075848">next</a><span>|</span><label class="collapse" for="c-39075721">[-]</label><label class="expand" for="c-39075721">[2 more]</label></div><br/><div class="children"><div class="content">Hey you know what might not be AI generated post-2021? Almost everything run through Nightshade. So given it&#x27;s defeated, which is pretty likely, artists have effectively tagged their own work for inclusion.</div><br/><div id="39076023" class="c"><input type="checkbox" id="c-39076023" checked=""/><div class="controls bullet"><span class="by">hkt</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39075721">parent</a><span>|</span><a href="#39075848">next</a><span>|</span><label class="collapse" for="c-39076023">[-]</label><label class="expand" for="c-39076023">[1 more]</label></div><br/><div class="children"><div class="content">It is a great shame that we have come to a no-win situation for artists when VCs are virtually unable to lose.</div><br/></div></div></div></div><div id="39075848" class="c"><input type="checkbox" id="c-39075848" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075721">prev</a><span>|</span><a href="#39075732">next</a><span>|</span><label class="collapse" for="c-39075848">[-]</label><label class="expand" for="c-39075848">[1 more]</label></div><br/><div class="children"><div class="content">Correct me if I&#x27;m wrong but I understand image generators as relying on auto-labeled images to understand what means what, and the point of this attack to make the auto-labelers mislabel the image, but as the top-level comment said it&#x27;s seemingly not tricking newer auto-labelers.</div><br/></div></div><div id="39075732" class="c"><input type="checkbox" id="c-39075732" checked=""/><div class="controls bullet"><span class="by">webmaven</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075848">prev</a><span>|</span><a href="#39075705">next</a><span>|</span><label class="collapse" for="c-39075732">[-]</label><label class="expand" for="c-39075732">[1 more]</label></div><br/><div class="children"><div class="content">Even if no new images are being scraped to train the foundation text-to-image models, you can be certain that there is a small horde of folk still scraping to create datasets for training fine-tuned models, LoRAs, Textual Inversions, and all the new hotness training methods still being created each day.</div><br/></div></div><div id="39075705" class="c"><input type="checkbox" id="c-39075705" checked=""/><div class="controls bullet"><span class="by">ptdn</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075732">prev</a><span>|</span><a href="#39076141">next</a><span>|</span><label class="collapse" for="c-39075705">[-]</label><label class="expand" for="c-39075705">[1 more]</label></div><br/><div class="children"><div class="content">The context windows of LLMs are now significantly larger than 2048 tokens, and there are clever ways to autopopulate context window to remind it of things.</div><br/></div></div><div id="39076141" class="c"><input type="checkbox" id="c-39076141" checked=""/><div class="controls bullet"><span class="by">GaggiX</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39075705">prev</a><span>|</span><a href="#39075343">next</a><span>|</span><label class="collapse" for="c-39076141">[-]</label><label class="expand" for="c-39076141">[1 more]</label></div><br/><div class="children"><div class="content">If it doesn&#x27;t work during inference I really doubt it will have any intended effect during training, there is simply too much signal and the added adversarial noise works on the frozen and small proxy model they used (CLIP image encoder I think) but it doesn&#x27;t work on a larger model and trained on a different dataset, if there is any effect during training it will probably just be the model learning that it can&#x27;t take shortcuts (the artifacts working on the proxy model showcase gaps in its visual knowledge).<p>Generative models like text-to-image have an encoder part (it could be explicit or not) that extract the semantic from the noised image, if the auto-labelers can correctly label the samples then the encoded trained on both actual and adversarial images will learn to not take the same shortcuts that the proxy model has taken making the model more robust, I cannot see an argument where this should be a negative thing for the model.</div><br/></div></div><div id="39075343" class="c"><input type="checkbox" id="c-39075343" checked=""/><div class="controls bullet"><span class="by">jerbear4328</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39073648">parent</a><span>|</span><a href="#39076141">prev</a><span>|</span><a href="#39070858">next</a><span>|</span><label class="collapse" for="c-39075343">[-]</label><label class="expand" for="c-39075343">[2 more]</label></div><br/><div class="children"><div class="content">[3] sounds really interesting - do you have a link?</div><br/><div id="39075646" class="c"><input type="checkbox" id="c-39075646" checked=""/><div class="controls bullet"><span class="by">ittseta</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39075343">parent</a><span>|</span><a href="#39070858">next</a><span>|</span><label class="collapse" for="c-39075646">[-]</label><label class="expand" for="c-39075646">[1 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41467-023-40499-0" rel="nofollow">https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41467-023-40499-0</a>
<a href="https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;images-altered-to-trick-machine-vision-can-influence-humans-too&#x2F;" rel="nofollow">https:&#x2F;&#x2F;deepmind.google&#x2F;discover&#x2F;blog&#x2F;images-altered-to-tric...</a><p>Study on the Influence of Adversarial Images on Human Perception</div><br/></div></div></div></div></div></div><div id="39070858" class="c"><input type="checkbox" id="c-39070858" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39073648">prev</a><span>|</span><a href="#39071249">next</a><span>|</span><label class="collapse" for="c-39070858">[-]</label><label class="expand" for="c-39070858">[1 more]</label></div><br/><div class="children"><div class="content">Yeah. At worst a simple img2img diffusion step would mitigate this, but just eyeballing the examples, traditional denoisers would probably do the job?<p>Denoising is probably a good preprocessing step anyway.</div><br/></div></div><div id="39071249" class="c"><input type="checkbox" id="c-39071249" checked=""/><div class="controls bullet"><span class="by">pimlottc</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39070858">prev</a><span>|</span><a href="#39074931">next</a><span>|</span><label class="collapse" for="c-39071249">[-]</label><label class="expand" for="c-39071249">[18 more]</label></div><br/><div class="children"><div class="content">I can’t really see any difference in those images on the Twitter example when viewing it on mobile</div><br/><div id="39071623" class="c"><input type="checkbox" id="c-39071623" checked=""/><div class="controls bullet"><span class="by">vhcr</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39075606">next</a><span>|</span><label class="collapse" for="c-39071623">[-]</label><label class="expand" for="c-39071623">[5 more]</label></div><br/><div class="children"><div class="content">The animation when you change images makes it harder to see the difference, I opened the three images each in its own tab and the differences are more apparent when you change between each other instantly.</div><br/><div id="39074431" class="c"><input type="checkbox" id="c-39074431" checked=""/><div class="controls bullet"><span class="by">SirMaster</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071623">parent</a><span>|</span><a href="#39071959">next</a><span>|</span><label class="collapse" for="c-39074431">[-]</label><label class="expand" for="c-39074431">[3 more]</label></div><br/><div class="children"><div class="content">But that’s not realistic?<p>If you have to have both and instantly toggle between them to notice the difference, then it sounds like it’s doing its job well and is hard to notice the difference.</div><br/><div id="39076753" class="c"><input type="checkbox" id="c-39076753" checked=""/><div class="controls bullet"><span class="by">bowsamic</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39074431">parent</a><span>|</span><a href="#39075766">next</a><span>|</span><label class="collapse" for="c-39076753">[-]</label><label class="expand" for="c-39076753">[1 more]</label></div><br/><div class="children"><div class="content">What kind of artist is not going to be bothered with seeing huge artifacting on their work? Btw for me it was immediately noticeable even on mobile</div><br/></div></div><div id="39075766" class="c"><input type="checkbox" id="c-39075766" checked=""/><div class="controls bullet"><span class="by">battles</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39074431">parent</a><span>|</span><a href="#39076753">prev</a><span>|</span><a href="#39071959">next</a><span>|</span><label class="collapse" for="c-39075766">[-]</label><label class="expand" for="c-39075766">[1 more]</label></div><br/><div class="children"><div class="content">The person who drew it would definitely notice.</div><br/></div></div></div></div><div id="39071959" class="c"><input type="checkbox" id="c-39071959" checked=""/><div class="controls bullet"><span class="by">dontupvoteme</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071623">parent</a><span>|</span><a href="#39074431">prev</a><span>|</span><a href="#39075606">next</a><span>|</span><label class="collapse" for="c-39071959">[-]</label><label class="expand" for="c-39071959">[1 more]</label></div><br/><div class="children"><div class="content">One of the few times a &#x27;blink comparator&#x27; feature in image viewers would be useful!</div><br/></div></div></div></div><div id="39075606" class="c"><input type="checkbox" id="c-39075606" checked=""/><div class="controls bullet"><span class="by">fenomas</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39071623">prev</a><span>|</span><a href="#39073127">next</a><span>|</span><label class="collapse" for="c-39075606">[-]</label><label class="expand" for="c-39075606">[4 more]</label></div><br/><div class="children"><div class="content">At full size it&#x27;s <i>super</i> obvious - I made a side-by-side:<p><a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;I6EQ05g.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;I6EQ05g.png</a></div><br/><div id="39076191" class="c"><input type="checkbox" id="c-39076191" checked=""/><div class="controls bullet"><span class="by">trimethylpurine</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39075606">parent</a><span>|</span><a href="#39073127">next</a><span>|</span><label class="collapse" for="c-39076191">[-]</label><label class="expand" for="c-39076191">[3 more]</label></div><br/><div class="children"><div class="content">I still don&#x27;t see a difference. (Mobile)</div><br/><div id="39076271" class="c"><input type="checkbox" id="c-39076271" checked=""/><div class="controls bullet"><span class="by">fenomas</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39076191">parent</a><span>|</span><a href="#39076758">next</a><span>|</span><label class="collapse" for="c-39076271">[-]</label><label class="expand" for="c-39076271">[1 more]</label></div><br/><div class="children"><div class="content">Here&#x27;s a maybe more mobile friendly comparison:<p><a href="https:&#x2F;&#x2F;i.imgur.com&#x2F;zUVn8rt.png" rel="nofollow">https:&#x2F;&#x2F;i.imgur.com&#x2F;zUVn8rt.png</a><p>But now that I double-check, I was comparing with the images zoomed to 200%. On desktop the artifacts are also noticeable at 100%, but not nearly as bad as in my previous comment.</div><br/></div></div><div id="39076758" class="c"><input type="checkbox" id="c-39076758" checked=""/><div class="controls bullet"><span class="by">bowsamic</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39076191">parent</a><span>|</span><a href="#39076271">prev</a><span>|</span><a href="#39073127">next</a><span>|</span><label class="collapse" for="c-39076758">[-]</label><label class="expand" for="c-39076758">[1 more]</label></div><br/><div class="children"><div class="content">What phone are you using? It’s extremely obvious on my iPhone</div><br/></div></div></div></div></div></div><div id="39073127" class="c"><input type="checkbox" id="c-39073127" checked=""/><div class="controls bullet"><span class="by">josefx</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39075606">prev</a><span>|</span><a href="#39071467">next</a><span>|</span><label class="collapse" for="c-39073127">[-]</label><label class="expand" for="c-39073127">[1 more]</label></div><br/><div class="children"><div class="content">Something similar to jpeg artifacts on any surface with a normally smooth color gradient, in some cases rather significant.</div><br/></div></div><div id="39071467" class="c"><input type="checkbox" id="c-39071467" checked=""/><div class="controls bullet"><span class="by">0xcde4c3db</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39073127">prev</a><span>|</span><a href="#39071419">next</a><span>|</span><label class="collapse" for="c-39071467">[-]</label><label class="expand" for="c-39071467">[1 more]</label></div><br/><div class="children"><div class="content">I didn&#x27;t see it immediately either, but there&#x27;s a <i>ton</i> of added noise. The most noticeable bit for me was near the standing person&#x27;s bent elbow, but there&#x27;s a lot more that becomes obvious when flipping back and forth between browser tabs instead of swiping on Twitter.</div><br/></div></div><div id="39071419" class="c"><input type="checkbox" id="c-39071419" checked=""/><div class="controls bullet"><span class="by">Keyframe</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39071467">prev</a><span>|</span><a href="#39071402">next</a><span>|</span><label class="collapse" for="c-39071419">[-]</label><label class="expand" for="c-39071419">[1 more]</label></div><br/><div class="children"><div class="content">look at the green drapes to the right, or any large uniform colored space. It looks similar to bad JPEG artifacts.</div><br/></div></div><div id="39071402" class="c"><input type="checkbox" id="c-39071402" checked=""/><div class="controls bullet"><span class="by">pxc</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39071419">prev</a><span>|</span><a href="#39075463">next</a><span>|</span><label class="collapse" for="c-39071402">[-]</label><label class="expand" for="c-39071402">[2 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t have great vision, but me neither. They&#x27;re indistinguishable to me (likewise on mobile).</div><br/><div id="39075183" class="c"><input type="checkbox" id="c-39075183" checked=""/><div class="controls bullet"><span class="by">Gigachad</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071402">parent</a><span>|</span><a href="#39075463">next</a><span>|</span><label class="collapse" for="c-39075183">[-]</label><label class="expand" for="c-39075183">[1 more]</label></div><br/><div class="children"><div class="content">I was on desktop and it looks like pretty heavy jpeg compression. Doesn&#x27;t completely destroy the image, but it&#x27;s pretty noticeable when blown up large enough.</div><br/></div></div></div></div><div id="39075463" class="c"><input type="checkbox" id="c-39075463" checked=""/><div class="controls bullet"><span class="by">jquery</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39071402">prev</a><span>|</span><a href="#39071870">next</a><span>|</span><label class="collapse" for="c-39075463">[-]</label><label class="expand" for="c-39075463">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s really noticeable on desktop, like compressing an 800kb jpeg to 50kb. Maybe on mobile you won&#x27;t notice, but on desktop the image looks blown out.</div><br/></div></div><div id="39071870" class="c"><input type="checkbox" id="c-39071870" checked=""/><div class="controls bullet"><span class="by">charcircuit</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39075463">prev</a><span>|</span><a href="#39071417">next</a><span>|</span><label class="collapse" for="c-39071870">[-]</label><label class="expand" for="c-39071870">[1 more]</label></div><br/><div class="children"><div class="content">The gradient on the bat has blocks in it instead of being smooth.</div><br/></div></div><div id="39071417" class="c"><input type="checkbox" id="c-39071417" checked=""/><div class="controls bullet"><span class="by">milsorgen</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071249">parent</a><span>|</span><a href="#39071870">prev</a><span>|</span><a href="#39074931">next</a><span>|</span><label class="collapse" for="c-39071417">[-]</label><label class="expand" for="c-39071417">[1 more]</label></div><br/><div class="children"><div class="content">It took me a minute too but on the fast you can see some blocky artifacting by the elbow and a few spots elsewhere like curtain upper left.</div><br/></div></div></div></div><div id="39074931" class="c"><input type="checkbox" id="c-39074931" checked=""/><div class="controls bullet"><span class="by">h0p3</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39071249">prev</a><span>|</span><a href="#39071063">next</a><span>|</span><label class="collapse" for="c-39074931">[-]</label><label class="expand" for="c-39074931">[1 more]</label></div><br/><div class="children"><div class="content">Sir &#x2F;u&#x2F;b3nsn0w is courteous, `&#x2F;nod`.</div><br/></div></div><div id="39071063" class="c"><input type="checkbox" id="c-39071063" checked=""/><div class="controls bullet"><span class="by">gedy</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39074931">prev</a><span>|</span><a href="#39071545">next</a><span>|</span><label class="collapse" for="c-39071063">[-]</label><label class="expand" for="c-39071063">[3 more]</label></div><br/><div class="children"><div class="content">Maybe it&#x27;s more about &quot;protecting&quot; images that artists want to publicly share to advertise work, but it&#x27;s not appropriate for final digital media, etc.</div><br/><div id="39071234" class="c"><input type="checkbox" id="c-39071234" checked=""/><div class="controls bullet"><span class="by">sesm</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071063">parent</a><span>|</span><a href="#39071545">next</a><span>|</span><label class="collapse" for="c-39071234">[-]</label><label class="expand" for="c-39071234">[2 more]</label></div><br/><div class="children"><div class="content">In short, anti-AI watermark.</div><br/><div id="39073507" class="c"><input type="checkbox" id="c-39073507" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071234">parent</a><span>|</span><a href="#39071545">next</a><span>|</span><label class="collapse" for="c-39073507">[-]</label><label class="expand" for="c-39073507">[1 more]</label></div><br/><div class="children"><div class="content">Yeah. It may mess with the artist&#x27;s vision but the impact is still way more subtle than other methods used to protect against these unwanted actions.<p>Of course I&#x27;m assuming it works to begin with. Sounds like a game of cat and mouse. And AI has a lot of rich cats.</div><br/></div></div></div></div></div></div><div id="39071545" class="c"><input type="checkbox" id="c-39071545" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39068620">parent</a><span>|</span><a href="#39071063">prev</a><span>|</span><a href="#39071577">next</a><span>|</span><label class="collapse" for="c-39071545">[-]</label><label class="expand" for="c-39071545">[10 more]</label></div><br/><div class="children"><div class="content">The artifacts are a non-issue. It&#x27;s intended images with nightshade are intended to be silently scrapped and avoid human filtering.</div><br/><div id="39071803" class="c"><input type="checkbox" id="c-39071803" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071545">parent</a><span>|</span><a href="#39074946">next</a><span>|</span><label class="collapse" for="c-39071803">[-]</label><label class="expand" for="c-39071803">[6 more]</label></div><br/><div class="children"><div class="content">The artifacts are extremely an issue for artists who don&#x27;t want their images damaged for the possibility of them not being trained by AI.<p>It&#x27;s a bad tradeoff.</div><br/><div id="39071865" class="c"><input type="checkbox" id="c-39071865" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071803">parent</a><span>|</span><a href="#39074946">next</a><span>|</span><label class="collapse" for="c-39071865">[-]</label><label class="expand" for="c-39071865">[5 more]</label></div><br/><div class="children"><div class="content">Nightshaded images aren&#x27;t intended for portfolios. They&#x27;re mean to be uploaded enmasse and scraped later.</div><br/><div id="39072416" class="c"><input type="checkbox" id="c-39072416" checked=""/><div class="controls bullet"><span class="by">AJ007</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071865">parent</a><span>|</span><a href="#39074946">next</a><span>|</span><label class="collapse" for="c-39072416">[-]</label><label class="expand" for="c-39072416">[4 more]</label></div><br/><div class="children"><div class="content">To where? A place no one sees them and they aren&#x27;t scraped?</div><br/><div id="39072560" class="c"><input type="checkbox" id="c-39072560" checked=""/><div class="controls bullet"><span class="by">filleduchaos</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39072416">parent</a><span>|</span><a href="#39072925">next</a><span>|</span><label class="collapse" for="c-39072560">[-]</label><label class="expand" for="c-39072560">[1 more]</label></div><br/><div class="children"><div class="content">I think the point is that they&#x27;re akin to a watermark.<p>Even before the current AI boom, plenty of artists have wanted to <i>showcase</i> their work&#x2F;prove that it exists without necessarily making the highest quality original file public.</div><br/></div></div><div id="39072925" class="c"><input type="checkbox" id="c-39072925" checked=""/><div class="controls bullet"><span class="by">pgeorgi</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39072416">parent</a><span>|</span><a href="#39072560">prev</a><span>|</span><a href="#39072796">next</a><span>|</span><label class="collapse" for="c-39072925">[-]</label><label class="expand" for="c-39072925">[1 more]</label></div><br/><div class="children"><div class="content">For example in accounts on image sites that are exposed to suspected scrapers but not to others. Scrapers will still see the real data, but they&#x27;ll also run into stuff designed to mix up the training process.</div><br/></div></div><div id="39072796" class="c"><input type="checkbox" id="c-39072796" checked=""/><div class="controls bullet"><span class="by">Diti</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39072416">parent</a><span>|</span><a href="#39072925">prev</a><span>|</span><a href="#39074946">next</a><span>|</span><label class="collapse" for="c-39072796">[-]</label><label class="expand" for="c-39072796">[1 more]</label></div><br/><div class="children"><div class="content">Most serious artists I know (at least in my community) release their high-quality images on Patreon or similar.</div><br/></div></div></div></div></div></div></div></div><div id="39074946" class="c"><input type="checkbox" id="c-39074946" checked=""/><div class="controls bullet"><span class="by">soulofmischief</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071545">parent</a><span>|</span><a href="#39071803">prev</a><span>|</span><a href="#39072858">next</a><span>|</span><label class="collapse" for="c-39074946">[-]</label><label class="expand" for="c-39074946">[1 more]</label></div><br/><div class="children"><div class="content">&gt; The artifacts are a non-issue.<p>According to which authority?</div><br/></div></div><div id="39072858" class="c"><input type="checkbox" id="c-39072858" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39071545">parent</a><span>|</span><a href="#39074946">prev</a><span>|</span><a href="#39071577">next</a><span>|</span><label class="collapse" for="c-39072858">[-]</label><label class="expand" for="c-39072858">[2 more]</label></div><br/><div class="children"><div class="content">do you mean scrapped or scraped?</div><br/><div id="39073155" class="c"><input type="checkbox" id="c-39073155" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39068620">root</a><span>|</span><a href="#39072858">parent</a><span>|</span><a href="#39071577">next</a><span>|</span><label class="collapse" for="c-39073155">[-]</label><label class="expand" for="c-39073155">[1 more]</label></div><br/><div class="children"><div class="content">scraped</div><br/></div></div></div></div></div></div></div></div><div id="39071577" class="c"><input type="checkbox" id="c-39071577" checked=""/><div class="controls bullet"><span class="by">gfodor</span><span>|</span><a href="#39068620">prev</a><span>|</span><a href="#39071676">next</a><span>|</span><label class="collapse" for="c-39071577">[-]</label><label class="expand" for="c-39071577">[20 more]</label></div><br/><div class="children"><div class="content">Huge market for snake oil here. There is no way that such tools will ever win, given the requirements the art remain viewable to human perception, so even if you made something that worked (which this sounds like it doesn’t) from first principles it will be worked around immediately.<p>The only real way for artists or anyone really to try to hold back models from training on human outputs is through the law, ie, leveraging state backed violence to deter the things they don’t want. This too won’t be a perfect solution, if anything it will just put more incentives for people to develop decentralized training networks that “launder” the copyright violations that would allow for prosecutions.<p>All in all it’s a losing battle at a minimum and a stupid battle at worst. We know these models can be created easily and so they will, eventually, since you can’t prevent a computer from observing images you want humans to be able to observe freely.</div><br/><div id="39072466" class="c"><input type="checkbox" id="c-39072466" checked=""/><div class="controls bullet"><span class="by">AJ007</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39076330">next</a><span>|</span><label class="collapse" for="c-39072466">[-]</label><label class="expand" for="c-39072466">[9 more]</label></div><br/><div class="children"><div class="content">The level of claims accompanied by enthusiastic reception from a technically illiterate audience make it sound, smell, and sound like snake oil without much deep investigation.<p>There is another alternative to the law. Provide your art for private viewing only, and ensure your in person audience does not bring recording devices with them. That may sound absurd, but it&#x27;s a common practice during activities like having sex.</div><br/><div id="39076073" class="c"><input type="checkbox" id="c-39076073" checked=""/><div class="controls bullet"><span class="by">wraptile</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39072466">parent</a><span>|</span><a href="#39075451">next</a><span>|</span><label class="collapse" for="c-39076073">[-]</label><label class="expand" for="c-39076073">[4 more]</label></div><br/><div class="children"><div class="content">The thing is people want the benefits of having their stuff public but not bear the costs. Scraping has been mostly a solved problem especially when it comes to broad crawling. Put it under a login, there, no more AI &quot;stealing&quot; your work.</div><br/><div id="39076780" class="c"><input type="checkbox" id="c-39076780" checked=""/><div class="controls bullet"><span class="by">csydas</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076073">parent</a><span>|</span><a href="#39076724">next</a><span>|</span><label class="collapse" for="c-39076780">[-]</label><label class="expand" for="c-39076780">[1 more]</label></div><br/><div class="children"><div class="content">I don&#x27;t think that&#x27;s true at all. Images and text get reposted with or without consent, often without attribution. It wouldn&#x27;t make it right for the AI companies to scrape when the original author doesn&#x27;t want that but someone else has ignored their wishes and requirements. Basically, what good is putting your stuff behind login or some other restrictive viewing method if someone just saves the image&#x2F;text? I think it&#x27;s still a relatively serious problem for people creating things. And without some form of easy access to viewing, the people creating things don&#x27;t get the visibility and exposure they need to get an audience&#x2F;clients.<p>This is one the AI companies should offer the olive branch on IMO, there must be a way to use stenography to transparently embed a &quot;don&#x27;t process for AI&quot; code into an image or text or music or any other creative work that won&#x27;t be noticeable by humans, but the AI would see if it tried to process the content for training. I think it would be a very convenient answer and probably not be detrimental to the AI companies, but I also imagine that the AI companies would not be very eager to spend the resources implementing this. I do think they&#x27;re the best source for such protections for artists though.<p>Ideally, without a previous written agreement for a dataset from the original creators, the AI companies probably shouldn&#x27;t be using it for training at all, but I doubt that will happen -- the system I mention above should be _opt-in_, that is, you must tag such content that is free to be AI trained in order for AI to be trained on it, but I have 0 faith that the AI companies would agree to such a self-limitation.<p>edit: added mention to music and other creative works in second paragraph 1st sentence<p>edit 2: Added final paragraph as I do think this should be opt-in, but don&#x27;t believe AI companies would ever accept this, even though they should by all means in my opinion.</div><br/></div></div><div id="39076724" class="c"><input type="checkbox" id="c-39076724" checked=""/><div class="controls bullet"><span class="by">946789987649</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076073">parent</a><span>|</span><a href="#39076780">prev</a><span>|</span><a href="#39075451">next</a><span>|</span><label class="collapse" for="c-39076724">[-]</label><label class="expand" for="c-39076724">[2 more]</label></div><br/><div class="children"><div class="content">Is that login statement strictly true? Unless the login is paid, there&#x27;s no reason we can&#x27;t get to (if not already there) the point where the AI scraper can just create a login first.</div><br/><div id="39076786" class="c"><input type="checkbox" id="c-39076786" checked=""/><div class="controls bullet"><span class="by">Tade0</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076724">parent</a><span>|</span><a href="#39075451">next</a><span>|</span><label class="collapse" for="c-39076786">[-]</label><label class="expand" for="c-39076786">[1 more]</label></div><br/><div class="children"><div class="content">But then you can rate-limit to a point where scraping everything will take a considerable amount of time.<p>Of course the workaround would be to have multiple accounts, but that in turn can be made unscalable with a &quot;prove you&#x27;re human&quot; box.</div><br/></div></div></div></div></div></div><div id="39075451" class="c"><input type="checkbox" id="c-39075451" checked=""/><div class="controls bullet"><span class="by">Gormo</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39072466">parent</a><span>|</span><a href="#39076073">prev</a><span>|</span><a href="#39074637">next</a><span>|</span><label class="collapse" for="c-39075451">[-]</label><label class="expand" for="c-39075451">[1 more]</label></div><br/><div class="children"><div class="content">That doesn&#x27;t sound like a viable business model.  There seems to be a non-trivial bootstrap problem involved -- how do you become well-known enough to attract audiences to private venues in sufficient volume to make a living? -- and would in no way diminish demand for AI-generated artwork which would still continue to draw attention away from you.</div><br/></div></div><div id="39074637" class="c"><input type="checkbox" id="c-39074637" checked=""/><div class="controls bullet"><span class="by">Art9681</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39072466">parent</a><span>|</span><a href="#39075451">prev</a><span>|</span><a href="#39072586">next</a><span>|</span><label class="collapse" for="c-39074637">[-]</label><label class="expand" for="c-39074637">[2 more]</label></div><br/><div class="children"><div class="content">This would just create a new market for art paparazzis who would find any and all means to inflitrate such private viewings with futuristic miniature cameras and other sensors and selling it for a premium. Less than 24 hours later the files end up on hundreds or thousands of centralized and decentralized servers.<p>I&#x27;m not defending it. Just acknowledging the reality. The next TMZ for private art gatherings is percolating in someone&#x27;s garage at the moment.</div><br/></div></div><div id="39072586" class="c"><input type="checkbox" id="c-39072586" checked=""/><div class="controls bullet"><span class="by">gfodor</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39072466">parent</a><span>|</span><a href="#39074637">prev</a><span>|</span><a href="#39076330">next</a><span>|</span><label class="collapse" for="c-39072586">[-]</label><label class="expand" for="c-39072586">[1 more]</label></div><br/><div class="children"><div class="content">True I can imagine that kind of thing becoming popular.</div><br/></div></div></div></div><div id="39076330" class="c"><input type="checkbox" id="c-39076330" checked=""/><div class="controls bullet"><span class="by">spaceman_2020</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39072466">prev</a><span>|</span><a href="#39072800">next</a><span>|</span><label class="collapse" for="c-39076330">[-]</label><label class="expand" for="c-39076330">[3 more]</label></div><br/><div class="children"><div class="content">This is the hard reality. There is no putting this genie back in the bottle.<p>The only way to be an artist now is to have a unique style of your own, and to never make it online.</div><br/><div id="39076716" class="c"><input type="checkbox" id="c-39076716" checked=""/><div class="controls bullet"><span class="by">hutzlibu</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39076330">parent</a><span>|</span><a href="#39076441">next</a><span>|</span><label class="collapse" for="c-39076716">[-]</label><label class="expand" for="c-39076716">[1 more]</label></div><br/><div class="children"><div class="content">&quot;and to never make it online.&quot;<p>So then of course, you also cannot sell your work, as those might put it online. And you cannot show your art to big crowds, as some will make pictures and put it online. So ... you can become a literal underground artists, where only some may see your work. I think only some will like that.<p>But I actually disagree, there are plenty of ways to be an artist now - but most should probably think about including AI as a tool, if they still want to make money. But with the exception of some superstars, most artists are famously low on money - and AI did not introduce this. (all the professional artists I know, those who went to art school - do not make their income with their art)</div><br/></div></div></div></div><div id="39072800" class="c"><input type="checkbox" id="c-39072800" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39076330">prev</a><span>|</span><a href="#39074285">next</a><span>|</span><label class="collapse" for="c-39072800">[-]</label><label class="expand" for="c-39072800">[1 more]</label></div><br/><div class="children"><div class="content">&gt;There is no way that such tools will ever win, given the requirements the art remain viewable to human perception<p>On the other hand, the adversarial environment might push models towards a representation more aligned with human perception, which is neat.</div><br/></div></div><div id="39074285" class="c"><input type="checkbox" id="c-39074285" checked=""/><div class="controls bullet"><span class="by">aqfamnzc</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39072800">prev</a><span>|</span><a href="#39074368">next</a><span>|</span><label class="collapse" for="c-39074285">[-]</label><label class="expand" for="c-39074285">[1 more]</label></div><br/><div class="children"><div class="content">The ol&#x27; Analog Gap. <a href="https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Analog_hole" rel="nofollow">https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Analog_hole</a></div><br/></div></div><div id="39074368" class="c"><input type="checkbox" id="c-39074368" checked=""/><div class="controls bullet"><span class="by">Reubend</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39074285">prev</a><span>|</span><a href="#39075946">next</a><span>|</span><label class="collapse" for="c-39074368">[-]</label><label class="expand" for="c-39074368">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Huge market for snake oil here.<p>This tool is free, and as far as I can tell it runs locally. If you&#x27;re not selling anything, and there&#x27;s no profit motive, then I don&#x27;t think you can reasonably call it &quot;snake oil&quot;.<p>At worst, it&#x27;s a waste of time. But nobody&#x27;s being deceived into purchasing it.</div><br/><div id="39076000" class="c"><input type="checkbox" id="c-39076000" checked=""/><div class="controls bullet"><span class="by">autoexec</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39074368">parent</a><span>|</span><a href="#39075946">next</a><span>|</span><label class="collapse" for="c-39076000">[-]</label><label class="expand" for="c-39076000">[1 more]</label></div><br/><div class="children"><div class="content">If this is a danger from &quot;snake oil&quot; of this type, it&#x27;d be from the other side, where artists are intentionally tricked into believing that tools like this mean that AI isn&#x27;t or won&#x27;t be a threat to their copyrights in order to get them to stop opposing it so strongly, when in fact the tool does nothing to prevent their copyrights from being violated.<p>I don&#x27;t think that&#x27;s the intention of Nightshade, but I wouldn&#x27;t put past someone to try it.</div><br/></div></div></div></div><div id="39075946" class="c"><input type="checkbox" id="c-39075946" checked=""/><div class="controls bullet"><span class="by">AlfeG</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39074368">prev</a><span>|</span><a href="#39075787">next</a><span>|</span><label class="collapse" for="c-39075946">[-]</label><label class="expand" for="c-39075946">[2 more]</label></div><br/><div class="children"><div class="content">My guess. Is that at some poi t of time You will not be able to use any generated image or video in commercial. Because of 100% copyright claim for using parts of copyrighted image. Like YouTube those days. When some random beeps matches with someone music...</div><br/><div id="39076078" class="c"><input type="checkbox" id="c-39076078" checked=""/><div class="controls bullet"><span class="by">abrarsami</span><span>|</span><a href="#39071577">root</a><span>|</span><a href="#39075946">parent</a><span>|</span><a href="#39075787">next</a><span>|</span><label class="collapse" for="c-39076078">[-]</label><label class="expand" for="c-39076078">[1 more]</label></div><br/><div class="children"><div class="content">It should be like that. I agree</div><br/></div></div></div></div><div id="39075787" class="c"><input type="checkbox" id="c-39075787" checked=""/><div class="controls bullet"><span class="by">jedberg</span><span>|</span><a href="#39071577">parent</a><span>|</span><a href="#39075946">prev</a><span>|</span><a href="#39071676">next</a><span>|</span><label class="collapse" for="c-39075787">[-]</label><label class="expand" for="c-39075787">[1 more]</label></div><br/><div class="children"><div class="content">Everything old is new again.  It&#x27;s the same thing with any DRM that happens on the client side.  As long as it&#x27;s viewable by humans, someone will figure out a way to feed that into a machine.</div><br/></div></div></div></div><div id="39071676" class="c"><input type="checkbox" id="c-39071676" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39071577">prev</a><span>|</span><a href="#39073118">next</a><span>|</span><label class="collapse" for="c-39071676">[-]</label><label class="expand" for="c-39071676">[1 more]</label></div><br/><div class="children"><div class="content">A few months ago I made a proof-of-concept on how finetuning Stable Diffusion XL on known bad&#x2F;incoherent images can actually allow it to output &quot;better&quot; images if those images are used as a negative prompt, i.e. specifying a high-dimensional area of the latent space that model generation should stay away from: <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37211519">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37211519</a><p>There&#x27;s a nonzero chance that encouraging the creation of a large dataset of known tampered data can ironically <i>improve</i> generative AI art models by allowing the model to recognize tampered data and allow the training process to work around it.</div><br/></div></div><div id="39073118" class="c"><input type="checkbox" id="c-39073118" checked=""/><div class="controls bullet"><span class="by">eigenvalue</span><span>|</span><a href="#39071676">prev</a><span>|</span><a href="#39071378">next</a><span>|</span><label class="collapse" for="c-39073118">[-]</label><label class="expand" for="c-39073118">[5 more]</label></div><br/><div class="children"><div class="content">This seems like a pretty pointless &quot;arms race&quot; or &quot;cat and mouse game&quot;. People who want to train generative image models and who don&#x27;t care about what artists think about it at all can just do some basic post-processing on the images that is just enough to destroy the very carefully tuned changes this Nightshade algorithm makes. Something like resampling it to slightly lower resolution and then using another super-resolution model on it to upsample it again would probably be able to destroy these subtle tweaks without making a big difference to a human observer.<p>In the future, my guess is that courts will generally be on the side of artists because of societal pressures, and artists will be able to challenge any image they find and have it sent to yet another ML model that can quickly adjudicate whether the generated image is &quot;too similar&quot; to the artist&#x27;s style (which would also need to be dissimilar enough from everyone else&#x27;s style to give a reasonable legal claim in the first place).<p>Or maybe artists will just give up on trying to monetize the images themselves and focus only on creating physical artifacts, similar to how independent musicians make most of their money nowadays from touring and selling merchandise at shows (plus Patreon). Who knows? It&#x27;s hard to predict the future when there are such huge fundamental changes that happen so quickly!</div><br/><div id="39073735" class="c"><input type="checkbox" id="c-39073735" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#39073118">parent</a><span>|</span><a href="#39075640">next</a><span>|</span><label class="collapse" for="c-39073735">[-]</label><label class="expand" for="c-39073735">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Or maybe artists will just give up on trying to monetize the images themselves and focus only on creating physical artifacts, similar to how independent musicians make most of their money nowadays from touring and selling merchandise at shows (plus Patreon).<p>As is, art already isn&#x27;t a sustainable career for most people who can&#x27;t get a job in industry. The most common monetization is either commissions or hiding extra content behind a pay wall.<p>To be honest I can see more proverbial &quot;Furry artists&quot; sprouting up in a cynical timeline. I imagine like every other big tech that the 18+ side of this will be clamped down hard by the various powers that be. Which means NSFW stuff will be shielded a bit by the advancement and you either need to find underground training models or go back to an artist. .</div><br/><div id="39075209" class="c"><input type="checkbox" id="c-39075209" checked=""/><div class="controls bullet"><span class="by">Gigachad</span><span>|</span><a href="#39073118">root</a><span>|</span><a href="#39073735">parent</a><span>|</span><a href="#39075640">next</a><span>|</span><label class="collapse" for="c-39075209">[-]</label><label class="expand" for="c-39075209">[1 more]</label></div><br/><div class="children"><div class="content">&gt;need to find underground training models<p>It&#x27;s not particularly that hard. The furry nsfw models are already the most well developed and available models you can get right now. And they are spitting out stuff that is almost indistinguishable from regular art.</div><br/></div></div></div></div><div id="39075640" class="c"><input type="checkbox" id="c-39075640" checked=""/><div class="controls bullet"><span class="by">raincole</span><span>|</span><a href="#39073118">parent</a><span>|</span><a href="#39073735">prev</a><span>|</span><a href="#39073164">next</a><span>|</span><label class="collapse" for="c-39075640">[-]</label><label class="expand" for="c-39075640">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This seems like a pretty pointless &quot;arms race&quot; or &quot;cat and mouse game&quot;.<p>If there is any &quot;point&quot; of this, it&#x27;s that&#x27;s going to push the AI models to become <i>better</i> at capturing how humans see things.</div><br/></div></div><div id="39073164" class="c"><input type="checkbox" id="c-39073164" checked=""/><div class="controls bullet"><span class="by">hackernewds</span><span>|</span><a href="#39073118">parent</a><span>|</span><a href="#39075640">prev</a><span>|</span><a href="#39071378">next</a><span>|</span><label class="collapse" for="c-39073164">[-]</label><label class="expand" for="c-39073164">[1 more]</label></div><br/><div class="children"><div class="content">the point is you could circumvent one nightshade, but as long as the cat and mouse game continues there can be more</div><br/></div></div></div></div><div id="39071378" class="c"><input type="checkbox" id="c-39071378" checked=""/><div class="controls bullet"><span class="by">marcinzm</span><span>|</span><a href="#39073118">prev</a><span>|</span><a href="#39072007">next</a><span>|</span><label class="collapse" for="c-39071378">[-]</label><label class="expand" for="c-39071378">[1 more]</label></div><br/><div class="children"><div class="content">This feels like it&#x27;ll actually help make AI models better versus worse once they train on these images. Artists are basically, for free, creating training data that conveys what types of noise does not change the intended meaning of the image to the artist themselves.</div><br/></div></div><div id="39072007" class="c"><input type="checkbox" id="c-39072007" checked=""/><div class="controls bullet"><span class="by">chris-orgmenta</span><span>|</span><a href="#39071378">prev</a><span>|</span><a href="#39068221">next</a><span>|</span><label class="collapse" for="c-39072007">[-]</label><label class="expand" for="c-39072007">[3 more]</label></div><br/><div class="children"><div class="content">I want <i>progressive fees</i> on copyright&#x2F;IP&#x2F;patent usage, and worldwide gov cooperation&#x2F;legislation (and perhaps even worldwide ability to use works without obtaining initial permission, although let&#x27;s not go into that outlandish stuff)<p>I want a scaling license fee to apply (e.g. % pegged to revenue. This still has an indirect problem with different industries having different profit margins, but still seems the fairest).<p>And I want the world (or EU, then others to follow suit) to slowly reduce copyright to 0 years* after artists death if owned by a person, and 20-30 years max if owned by a corporation.<p>And I want the penalties for not declaring usage** &#x2F; not paying fees, to be incredibly high for corporations... 50% gross (harder) &#x2F; net (easier) profit margin for the year? Something that isn&#x27;t a slap on the wrist and can&#x27;t be wriggled out of <i>quite</i> so easily, and is actually an incentive not to steal in the first place.)<p>[*]or whatever society deems appropriate.<p>[**]Until auto-detection (for better or worse) gets good enough.<p>IMO that would allow personal use, encourages new entrants to market, encourages innovation, incentivises better behaviour from OpenAI et al.</div><br/><div id="39074752" class="c"><input type="checkbox" id="c-39074752" checked=""/><div class="controls bullet"><span class="by">Dylan16807</span><span>|</span><a href="#39072007">parent</a><span>|</span><a href="#39076132">next</a><span>|</span><label class="collapse" for="c-39074752">[-]</label><label class="expand" for="c-39074752">[1 more]</label></div><br/><div class="children"><div class="content">&gt; And I want the world (or EU, then others to follow suit) to slowly reduce copyright to 0 years* after artists death if owned by a person, and 20-30 years max if owned by a corporation.<p>Why death at all?<p>It&#x27;s icky to trigger soon after death, it&#x27;s bad to have copyright vary so much based on author age, and it&#x27;s bad for many works to still have huge copyright lengths.<p>It&#x27;s perfectly fine to let copyright expire during the author&#x27;s life.  20-30 years for everything.</div><br/></div></div><div id="39076132" class="c"><input type="checkbox" id="c-39076132" checked=""/><div class="controls bullet"><span class="by">wraptile</span><span>|</span><a href="#39072007">parent</a><span>|</span><a href="#39074752">prev</a><span>|</span><a href="#39068221">next</a><span>|</span><label class="collapse" for="c-39076132">[-]</label><label class="expand" for="c-39076132">[1 more]</label></div><br/><div class="children"><div class="content">Extremely naive to think that any of this could be enforced to any adequate level. Copyright is fundamentally broken and putting some plasters on it is not going to do much especially when these plasters are several decades too late.</div><br/></div></div></div></div><div id="39068221" class="c"><input type="checkbox" id="c-39068221" checked=""/><div class="controls bullet"><span class="by">KingOfCoders</span><span>|</span><a href="#39072007">prev</a><span>|</span><a href="#39071494">next</a><span>|</span><label class="collapse" for="c-39068221">[-]</label><label class="expand" for="c-39068221">[167 more]</label></div><br/><div class="children"><div class="content">Artists sitting in art school looking at other artists pictures to learn how to paint in different styles defend against AI learning from their pictures how to paint in different styles.</div><br/><div id="39068637" class="c"><input type="checkbox" id="c-39068637" checked=""/><div class="controls bullet"><span class="by">bluejekyll</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39076660">next</a><span>|</span><label class="collapse" for="c-39068637">[-]</label><label class="expand" for="c-39068637">[39 more]</label></div><br/><div class="children"><div class="content">My issue with this line of argument is that it’s anthropomorphizing machines. It’s fine to compare how humans do a task with how a machine does a task, but in the end they are very different from each other, organic vs hardware and software logic.<p>First, you need to prove that generative AI works fundamentally the same way as humans at the task of learning. Next you have to prove that it recalls information in the same way as humans. I don’t think anyone would say these are things that we can prove, let alone believe they do. So what we get is comments like they are similar.<p>What this means, is these systems will fall into different categories of law around copyright and free-use. What’s clear is that there are people who believe that they are harmed by the use of their work in training these systems and it reproducing that work in some manner later on (the degree to which that single work or the corpus of their work influences that final product is an interesting question). If your terms of use&#x2F;copyright&#x2F;license says “you may not train on this data”, then should that be protected in law? If a system like nightshade can effectively influence a training model enough to make it clear that something protected was used in its training, is that enough proof that the legal protections were broken?</div><br/><div id="39070822" class="c"><input type="checkbox" id="c-39070822" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068637">parent</a><span>|</span><a href="#39071263">next</a><span>|</span><label class="collapse" for="c-39070822">[-]</label><label class="expand" for="c-39070822">[4 more]</label></div><br/><div class="children"><div class="content">&gt;First, you need to prove that generative AI works fundamentally the same way as humans at the task of learning. Next you have to prove that it recalls information in the same way as humans.<p>No, you don&#x27;t need to prove any of those things. They&#x27;re irrelevant. You&#x27;d need to prove that the AI is itself morally (or, depending on the nature of the dispute, legally) equivalent to a human and therefore deserving of (or entitled to) the same rights and protections as a human. Since it is pretty indisputably the case that software is not currently legally equivalent to a human, you&#x27;re stuck with the moral argument that it ought to be, but I think we&#x27;re very far from a point where that position is warranted or likely to see much support.</div><br/><div id="39072920" class="c"><input type="checkbox" id="c-39072920" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070822">parent</a><span>|</span><a href="#39070919">next</a><span>|</span><label class="collapse" for="c-39072920">[-]</label><label class="expand" for="c-39072920">[1 more]</label></div><br/><div class="children"><div class="content">Few people are claiming that the AI itself has the same rights as a human. They are arguing that a human with an AI has the same rights as a human who doesn&#x27;t have an AI.</div><br/></div></div><div id="39070919" class="c"><input type="checkbox" id="c-39070919" checked=""/><div class="controls bullet"><span class="by">kelseyfrog</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070822">parent</a><span>|</span><a href="#39072920">prev</a><span>|</span><a href="#39071661">next</a><span>|</span><label class="collapse" for="c-39070919">[-]</label><label class="expand" for="c-39070919">[1 more]</label></div><br/><div class="children"><div class="content">You don&#x27;t even need to do that. Art is an act of ontological framing.<p>Duchamp didn&#x27;t need negotiate with the ceramic makers to make the Fountain into art.</div><br/></div></div><div id="39071661" class="c"><input type="checkbox" id="c-39071661" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070822">parent</a><span>|</span><a href="#39070919">prev</a><span>|</span><a href="#39071263">next</a><span>|</span><label class="collapse" for="c-39071661">[-]</label><label class="expand" for="c-39071661">[1 more]</label></div><br/><div class="children"><div class="content">&gt; ou&#x27;d need to prove that the AI is itself morally (or, depending on the nature of the dispute, legally) equivalent to a human and therefore deserving of<p>No you don&#x27;t.<p>A human using a computer to make art doesn&#x27;t automatically lose their fair use rights as a human.<p>&gt; indisputably the case that software is not currently legally equivalent to a human<p>Fortunately it is the human who uses the computer who has the legal rights to use computers in their existing process of fair use.<p>Human brains or giving rights to computers has absolutely nothing to do with the rights of human to use a camera, use photoshop, or even use AI, on a computer.</div><br/></div></div></div></div><div id="39071263" class="c"><input type="checkbox" id="c-39071263" checked=""/><div class="controls bullet"><span class="by">usrbinbash</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068637">parent</a><span>|</span><a href="#39070822">prev</a><span>|</span><a href="#39070907">next</a><span>|</span><label class="collapse" for="c-39071263">[-]</label><label class="expand" for="c-39071263">[3 more]</label></div><br/><div class="children"><div class="content">&gt; that it’s anthropomorphizing machines.<p>No, it&#x27;s not. It&#x27;s merely pointing out the similarity between the process of training artists (by ingesting publicly available works) and ML models (which ingest publicly available works).<p>&gt; First, you need to prove that generative AI works fundamentally the same way as humans at the task of learning.<p>Given that there is no comprehensive model for how humans actually learn things, that would be an unfeasible requirement.</div><br/><div id="39071833" class="c"><input type="checkbox" id="c-39071833" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071263">parent</a><span>|</span><a href="#39070907">next</a><span>|</span><label class="collapse" for="c-39071833">[-]</label><label class="expand" for="c-39071833">[2 more]</label></div><br/><div class="children"><div class="content">What a reductive way to describe learning art. The similarities are merely surface level.<p>&gt; Given that there is no comprehensive model for how humans actually learn things, that would be an unfeasible requirement.<p>That is precisely why we should not be making this comparison.</div><br/><div id="39076779" class="c"><input type="checkbox" id="c-39076779" checked=""/><div class="controls bullet"><span class="by">bowsamic</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071833">parent</a><span>|</span><a href="#39070907">next</a><span>|</span><label class="collapse" for="c-39076779">[-]</label><label class="expand" for="c-39076779">[1 more]</label></div><br/><div class="children"><div class="content">I’m being told repeatedly that the similarities are surface level, but no one seems to be able to give an example of a deep difference</div><br/></div></div></div></div></div></div><div id="39070907" class="c"><input type="checkbox" id="c-39070907" checked=""/><div class="controls bullet"><span class="by">Phiwise_</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068637">parent</a><span>|</span><a href="#39071263">prev</a><span>|</span><a href="#39071460">next</a><span>|</span><label class="collapse" for="c-39070907">[-]</label><label class="expand" for="c-39070907">[1 more]</label></div><br/><div class="children"><div class="content">The first perceptron was explicitly designed to be a trainable visual pattern encoder. Zero assumptions about potential feelings of the ghost in the machine need to be made to conclude the program is probably doing what humans studying art <i>say they assume</i> is happening in their head when you show both of them a series of previous artists&#x27; works. This argument is such a tired misdirection.</div><br/></div></div><div id="39071460" class="c"><input type="checkbox" id="c-39071460" checked=""/><div class="controls bullet"><span class="by">jwells89</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068637">parent</a><span>|</span><a href="#39070907">prev</a><span>|</span><a href="#39071876">next</a><span>|</span><label class="collapse" for="c-39071460">[-]</label><label class="expand" for="c-39071460">[4 more]</label></div><br/><div class="children"><div class="content">The way these ML models and humans operate are indeed quite different.<p>Humans work by abstracting concepts in what they see, even when looking at the work of others. Even individuals with photographic memories mentally abstract things like lighting, body kinetics, musculature, color theory, etc and produce new work based on those abstractions rather than directly copying original work (unless the artist is intentionally plagiarizing). As a result, all new works produced by humans will have a certain degree of originality to them, regardless of influences due to differences in perception, mental abstraction processes, and life experiences among other factors. Furthermore, humans can produce art without any external instruction or input… give a 5 year old that’s never been exposed to art and hasn’t been shown how to make art a box of crayons and it’s a matter of time before they start drawing.<p>ML models are closer to highly advanced collage makers that take known images and blend them together in a way that’s convincing at first glance, which is why it’s not uncommon to see elements lifted directly from training data in the images they produce. They do not abstract the same way and by definition cannot produce anything that’s not a blend of training data. Give them no data and they cannot produce anything.<p>It’s absolutely erroneous to compare them to humans, and I believe it will continue to be so until ML models evolve into something closer to AGI which can e.g. produce stylized work with nothing but photographic input that it’s gathered in a robot body and artistic experimentation.</div><br/><div id="39072390" class="c"><input type="checkbox" id="c-39072390" checked=""/><div class="controls bullet"><span class="by">l33tman</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071460">parent</a><span>|</span><a href="#39072317">next</a><span>|</span><label class="collapse" for="c-39072390">[-]</label><label class="expand" for="c-39072390">[2 more]</label></div><br/><div class="children"><div class="content">You&#x27;re wrong in your concept of how AI&#x2F;ML works. Even trivial 1980&#x27;s neural networks generalize, it&#x27;s the whole point of AI&#x2F;ML or you&#x27;d just have a lookup-table (or, as you put it, something that copies and pastes images together).<p>I&#x27;ve seen &quot;infographics&quot; spread by anti-AI people (or just attention-seekers) on Twitter that tries to &quot;explain&quot; that AI image generators blend together existing images, which is simply not true..<p>It is however the case that different AI models (and the brain) generalize a bit differently. That is probably the case between different humans too. Not the least with for example like you say those with photographic memory, autists etc.<p>What you call creativity in humans is just noise in combination with a boatload of exposure to multi-modal training data. Both aspects are already in the modern diffusion models. I would however ascribe a big edge in humans to what you normally call &quot;the creative process&quot; which can be much richer, like a process where you figure out what you lack to produce a work, go out and learn something new and specific, talk with your peers, listen to more noise.. stuff like that seems (currently) more difficult for AIs, though I guess plugins that do more iterative stuff like chatgpt&#x27;s new plugins will appear in media generators as well eventually..</div><br/><div id="39072744" class="c"><input type="checkbox" id="c-39072744" checked=""/><div class="controls bullet"><span class="by">jwells89</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072390">parent</a><span>|</span><a href="#39072317">next</a><span>|</span><label class="collapse" for="c-39072744">[-]</label><label class="expand" for="c-39072744">[1 more]</label></div><br/><div class="children"><div class="content">ML generalization and human abstraction are very different beasts.<p>For example, a human artist would have an understanding of how line weight factors into stylization and <i>why</i> it looks the way it does and be able to accurately apply these concepts to drawings of things they’ve never seen in that style (or even seen at all, if it’s of something imaginary).<p>The best an ML model can do is mimic examples of line art in the given style within its training data, the product of which will contain errors due to not understanding the underlying principles, especially if you ask it to draw something it hasn’t seen in the style you’re asking for. This is why generative AI needs such vast volumes of data to work well; it’s going to falter in cases not well covered by the data. It’s not learning concepts, only statistical probabilities.</div><br/></div></div></div></div><div id="39072317" class="c"><input type="checkbox" id="c-39072317" checked=""/><div class="controls bullet"><span class="by">shlubbert</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071460">parent</a><span>|</span><a href="#39072390">prev</a><span>|</span><a href="#39071876">next</a><span>|</span><label class="collapse" for="c-39072317">[-]</label><label class="expand" for="c-39072317">[1 more]</label></div><br/><div class="children"><div class="content">Beautifully put. I wish this nuance was more widely understood in the current AI debate.</div><br/></div></div></div></div><div id="39071876" class="c"><input type="checkbox" id="c-39071876" checked=""/><div class="controls bullet"><span class="by">z7</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068637">parent</a><span>|</span><a href="#39071460">prev</a><span>|</span><a href="#39070900">next</a><span>|</span><label class="collapse" for="c-39071876">[-]</label><label class="expand" for="c-39071876">[1 more]</label></div><br/><div class="children"><div class="content">&gt;My issue with this line of argument is that it’s anthropomorphizing machines. It’s fine to compare how humans do a task with how a machine does a task, but in the end they are very different from each other, organic vs hardware and software logic.<p>There&#x27;s an entire branch of philosophy that calls these assumptions into question:<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Posthumanism" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Posthumanism</a><p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Antihumanism" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Antihumanism</a><p>&gt;Martin Heidegger viewed humanism as a metaphysical philosophy that ascribes to humanity a universal essence and privileges it above all other forms of existence. For Heidegger, humanism takes consciousness as the paradigm of philosophy, leading it to a subjectivism and idealism that must be avoided.<p>&gt;Processes of technological and non-technological posthumanization both tend to result in a partial &quot;de-anthropocentrization&quot; of human society, as its circle of membership is expanded to include other types of entities and the position of human beings is decentered. A common theme of posthumanist study is the way in which processes of posthumanization challenge or blur simple binaries, such as those of &quot;human versus non-human&quot;, &quot;natural versus artificial&quot;, &quot;alive versus non-alive&quot;, and &quot;biological versus mechanical&quot;.</div><br/></div></div><div id="39070900" class="c"><input type="checkbox" id="c-39070900" checked=""/><div class="controls bullet"><span class="by">echelon</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068637">parent</a><span>|</span><a href="#39071876">prev</a><span>|</span><a href="#39071642">next</a><span>|</span><label class="collapse" for="c-39070900">[-]</label><label class="expand" for="c-39070900">[3 more]</label></div><br/><div class="children"><div class="content">We are machines. We just haven&#x27;t evenly accepted it yet.<p>Our biology is mechanical, and lay people don&#x27;t possess an intuition about this. Unless you&#x27;ve studied molecular biology and biochemistry, it&#x27;s not something that you can easily grasp.<p>Our inventions are mechanical, too, and they&#x27;re reaching increasing levels of sophistication. At some point we&#x27;ll meet in the middle.</div><br/><div id="39074979" class="c"><input type="checkbox" id="c-39074979" checked=""/><div class="controls bullet"><span class="by">qgin</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070900">parent</a><span>|</span><a href="#39071909">next</a><span>|</span><label class="collapse" for="c-39074979">[-]</label><label class="expand" for="c-39074979">[1 more]</label></div><br/><div class="children"><div class="content">This is the truth. And it&#x27;s also the reason why this stuff will be in court until The Singularity itself. Most people will never be able to come to terms with this.</div><br/></div></div><div id="39071909" class="c"><input type="checkbox" id="c-39071909" checked=""/><div class="controls bullet"><span class="by">DennisAleynikov</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070900">parent</a><span>|</span><a href="#39074979">prev</a><span>|</span><a href="#39071642">next</a><span>|</span><label class="collapse" for="c-39071909">[-]</label><label class="expand" for="c-39071909">[1 more]</label></div><br/><div class="children"><div class="content">100% this. Labor and all these other concepts are outdated ways to interpret reality<p>Humans are themselves mechanical so at the end of the day none of these issues actually matter</div><br/></div></div></div></div><div id="39071642" class="c"><input type="checkbox" id="c-39071642" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068637">parent</a><span>|</span><a href="#39070900">prev</a><span>|</span><a href="#39070849">next</a><span>|</span><label class="collapse" for="c-39071642">[-]</label><label class="expand" for="c-39071642">[3 more]</label></div><br/><div class="children"><div class="content">&gt; What this means, is these systems will fall into different categories of law around copyright and free-use.<p>No they won&#x27;t.<p>A human who uses a computer as a tool (under all the previous qualifications of fair use) is still a human doing something in fair use.<p>Adding a computer to the workflow of a human doesn&#x27;t make fair use disappear.<p>A human can use photoshop, in fair use. They can use a camera.  They can use all sorts of machines.<p>The fact that photoshop is not the same as a human brain is simply a completely unrelated non sequitur.  Same applies to AI.<p>And all the legal protections that are offered to someone who uses a regular computer, to use photoshop in fair use, are also extended to someone who uses AI in fair use.</div><br/><div id="39071874" class="c"><input type="checkbox" id="c-39071874" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071642">parent</a><span>|</span><a href="#39070849">next</a><span>|</span><label class="collapse" for="c-39071874">[-]</label><label class="expand" for="c-39071874">[2 more]</label></div><br/><div class="children"><div class="content">Yet the copyright office has already stated that getting an AI to create an image for you does not have sufficient human authorship to be copyrighted. There&#x27;s already a legal distinction here between this &quot;tool&quot; and tools like photoshop and cameras.<p>It&#x27;s also presumptive to assume that AI tools have these fair use protections when none of this has actually been decided in a court of law yet. There&#x27;s still several unsettled cases here.</div><br/><div id="39075182" class="c"><input type="checkbox" id="c-39075182" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071874">parent</a><span>|</span><a href="#39070849">next</a><span>|</span><label class="collapse" for="c-39075182">[-]</label><label class="expand" for="c-39075182">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Yet the copyright office has already stated that getting an AI to create an image for you does not have sufficient human authorship to be copyrighted.<p>Gotcha.<p>That has nothing to do with fair use though.<p>Also, the same argument absolutely applies to photoshop.<p>If someone didn&#x27;t include sufficient human authorship while using photoshop, that wouldn&#x27;t be copyrightable either.<p>Also, the ruling has no bearing on if someone using AI, while also inputting a significant amount of human authorship. Instead, it was only about the cases where there weren&#x27;t much human authorship.<p>At no point did the copyright office disclude copyright protections from anything that used AI in any way what so ever.  In fact, the copyright office now includes new forms and fields where you talk about the whole process that you did, and how you used AI, in conjunction with human authorship to create the work.<p>&gt; It&#x27;s also presumptive to assume that AI tools<p>I&#x27;m not talking about the computer.  I never claimed that computer&#x27;s have rights.  Instead, I&#x27;m talking about the human.  Yes, a human has fair use protections, even if they use a computer.<p>&gt;  There&#x27;s still several unsettled cases here.<p>There is no reason to believe that copyright law will be interpreted in a significantly different way than it has been in the past.<p>There is long standing precent, regarding all sorts of copyright cases that involve using a computer.</div><br/></div></div></div></div></div></div><div id="39070849" class="c"><input type="checkbox" id="c-39070849" checked=""/><div class="controls bullet"><span class="by">huytersd</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068637">parent</a><span>|</span><a href="#39071642">prev</a><span>|</span><a href="#39071223">next</a><span>|</span><label class="collapse" for="c-39070849">[-]</label><label class="expand" for="c-39070849">[16 more]</label></div><br/><div class="children"><div class="content">Why do you have to prove that? There is no replication (except in very rare cases), how someone draws a line should not be copyrightable.</div><br/><div id="39071072" class="c"><input type="checkbox" id="c-39071072" checked=""/><div class="controls bullet"><span class="by">pfist</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070849">parent</a><span>|</span><a href="#39071223">next</a><span>|</span><label class="collapse" for="c-39071072">[-]</label><label class="expand" for="c-39071072">[15 more]</label></div><br/><div class="children"><div class="content">Therein lies the crux of the issue: AI is not “someone”. We need to approach this without anthropomorphizing the AI.</div><br/><div id="39071168" class="c"><input type="checkbox" id="c-39071168" checked=""/><div class="controls bullet"><span class="by">Almondsetat</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071072">parent</a><span>|</span><a href="#39071300">next</a><span>|</span><label class="collapse" for="c-39071168">[-]</label><label class="expand" for="c-39071168">[12 more]</label></div><br/><div class="children"><div class="content">You are right, AI is nothing but a tool akin to a pen or a brush.<p>If you draw Mickey Mouse with a pencil and you publish (and sell) the drawing who is getting the blame? Is the pencil infringing the copyright? No, it&#x27;s you.<p>Same with AI. There is nothijg wrong with using copyrighted works to train an algorithm, but if you generate an image and it contains copyrighted materials you are getting sued.</div><br/><div id="39071562" class="c"><input type="checkbox" id="c-39071562" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071168">parent</a><span>|</span><a href="#39071300">next</a><span>|</span><label class="collapse" for="c-39071562">[-]</label><label class="expand" for="c-39071562">[11 more]</label></div><br/><div class="children"><div class="content">But there is. You are arguably making unauthorized copies to train.</div><br/><div id="39071646" class="c"><input type="checkbox" id="c-39071646" checked=""/><div class="controls bullet"><span class="by">Almondsetat</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071562">parent</a><span>|</span><a href="#39072964">next</a><span>|</span><label class="collapse" for="c-39071646">[-]</label><label class="expand" for="c-39071646">[9 more]</label></div><br/><div class="children"><div class="content">Unauthorized copies? If the images are published on the internet how is it downloading them &quot;unauthorized&quot;?</div><br/><div id="39071906" class="c"><input type="checkbox" id="c-39071906" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071646">parent</a><span>|</span><a href="#39072964">next</a><span>|</span><label class="collapse" for="c-39071906">[-]</label><label class="expand" for="c-39071906">[8 more]</label></div><br/><div class="children"><div class="content">Publicly available doesn&#x27;t mean you have a license to do whatever you like with the image. If I download an image and re-upload it to my own art station or sell prints of it, that is something I can physically do because the image is public, but I&#x27;m absolutely violating copyright.</div><br/><div id="39071974" class="c"><input type="checkbox" id="c-39071974" checked=""/><div class="controls bullet"><span class="by">Almondsetat</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071906">parent</a><span>|</span><a href="#39072964">next</a><span>|</span><label class="collapse" for="c-39071974">[-]</label><label class="expand" for="c-39071974">[7 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not an unautharized copy, it&#x27;s unauthorized distribution. By the same metric me seeing the image and copying it by hand is also unauthorized copy (or reproduction is you will)</div><br/><div id="39072633" class="c"><input type="checkbox" id="c-39072633" checked=""/><div class="controls bullet"><span class="by">xigoi</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071974">parent</a><span>|</span><a href="#39072964">next</a><span>|</span><label class="collapse" for="c-39072633">[-]</label><label class="expand" for="c-39072633">[6 more]</label></div><br/><div class="children"><div class="content">IANAL, but I’m pretty sure copying an image by hand is copyright violation.</div><br/><div id="39072922" class="c"><input type="checkbox" id="c-39072922" checked=""/><div class="controls bullet"><span class="by">Almondsetat</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072633">parent</a><span>|</span><a href="#39072964">next</a><span>|</span><label class="collapse" for="c-39072922">[-]</label><label class="expand" for="c-39072922">[5 more]</label></div><br/><div class="children"><div class="content">So you cannot train your drawing skills by copying other people&#x27;s artworks?</div><br/><div id="39072937" class="c"><input type="checkbox" id="c-39072937" checked=""/><div class="controls bullet"><span class="by">xigoi</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072922">parent</a><span>|</span><a href="#39072964">next</a><span>|</span><label class="collapse" for="c-39072937">[-]</label><label class="expand" for="c-39072937">[4 more]</label></div><br/><div class="children"><div class="content">You can do it in private, but you can’t distribute the resulting image, let alone sell it.</div><br/><div id="39073075" class="c"><input type="checkbox" id="c-39073075" checked=""/><div class="controls bullet"><span class="by">Almondsetat</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072937">parent</a><span>|</span><a href="#39072964">next</a><span>|</span><label class="collapse" for="c-39073075">[-]</label><label class="expand" for="c-39073075">[3 more]</label></div><br/><div class="children"><div class="content">Then I don&#x27;t really understand your original reply. Simply copying a publicly available image doesn&#x27;t infringe anything (unless it was supposed to be private&#x2F;secret). Doing stuff with that image in private still doesn&#x27;t constitute infringement. Distribution does, but that wasn&#x27;t the topic at hand</div><br/><div id="39076159" class="c"><input type="checkbox" id="c-39076159" checked=""/><div class="controls bullet"><span class="by">zerocrates</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073075">parent</a><span>|</span><a href="#39073090">next</a><span>|</span><label class="collapse" for="c-39076159">[-]</label><label class="expand" for="c-39076159">[1 more]</label></div><br/><div class="children"><div class="content">The most basic right protected by copyright is the right to make copies.<p>Merely making a copy can definitely be infringement. &quot;Copies&quot; made in the computing context even simply between disk and RAM have been held to be infringement in some cases.<p>Fair use is the big question mark here, as it acts to allow various kinds of harmless&#x2F;acceptable&#x2F;desirable copying. For AI, it&#x27;s particularly relevant that there&#x27;s a factor of the &quot;transformative&quot; nature of a use that weighs in favor of fair use.</div><br/></div></div><div id="39073090" class="c"><input type="checkbox" id="c-39073090" checked=""/><div class="controls bullet"><span class="by">xigoi</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073075">parent</a><span>|</span><a href="#39076159">prev</a><span>|</span><a href="#39072964">next</a><span>|</span><label class="collapse" for="c-39073090">[-]</label><label class="expand" for="c-39073090">[1 more]</label></div><br/><div class="children"><div class="content">You can train a neural network in private too and nobody will have a problem with that. The topic of discussion is commercial AI.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39072964" class="c"><input type="checkbox" id="c-39072964" checked=""/><div class="controls bullet"><span class="by">huytersd</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071562">parent</a><span>|</span><a href="#39071646">prev</a><span>|</span><a href="#39071300">next</a><span>|</span><label class="collapse" for="c-39072964">[-]</label><label class="expand" for="c-39072964">[1 more]</label></div><br/><div class="children"><div class="content">If you are viewing the image on your browser on a website, you are making a local copy. That’s not unauthorized.</div><br/></div></div></div></div></div></div><div id="39071300" class="c"><input type="checkbox" id="c-39071300" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071072">parent</a><span>|</span><a href="#39071168">prev</a><span>|</span><a href="#39071223">next</a><span>|</span><label class="collapse" for="c-39071300">[-]</label><label class="expand" for="c-39071300">[2 more]</label></div><br/><div class="children"><div class="content">Companies aren&#x27;t someone, yet in the US we seem to give them rights of someone.</div><br/><div id="39071572" class="c"><input type="checkbox" id="c-39071572" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071300">parent</a><span>|</span><a href="#39071223">next</a><span>|</span><label class="collapse" for="c-39071572">[-]</label><label class="expand" for="c-39071572">[1 more]</label></div><br/><div class="children"><div class="content">They are someone in the eyes of the law. They just have a different set of rights.</div><br/></div></div></div></div></div></div></div></div><div id="39071223" class="c"><input type="checkbox" id="c-39071223" checked=""/><div class="controls bullet"><span class="by">michaelmrose</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068637">parent</a><span>|</span><a href="#39070849">prev</a><span>|</span><a href="#39076660">next</a><span>|</span><label class="collapse" for="c-39071223">[-]</label><label class="expand" for="c-39071223">[3 more]</label></div><br/><div class="children"><div class="content">What we actually need to prove is whether such technology is a net benefit to society all else is essentially hand waving. There is no natural right to poorly named intellectual property and even if there was such a matter would never be decided based on the outcome of a philosophical argument because we don&#x27;t decide anything that way.</div><br/><div id="39071352" class="c"><input type="checkbox" id="c-39071352" checked=""/><div class="controls bullet"><span class="by">tqi</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071223">parent</a><span>|</span><a href="#39071259">next</a><span>|</span><label class="collapse" for="c-39071352">[-]</label><label class="expand" for="c-39071352">[1 more]</label></div><br/><div class="children"><div class="content">How do you measure &quot;benefit&quot;, and what does &quot;net&quot; actually mean?</div><br/></div></div><div id="39071259" class="c"><input type="checkbox" id="c-39071259" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071223">parent</a><span>|</span><a href="#39071352">prev</a><span>|</span><a href="#39076660">next</a><span>|</span><label class="collapse" for="c-39071259">[-]</label><label class="expand" for="c-39071259">[1 more]</label></div><br/><div class="children"><div class="content">&gt; such technology is a net benefit to society all else is essentially hand waving<p>Some might have said this about cars ... yet, here we are. Cars are definitely the opposite, except for longer-distance travel.</div><br/></div></div></div></div></div></div><div id="39076660" class="c"><input type="checkbox" id="c-39076660" checked=""/><div class="controls bullet"><span class="by">eggdaft</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39068637">prev</a><span>|</span><a href="#39068764">next</a><span>|</span><label class="collapse" for="c-39076660">[-]</label><label class="expand" for="c-39076660">[1 more]</label></div><br/><div class="children"><div class="content">That is not how artists learn. This is a false equivalence used to justify the imitation and copying of artists’ work.
 Artists’ work isn’t derivative in the same way that AI work is. Artists create work based on other sources of inspiration, some of them almost or completely to the disregard of other art.<p>Many artists don’t even go to art school. And those that do, do not spend most (all) of that time learning how to copy or imitate other artists.<p>I’m not expressing an opinion of whether GenAI is unethical or illegal - I think that’s a really difficult issue to wrestle with - just that this argument is a post-hoc rationalisation made in ignorance of how good artists work (not to say ignorance of the difference between illustration and art, conceptual art training vs say a foundation course etc).</div><br/></div></div><div id="39068764" class="c"><input type="checkbox" id="c-39068764" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39076660">prev</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39068764">[-]</label><label class="expand" for="c-39068764">[41 more]</label></div><br/><div class="children"><div class="content">And? Even if neural networks learn the same way humans do, this is not an argument against taking measures against one&#x27;s art being used as training data, since there are different implications if a human learns to paint the same way as another human vs. if an AI learns to paint the same way as a human. If the two were <i>exactly</i> indistinguishable in their effects no one would care about AIs, not even researchers.</div><br/><div id="39071284" class="c"><input type="checkbox" id="c-39071284" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068764">parent</a><span>|</span><a href="#39068977">next</a><span>|</span><label class="collapse" for="c-39071284">[-]</label><label class="expand" for="c-39071284">[28 more]</label></div><br/><div class="children"><div class="content">And yet, some people don&#x27;t even want their artwork studied in schools. Even if you argue that an AI is &quot;human enough&quot; the artists should still have the right to refuse their art being studies.</div><br/><div id="39072692" class="c"><input type="checkbox" id="c-39072692" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071284">parent</a><span>|</span><a href="#39071524">next</a><span>|</span><label class="collapse" for="c-39072692">[-]</label><label class="expand" for="c-39072692">[8 more]</label></div><br/><div class="children"><div class="content">&gt;the artists should still have the right to refuse their art being studies.<p>No, that right doesn&#x27;t exist. If you put your work of art out there for people to see, people will see it and learn from it, and be inspired by it. It&#x27;s unavoidable. How could it possibly work otherwise?<p>Artist A: You studied my work to produce yours, even when I asked people not to do that!<p>Artist B: Prove it.<p>What kind of evidence or argument could Artist A possibly provide to show that Artist B did what they&#x27;re accusing them of, without being privy to the internal state of their mind. You&#x27;re not talking about plagiarism; that&#x27;s comparatively easy to prove. You&#x27;re asking about merely <i>studying</i> the work.</div><br/><div id="39072787" class="c"><input type="checkbox" id="c-39072787" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072692">parent</a><span>|</span><a href="#39071524">next</a><span>|</span><label class="collapse" for="c-39072787">[-]</label><label class="expand" for="c-39072787">[7 more]</label></div><br/><div class="children"><div class="content">The right to not use my things exists everywhere, universally. Good people usually ask before they use something of someone else&#x27;s, and the person being asked can say &quot;no.&quot; How hard is that to understand? You might believe they don&#x27;t have the right to say &quot;no,&quot; but they can say whatever they want.<p>Example:<p>If you studied my (we will assume &quot;unique&quot;) work and used it without my permission, then let us say I sue you. At that point, you would claim &quot;fair use,&quot; and the courts would decide whether it was fair use (ask everyone who used a mouse and got sued for it in the last ~100 years). The court would either agree that you used my works under &quot;fair use&quot; ... or not. It would be up to how you presented it to the court, and humans would analyze your intent and decide.<p>OR, I might agree it is fair use and not sue you. However, that weakens my standing on my copyright, so it&#x27;s better for me to sue you (assuming I have the resources to do so when it is clearly fair use).</div><br/><div id="39073028" class="c"><input type="checkbox" id="c-39073028" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072787">parent</a><span>|</span><a href="#39071524">next</a><span>|</span><label class="collapse" for="c-39073028">[-]</label><label class="expand" for="c-39073028">[6 more]</label></div><br/><div class="children"><div class="content">&gt;You might believe they don&#x27;t have the right to say &quot;no,&quot; but they can say whatever they want.<p>You have a right to say anything you want. Others aren&#x27;t obligated do as you say just because you say it.<p>&gt;If you studied my (we will assume &quot;unique&quot;) techniques and used them without my permission, then let us say I sue you. At that point, you would claim &quot;fair use,&quot;<p>On what grounds would you sue me? You think my defense would be &quot;fair use&quot;, so you must think my copying your style constitutes copyright infringement, and so you&#x27;d sue me for that. Well, no, I would not say &quot;fair use&quot;, I&#x27;d say &quot;artistic style is not copyrightable; copyright pertains to works, not to styles&quot;. There&#x27;s even jurisprudence backing me up in the US. Apple tried to use Microsoft for copying the look-and-feel of their OS, and it was ruled to be non-copyrightable. Even if was so good that I was able to trick anyone into thinking that my painting of a dog carrying a tennis ball in his mouth was your work, if you&#x27;ve never painted anything like that you would have no grounds to sue me for copyright infringement.<p>Now, usually in the artistic world it&#x27;s considered poor manners to outright <i>copy</i> another artist&#x27;s style, but if we&#x27;re talking about rights and law, I&#x27;m sorry to say you&#x27;re just wrong. And if we&#x27;re talking about merely <i>studying</i> someone&#x27;s work without copying it, that&#x27;s not even frowned upon. Like I said, it&#x27;s unavoidable. I don&#x27;t know where you got this idea that anyone has the right to or is even capable of preventing this (beyond simply never showing it to anyone).</div><br/><div id="39073102" class="c"><input type="checkbox" id="c-39073102" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073028">parent</a><span>|</span><a href="#39071524">next</a><span>|</span><label class="collapse" for="c-39073102">[-]</label><label class="expand" for="c-39073102">[5 more]</label></div><br/><div class="children"><div class="content">&gt; Others aren&#x27;t obligated do as you say just because you say it.<p>Yeah, that&#x27;s exactly why you&#x27;d get sued for copyright theft.<p>&gt; you must think my copying your style constitutes copyright infringement<p>Autocorrect screwed that wording up. I&#x27;ve fixed it.</div><br/><div id="39073250" class="c"><input type="checkbox" id="c-39073250" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073102">parent</a><span>|</span><a href="#39071524">next</a><span>|</span><label class="collapse" for="c-39073250">[-]</label><label class="expand" for="c-39073250">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure what you&#x27;ve changed, but I&#x27;ll reiterate: my copying your style is not fair use. Fair use applies to copyrighted things. A style cannot be copyrighted, so if you tried to sue me for infringing upon the copyright of your artistic style, your case would be dismissed. It would be as invalid as you trying to sue me for distributing illegal copies of someone else&#x27;s painting. Legally you have as much ownership of your artistic style as of that other person&#x27;s painting.</div><br/><div id="39073848" class="c"><input type="checkbox" id="c-39073848" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073250">parent</a><span>|</span><a href="#39071524">next</a><span>|</span><label class="collapse" for="c-39073848">[-]</label><label class="expand" for="c-39073848">[3 more]</label></div><br/><div class="children"><div class="content">Now, I just think you are arguing in bad faith. What I meant to say was clear, but I said &quot;technique&quot; instead. Then, instead of debating what I meant to say (you know, the actual point of the conversation), you took my words verbatim.<p>I&#x27;m not sure where you are going with this ... but for what it&#x27;s worth, techniques can be copyrighted ... even patented, or protected via trade secrets. I never said what the techniques were, and I&#x27;m not sure what you are going on about.<p>I&#x27;ll repeat this as well: &quot;Fair use&quot; DOES NOT EXIST unless you are getting sued. It&#x27;s a legal defense when you are accused of stealing someone else&#x27;s work, and there is proof you stole it. Even then, it isn&#x27;t something you DO; it&#x27;s something a court says YOU DID. Any time you use something with &quot;fair use&quot; in mind, it is the equivalent of saying, &quot;I&#x27;m going to steal this, and hopefully, a court agrees that this is fair use.&quot;<p>If you steal any copyrighted material, even when it is very clearly NOT fair use (such as in most AI&#x27;s case), you would be a blubbering idiot NOT to claim fair use in the hopes that someone will agree. There is a crap load of case law showing &quot;research for commercial purposes is not fair use,&quot; ... and guess who is selling access to the AI? If it&#x27;s actual research, it is &quot;free&quot; for humanity to use (or at least as inexpensive as possible) and not for profit. Sure, some of the companies might be non-profits doing research and &#x27;giving it away,&#x27; and those are probably using things fairly ... then there are other companies very clearly doing it for a profit (like a big software company going through code they host).</div><br/><div id="39074139" class="c"><input type="checkbox" id="c-39074139" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073848">parent</a><span>|</span><a href="#39075282">next</a><span>|</span><label class="collapse" for="c-39074139">[-]</label><label class="expand" for="c-39074139">[1 more]</label></div><br/><div class="children"><div class="content">&gt;What I meant to say was clear<p>I&#x27;m not privy to what goes on inside your head, I can only reply to what you say.<p>&gt;Then, instead of debating what I meant to say (you know, the actual point of the conversation), you took my words verbatim.<p>The actual point of the conversation is about intelligent entities (either natural or artificial) copying each other&#x27;s artistic styles. My answers have been within that framework.<p>&gt;techniques can be copyrighted ... even patented, or protected via trade secrets.<p>First, what do you mean by &quot;technique&quot;? We&#x27;re talking about art, right? Like, the way a person grabs a brush or pencil, or how they mix their colors...? That sort of thing?<p>Second:<p>&gt;A patent is a type of intellectual property that gives its owner the legal right to exclude others from making, using, or selling an invention for a limited period of time in exchange for publishing an enabling disclosure of the invention.<p>Now, I may be mistaken, but I don&#x27;t think an artistic technique counts as an invention. An artist might invent some kind of implement that their technique involves, in which case they can patent that device. I don&#x27;t think the technique itself is patentable. If you think I&#x27;m wrong then please cite a patent on an artistic technique.<p>Third, how do you imagine an artist using a trade secret to protect their technique? Unless they do something really out there, most skilled artists should be able to understand what they&#x27;re doing just by looking at the final product.<p>&gt;I&#x27;ll repeat this as well: &quot;Fair use&quot;<p>Okay, repeat it. I don&#x27;t know why, since I never said that copying someone else&#x27;s style or technique is fair use. What I said was that it cannot possibly be copyright infringement, because neither styles nor techniques are copyrighted.<p>&gt;It&#x27;s a legal defense when you are accused of stealing someone else&#x27;s work<p>I&#x27;m not going to reply to any of this until you clean up the language you&#x27;re using. &quot;Steal&quot; is inapplicable here, as it involves the removal of physical items from someone else&#x27;s possession. What are you saying? Are you talking about illegal distribution, are you talking about unauthorized adaptations, are you talking about plagiarism, or what?<p>&gt;&quot;research for commercial purposes is not fair use,&quot;<p>Sorry, what? What does that even mean? What constitutes &quot;research&quot; as applied to a human creation? If you say there&#x27;s a crapload of case law that backs this up then I&#x27;m forced to ask you to cite it, because I honestly have no idea what you&#x27;re saying.</div><br/></div></div><div id="39075282" class="c"><input type="checkbox" id="c-39075282" checked=""/><div class="controls bullet"><span class="by">chipotle_coyote</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073848">parent</a><span>|</span><a href="#39074139">prev</a><span>|</span><a href="#39071524">next</a><span>|</span><label class="collapse" for="c-39075282">[-]</label><label class="expand" for="c-39075282">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Any time you use something with &quot;fair use&quot; in mind, it is the equivalent of saying, &quot;I&#x27;m going to steal this, and hopefully, a court agrees that this is fair use.&quot;<p>Thousands of reviews, book reports, quotations on fan sites and so on are published daily; you seem to be arguing that they are all copyright violations unless and until the original copyright holder takes those reviewers, seventh graders, and Tumblr stans to court and loses, at which point they are now a-ok. To quote a meme in a way that I&#x27;m pretty sure does, in fact, fall under fair use: &quot;That&#x27;s not the way any of this works.&quot;<p>&gt; There is a crap load of case law showing &quot;research for commercial purposes is not fair use,&quot;<p>While you may be annoyed with the OP for asking you to name a bit of that case law, it isn&#x27;t an unreasonable demand. For instance:<p><a href="https:&#x2F;&#x2F;guides.nyu.edu&#x2F;fairuse#:~:text=As%20a%20general%20matter%2C%20educational,defeat%20a%20fair%20use%20claim" rel="nofollow">https:&#x2F;&#x2F;guides.nyu.edu&#x2F;fairuse#:~:text=As%20a%20general%20ma...</a>.<p>&quot;As a general matter, educational, nonprofit, and personal uses are favored as fair uses. Making a commercial use of a work typically weighs against fair use, but a commercial use does not automatically defeat a fair use claim. &#x27;Transformative&#x27; uses are also favored as fair uses. A use is considered to be transformative when it results in the creation of an entirely new work (as opposed to an adaptation of an existing work, which is merely derivative).&quot;<p>This is almost certainly going to be used by AI companies as part of their defense against such claims; &quot;transformative uses&quot; have literally been name-checked by courts. It&#x27;s also been established that commercial companies can ingest mountains of copyrighted material and still fall under the fair use doctrine -- this is what the whole Google Books case about a decade ago was about. Google won.<p>I feel like you&#x27;re trying to make a <i>moral</i> argument against generative AI, one that I largely agree with, but a moral argument is not a <i>legal</i> argument. If you want to make a <i>legal</i> argument against generative AI with respect to copyright violation and fair use, perhaps try something like:<p>- The NYT&#x27;s case against OpenAI involves being able to get ChatGPT to spit out large sections of NYT articles given prompts like &quot;here is the article&#x27;s URL and here is the first paragraph of the article; tell me what the rest of the text is&quot;. OpenAI and its defenders have argued that such prompts aren&#x27;t playing fair, but &quot;you have to put some effort into getting our product to commit clear copyright violation&quot; is a rather thin defense.<p>- A crucial test of fair use is &quot;the effect of the use upon the potential market for or value of the copyrighted work&quot; (quoting directly from the relevant law). If an image generator can be told to do new artwork in a specific artist&#x27;s style, <i>and</i> it can do a credible job of doing so, <i>and</i> it can be reasonably established that the training model included work from the named artist, then the argument the generator is damaging the market for that artist&#x27;s work seems quite compelling.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39071524" class="c"><input type="checkbox" id="c-39071524" checked=""/><div class="controls bullet"><span class="by">dehrmann</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071284">parent</a><span>|</span><a href="#39072692">prev</a><span>|</span><a href="#39071345">next</a><span>|</span><label class="collapse" for="c-39071524">[-]</label><label class="expand" for="c-39071524">[14 more]</label></div><br/><div class="children"><div class="content">&gt; And yet, some people don&#x27;t even want their artwork studied in schools.<p>You can either make it for yourself and keep it for yourself or you can put it out into the world for all to see, criticize, study, imitate, and admire.</div><br/><div id="39071627" class="c"><input type="checkbox" id="c-39071627" checked=""/><div class="controls bullet"><span class="by">Barrin92</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071524">parent</a><span>|</span><a href="#39071345">next</a><span>|</span><label class="collapse" for="c-39071627">[-]</label><label class="expand" for="c-39071627">[13 more]</label></div><br/><div class="children"><div class="content">that&#x27;s not how licensing work, be it art, software or just about anything else. We have some pretty well defined and differentiated rules what you can and cannot do, in particular commercially or in public, with someone else&#x27;s work. If you go and study a work of fiction in a college class, unless that material is in the public domain, you&#x27;re gonna have to pay for your copy, you want to broadcast a movie in public, you&#x27;re going to have to pay the rightsholder.</div><br/><div id="39071758" class="c"><input type="checkbox" id="c-39071758" checked=""/><div class="controls bullet"><span class="by">dehrmann</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071627">parent</a><span>|</span><a href="#39071751">next</a><span>|</span><label class="collapse" for="c-39071758">[-]</label><label class="expand" for="c-39071758">[7 more]</label></div><br/><div class="children"><div class="content">Right, but there&#x27;s also fair use, and every use I mentioned could plausibly fall under that.</div><br/><div id="39071843" class="c"><input type="checkbox" id="c-39071843" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071758">parent</a><span>|</span><a href="#39071751">next</a><span>|</span><label class="collapse" for="c-39071843">[-]</label><label class="expand" for="c-39071843">[6 more]</label></div><br/><div class="children"><div class="content">There&#x27;s no such thing as fair use until you get to court (as a legal defense). Then, the court decides whether it is fair use or not. They may or may not agree with you. Only a court can determine what constitutes fair use (at least in the US).<p>So, if you are doing something and asserting &quot;fair use,&quot; you are literally asking for someone to challenge you and prove it is not fair use.</div><br/><div id="39071967" class="c"><input type="checkbox" id="c-39071967" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071843">parent</a><span>|</span><a href="#39071751">next</a><span>|</span><label class="collapse" for="c-39071967">[-]</label><label class="expand" for="c-39071967">[5 more]</label></div><br/><div class="children"><div class="content">&gt; There&#x27;s no such thing as fair use until you get to court (as a legal defense)<p>Well the point is that it wouldn&#x27;t go to court, as it would be completely legal.<p>So yes, if nobody sues you, then you are completely in the clear and aren&#x27;t in trouble.<p>Thats what people mean by fair use.  They mean that nobody is going to sue you, because the other person would lose the lawsuit, therefore your actions are safe and legal.<p>&gt; you are literally asking for someone to challenge you and prove it is not fair use.<p>No, instead of that, the most likely circumstance is that nobody sues you, and you aren&#x27;t in trouble at all, and therefore you did nothing wrong and are safe.</div><br/><div id="39072477" class="c"><input type="checkbox" id="c-39072477" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071967">parent</a><span>|</span><a href="#39071751">next</a><span>|</span><label class="collapse" for="c-39072477">[-]</label><label class="expand" for="c-39072477">[4 more]</label></div><br/><div class="children"><div class="content">&gt; as it would be completely legal.<p>Theft is never legal; that&#x27;s why you can be sued. &quot;Fair use&quot; is a legal defense in the theft of copyrighted works.<p>&gt; They mean that nobody is going to sue you, because the other person would lose the lawsuit<p>That hasn&#x27;t stopped people from suing anyone ever. If they want to sue you, they&#x27;ll sue you.<p>&gt; and therefore you did nothing wrong and are safe.<p>If you steal a pen from a store, it&#x27;s still theft even if nobody catches you; or cares.</div><br/><div id="39072673" class="c"><input type="checkbox" id="c-39072673" checked=""/><div class="controls bullet"><span class="by">sgift</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072477">parent</a><span>|</span><a href="#39075188">next</a><span>|</span><label class="collapse" for="c-39072673">[-]</label><label class="expand" for="c-39072673">[2 more]</label></div><br/><div class="children"><div class="content">&gt; Theft is never legal; that&#x27;s why you can be sued.<p>That&#x27;s incorrect. You can be sued for anything. If it <i>is</i> theft or something else or nothing is decided by the courts.</div><br/><div id="39072814" class="c"><input type="checkbox" id="c-39072814" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072673">parent</a><span>|</span><a href="#39075188">next</a><span>|</span><label class="collapse" for="c-39072814">[-]</label><label class="expand" for="c-39072814">[1 more]</label></div><br/><div class="children"><div class="content">That is entirely my point. It can only be decided by the courts. This being a civil matter, it has to be brought up by a lawsuit. Thus, you have to be sued and it has to be decided by the courts.</div><br/></div></div></div></div><div id="39075188" class="c"><input type="checkbox" id="c-39075188" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072477">parent</a><span>|</span><a href="#39072673">prev</a><span>|</span><a href="#39071751">next</a><span>|</span><label class="collapse" for="c-39075188">[-]</label><label class="expand" for="c-39075188">[1 more]</label></div><br/><div class="children"><div class="content">&gt; If you steal a pen from a store<p>Fortunately I am not talking about someone illegally taking property from someone else.<p>Instead I am talking about people taking completely legal actions that are protected by law.<p>&gt;  in the theft of copyrighted works<p>Actually, it wouldn&#x27;t be theft if it was done in fair use.  Instead it would be completely legal.<p>If nobody sues you and proves that it was illegal then you are completely safe, if you did this in fair use.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39071751" class="c"><input type="checkbox" id="c-39071751" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071627">parent</a><span>|</span><a href="#39071758">prev</a><span>|</span><a href="#39071345">next</a><span>|</span><label class="collapse" for="c-39071751">[-]</label><label class="expand" for="c-39071751">[5 more]</label></div><br/><div class="children"><div class="content">&gt; If you go and study a work of fiction in a college class, unless that material is in the public domain, you&#x27;re gonna have to pay for your copy,<p>No you wont!<p>It is only someone who distributes copies who can get in trouble.<p>If instead of that you as an individual decide to study a piece of art or fiction, and you do no distribute copies of it to anyone, this is completely legal and you don&#x27;t have to pay anyone for it.<p>In addition to that, fair use protections apply regardless of what the creative works creator wants.</div><br/><div id="39071863" class="c"><input type="checkbox" id="c-39071863" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071751">parent</a><span>|</span><a href="#39071345">next</a><span>|</span><label class="collapse" for="c-39071863">[-]</label><label class="expand" for="c-39071863">[4 more]</label></div><br/><div class="children"><div class="content">Making a profit off variations of someone&#x27;s work isn&#x27;t covered under fair use.</div><br/><div id="39073858" class="c"><input type="checkbox" id="c-39073858" checked=""/><div class="controls bullet"><span class="by">boolemancer</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071863">parent</a><span>|</span><a href="#39071946">next</a><span>|</span><label class="collapse" for="c-39073858">[-]</label><label class="expand" for="c-39073858">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s not a fair statement to make. It can influence a judge&#x27;s decision on whether something is fair use, but it can still be fair use even if you profit from it.</div><br/></div></div><div id="39071946" class="c"><input type="checkbox" id="c-39071946" checked=""/><div class="controls bullet"><span class="by">stale2002</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071863">parent</a><span>|</span><a href="#39073858">prev</a><span>|</span><a href="#39071345">next</a><span>|</span><label class="collapse" for="c-39071946">[-]</label><label class="expand" for="c-39071946">[2 more]</label></div><br/><div class="children"><div class="content">Gotcha.<p>I wasn&#x27;t talking about someone creating and selling copies of someone else&#x27;s work, fortunately.<p>So my point stands and your completely is in agreement with me that people are allowed to learn from other people&#x27;s works.  If someone wants to learn from someone else&#x27;s work, that is completely legal no matter the licensing terms.<p>Instead, it is only distributing copies that is not allowed.</div><br/><div id="39072538" class="c"><input type="checkbox" id="c-39072538" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071946">parent</a><span>|</span><a href="#39071345">next</a><span>|</span><label class="collapse" for="c-39072538">[-]</label><label class="expand" for="c-39072538">[1 more]</label></div><br/><div class="children"><div class="content">AI isn&#x27;t a human. It isn&#x27;t &quot;learning&quot;; instead, it&#x27;s encoding data so that it may be reproduced in combination with other things it has encoded.<p>If I paint a painting in the style of Monet, then I would give that person attribution by stating that.  Monet may have never painted my artwork, but it&#x27;s still based on that person&#x27;s work. If I paint anything, I can usually point to everything that inspired me to do so. AI can&#x27;t do that (yet) and thus has no idea what it is doing. It is a printer that prints random parts of people&#x27;s works with no attribution. And finally, it is distributing them to it&#x27;s owner&#x27;s customers.<p>I actually hope that true AI comes to fruition at some point; when that happens I would be arguing the exact opposite. We don&#x27;t have that yet, so this is just literally printing variations of other people&#x27;s work. Don&#x27;t believe me, try running an AI without training it on other people&#x27;s work!</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39071345" class="c"><input type="checkbox" id="c-39071345" checked=""/><div class="controls bullet"><span class="by">deeviant</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071284">parent</a><span>|</span><a href="#39071524">prev</a><span>|</span><a href="#39068977">next</a><span>|</span><label class="collapse" for="c-39071345">[-]</label><label class="expand" for="c-39071345">[5 more]</label></div><br/><div class="children"><div class="content">&gt;  the artists should still have the right to refuse their art being studies.<p>Why? That certainly isn&#x27;t a right spelled out in either patents or copyrights, both of which are supposed to <i>support</i> the development of arts and technology, not hinder it.<p>If I discover a new mathematical formula, musical scale, or whatnot, should I be able to prevent others from learning about it?</div><br/><div id="39071397" class="c"><input type="checkbox" id="c-39071397" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071345">parent</a><span>|</span><a href="#39068977">next</a><span>|</span><label class="collapse" for="c-39071397">[-]</label><label class="expand" for="c-39071397">[4 more]</label></div><br/><div class="children"><div class="content">It’s called a license and you can make it almost anything. It doesn’t even need to be spelled out, it can be verbal: “no, I won’t let you have it”<p>It’s yours. That’s literally what copyright is there to enforce.</div><br/><div id="39072565" class="c"><input type="checkbox" id="c-39072565" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071397">parent</a><span>|</span><a href="#39073905">next</a><span>|</span><label class="collapse" for="c-39072565">[-]</label><label class="expand" for="c-39072565">[2 more]</label></div><br/><div class="children"><div class="content">License doesn&#x27;t matter if fair use applies.<p>&gt; Fair use allows reproduction and other uses of copyrighted works – without requiring permission from the copyright owner – under certain conditions. In many cases, you can use copyrighted materials for purposes such as criticism, comment, news reporting, teaching (including multiple copies for classroom use), scholarship or research.<p>Reminder that you can&#x27;t own ideas, no matter what the law says.<p>NOTE: This comment is copyrighted and provided to you under license only. By reading this comment, you agree to give me 5 billion dollars.</div><br/><div id="39072629" class="c"><input type="checkbox" id="c-39072629" checked=""/><div class="controls bullet"><span class="by">withinboredom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072565">parent</a><span>|</span><a href="#39073905">next</a><span>|</span><label class="collapse" for="c-39072629">[-]</label><label class="expand" for="c-39072629">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;d love to see you try to enforce that license because it would only prove my point. You&#x27;d have to sue me; then I would point to the terms of service of this platform and point out that by using it, you have no license here.<p>Fair use though, only applies as a legal defense because someone asserts you stole their work. Then ONLY the court decides whether or not you used it under fair use. You don&#x27;t get to make that decision; you just get to decide whether to try and use it as a defense.<p>Even if you actually did unfairly use copyrighted works, you would be stupid not to use that as a defense. Because maybe somebody on the jury agrees with you...</div><br/></div></div></div></div><div id="39073905" class="c"><input type="checkbox" id="c-39073905" checked=""/><div class="controls bullet"><span class="by">boolemancer</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071397">parent</a><span>|</span><a href="#39072565">prev</a><span>|</span><a href="#39068977">next</a><span>|</span><label class="collapse" for="c-39073905">[-]</label><label class="expand" for="c-39073905">[1 more]</label></div><br/><div class="children"><div class="content">Copyright is there to allow you to stop other people from copying your work, but it doesn&#x27;t give you control over anything else that they might do with it.<p>If I buy your painting, you can stop me from making copies and selling them to other people, but you can&#x27;t stop me from selling my original copy to whomever I want, nor could you stop me from painting little dinosaurs all over it and hanging it in my hallway.<p>That means that if I buy your painting, I&#x27;m also free to study it and learn from it in whichever way I please. Studying something is not copying it.</div><br/></div></div></div></div></div></div></div></div><div id="39068977" class="c"><input type="checkbox" id="c-39068977" checked=""/><div class="controls bullet"><span class="by">MichaelZuo</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068764">parent</a><span>|</span><a href="#39071284">prev</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39068977">[-]</label><label class="expand" for="c-39068977">[12 more]</label></div><br/><div class="children"><div class="content">But the &#x27;different implications&#x27; only exist in the heads of said artists?<p>EDIT: removed a part.</div><br/><div id="39069049" class="c"><input type="checkbox" id="c-39069049" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068977">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39069049">[-]</label><label class="expand" for="c-39069049">[11 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure what you mean when you say different implications existing is subjective, since they clearly aren&#x27;t, but regardless of who has more say in general terms, the author of a work can decide how to publish it, and no one has more say than them on that subject.</div><br/><div id="39070387" class="c"><input type="checkbox" id="c-39070387" checked=""/><div class="controls bullet"><span class="by">MichaelZuo</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39069049">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39070387">[-]</label><label class="expand" for="c-39070387">[10 more]</label></div><br/><div class="children"><div class="content">What are you saying?<p>Of course it&#x27;s subjective, e.g. 3 million years ago there were no &#x27;different implications&#x27; whatsoever, of any kind, because there were no humans around to have thoughts like that.</div><br/><div id="39070565" class="c"><input type="checkbox" id="c-39070565" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070387">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39070565">[-]</label><label class="expand" for="c-39070565">[9 more]</label></div><br/><div class="children"><div class="content">I&#x27;m using &quot;implication&quot; as a synonym of &quot;effect&quot;. If a human learns to imitate your style, that human can make at most a handful of drawings in a single day. The only way for the rate of output to increase is for more humans to learn to imitate it. If an AI learns to imitate your style, the AI can be trivially copied to any number of computers and the maximum output rate is unbounded. Whether this is good or bad is subjective, but this difference in consequences is objective, and someone could be entirely justified in seeking to impede it.</div><br/><div id="39071268" class="c"><input type="checkbox" id="c-39071268" checked=""/><div class="controls bullet"><span class="by">MichaelZuo</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070565">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39071268">[-]</label><label class="expand" for="c-39071268">[8 more]</label></div><br/><div class="children"><div class="content">Ah okay, I get your meaning now, I&#x27;ll edit my original comment too.<p>Though we already have an established precedent in-between, that of Photoshop allowing artists to be, easily, 10x faster then the best painters previously.<p>i.e. Right now &#x27;AI&#x27; artistry could be considered a turbo-Photoshop.</div><br/><div id="39071504" class="c"><input type="checkbox" id="c-39071504" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071268">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39071504">[-]</label><label class="expand" for="c-39071504">[7 more]</label></div><br/><div class="children"><div class="content">Tool improvements only apply a constant factor to the effectiveness of learning. Creating a generative model applies an <i>unbounded</i> factor to the effectiveness of learning because, as I said, the only limit is how much computing resources are available to humanity. If a single person was able to copy themselves at practically no cost and the copy retained all the knowledge of the original then the two situations would be equivalent, but that&#x27;s impossible. Having n people with the same skill multiplies the cost of learning by n. Having n instances of an AI with the same skill multiplies the cost of learning by 1.</div><br/><div id="39072100" class="c"><input type="checkbox" id="c-39072100" checked=""/><div class="controls bullet"><span class="by">MichaelZuo</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071504">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39072100">[-]</label><label class="expand" for="c-39072100">[6 more]</label></div><br/><div class="children"><div class="content">Right, but the &#x27;unbounded factor&#x27; is irrelevant because the output will quickly trend into random noise.<p>And only the most interesting top few million art pieces will actually attract the attention of any concrete individual.<p>For a current example, there&#x27;s already billions of man-hours worth of AI spam writing, indexed by Google, that is likely not actually read by even a single person on Earth.</div><br/><div id="39072631" class="c"><input type="checkbox" id="c-39072631" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072100">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39072631">[-]</label><label class="expand" for="c-39072631">[5 more]</label></div><br/><div class="children"><div class="content">Whether it&#x27;s irrelevant is a matter of opinion. The fact remains that a machine being able to copy the artistic style of a human makes it so that anyone can produce output in the style of that human by just feeding the machine electricity. That inherently devalues the style the artist has painstakingly developed. If someone wants a piece of art in that artist&#x27;s style they don&#x27;t have to go to that artist, they just need to request the machine for what they want. Is the machine&#x27;s output of low quality? Maybe. Will there be people for whom that low quality still makes them want to seek out the human? No doubt. It doesn&#x27;t change the fact that the style is still devalued, nor that there exist artists who would want to prevent that.</div><br/><div id="39073190" class="c"><input type="checkbox" id="c-39073190" checked=""/><div class="controls bullet"><span class="by">MichaelZuo</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072631">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39073190">[-]</label><label class="expand" for="c-39073190">[4 more]</label></div><br/><div class="children"><div class="content">&gt; Whether it&#x27;s irrelevant is a matter of opinion.<p>It&#x27;s just as much of an opinion, or as &#x27;objective&#x27;, as your prior statements.<p>Your going to have to face up to the fact that just saying something is &#x27;objective&#x27; doesn&#x27;t necessarily mean all 8 billion people will agree that it is so.</div><br/><div id="39073466" class="c"><input type="checkbox" id="c-39073466" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073190">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39073466">[-]</label><label class="expand" for="c-39073466">[3 more]</label></div><br/><div class="children"><div class="content">Yes, someone can disagree on whether a fact is true. That&#x27;s obviously true, but it has no effect on the truth of that fact.<p>I&#x27;m saying something very simple: If a machine can copy your style, that&#x27;s a fundamentally different situation than if a human can copy your style, and it has utterly different consequences. You can disagree with my statement, or say that whether it&#x27;s fundamentally different is subjective, or you can even say &quot;nuh-uh&quot;. But it seems kind of pointless to me. Why are you here commenting if you&#x27;re not going to engage intellectually with other people, and are simply going to resort to a childish game of contradiction?</div><br/><div id="39074123" class="c"><input type="checkbox" id="c-39074123" checked=""/><div class="controls bullet"><span class="by">MichaelZuo</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073466">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39074123">[-]</label><label class="expand" for="c-39074123">[2 more]</label></div><br/><div class="children"><div class="content">&gt; For a current example, there&#x27;s already billions of man-hours worth of AI spam writing, indexed by Google, that is likely not actually read by even a single person on Earth.<p>Continuing to ignore this point won&#x27;t make the prior comments seem any more persuasive, in fact probably less.<p>So here&#x27;s another chance to engage productively instead of just declaring things to be true or false, &#x27;objective&#x27;, etc., with only the strength of a pseudonymous HN account&#x27;s opinion behind it.<p>Try to actually convince readers with solid arguments instead.</div><br/><div id="39074259" class="c"><input type="checkbox" id="c-39074259" checked=""/><div class="controls bullet"><span class="by">deadbeeves</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39074123">parent</a><span>|</span><a href="#39069027">next</a><span>|</span><label class="collapse" for="c-39074259">[-]</label><label class="expand" for="c-39074259">[1 more]</label></div><br/><div class="children"><div class="content">I believe I&#x27;ve already addressed it.<p>You say: The fact that production in style S (of artist A) can exceed human consumption capability makes the fact that someone&#x27;s style can be reproduced without bounds irrelevant. You mention as an example all the AI-generated garbage text that no human will ever read.<p>I say: Whether it&#x27;s irrelevant is subjective, but that production in style S is arbitrarily higher with an AI that&#x27;s able to imitate it than with only humans that are able to imitate it objective, and an artist can (subjectively) not like this and seek to frustrate training efforts.<p>You say: It&#x27;s all subjective.<p>As far as I can tell, we&#x27;re at an impasse. If we can&#x27;t agree on what the facts are (in this case, that AI can copy an artist&#x27;s style in an incomparably higher volume than humans ever could) we can&#x27;t discuss the topic.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39069027" class="c"><input type="checkbox" id="c-39069027" checked=""/><div class="controls bullet"><span class="by">dorkwood</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39068764">prev</a><span>|</span><a href="#39071143">next</a><span>|</span><label class="collapse" for="c-39069027">[-]</label><label class="expand" for="c-39069027">[8 more]</label></div><br/><div class="children"><div class="content">Is it strange to you that cars and pedestrians are both subject to different rules? They both utilise friction and gravity to travel along the ground. I&#x27;m curious if you see a difference between them, and if you could describe what it is.</div><br/><div id="39071000" class="c"><input type="checkbox" id="c-39071000" checked=""/><div class="controls bullet"><span class="by">ta8645</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39069027">parent</a><span>|</span><a href="#39071143">next</a><span>|</span><label class="collapse" for="c-39071000">[-]</label><label class="expand" for="c-39071000">[7 more]</label></div><br/><div class="children"><div class="content">Both cars and pedestrians can be videotaped in public, without asking for their explicit permission.  That video can be manipulated by a computer to produce an artwork that is then put on public display.  No compensation need be offered to anyone.</div><br/><div id="39071252" class="c"><input type="checkbox" id="c-39071252" checked=""/><div class="controls bullet"><span class="by">estebank</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071000">parent</a><span>|</span><a href="#39071143">next</a><span>|</span><label class="collapse" for="c-39071252">[-]</label><label class="expand" for="c-39071252">[6 more]</label></div><br/><div class="children"><div class="content">&gt; Both cars and pedestrians can be videotaped in public, without asking for their explicit permission.<p>This is not universally true. Legislation is different from place to place.</div><br/><div id="39071486" class="c"><input type="checkbox" id="c-39071486" checked=""/><div class="controls bullet"><span class="by">ta8645</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071252">parent</a><span>|</span><a href="#39071143">next</a><span>|</span><label class="collapse" for="c-39071486">[-]</label><label class="expand" for="c-39071486">[5 more]</label></div><br/><div class="children"><div class="content">Hardly the point.  The same can be said for road rules between vehicles and pedestrians, for example in major Indian cities, it&#x27;s pretty much a free-for-all.</div><br/><div id="39071591" class="c"><input type="checkbox" id="c-39071591" checked=""/><div class="controls bullet"><span class="by">estebank</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071486">parent</a><span>|</span><a href="#39071143">next</a><span>|</span><label class="collapse" for="c-39071591">[-]</label><label class="expand" for="c-39071591">[4 more]</label></div><br/><div class="children"><div class="content">My point is that in a lot of places in the US you can point a video camera at the street and record. In Germany, you can&#x27;t. The law in some locales makes a distinction between manual recording (writing or drawing your surroundings) and mechanized recording (photographing or filming). Scalability of an action is taken into consideration on whether something is ok to do or not.</div><br/><div id="39071667" class="c"><input type="checkbox" id="c-39071667" checked=""/><div class="controls bullet"><span class="by">ta8645</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071591">parent</a><span>|</span><a href="#39071143">next</a><span>|</span><label class="collapse" for="c-39071667">[-]</label><label class="expand" for="c-39071667">[3 more]</label></div><br/><div class="children"><div class="content">That has no bearing at all on the issue at hand.  The same can be said of the original argument that started this thread.</div><br/><div id="39073107" class="c"><input type="checkbox" id="c-39073107" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071667">parent</a><span>|</span><a href="#39071143">next</a><span>|</span><label class="collapse" for="c-39073107">[-]</label><label class="expand" for="c-39073107">[2 more]</label></div><br/><div class="children"><div class="content">You think scalability isn&#x27;t relevant to the difference between a person doing something by hand or with software operating on the entire internet?</div><br/><div id="39073791" class="c"><input type="checkbox" id="c-39073791" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073107">parent</a><span>|</span><a href="#39071143">next</a><span>|</span><label class="collapse" for="c-39073791">[-]</label><label class="expand" for="c-39073791">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, that&#x27;s the oddest part of many of the pro-AI arguments. They want to anthromopotize the idea of learning but also clearly understand that the scalability of a bot exceeds that of a human.<p>They also don&#x27;t seem to have much experience in the artist world. An artist usually can&#x27;t reproduce a picture from memory, and if they can they are subject to copyright infringement depending on what and how they depict it, even if the image isn&#x27;t a complete copy. By this logic of &quot;bots are humans&quot; a bot should be subject if they make a Not-legally-disctinct-enough talking mouse</div><br/></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div id="39071143" class="c"><input type="checkbox" id="c-39071143" checked=""/><div class="controls bullet"><span class="by">schmichael</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39069027">prev</a><span>|</span><a href="#39072679">next</a><span>|</span><label class="collapse" for="c-39071143">[-]</label><label class="expand" for="c-39071143">[2 more]</label></div><br/><div class="children"><div class="content">This is not one artist inspiring another. This is all artists providing their work for free to immensely capitalized corporations for the corporations sole profit.<p>People keep making metaphors as if the AI is an entity in this transaction: it’s not! The AI is only the mechanism by which corporations launder IP.</div><br/><div id="39073135" class="c"><input type="checkbox" id="c-39073135" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071143">parent</a><span>|</span><a href="#39072679">next</a><span>|</span><label class="collapse" for="c-39073135">[-]</label><label class="expand" for="c-39073135">[1 more]</label></div><br/><div class="children"><div class="content">&gt;This is all artists providing their work for free to immensely capitalized corporations for the corporations sole profit.<p>No, the artists would be within their rights to do that if they chose to. This is corporations taking all the work of all artists regardless of the terms under which it was provided.</div><br/></div></div></div></div><div id="39072679" class="c"><input type="checkbox" id="c-39072679" checked=""/><div class="controls bullet"><span class="by">bradleyishungry</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39071143">prev</a><span>|</span><a href="#39069673">next</a><span>|</span><label class="collapse" for="c-39072679">[-]</label><label class="expand" for="c-39072679">[1 more]</label></div><br/><div class="children"><div class="content">This is such a nothing argument. Yes, new artists are inspired by other artists and sometimes make art similar to others, but a huge part of learning and doing art is to find a unique style.<p>But that’s not even the important part of the argument. A lot of artists work for commission, and are hired for their style. If an AI can be trained without explicit permission from their images, they lose work because a user can just prompt “in the style of”.<p>There’s no real great solution, outside of law, because the possibility of doing that is already here. But I’ve seen this argument so much and it’s just low effort</div><br/></div></div><div id="39069673" class="c"><input type="checkbox" id="c-39069673" checked=""/><div class="controls bullet"><span class="by">adr1an</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39072679">prev</a><span>|</span><a href="#39068258">next</a><span>|</span><label class="collapse" for="c-39069673">[-]</label><label class="expand" for="c-39069673">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s not the learning per se what&#x27;s concerning here but the ease of production (e.g. generate thousands of images in a day)</div><br/></div></div><div id="39068258" class="c"><input type="checkbox" id="c-39068258" checked=""/><div class="controls bullet"><span class="by">visarga</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39069673">prev</a><span>|</span><a href="#39073529">next</a><span>|</span><label class="collapse" for="c-39068258">[-]</label><label class="expand" for="c-39068258">[4 more]</label></div><br/><div class="children"><div class="content">AI is just a tool in someone&#x27;s hand, there&#x27;s a human who intends something</div><br/><div id="39070882" class="c"><input type="checkbox" id="c-39070882" checked=""/><div class="controls bullet"><span class="by">ta8645</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068258">parent</a><span>|</span><a href="#39073529">next</a><span>|</span><label class="collapse" for="c-39070882">[-]</label><label class="expand" for="c-39070882">[3 more]</label></div><br/><div class="children"><div class="content">If that&#x27;s true, then it should be fine for that human to paint with the brush of his AI tool.  Why should that human artist be restricted in the types of tools he uses to create his artwork?</div><br/><div id="39073341" class="c"><input type="checkbox" id="c-39073341" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070882">parent</a><span>|</span><a href="#39073529">next</a><span>|</span><label class="collapse" for="c-39073341">[-]</label><label class="expand" for="c-39073341">[2 more]</label></div><br/><div class="children"><div class="content">Should I be restricted in using copy paste as my tool for creating art?</div><br/><div id="39074120" class="c"><input type="checkbox" id="c-39074120" checked=""/><div class="controls bullet"><span class="by">ta8645</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073341">parent</a><span>|</span><a href="#39073529">next</a><span>|</span><label class="collapse" for="c-39074120">[-]</label><label class="expand" for="c-39074120">[1 more]</label></div><br/><div class="children"><div class="content">No you should not.  You should be able to use any tool you want.<p>If you produce a work that is too much of a copy from the original, you might be liable to a copyright claim.. but the act of copy and paste should not be prohibited in the generation of something new.<p>This is done all the time by artists.. who perhaps create an artwork by copy and pasting advertisements out of a womans magazine to create an image of a womans face made only of those clipping.  Making a statement about identity creation from corporate media...   we should not put restrictions on such art work.<p>Here&#x27;s just one example of an artist using copy-n-paste of content they don&#x27;t own to create something new:<p><a href="https:&#x2F;&#x2F;torontolife.com&#x2F;culture&#x2F;this-artist-creates-one-of-a-kind-celebrity-portraits-from-maps-news-clippings-and-pages-of-books&#x2F;" rel="nofollow">https:&#x2F;&#x2F;torontolife.com&#x2F;culture&#x2F;this-artist-creates-one-of-a...</a></div><br/></div></div></div></div></div></div></div></div><div id="39073529" class="c"><input type="checkbox" id="c-39073529" checked=""/><div class="controls bullet"><span class="by">password54321</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39068258">prev</a><span>|</span><a href="#39071108">next</a><span>|</span><label class="collapse" for="c-39073529">[-]</label><label class="expand" for="c-39073529">[1 more]</label></div><br/><div class="children"><div class="content">It is only natural to see a moral difference between people going to school and learn from your art because they are passionate about it, versus someone on the internet just scraping as many images as possible and automating the learning process.</div><br/></div></div><div id="39071108" class="c"><input type="checkbox" id="c-39071108" checked=""/><div class="controls bullet"><span class="by">amelius</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39073529">prev</a><span>|</span><a href="#39068555">next</a><span>|</span><label class="collapse" for="c-39071108">[-]</label><label class="expand" for="c-39071108">[1 more]</label></div><br/><div class="children"><div class="content">You might as well compare a Xerox copier to a human.</div><br/></div></div><div id="39068555" class="c"><input type="checkbox" id="c-39068555" checked=""/><div class="controls bullet"><span class="by">ozten</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39071108">prev</a><span>|</span><a href="#39071773">next</a><span>|</span><label class="collapse" for="c-39068555">[-]</label><label class="expand" for="c-39068555">[4 more]</label></div><br/><div class="children"><div class="content">The memetic weapons humans unleashed on other humans at art school to deter copying are brutal. Just wait until critique.</div><br/><div id="39068624" class="c"><input type="checkbox" id="c-39068624" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068555">parent</a><span>|</span><a href="#39071773">next</a><span>|</span><label class="collapse" for="c-39068624">[-]</label><label class="expand" for="c-39068624">[3 more]</label></div><br/><div class="children"><div class="content">&quot;Sorry, this is not art, is AI generated trash.&quot;</div><br/><div id="39074782" class="c"><input type="checkbox" id="c-39074782" checked=""/><div class="controls bullet"><span class="by">HKH2</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068624">parent</a><span>|</span><a href="#39071773">next</a><span>|</span><label class="collapse" for="c-39074782">[-]</label><label class="expand" for="c-39074782">[2 more]</label></div><br/><div class="children"><div class="content">Who cares? With AI, you don&#x27;t need art school. AI is making humanities redundant, and people are too proud to admit it.<p>I can&#x27;t believe how many people are not in awe of the possibilities of AI art, so it&#x27;s great to see AI disturbing the cynics until they learn. Not everything is political, but I&#x27;ll let them have this one.</div><br/><div id="39075926" class="c"><input type="checkbox" id="c-39075926" checked=""/><div class="controls bullet"><span class="by">squidsoup</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39074782">parent</a><span>|</span><a href="#39071773">next</a><span>|</span><label class="collapse" for="c-39075926">[-]</label><label class="expand" for="c-39075926">[1 more]</label></div><br/><div class="children"><div class="content">&gt; With AI, you don&#x27;t need art school. AI is making humanities redundant, and people are too proud to admit it.<p>If you think this is true, you&#x27;ve never understood art. Art is a human endeavour fundamentally. What ML produces is not art.</div><br/></div></div></div></div></div></div></div></div><div id="39071773" class="c"><input type="checkbox" id="c-39071773" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39068555">prev</a><span>|</span><a href="#39070904">next</a><span>|</span><label class="collapse" for="c-39071773">[-]</label><label class="expand" for="c-39071773">[1 more]</label></div><br/><div class="children"><div class="content">Human learning =&#x2F;= machine learning<p>Most artists are happy to see more people getting into art and joining the community. More artists means the skills of this culture get passed down to the next generation.<p>Obviously a billion dollar corporation using their work to create an industrial tool designed to displace them is very different.</div><br/></div></div><div id="39070904" class="c"><input type="checkbox" id="c-39070904" checked=""/><div class="controls bullet"><span class="by">analog31</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39071773">prev</a><span>|</span><a href="#39069093">next</a><span>|</span><label class="collapse" for="c-39070904">[-]</label><label class="expand" for="c-39070904">[2 more]</label></div><br/><div class="children"><div class="content">This seems more like looking at other artists and being totally incapacitated by some little touch in the painting you&#x27;re looking at.</div><br/><div id="39072098" class="c"><input type="checkbox" id="c-39072098" checked=""/><div class="controls bullet"><span class="by">adhesive_wombat</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070904">parent</a><span>|</span><a href="#39069093">next</a><span>|</span><label class="collapse" for="c-39072098">[-]</label><label class="expand" for="c-39072098">[1 more]</label></div><br/><div class="children"><div class="content">The Nam-shub of Hockney?</div><br/></div></div></div></div><div id="39069093" class="c"><input type="checkbox" id="c-39069093" checked=""/><div class="controls bullet"><span class="by">krapp</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39070904">prev</a><span>|</span><a href="#39071154">next</a><span>|</span><label class="collapse" for="c-39069093">[-]</label><label class="expand" for="c-39069093">[4 more]</label></div><br/><div class="children"><div class="content">Human beings and LLMs are essentially equivalent, and their processes of &quot;learning&quot; are essentially equivalent, yet human artists are not affected by tools like Nightshade. Odd.</div><br/><div id="39070985" class="c"><input type="checkbox" id="c-39070985" checked=""/><div class="controls bullet"><span class="by">danielbln</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39069093">parent</a><span>|</span><a href="#39071339">next</a><span>|</span><label class="collapse" for="c-39070985">[-]</label><label class="expand" for="c-39070985">[1 more]</label></div><br/><div class="children"><div class="content">As another posted out, modern models like BLIP or GPT4V aren&#x27;t affected by this either.</div><br/></div></div><div id="39071339" class="c"><input type="checkbox" id="c-39071339" checked=""/><div class="controls bullet"><span class="by">pixl97</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39069093">parent</a><span>|</span><a href="#39070985">prev</a><span>|</span><a href="#39071154">next</a><span>|</span><label class="collapse" for="c-39071339">[-]</label><label class="expand" for="c-39071339">[2 more]</label></div><br/><div class="children"><div class="content">Humans don&#x27;t fall for optical illusions? News to me.</div><br/><div id="39071932" class="c"><input type="checkbox" id="c-39071932" checked=""/><div class="controls bullet"><span class="by">krapp</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071339">parent</a><span>|</span><a href="#39071154">next</a><span>|</span><label class="collapse" for="c-39071932">[-]</label><label class="expand" for="c-39071932">[1 more]</label></div><br/><div class="children"><div class="content">Nightshade isn&#x27;t an optical illusion. It doesn&#x27;t operate within LLMs in any way equivalent to the way optical illusion do in humans. A human who sees an optical illusion does not have their perception nor ability to function affected in the same way as an LLM.<p>I realize you and people like yourself have a lot invested in furthering the narrative that LLMs are equivalent to human beings in every relevant sense - especially any <i>legal</i> sense which might prevent you from profiting on the copyrighted material that LLMs are trained on.<p>But it&#x27;s a specious argument. LLMs are not human. They don&#x27;t think. They don&#x27;t see. They don&#x27;t reason. They aren&#x27;t entities possessed of self-awareness. The fact that one cannot &quot;poison&quot; human cognition the way one can &quot;poison&quot; LLM models is only one of numerous examples of that fact. LLMs are software, not people.<p>And no, it isn&#x27;t incumbent upon me to prove any of these claims. It is incumbent upon you and those like yourself who pollute every thread about AI with such claims to back them up with even ordinary proof.<p>But you won&#x27;t, because you can&#x27;t. Such proof doesn&#x27;t exist, whereas evidence to the contrary exists in abundance. Perhaps you&#x27;re simply naive and assume that because LLMs are capable of generating what appears to be intelligent output, it must therefore be intelligent. Or perhaps you&#x27;re one of the many people who have a vested interest in ensuring that LLMs are granted the same legal status as human beings, so that you can make stronger copyright claims on their output.<p>It doesn&#x27;t matter. Every single time this argument comes up people will chime in with the same tedious false equivalencies. But it isn&#x27;t clever, it&#x27;s just getting annoying.</div><br/></div></div></div></div></div></div><div id="39071154" class="c"><input type="checkbox" id="c-39071154" checked=""/><div class="controls bullet"><span class="by">itronitron</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39069093">prev</a><span>|</span><a href="#39071226">next</a><span>|</span><label class="collapse" for="c-39071154">[-]</label><label class="expand" for="c-39071154">[2 more]</label></div><br/><div class="children"><div class="content">Art schools don&#x27;t teach people how to paint in different artistic styles. They teach materials and technique.</div><br/><div id="39074776" class="c"><input type="checkbox" id="c-39074776" checked=""/><div class="controls bullet"><span class="by">skydhash</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071154">parent</a><span>|</span><a href="#39071226">next</a><span>|</span><label class="collapse" for="c-39074776">[-]</label><label class="expand" for="c-39074776">[1 more]</label></div><br/><div class="children"><div class="content">Very true. I was watching a video yesterday learning how to make brush work digitally. While there were examples, they were just examples but the rest was specific techniques and demonstrations.</div><br/></div></div></div></div><div id="39071226" class="c"><input type="checkbox" id="c-39071226" checked=""/><div class="controls bullet"><span class="by">jurynulifcation</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39071154">prev</a><span>|</span><a href="#39068283">next</a><span>|</span><label class="collapse" for="c-39071226">[-]</label><label class="expand" for="c-39071226">[1 more]</label></div><br/><div class="children"><div class="content">Artists learning to innovate a trade defend their trade from incursion by bloodthirsty, no-value-adding vampiric middle men attempting to cut them out of the loop.</div><br/></div></div><div id="39068283" class="c"><input type="checkbox" id="c-39068283" checked=""/><div class="controls bullet"><span class="by">NoraCodes</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39071226">prev</a><span>|</span><a href="#39075469">next</a><span>|</span><label class="collapse" for="c-39068283">[-]</label><label class="expand" for="c-39068283">[45 more]</label></div><br/><div class="children"><div class="content">This is a tired argument; whether or not the diffusion models are &quot;learning&quot;, they are a tool of capital to fuck over human artists, and should be resisted for that reason alone.</div><br/><div id="39068586" class="c"><input type="checkbox" id="c-39068586" checked=""/><div class="controls bullet"><span class="by">educaysean</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068283">parent</a><span>|</span><a href="#39075805">next</a><span>|</span><label class="collapse" for="c-39068586">[-]</label><label class="expand" for="c-39068586">[12 more]</label></div><br/><div class="children"><div class="content">As a human artist I don&#x27;t feel the same as you, and I somehow doubt that you care all that much about what we think anyways. You already made up your  mind about the tech, so don&#x27;t feel the need to protect us from &quot;a tool of capital [sic]&quot; to fortify your argument.</div><br/><div id="39069128" class="c"><input type="checkbox" id="c-39069128" checked=""/><div class="controls bullet"><span class="by">NoraCodes</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068586">parent</a><span>|</span><a href="#39070971">next</a><span>|</span><label class="collapse" for="c-39069128">[-]</label><label class="expand" for="c-39069128">[1 more]</label></div><br/><div class="children"><div class="content">My opinion is based on my interactions with my friends who are artists. I admit freely to caring less about what people I don&#x27;t know say, in the absence of additional evidence.</div><br/></div></div><div id="39070971" class="c"><input type="checkbox" id="c-39070971" checked=""/><div class="controls bullet"><span class="by">tester457</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068586">parent</a><span>|</span><a href="#39069128">prev</a><span>|</span><a href="#39071146">next</a><span>|</span><label class="collapse" for="c-39070971">[-]</label><label class="expand" for="c-39070971">[8 more]</label></div><br/><div class="children"><div class="content">Among working human artists your opinion is in the minority. Most professionals are not a fan of this.</div><br/><div id="39071647" class="c"><input type="checkbox" id="c-39071647" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070971">parent</a><span>|</span><a href="#39071146">next</a><span>|</span><label class="collapse" for="c-39071647">[-]</label><label class="expand" for="c-39071647">[7 more]</label></div><br/><div class="children"><div class="content">Yeah because their wage is inflated. Photographers were mad about digital cameras too. Womp womp.</div><br/><div id="39072707" class="c"><input type="checkbox" id="c-39072707" checked=""/><div class="controls bullet"><span class="by">tester457</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071647">parent</a><span>|</span><a href="#39071146">next</a><span>|</span><label class="collapse" for="c-39072707">[-]</label><label class="expand" for="c-39072707">[6 more]</label></div><br/><div class="children"><div class="content">Inflated is not an apt descriptor of artist wages, those are known to be low.</div><br/><div id="39073172" class="c"><input type="checkbox" id="c-39073172" checked=""/><div class="controls bullet"><span class="by">MacsHeadroom</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072707">parent</a><span>|</span><a href="#39073153">next</a><span>|</span><label class="collapse" for="c-39073172">[-]</label><label class="expand" for="c-39073172">[2 more]</label></div><br/><div class="children"><div class="content">And horse wages (some oats) were low when the car was invented. Yet they were still inflated. There used to be more horses than humans in this country. Couldn&#x27;t even earn their keep when the Ford Model T came along.</div><br/><div id="39073818" class="c"><input type="checkbox" id="c-39073818" checked=""/><div class="controls bullet"><span class="by">NoraCodes</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073172">parent</a><span>|</span><a href="#39073153">next</a><span>|</span><label class="collapse" for="c-39073818">[-]</label><label class="expand" for="c-39073818">[1 more]</label></div><br/><div class="children"><div class="content">You&#x27;re comparing human artists to horses? Seriously?</div><br/></div></div></div></div><div id="39073153" class="c"><input type="checkbox" id="c-39073153" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072707">parent</a><span>|</span><a href="#39073172">prev</a><span>|</span><a href="#39071146">next</a><span>|</span><label class="collapse" for="c-39073153">[-]</label><label class="expand" for="c-39073153">[3 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re independent selling paintings, sure. Designing packaging or something commercial? 4 hours of work a week for nearly 6 figures. I know a couple graphic designers and they don&#x27;t do shit for what they&#x27;re paid.</div><br/><div id="39073884" class="c"><input type="checkbox" id="c-39073884" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073153">parent</a><span>|</span><a href="#39071146">next</a><span>|</span><label class="collapse" for="c-39073884">[-]</label><label class="expand" for="c-39073884">[2 more]</label></div><br/><div class="children"><div class="content">You should probably tell the other millions of artists busting out 60+ hour workweek in industry for half that price where these jobs are. That could solve this problem overnight.</div><br/><div id="39075173" class="c"><input type="checkbox" id="c-39075173" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073884">parent</a><span>|</span><a href="#39071146">next</a><span>|</span><label class="collapse" for="c-39075173">[-]</label><label class="expand" for="c-39075173">[1 more]</label></div><br/><div class="children"><div class="content">Manufacturing&#x2F;packaging.</div><br/></div></div></div></div></div></div></div></div></div></div></div></div><div id="39071146" class="c"><input type="checkbox" id="c-39071146" checked=""/><div class="controls bullet"><span class="by">big_whack</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068586">parent</a><span>|</span><a href="#39070971">prev</a><span>|</span><a href="#39068665">next</a><span>|</span><label class="collapse" for="c-39071146">[-]</label><label class="expand" for="c-39071146">[1 more]</label></div><br/><div class="children"><div class="content">Do you make your living as an artist?</div><br/></div></div></div></div><div id="39075805" class="c"><input type="checkbox" id="c-39075805" checked=""/><div class="controls bullet"><span class="by">dartharva</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068283">parent</a><span>|</span><a href="#39068586">prev</a><span>|</span><a href="#39068449">next</a><span>|</span><label class="collapse" for="c-39075805">[-]</label><label class="expand" for="c-39075805">[1 more]</label></div><br/><div class="children"><div class="content">Exactly. Artists should drop the pretentious philosophical bumbling and accept what this is, a fight for their livelihood. Which is, in every sense, completely warranted and good.<p>Putting blame on the technology and trying to limit public access to software will not go anywhere. Your fight for regulation needs to be with publishers and producers, not with the teen trying to make a cool new wallpaper or the office-man trying to make an aesthetic powerpoint presentation.</div><br/></div></div><div id="39068449" class="c"><input type="checkbox" id="c-39068449" checked=""/><div class="controls bullet"><span class="by">SonicSoul</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068283">parent</a><span>|</span><a href="#39075805">prev</a><span>|</span><a href="#39068334">next</a><span>|</span><label class="collapse" for="c-39068449">[-]</label><label class="expand" for="c-39068449">[7 more]</label></div><br/><div class="children"><div class="content">great comment!<p>imagine being a photographer that takes decades to perfect their craft. sure another student can study and mimic your style. but it&#x27;s still different than some computer model &quot;ingesting&quot; vast amount of photos and vomiting something similar for $5.99 in aws cpu cost so that some prompt jockey can call themselves an AI artist and make money off of other peoples talent.<p>i get that this is cynical and does not encompass all ai art, but why not let computers develop their own style wihout ingesting human art? that&#x27;s when it would actually be AI art</div><br/><div id="39068557" class="c"><input type="checkbox" id="c-39068557" checked=""/><div class="controls bullet"><span class="by">wincy</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068449">parent</a><span>|</span><a href="#39069138">next</a><span>|</span><label class="collapse" for="c-39068557">[-]</label><label class="expand" for="c-39068557">[4 more]</label></div><br/><div class="children"><div class="content">Like 99.9% of the art the common people care about is Darth Vader and Taylor Swift and other pop culture stuff like that.<p>These people literally don’t care what your definition of what is and isn’t art is, or how it’s made, they just want a lock screen wallpaper of themselves fighting against Thanos on top of a volcano.<p>The argument of “what is art” has been an academic conversation largely ignored by the people actually consuming the art for hundreds of years. Photography was just pop culture trash, comics were pop culture trash, stick figure web comics were pop culture trash. Today’s pop culture trash is the “prompt jockey”.<p>I make probably 5-10 pictures every day over the course of maybe 20 minutes as jokes on Teams because we have Bing Chat Enterprise. My coworkers seem to enjoy it. Nobody cares that it’s generated. I’m also not trying to be an “artist” whatever that means. It just is, and it’s fun. I wasn’t gonna hire an artist to draw me pictures to shitpost to my coworkers. It’s instead unlocked a new fun way to communicate.</div><br/><div id="39068646" class="c"><input type="checkbox" id="c-39068646" checked=""/><div class="controls bullet"><span class="by">SonicSoul</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068557">parent</a><span>|</span><a href="#39073925">next</a><span>|</span><label class="collapse" for="c-39068646">[-]</label><label class="expand" for="c-39068646">[1 more]</label></div><br/><div class="children"><div class="content">not entirely sure what your point is, but i think you are saying that art is just a commodity we use for cheap entertainment so it&#x27;s ok for computers to do the same?<p>in the context of what i was saying the definition of what is art can be summed up as anything made by humans. i have no problem when its used in memes and being open sourced etc.. the issue i have is when a human invests real time into it and then its taken and regurgitated without their permission. do you see that distinction?</div><br/></div></div><div id="39073925" class="c"><input type="checkbox" id="c-39073925" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068557">parent</a><span>|</span><a href="#39068646">prev</a><span>|</span><a href="#39075830">next</a><span>|</span><label class="collapse" for="c-39073925">[-]</label><label class="expand" for="c-39073925">[1 more]</label></div><br/><div class="children"><div class="content">I mean, I don&#x27;t think many care about your personal use of art. You can take copyright images and shit post and Disney won&#x27;t go suing your workplace.<p>But many big players do want to use this commercially and that&#x27;s where a lot of these lines start to form. No matter how lawsuits go you will probably still be able to find some LLM to make Thanos fighting a volcano. It&#x27;s just a matter of how&#x2F;if companies can profit from it.</div><br/></div></div><div id="39075830" class="c"><input type="checkbox" id="c-39075830" checked=""/><div class="controls bullet"><span class="by">dartharva</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068557">parent</a><span>|</span><a href="#39073925">prev</a><span>|</span><a href="#39069138">next</a><span>|</span><label class="collapse" for="c-39075830">[-]</label><label class="expand" for="c-39075830">[1 more]</label></div><br/><div class="children"><div class="content">This response should be gilded</div><br/></div></div></div></div><div id="39069138" class="c"><input type="checkbox" id="c-39069138" checked=""/><div class="controls bullet"><span class="by">Levitz</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068449">parent</a><span>|</span><a href="#39068557">prev</a><span>|</span><a href="#39071697">next</a><span>|</span><label class="collapse" for="c-39069138">[-]</label><label class="expand" for="c-39069138">[1 more]</label></div><br/><div class="children"><div class="content">Because that&#x27;s not what happens, ever. You wouldn&#x27;t ask a human to have their style of photographing when they don&#x27;t know what a photograph even looks like.</div><br/></div></div><div id="39071697" class="c"><input type="checkbox" id="c-39071697" checked=""/><div class="controls bullet"><span class="by">bongodongobob</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068449">parent</a><span>|</span><a href="#39069138">prev</a><span>|</span><a href="#39068334">next</a><span>|</span><label class="collapse" for="c-39071697">[-]</label><label class="expand" for="c-39071697">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a funny argument because artists lost their shit over photography too. Now anyone can make a portrait! Photography will kill art!<p>Art is the biggest gate kept industry there is and I detest artists who believe only they are the chosen one.<p>Art is human expression. We all have a right to create what we want with whatever tools we want. They can adapt or be left behind. No sympathy from me.</div><br/></div></div></div></div><div id="39068334" class="c"><input type="checkbox" id="c-39068334" checked=""/><div class="controls bullet"><span class="by">persnickety</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068283">parent</a><span>|</span><a href="#39068449">prev</a><span>|</span><a href="#39068573">next</a><span>|</span><label class="collapse" for="c-39068334">[-]</label><label class="expand" for="c-39068334">[15 more]</label></div><br/><div class="children"><div class="content">As a representative of a lot of things but hardly any capital who uses diffusion models to get something I would otherwise not pay a human artist for anyway, I testify that, the models are not exclusively what you describe them to be.<p>I do not support indiscriminate banning of anything and everything that can potentially be used to fuck someone over.</div><br/><div id="39068354" class="c"><input type="checkbox" id="c-39068354" checked=""/><div class="controls bullet"><span class="by">NoraCodes</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068334">parent</a><span>|</span><a href="#39068573">next</a><span>|</span><label class="collapse" for="c-39068354">[-]</label><label class="expand" for="c-39068354">[14 more]</label></div><br/><div class="children"><div class="content">I did not say they were <i>exclusively</i> that; I said they <i>were</i> that.<p>Once we as a society have implemented a good way for the artists whose work powers these machines to survive, you can feel good about using them. Until then, frankly, you&#x27;re doing something immoral by paying to use them.</div><br/><div id="39069184" class="c"><input type="checkbox" id="c-39069184" checked=""/><div class="controls bullet"><span class="by">Levitz</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068354">parent</a><span>|</span><a href="#39068377">next</a><span>|</span><label class="collapse" for="c-39069184">[-]</label><label class="expand" for="c-39069184">[4 more]</label></div><br/><div class="children"><div class="content">By this logic we ought to start lynching artists, why they didn&#x27;t care about all of those who lost their jobs making pigments, canvasses, pencils, brushes etc etc</div><br/><div id="39071541" class="c"><input type="checkbox" id="c-39071541" checked=""/><div class="controls bullet"><span class="by">hirsin</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39069184">parent</a><span>|</span><a href="#39068377">next</a><span>|</span><label class="collapse" for="c-39071541">[-]</label><label class="expand" for="c-39071541">[3 more]</label></div><br/><div class="children"><div class="content">Artists pay those people and make their jobs needed. Same as the person above claiming Duchamp didn&#x27;t negotiate with the ceramics makers - yes, they absolutely did and do pay their suppliers. Artists aren&#x27;t smash and grabbing their local Blick.<p>AI pays no artist.</div><br/><div id="39073778" class="c"><input type="checkbox" id="c-39073778" checked=""/><div class="controls bullet"><span class="by">Levitz</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071541">parent</a><span>|</span><a href="#39072815">next</a><span>|</span><label class="collapse" for="c-39073778">[-]</label><label class="expand" for="c-39073778">[1 more]</label></div><br/><div class="children"><div class="content">&gt;Artists pay those people and make their jobs needed.<p>Enter factories, now you gather all the knowledge from those who made the product, automate it and leave them without jobs.</div><br/></div></div><div id="39072815" class="c"><input type="checkbox" id="c-39072815" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071541">parent</a><span>|</span><a href="#39073778">prev</a><span>|</span><a href="#39068377">next</a><span>|</span><label class="collapse" for="c-39072815">[-]</label><label class="expand" for="c-39072815">[1 more]</label></div><br/><div class="children"><div class="content">Not digital artists, though.</div><br/></div></div></div></div></div></div><div id="39068377" class="c"><input type="checkbox" id="c-39068377" checked=""/><div class="controls bullet"><span class="by">akx</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068354">parent</a><span>|</span><a href="#39069184">prev</a><span>|</span><a href="#39068388">next</a><span>|</span><label class="collapse" for="c-39068377">[-]</label><label class="expand" for="c-39068377">[4 more]</label></div><br/><div class="children"><div class="content">What if I run Stable Diffusion locally without paying anyone anything? Is it less immoral?</div><br/><div id="39068596" class="c"><input type="checkbox" id="c-39068596" checked=""/><div class="controls bullet"><span class="by">NoraCodes</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068377">parent</a><span>|</span><a href="#39068388">next</a><span>|</span><label class="collapse" for="c-39068596">[-]</label><label class="expand" for="c-39068596">[3 more]</label></div><br/><div class="children"><div class="content">Marginally, yeah, since you&#x27;re not supporting the development of more capable labor-saving devices in this category.<p>I&#x27;m still not a fan, though.</div><br/><div id="39070997" class="c"><input type="checkbox" id="c-39070997" checked=""/><div class="controls bullet"><span class="by">riversflow</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068596">parent</a><span>|</span><a href="#39068388">next</a><span>|</span><label class="collapse" for="c-39070997">[-]</label><label class="expand" for="c-39070997">[2 more]</label></div><br/><div class="children"><div class="content">How is empowering others to create not a moral good?</div><br/><div id="39073844" class="c"><input type="checkbox" id="c-39073844" checked=""/><div class="controls bullet"><span class="by">NoraCodes</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39070997">parent</a><span>|</span><a href="#39068388">next</a><span>|</span><label class="collapse" for="c-39073844">[-]</label><label class="expand" for="c-39073844">[1 more]</label></div><br/><div class="children"><div class="content">It is! This method of doing so has overwhelming negative externalities, though. I&#x27;d expect anyone who actually gave a shit about AI empowering people to create to spend just as much effort pushing legislation so the displaced artists don&#x27;t starve on the street as a result.</div><br/></div></div></div></div></div></div></div></div><div id="39068388" class="c"><input type="checkbox" id="c-39068388" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068354">parent</a><span>|</span><a href="#39068377">prev</a><span>|</span><a href="#39068573">next</a><span>|</span><label class="collapse" for="c-39068388">[-]</label><label class="expand" for="c-39068388">[5 more]</label></div><br/><div class="children"><div class="content">Who pays to use generators? The open ones are way more capable and interesting, generally.</div><br/><div id="39068642" class="c"><input type="checkbox" id="c-39068642" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068388">parent</a><span>|</span><a href="#39068510">next</a><span>|</span><label class="collapse" for="c-39068642">[-]</label><label class="expand" for="c-39068642">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t high-quality open image generation almost entirely dependent on Stability releasing their foundational models for free, at great expense to them?<p>That&#x27;s not something you&#x27;ll be able to rely on long-term, there won&#x27;t always be a firehose of venture capital money to subsidise that kind of charity.</div><br/><div id="39073216" class="c"><input type="checkbox" id="c-39073216" checked=""/><div class="controls bullet"><span class="by">Filligree</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068642">parent</a><span>|</span><a href="#39068510">next</a><span>|</span><label class="collapse" for="c-39073216">[-]</label><label class="expand" for="c-39073216">[1 more]</label></div><br/><div class="children"><div class="content">The cost of training them is going down, though. Given the existence of models like Pixart, I don’t think we’ll stay dependent on corporate charity for long.</div><br/></div></div></div></div><div id="39068510" class="c"><input type="checkbox" id="c-39068510" checked=""/><div class="controls bullet"><span class="by">wokwokwok</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068388">parent</a><span>|</span><a href="#39068642">prev</a><span>|</span><a href="#39068573">next</a><span>|</span><label class="collapse" for="c-39068510">[-]</label><label class="expand" for="c-39068510">[2 more]</label></div><br/><div class="children"><div class="content">Is that really your concern?<p>Whether you pay for it?<p>Let’s put it this way: paying for or not paying for stolen goods. Does it make any difference?<p>Why is that remotely relevant?<p>You want to argue “are the good stolen?” Sure. That’s a discussion we can have.<p>Did you pay for them or not? Who cares?</div><br/><div id="39073443" class="c"><input type="checkbox" id="c-39073443" checked=""/><div class="controls bullet"><span class="by">thfuran</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068510">parent</a><span>|</span><a href="#39068573">next</a><span>|</span><label class="collapse" for="c-39073443">[-]</label><label class="expand" for="c-39073443">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s a terrible analogy. Until the scrapers start deleting all other copies of what what they&#x27;re scraping, &quot;stealing&quot; the art in a traditional sense, there&#x27;s no harm done in the process of training the network. Any harm done comes after that.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39068573" class="c"><input type="checkbox" id="c-39068573" checked=""/><div class="controls bullet"><span class="by">witherk</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068283">parent</a><span>|</span><a href="#39068334">prev</a><span>|</span><a href="#39069712">next</a><span>|</span><label class="collapse" for="c-39068573">[-]</label><label class="expand" for="c-39068573">[5 more]</label></div><br/><div class="children"><div class="content">&quot;Cameras are a tool of captial to fuck over human portrait artists&quot;<p>It&#x27;s funny that these people use the langauge of communism, but apparently see artwork as purley an economic activity.</div><br/><div id="39069172" class="c"><input type="checkbox" id="c-39069172" checked=""/><div class="controls bullet"><span class="by">indigo0086</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068573">parent</a><span>|</span><a href="#39069153">next</a><span>|</span><label class="collapse" for="c-39069172">[-]</label><label class="expand" for="c-39069172">[1 more]</label></div><br/><div class="children"><div class="content">They tried to use the labor theory early on by claiming, &quot;real art takes hard work and time as opposed to the miniscule cpu hours computers use to make &#x27;AI art&quot;. The worst thing AI brings to the table is amplifying these types of sentiments to control industry in their favor where they would otherwise be unheard and relegated to Instagram likes</div><br/></div></div><div id="39069153" class="c"><input type="checkbox" id="c-39069153" checked=""/><div class="controls bullet"><span class="by">NoraCodes</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068573">parent</a><span>|</span><a href="#39069172">prev</a><span>|</span><a href="#39073364">next</a><span>|</span><label class="collapse" for="c-39069153">[-]</label><label class="expand" for="c-39069153">[1 more]</label></div><br/><div class="children"><div class="content">That&#x27;s an intentional misinterpretation, I think. I mention art as an economic activity because it&#x27;s primarily professional artists that are harmed by the widespread adoption of this technology.</div><br/></div></div><div id="39073364" class="c"><input type="checkbox" id="c-39073364" checked=""/><div class="controls bullet"><span class="by">redwall_hp</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068573">parent</a><span>|</span><a href="#39069153">prev</a><span>|</span><a href="#39069712">next</a><span>|</span><label class="collapse" for="c-39073364">[-]</label><label class="expand" for="c-39073364">[2 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s funny that these people use the langauge of communism, but apparently see artwork as purley an economic activity.<p>You hit the nail on the head. Copyright is, by its very nature, a &quot;tool of capital.&quot; It&#x27;s a means of creating new artificial property fiefdoms for a select few capital holders to lord over, while taking rights from anyone else who wants to engage in the practice of making art.<p>Everyone has their right to expression infringed upon, all so the 1% of artists can perpetually make money on things, which are ultimately sold to corporations that only pay them pennies on the dollar anyway.<p>You, as an indie hip hop or house musician supported by a day job, can&#x27;t sample and chop some vocals or use a slice of a chord played in a song (as were common in the 80s and 90s) for a completely new work, but apparently the world is such a better place because Taylor Swift is a multimillionaire and Disney can milk the maximum value from space and superhero films.<p>I&#x27;d rather live in a world where anyone is free to make whatever art they want, even if everyone has to have a day job.</div><br/><div id="39075486" class="c"><input type="checkbox" id="c-39075486" checked=""/><div class="controls bullet"><span class="by">skydhash</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39073364">parent</a><span>|</span><a href="#39069712">next</a><span>|</span><label class="collapse" for="c-39075486">[-]</label><label class="expand" for="c-39075486">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s a means of creating new artificial property fiefdoms for a select few capital holders to lord over, while taking rights from anyone else who wants to engage in the practice of making art.<p>I doubt even Disney sue people who want to make fan art. But if you want to sell said art or distribute it, they will.</div><br/></div></div></div></div></div></div><div id="39069712" class="c"><input type="checkbox" id="c-39069712" checked=""/><div class="controls bullet"><span class="by">matheusmoreira</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068283">parent</a><span>|</span><a href="#39068573">prev</a><span>|</span><a href="#39075469">next</a><span>|</span><label class="collapse" for="c-39069712">[-]</label><label class="expand" for="c-39069712">[4 more]</label></div><br/><div class="children"><div class="content">&gt; they are a tool of capital to fuck over human artists<p>So are the copyright and intellectual property laws that artists rely on. From my perspective, <i>you</i> are the capital and <i>I</i> am the one being fucked. So are you ready to abolish all that?</div><br/><div id="39072831" class="c"><input type="checkbox" id="c-39072831" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39069712">parent</a><span>|</span><a href="#39075469">next</a><span>|</span><label class="collapse" for="c-39072831">[-]</label><label class="expand" for="c-39072831">[3 more]</label></div><br/><div class="children"><div class="content">Right. This new outrage is just the copyright owners realising that their power is not safe. Where is the outrage when self checkouts happened?</div><br/><div id="39072926" class="c"><input type="checkbox" id="c-39072926" checked=""/><div class="controls bullet"><span class="by">matheusmoreira</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072831">parent</a><span>|</span><a href="#39075469">next</a><span>|</span><label class="collapse" for="c-39072926">[-]</label><label class="expand" for="c-39072926">[2 more]</label></div><br/><div class="children"><div class="content">Copyright owners indeed. That&#x27;s what these artists are. They&#x27;re copyright owners. Monopolists. They <i>are</i> the capital. Capitalism is all about owning property. Copyright is <i>intellectual</i> property. Literally imaginary property. Ownership of information, of bits, of <i>numbers</i>. These artists are the literal epitome of capitalism. They enjoy state granted monopolies that last multiple human lifetimes. We&#x27;ll be long dead before their works enter the public domain. They <i>want</i> it to be this way. They <i>want</i> eternal rent seeking for themselves and their descendants. At least one artist has told me exactly that in discussions here on HN. They think it&#x27;s fair.<p>They are the quintessential representation of capital. And they come here to ask us to &quot;resist&quot; the other forms of capital on principle.<p>I&#x27;m sorry but... No. I&#x27;m gonna resist them instead. It&#x27;s my sincere hope that this AI technology hammers in the last nails on the coffin of copyright and intellectual property as a whole. I want all the models to leak so that it becomes literally impossible to get rid of this technology no matter how much they hate it. I want it to progress so that we can run it on our own machines, so that it&#x27;ll be so ubiquitous it can&#x27;t be censored or banned no matter how much they lobby for it.</div><br/><div id="39073128" class="c"><input type="checkbox" id="c-39073128" checked=""/><div class="controls bullet"><span class="by">NoraCodes</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39072926">parent</a><span>|</span><a href="#39075469">next</a><span>|</span><label class="collapse" for="c-39073128">[-]</label><label class="expand" for="c-39073128">[1 more]</label></div><br/><div class="children"><div class="content">&gt; It&#x27;s my sincere hope that this AI technology hammers in the last nails on the coffin of copyright and intellectual property as a whole.<p>If it does, I will give you one thousand United States dollars, and you can quote me on thst whenever you like.<p>More likely, big companies will retain control as they always have (via expensive lawyers), and individual artists will get screwed.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39075469" class="c"><input type="checkbox" id="c-39075469" checked=""/><div class="controls bullet"><span class="by">SirMaster</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39068283">prev</a><span>|</span><a href="#39071065">next</a><span>|</span><label class="collapse" for="c-39075469">[-]</label><label class="expand" for="c-39075469">[1 more]</label></div><br/><div class="children"><div class="content">Lol, the scale is other-worldly different...</div><br/></div></div><div id="39071065" class="c"><input type="checkbox" id="c-39071065" checked=""/><div class="controls bullet"><span class="by">bakugo</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39075469">prev</a><span>|</span><a href="#39068288">next</a><span>|</span><label class="collapse" for="c-39071065">[-]</label><label class="expand" for="c-39071065">[4 more]</label></div><br/><div class="children"><div class="content">A human artist cannot look at and memorize 100000 pictures in a day, and cannot paint 100000 pictures in a day.<p>I am SO tired of this non-argument</div><br/><div id="39071755" class="c"><input type="checkbox" id="c-39071755" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071065">parent</a><span>|</span><a href="#39068288">next</a><span>|</span><label class="collapse" for="c-39071755">[-]</label><label class="expand" for="c-39071755">[3 more]</label></div><br/><div class="children"><div class="content">A human artist does not need to look at and memorize 100000 pictures in any span of time, period. Current AI does.<p>We needed huge amounts of human labor to fund and build Versailles. I&#x27;m sure many died as a result. Now we have machines that save many of those lives and labor.<p>What&#x27;s your non-argument?</div><br/><div id="39072206" class="c"><input type="checkbox" id="c-39072206" checked=""/><div class="controls bullet"><span class="by">MattRix</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071755">parent</a><span>|</span><a href="#39073861">next</a><span>|</span><label class="collapse" for="c-39072206">[-]</label><label class="expand" for="c-39072206">[1 more]</label></div><br/><div class="children"><div class="content">The argument is that the humans producing the work should be <i>willing</i> participants. I don’t think that’s too much to ask for.</div><br/></div></div><div id="39073861" class="c"><input type="checkbox" id="c-39073861" checked=""/><div class="controls bullet"><span class="by">johnnyanmac</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39071755">parent</a><span>|</span><a href="#39072206">prev</a><span>|</span><a href="#39068288">next</a><span>|</span><label class="collapse" for="c-39073861">[-]</label><label class="expand" for="c-39073861">[1 more]</label></div><br/><div class="children"><div class="content">&gt;What&#x27;s your non-argument?<p>That perhaps we shoildnt compare modern capitalistic societies to 18th century European royalty? I sure don&#x27;t sympathize with the justification of the ability to use less labor to feed the rich.</div><br/></div></div></div></div></div></div><div id="39068288" class="c"><input type="checkbox" id="c-39068288" checked=""/><div class="controls bullet"><span class="by">Snow_Falls</span><span>|</span><a href="#39068221">parent</a><span>|</span><a href="#39071065">prev</a><span>|</span><a href="#39071494">next</a><span>|</span><label class="collapse" for="c-39068288">[-]</label><label class="expand" for="c-39068288">[3 more]</label></div><br/><div class="children"><div class="content">These AIs are not people. They do not learn.</div><br/><div id="39068305" class="c"><input type="checkbox" id="c-39068305" checked=""/><div class="controls bullet"><span class="by">jfdbcv</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068288">parent</a><span>|</span><a href="#39071494">next</a><span>|</span><label class="collapse" for="c-39068305">[-]</label><label class="expand" for="c-39068305">[2 more]</label></div><br/><div class="children"><div class="content">Define learn.</div><br/><div id="39070899" class="c"><input type="checkbox" id="c-39070899" checked=""/><div class="controls bullet"><span class="by">dudeinjapan</span><span>|</span><a href="#39068221">root</a><span>|</span><a href="#39068305">parent</a><span>|</span><a href="#39071494">next</a><span>|</span><label class="collapse" for="c-39070899">[-]</label><label class="expand" for="c-39070899">[1 more]</label></div><br/><div class="children"><div class="content">Define people.</div><br/></div></div></div></div></div></div></div></div><div id="39071494" class="c"><input type="checkbox" id="c-39071494" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#39068221">prev</a><span>|</span><a href="#39076620">next</a><span>|</span><label class="collapse" for="c-39071494">[-]</label><label class="expand" for="c-39071494">[41 more]</label></div><br/><div class="children"><div class="content">The number of people who are going to be able to produce high fidelity art with off the shelf tools in the near future is unbelievable.<p>It’s pretty exciting.<p>Being able to find a mix of styles you like and apply them to new subjects to make your own unique, personalized, artwork sounds like a wickedly cool power to give to billions of people.</div><br/><div id="39072915" class="c"><input type="checkbox" id="c-39072915" checked=""/><div class="controls bullet"><span class="by">kredd</span><span>|</span><a href="#39071494">parent</a><span>|</span><a href="#39073148">next</a><span>|</span><label class="collapse" for="c-39072915">[-]</label><label class="expand" for="c-39072915">[26 more]</label></div><br/><div class="children"><div class="content">In terms of art, population tends to put value not on the result, but origin and process. People will just look down on any art that’s AI generated in a couple of years when it becomes ubiquitous.</div><br/><div id="39074768" class="c"><input type="checkbox" id="c-39074768" checked=""/><div class="controls bullet"><span class="by">petesergeant</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072915">parent</a><span>|</span><a href="#39073186">next</a><span>|</span><label class="collapse" for="c-39074768">[-]</label><label class="expand" for="c-39074768">[1 more]</label></div><br/><div class="children"><div class="content">&gt; population tends to put value not on the result, but origin and process<p>I think population tends to value &quot;looks pretty&quot;, and it&#x27;s other artists, connoisseurs, and art critics who value origin and process. Exit Through the Gift Shop sums this up nicely</div><br/></div></div><div id="39073186" class="c"><input type="checkbox" id="c-39073186" checked=""/><div class="controls bullet"><span class="by">redwall_hp</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072915">parent</a><span>|</span><a href="#39074768">prev</a><span>|</span><a href="#39075103">next</a><span>|</span><label class="collapse" for="c-39073186">[-]</label><label class="expand" for="c-39073186">[3 more]</label></div><br/><div class="children"><div class="content">This is already the case. Art is a process, a form of human expression, not an end result.<p>I&#x27;m sure OpenAI&#x27;s models can shit out an approximation of a new Terry Pratchett or Douglas Adams novel, but nobody with any level of literary appreciation would give a damn unless fraud was committed to trick readers into buying it. It&#x27;s not the author&#x27;s work, and there&#x27;s no human message behind it.</div><br/><div id="39075467" class="c"><input type="checkbox" id="c-39075467" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073186">parent</a><span>|</span><a href="#39075534">next</a><span>|</span><label class="collapse" for="c-39075467">[-]</label><label class="expand" for="c-39075467">[1 more]</label></div><br/><div class="children"><div class="content">Novels aren&#x27;t about a message. They&#x27;re entertainment. If the novel is entertaining then it&#x27;s irrelevant whether there is or isn&#x27;t a message in it. Besides, literature enthusiasts will invent a message for a popular story even if there never was one.<p>Also, I&#x27;m sure that you can eventually just prompt the model with the message you want to put into the story, if you can&#x27;t already do that.</div><br/></div></div><div id="39075534" class="c"><input type="checkbox" id="c-39075534" checked=""/><div class="controls bullet"><span class="by">portaouflop</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073186">parent</a><span>|</span><a href="#39075467">prev</a><span>|</span><a href="#39075103">next</a><span>|</span><label class="collapse" for="c-39075534">[-]</label><label class="expand" for="c-39075534">[1 more]</label></div><br/><div class="children"><div class="content">I haven’t read anything “shit out” by any LLM that even nearly approaches the level of quality by the authors you named — would very much like to see something like that - do you have any evidence for your claims?<p>AFAICT current text generation is something approaching bad mimicry at best and downright abysmal in general. 
I think you still need a very skilled author and meaty brain with a story to tell to make use of an LLM for storytelling. 
Sure it’s a useful tool that will make authors more effective but we are far from the point where you tell the LLM “write a story set in Pratchetts Discworld” and something acceptable or even entertaining will be spit out - if such a thing can even be achieved.</div><br/></div></div></div></div><div id="39075103" class="c"><input type="checkbox" id="c-39075103" checked=""/><div class="controls bullet"><span class="by">Theodores</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072915">parent</a><span>|</span><a href="#39073186">prev</a><span>|</span><a href="#39073074">next</a><span>|</span><label class="collapse" for="c-39075103">[-]</label><label class="expand" for="c-39075103">[5 more]</label></div><br/><div class="children"><div class="content"><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Labor_theory_of_value" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Labor_theory_of_value</a><p>According to Marx, value is only created with human labour. This is not just a Marxist theory, it is an observation.<p>There may be lots of over-priced junk that makes you want to question this idea. But let&#x27;s not nit-pick on that.<p>In two years time people will not see any value in AI art, quite correctly because there is not much human labour in creating it.</div><br/><div id="39075479" class="c"><input type="checkbox" id="c-39075479" checked=""/><div class="controls bullet"><span class="by">Gormo</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075103">parent</a><span>|</span><a href="#39075286">next</a><span>|</span><label class="collapse" for="c-39075479">[-]</label><label class="expand" for="c-39075479">[1 more]</label></div><br/><div class="children"><div class="content">&gt; According to Marx, value is only created with human labour. This is not just a Marxist theory, it is an observation.<p>And yet it&#x27;s completely and absolutely wrong.  Value is created by the subjective utility offered to the consumer, irrespective of what inputs created the thing conveying that utility.</div><br/></div></div><div id="39075286" class="c"><input type="checkbox" id="c-39075286" checked=""/><div class="controls bullet"><span class="by">mesh</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075103">parent</a><span>|</span><a href="#39075479">prev</a><span>|</span><a href="#39075555">next</a><span>|</span><label class="collapse" for="c-39075286">[-]</label><label class="expand" for="c-39075286">[1 more]</label></div><br/><div class="children"><div class="content">In two years time, no one will know what was created with AI, what was created by humans, or what was created by both.</div><br/></div></div><div id="39075555" class="c"><input type="checkbox" id="c-39075555" checked=""/><div class="controls bullet"><span class="by">jquery</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075103">parent</a><span>|</span><a href="#39075286">prev</a><span>|</span><a href="#39075780">next</a><span>|</span><label class="collapse" for="c-39075555">[-]</label><label class="expand" for="c-39075555">[1 more]</label></div><br/><div class="children"><div class="content">Labor theory of value is quite controversial, many economists call it tautological or even metaphysical. I also don&#x27;t really see what LTV has to say about AI art, if anything, except that the economic value generated by AI art should be distributed to everybody and not just funneled to a few capitalists at the top. I would agree with that. It&#x27;s true that more jobs get created even as jobs are destroyed, but it&#x27;s also true that just as our ancestors fought for a 40 hour work week and a social safety net, we should be able to ask for more as computers become ever so productive.</div><br/></div></div><div id="39075780" class="c"><input type="checkbox" id="c-39075780" checked=""/><div class="controls bullet"><span class="by">petesergeant</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075103">parent</a><span>|</span><a href="#39075555">prev</a><span>|</span><a href="#39073074">next</a><span>|</span><label class="collapse" for="c-39075780">[-]</label><label class="expand" for="c-39075780">[1 more]</label></div><br/><div class="children"><div class="content">&gt; This is not just a Marxist theory, it is an observation.<p>Yeah? Well, you know, that&#x27;s just like uh, your opinion, man</div><br/></div></div></div></div><div id="39073074" class="c"><input type="checkbox" id="c-39073074" checked=""/><div class="controls bullet"><span class="by">MacsHeadroom</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072915">parent</a><span>|</span><a href="#39075103">prev</a><span>|</span><a href="#39075447">next</a><span>|</span><label class="collapse" for="c-39073074">[-]</label><label class="expand" for="c-39073074">[13 more]</label></div><br/><div class="children"><div class="content">Nope, but I already look down on artists who refuse to integrate generative AI into their processes.</div><br/><div id="39073163" class="c"><input type="checkbox" id="c-39073163" checked=""/><div class="controls bullet"><span class="by">mplewis</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073074">parent</a><span>|</span><a href="#39073185">next</a><span>|</span><label class="collapse" for="c-39073163">[-]</label><label class="expand" for="c-39073163">[1 more]</label></div><br/><div class="children"><div class="content">Can you share some of the art you’ve made with generative AI?</div><br/></div></div><div id="39073185" class="c"><input type="checkbox" id="c-39073185" checked=""/><div class="controls bullet"><span class="by">jurynulifcation</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073074">parent</a><span>|</span><a href="#39073163">prev</a><span>|</span><a href="#39073327">next</a><span>|</span><label class="collapse" for="c-39073185">[-]</label><label class="expand" for="c-39073185">[1 more]</label></div><br/><div class="children"><div class="content">Cool, who are you?</div><br/></div></div><div id="39073327" class="c"><input type="checkbox" id="c-39073327" checked=""/><div class="controls bullet"><span class="by">MisterBastahrd</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073074">parent</a><span>|</span><a href="#39073185">prev</a><span>|</span><a href="#39075447">next</a><span>|</span><label class="collapse" for="c-39073327">[-]</label><label class="expand" for="c-39073327">[10 more]</label></div><br/><div class="children"><div class="content">People who use generative AI in their processes are not artists.</div><br/><div id="39073829" class="c"><input type="checkbox" id="c-39073829" checked=""/><div class="controls bullet"><span class="by">blacklion</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073327">parent</a><span>|</span><a href="#39075625">next</a><span>|</span><label class="collapse" for="c-39073829">[-]</label><label class="expand" for="c-39073829">[2 more]</label></div><br/><div class="children"><div class="content">And people who use Photoshop are?<p>There is somewhat famous digital artist from Russia - Alexey Andreev. Google it, he has very distinctive style of realistic technique and surrealistic situations, like landing big manta ray on the deck of aircraft carrier. Or you can see his old works in his 5-years-not-updates LJ [1].<p>Now he uses generative AI as one of his tools. As Photoshop, as different (unrealistic!) brushes in Photoshop, as other digital tools. His style is still 100% recognizable and his works don&#x27;t become worse or more &quot;generic&quot;. Is he still artist? I think so.<p>Where will you draw the line?<p>[1] - <a href="https:&#x2F;&#x2F;alexandreev.livejournal.com&#x2F;" rel="nofollow">https:&#x2F;&#x2F;alexandreev.livejournal.com&#x2F;</a></div><br/></div></div><div id="39075625" class="c"><input type="checkbox" id="c-39075625" checked=""/><div class="controls bullet"><span class="by">smackeyacky</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073327">parent</a><span>|</span><a href="#39073829">prev</a><span>|</span><a href="#39074963">next</a><span>|</span><label class="collapse" for="c-39075625">[-]</label><label class="expand" for="c-39075625">[1 more]</label></div><br/><div class="children"><div class="content">I don’t think this is quite right.  I think paraphrasing The Incredibles has a better take:<p><i>When everybody is an artist, then nobody will be one.</i></div><br/></div></div><div id="39074963" class="c"><input type="checkbox" id="c-39074963" checked=""/><div class="controls bullet"><span class="by">davely</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073327">parent</a><span>|</span><a href="#39075625">prev</a><span>|</span><a href="#39073608">next</a><span>|</span><label class="collapse" for="c-39074963">[-]</label><label class="expand" for="c-39074963">[1 more]</label></div><br/><div class="children"><div class="content">I use generative AI to rubber duck and help improve my code.<p>Am I no longer a software engineer?</div><br/></div></div><div id="39073608" class="c"><input type="checkbox" id="c-39073608" checked=""/><div class="controls bullet"><span class="by">password54321</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073327">parent</a><span>|</span><a href="#39074963">prev</a><span>|</span><a href="#39075447">next</a><span>|</span><label class="collapse" for="c-39073608">[-]</label><label class="expand" for="c-39073608">[5 more]</label></div><br/><div class="children"><div class="content">This is true. They are just taking a sample from a generated latent space, just like taking a photo of something doesn&#x27;t make you an artist.</div><br/><div id="39073839" class="c"><input type="checkbox" id="c-39073839" checked=""/><div class="controls bullet"><span class="by">blacklion</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073608">parent</a><span>|</span><a href="#39075447">next</a><span>|</span><label class="collapse" for="c-39073839">[-]</label><label class="expand" for="c-39073839">[4 more]</label></div><br/><div class="children"><div class="content">So, there is no artists in, for example, street photography? Picture must be altered to become art, or staged?<p>Was it irony? :)</div><br/><div id="39073908" class="c"><input type="checkbox" id="c-39073908" checked=""/><div class="controls bullet"><span class="by">password54321</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073839">parent</a><span>|</span><a href="#39073874">next</a><span>|</span><label class="collapse" for="c-39073908">[-]</label><label class="expand" for="c-39073908">[1 more]</label></div><br/><div class="children"><div class="content">They are photographers. Here is the definition of an artist so you can have better clarity on what an artist is:<p>&quot;A person who creates art (such as painting, sculpture, music, or writing) using conscious skill and creative imagination&quot;</div><br/></div></div><div id="39075428" class="c"><input type="checkbox" id="c-39075428" checked=""/><div class="controls bullet"><span class="by">aqfamnzc</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073839">parent</a><span>|</span><a href="#39073874">prev</a><span>|</span><a href="#39075447">next</a><span>|</span><label class="collapse" for="c-39075428">[-]</label><label class="expand" for="c-39075428">[1 more]</label></div><br/><div class="children"><div class="content">I took gp as satire. But maybe not haha.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39075447" class="c"><input type="checkbox" id="c-39075447" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072915">parent</a><span>|</span><a href="#39073074">prev</a><span>|</span><a href="#39073148">next</a><span>|</span><label class="collapse" for="c-39075447">[-]</label><label class="expand" for="c-39075447">[3 more]</label></div><br/><div class="children"><div class="content">I disagree. I definitely value modern digital art more than most historical art, because it just looks better. If AI art looks better (and in some cases it does) then I&#x27;ll prefer that.</div><br/><div id="39076090" class="c"><input type="checkbox" id="c-39076090" checked=""/><div class="controls bullet"><span class="by">kredd</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39075447">parent</a><span>|</span><a href="#39073148">next</a><span>|</span><label class="collapse" for="c-39076090">[-]</label><label class="expand" for="c-39076090">[2 more]</label></div><br/><div class="children"><div class="content">That’s totally fine, everyone’s definition of art is subjective. But general value of an art as a piece will just still be zero for AI generated ones, just like any IKEA &#x2F; Amazon print piece. You just pay for the “looks pretty”, frame and paper.</div><br/><div id="39076759" class="c"><input type="checkbox" id="c-39076759" checked=""/><div class="controls bullet"><span class="by">Aerroon</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39076090">parent</a><span>|</span><a href="#39073148">next</a><span>|</span><label class="collapse" for="c-39076759">[-]</label><label class="expand" for="c-39076759">[1 more]</label></div><br/><div class="children"><div class="content">&gt;<i>You just pay for the “looks pretty”, frame and paper.</i><p>But you pay that for any piece of art though? You appreciate it because you like what it looks like. The utility of it is in how good it looks, it&#x27;s not how much effort was put into it.<p>If you need a ditch you&#x27;re not going to value the ditch more if the worker dug it by hand instead of using an excavator. You value it based on the utility it provides you.</div><br/></div></div></div></div></div></div></div></div><div id="39073148" class="c"><input type="checkbox" id="c-39073148" checked=""/><div class="controls bullet"><span class="by">falcolas</span><span>|</span><a href="#39071494">parent</a><span>|</span><a href="#39072915">prev</a><span>|</span><a href="#39072108">next</a><span>|</span><label class="collapse" for="c-39073148">[-]</label><label class="expand" for="c-39073148">[1 more]</label></div><br/><div class="children"><div class="content">&gt; Being able to find a mix of styles you like and apply them to new subjects to make your own unique, personalized, artwork sounds like a wickedly cool power to give to billions of people.<p>And in the process, they will obviate the need for Nightshade and similar tools.<p>AI models ingesting AI generated content does the work of destroying the models all by itself. Have a look at &quot;Model Collapse&quot; in relation to generative AI.</div><br/></div></div><div id="39072108" class="c"><input type="checkbox" id="c-39072108" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#39071494">parent</a><span>|</span><a href="#39073148">prev</a><span>|</span><a href="#39071744">next</a><span>|</span><label class="collapse" for="c-39072108">[-]</label><label class="expand" for="c-39072108">[4 more]</label></div><br/><div class="children"><div class="content">It&#x27;ll be about as wickedly tool as the ability to get on the internet, e.g. commoditized, transactional, and boring.</div><br/><div id="39072905" class="c"><input type="checkbox" id="c-39072905" checked=""/><div class="controls bullet"><span class="by">sebzim4500</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072108">parent</a><span>|</span><a href="#39071744">next</a><span>|</span><label class="collapse" for="c-39072905">[-]</label><label class="expand" for="c-39072905">[3 more]</label></div><br/><div class="children"><div class="content">I know this is an unpopular thing to say these days, but I still think the internet is amazing.<p>I have more access to information now than the most powerful people in the world did 40 years ago. I can learn about quantum field theory, about which pop star is allegedly fucking which other pop star, etc.<p>If I don&#x27;t care about the law I can read any of 25 million books or 100 million scientific papers all available on Anna&#x27;s Archive for free in seconds.</div><br/><div id="39074751" class="c"><input type="checkbox" id="c-39074751" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072905">parent</a><span>|</span><a href="#39073413">next</a><span>|</span><label class="collapse" for="c-39074751">[-]</label><label class="expand" for="c-39074751">[1 more]</label></div><br/><div class="children"><div class="content">As Jeff Bezos recently said on the Lex podcast: one of the greatest compliments you can give an inventor is that they’re invention will be taken for granted by future generations.<p>“It won’t be any more wickedly cool than the internet” - saying something won’t be any more wickedly cool than the most profound and impactful pieces of infrastructure human civilization has erected is a pretty high compliment.</div><br/></div></div></div></div></div></div><div id="39071744" class="c"><input type="checkbox" id="c-39071744" checked=""/><div class="controls bullet"><span class="by">__loam</span><span>|</span><a href="#39071494">parent</a><span>|</span><a href="#39072108">prev</a><span>|</span><a href="#39073553">next</a><span>|</span><label class="collapse" for="c-39071744">[-]</label><label class="expand" for="c-39071744">[6 more]</label></div><br/><div class="children"><div class="content">And we only had to alienate millions of people from their labor to do it.</div><br/><div id="39072010" class="c"><input type="checkbox" id="c-39072010" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39071744">parent</a><span>|</span><a href="#39071879">next</a><span>|</span><label class="collapse" for="c-39072010">[-]</label><label class="expand" for="c-39072010">[1 more]</label></div><br/><div class="children"><div class="content">Absolutely agree we should allow people to accumulate equity through effective allocation of their labor.<p>And I also agree that we shouldn’t build systems that alienate people from that accumulated equity.</div><br/></div></div><div id="39071879" class="c"><input type="checkbox" id="c-39071879" checked=""/><div class="controls bullet"><span class="by">DennisAleynikov</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39071744">parent</a><span>|</span><a href="#39072010">prev</a><span>|</span><a href="#39071884">next</a><span>|</span><label class="collapse" for="c-39071879">[-]</label><label class="expand" for="c-39071879">[3 more]</label></div><br/><div class="children"><div class="content">Yeah, sadly those millions of people don’t matter in the grand scheme of things and were never going to profit off their work long term</div><br/><div id="39072092" class="c"><input type="checkbox" id="c-39072092" checked=""/><div class="controls bullet"><span class="by">r3trohack3r</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39071879">parent</a><span>|</span><a href="#39071884">next</a><span>|</span><label class="collapse" for="c-39072092">[-]</label><label class="expand" for="c-39072092">[2 more]</label></div><br/><div class="children"><div class="content">What a bummer of a thing to say.<p>Those millions&#x2F;billions of people matter a great deal.</div><br/><div id="39074892" class="c"><input type="checkbox" id="c-39074892" checked=""/><div class="controls bullet"><span class="by">DennisAleynikov</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39072092">parent</a><span>|</span><a href="#39071884">next</a><span>|</span><label class="collapse" for="c-39074892">[-]</label><label class="expand" for="c-39074892">[1 more]</label></div><br/><div class="children"><div class="content">They matter but not under the current system. Artists are a rarely paid profession, and there are professional artists out there but there’s now a huge amount of people that will never contact an artist for work that used to only be human powered. It’s not personal for me. I understand that desire to resist the inevitable but it’s here now.<p>For what it’s worth I never use midjourney or dalle or any of the commercial closed systems that steal from artists but I know I can’t stop the masses from going there and inputting “give me pretty picture in style x”</div><br/></div></div></div></div></div></div><div id="39071884" class="c"><input type="checkbox" id="c-39071884" checked=""/><div class="controls bullet"><span class="by">mensetmanusman</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39071744">parent</a><span>|</span><a href="#39071879">prev</a><span>|</span><a href="#39073553">next</a><span>|</span><label class="collapse" for="c-39071884">[-]</label><label class="expand" for="c-39071884">[1 more]</label></div><br/><div class="children"><div class="content">Is this utilitarianism?</div><br/></div></div></div></div><div id="39073553" class="c"><input type="checkbox" id="c-39073553" checked=""/><div class="controls bullet"><span class="by">password54321</span><span>|</span><a href="#39071494">parent</a><span>|</span><a href="#39071744">prev</a><span>|</span><a href="#39076620">next</a><span>|</span><label class="collapse" for="c-39073553">[-]</label><label class="expand" for="c-39073553">[3 more]</label></div><br/><div class="children"><div class="content">Not really. There is a reason why we find realistic painting to be more fascinating than a photo and why some still practice it. The effort put in by another artist does affect our enjoyment.</div><br/><div id="39075495" class="c"><input type="checkbox" id="c-39075495" checked=""/><div class="controls bullet"><span class="by">wruza</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073553">parent</a><span>|</span><a href="#39075777">next</a><span>|</span><label class="collapse" for="c-39075495">[-]</label><label class="expand" for="c-39075495">[1 more]</label></div><br/><div class="children"><div class="content">For me it doesn’t. I’m generating images, realistic, 2.5d, 2d and I like them as much. I don’t feel (or miss) what you described. Or what any other arts guy describes, for that matter. Arts people are different, because they were trained to feel something a normal person wouldn’t. And that’s okay, a normal person without training wouldn’t see how much beauty and effort there is in an algorithm or a legal contract as well.</div><br/></div></div><div id="39075777" class="c"><input type="checkbox" id="c-39075777" checked=""/><div class="controls bullet"><span class="by">dartharva</span><span>|</span><a href="#39071494">root</a><span>|</span><a href="#39073553">parent</a><span>|</span><a href="#39075495">prev</a><span>|</span><a href="#39076620">next</a><span>|</span><label class="collapse" for="c-39075777">[-]</label><label class="expand" for="c-39075777">[1 more]</label></div><br/><div class="children"><div class="content">The word &quot;we&quot; is doing a lot of heavy lifting here. A large majority of consumers can&#x27;t even tell apart AI-generated from handmade, let alone care who or what made the thing.</div><br/></div></div></div></div></div></div><div id="39076620" class="c"><input type="checkbox" id="c-39076620" checked=""/><div class="controls bullet"><span class="by">snerc</span><span>|</span><a href="#39071494">prev</a><span>|</span><a href="#39070676">next</a><span>|</span><label class="collapse" for="c-39076620">[-]</label><label class="expand" for="c-39076620">[1 more]</label></div><br/><div class="children"><div class="content">I wonder if we know enough about any of these systems to make such claims. This is all predicated on the fact that this tool will be in widespread use. If it is somehow widely used beyond the folks who have seen it at the top of HN, won&#x27;t the big firms have countermeasures, ready to deploy?</div><br/></div></div><div id="39070676" class="c"><input type="checkbox" id="c-39070676" checked=""/><div class="controls bullet"><span class="by">alentred</span><span>|</span><a href="#39076620">prev</a><span>|</span><a href="#39068525">next</a><span>|</span><label class="collapse" for="c-39070676">[-]</label><label class="expand" for="c-39070676">[6 more]</label></div><br/><div class="children"><div class="content">With this &quot;solution&quot; it looks like the world of art enters the cat-and-mouse game the ad blockers were playing for the last decade or two.</div><br/><div id="39070816" class="c"><input type="checkbox" id="c-39070816" checked=""/><div class="controls bullet"><span class="by">isodev</span><span>|</span><a href="#39070676">parent</a><span>|</span><a href="#39070883">next</a><span>|</span><label class="collapse" for="c-39070816">[-]</label><label class="expand" for="c-39070816">[3 more]</label></div><br/><div class="children"><div class="content">I just tested it with Azure AI image classification and it worked - so this cat is yet to adapt to the mouse’s latest idea.<p>I still feel it is absolutely wrong to roam around the internet and scrape images (without consent) in order to power one’s cash cow AI. I hope more methods to protect artworks (including audio and other formats) become more accessible.</div><br/><div id="39074680" class="c"><input type="checkbox" id="c-39074680" checked=""/><div class="controls bullet"><span class="by">HKH2</span><span>|</span><a href="#39070676">root</a><span>|</span><a href="#39070816">parent</a><span>|</span><a href="#39070883">next</a><span>|</span><label class="collapse" for="c-39074680">[-]</label><label class="expand" for="c-39074680">[2 more]</label></div><br/><div class="children"><div class="content">Artists copy from each other all the time. Arguably, culture exists because of copying (folk stories by necessity); copyright makes culture top-down and stagnant, and you can&#x27;t avoid it because they have the money to shove it right in your face. Who wants trickle-down culture?</div><br/><div id="39075165" class="c"><input type="checkbox" id="c-39075165" checked=""/><div class="controls bullet"><span class="by">blibble</span><span>|</span><a href="#39070676">root</a><span>|</span><a href="#39074680">parent</a><span>|</span><a href="#39070883">next</a><span>|</span><label class="collapse" for="c-39075165">[-]</label><label class="expand" for="c-39075165">[1 more]</label></div><br/><div class="children"><div class="content">it&#x27;s not an artist, it&#x27;s a piece of software<p>in the same way bittorrent or gzip is</div><br/></div></div></div></div></div></div><div id="39070883" class="c"><input type="checkbox" id="c-39070883" checked=""/><div class="controls bullet"><span class="by">KTibow</span><span>|</span><a href="#39070676">parent</a><span>|</span><a href="#39070816">prev</a><span>|</span><a href="#39068525">next</a><span>|</span><label class="collapse" for="c-39070883">[-]</label><label class="expand" for="c-39070883">[2 more]</label></div><br/><div class="children"><div class="content">I might be missing something because I don&#x27;t know much about the architecture of either Nightshade or AI art generators, but I wonder if you could try to have a GAN-like architecture (an extra model trying to trick the model) for the part of the generator that labels images to build resistance to Nightshade-like filters.</div><br/><div id="39071288" class="c"><input type="checkbox" id="c-39071288" checked=""/><div class="controls bullet"><span class="by">the8472</span><span>|</span><a href="#39070676">root</a><span>|</span><a href="#39070883">parent</a><span>|</span><a href="#39068525">next</a><span>|</span><label class="collapse" for="c-39071288">[-]</label><label class="expand" for="c-39071288">[1 more]</label></div><br/><div class="children"><div class="content">It doesn&#x27;t even have to be a full GAN, you only need to train the discriminator side to filter out the data. Clean reference images + Nightshade would be the generator side.</div><br/></div></div></div></div></div></div><div id="39068525" class="c"><input type="checkbox" id="c-39068525" checked=""/><div class="controls bullet"><span class="by">jamesu</span><span>|</span><a href="#39070676">prev</a><span>|</span><a href="#39070835">next</a><span>|</span><label class="collapse" for="c-39068525">[-]</label><label class="expand" for="c-39068525">[7 more]</label></div><br/><div class="children"><div class="content">Long-term I think the real problem for artists will be corporations generating their own high quality targeted datasets from a cheap labor pool, completely outcompeting them by a landslide.</div><br/><div id="39072226" class="c"><input type="checkbox" id="c-39072226" checked=""/><div class="controls bullet"><span class="by">jdietrich</span><span>|</span><a href="#39068525">parent</a><span>|</span><a href="#39071476">next</a><span>|</span><label class="collapse" for="c-39072226">[-]</label><label class="expand" for="c-39072226">[1 more]</label></div><br/><div class="children"><div class="content">In the short-to-medium term, we&#x27;re seeing huge improvements in the data efficiency of generative models. We haven&#x27;t really started to see self-training in diffusion models, which could improve data efficiency by orders of magnitude. Current models are good at generalisation and are getting better at an incredible pace, so any efforts to limit the progress of AI by restricting access to training data is a speedbump rather than a roadblock.</div><br/></div></div><div id="39071778" class="c"><input type="checkbox" id="c-39071778" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068525">parent</a><span>|</span><a href="#39071476">prev</a><span>|</span><a href="#39070835">next</a><span>|</span><label class="collapse" for="c-39071778">[-]</label><label class="expand" for="c-39071778">[4 more]</label></div><br/><div class="children"><div class="content">It will democratize art.</div><br/><div id="39076690" class="c"><input type="checkbox" id="c-39076690" checked=""/><div class="controls bullet"><span class="by">sussmannbaka</span><span>|</span><a href="#39068525">root</a><span>|</span><a href="#39071778">parent</a><span>|</span><a href="#39072152">next</a><span>|</span><label class="collapse" for="c-39076690">[-]</label><label class="expand" for="c-39076690">[1 more]</label></div><br/><div class="children"><div class="content">Art is already democratized. It has been for decades. Everyone can pick it up at zero cost. Even you!<p>The poorest people have historically produced great art. Training a model, however? Expensive. Running it locally? Expensive. Paying the sub? Expensive.<p>Nothing is being democratized, the only thing this does is devaluing the blood and sweat people have put into their work so FAANG can sell it to lazy suckers.</div><br/></div></div><div id="39072152" class="c"><input type="checkbox" id="c-39072152" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#39068525">root</a><span>|</span><a href="#39071778">parent</a><span>|</span><a href="#39076690">prev</a><span>|</span><a href="#39070835">next</a><span>|</span><label class="collapse" for="c-39072152">[-]</label><label class="expand" for="c-39072152">[2 more]</label></div><br/><div class="children"><div class="content">then it won&#x27;t be art anymore, it&#x27;ll just be mountains of shit<p>sorta like what the laptop did for writing</div><br/><div id="39074447" class="c"><input type="checkbox" id="c-39074447" checked=""/><div class="controls bullet"><span class="by">jrflowers</span><span>|</span><a href="#39068525">root</a><span>|</span><a href="#39072152">parent</a><span>|</span><a href="#39070835">next</a><span>|</span><label class="collapse" for="c-39074447">[-]</label><label class="expand" for="c-39074447">[1 more]</label></div><br/><div class="children"><div class="content">This is a good point. There hasn’t been any writing since the release of the Gateway Solo in 1995</div><br/></div></div></div></div></div></div></div></div><div id="39070835" class="c"><input type="checkbox" id="c-39070835" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39068525">prev</a><span>|</span><a href="#39076658">next</a><span>|</span><label class="collapse" for="c-39070835">[-]</label><label class="expand" for="c-39070835">[6 more]</label></div><br/><div class="children"><div class="content">What the article doesn&#x27;t illustrate is that it destroys fine detail in the image, even in the thumbnails of the reference paper:
<a href="https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.13828.pdf" rel="nofollow">https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2310.13828.pdf</a><p>Also... Maybe I am naive, but it seems rather trivial to work around with a quick prefilter? I don&#x27;t know if tradition denoising would be enough, but worst case you could run img2img diffusion.<p>reply</div><br/><div id="39071269" class="c"><input type="checkbox" id="c-39071269" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39070835">parent</a><span>|</span><a href="#39076658">next</a><span>|</span><label class="collapse" for="c-39071269">[-]</label><label class="expand" for="c-39071269">[5 more]</label></div><br/><div class="children"><div class="content">The poisoned images aren&#x27;t intended to be viewed, rather scraped and pass a basic human screen. You wouldn&#x27;t be able to denoise as you&#x27;d have to denoise the entire dataset, the entire point is that these are virtually undetectable from typical training set examples, but they can push prompt frequencies around at will with a small number of poisoned examples.</div><br/><div id="39071603" class="c"><input type="checkbox" id="c-39071603" checked=""/><div class="controls bullet"><span class="by">minimaxir</span><span>|</span><a href="#39070835">root</a><span>|</span><a href="#39071269">parent</a><span>|</span><a href="#39076658">next</a><span>|</span><label class="collapse" for="c-39071603">[-]</label><label class="expand" for="c-39071603">[4 more]</label></div><br/><div class="children"><div class="content">&gt; You wouldn&#x27;t be able to denoise as you&#x27;d have to denoise the entire dataset<p>Doing that requires much less compute than training a large generative image model.</div><br/><div id="39071907" class="c"><input type="checkbox" id="c-39071907" checked=""/><div class="controls bullet"><span class="by">brucethemoose2</span><span>|</span><a href="#39070835">root</a><span>|</span><a href="#39071603">parent</a><span>|</span><a href="#39071898">next</a><span>|</span><label class="collapse" for="c-39071907">[-]</label><label class="expand" for="c-39071907">[2 more]</label></div><br/><div class="children"><div class="content">I guess the idea is that the model trainers are ignorant of this and wouldn&#x27;t know to preprocess&#x2F;wouldn&#x27;t bother?<p>That&#x27;s actually quite plausible.</div><br/><div id="39075025" class="c"><input type="checkbox" id="c-39075025" checked=""/><div class="controls bullet"><span class="by">BugsJustFindMe</span><span>|</span><a href="#39070835">root</a><span>|</span><a href="#39071907">parent</a><span>|</span><a href="#39071898">next</a><span>|</span><label class="collapse" for="c-39075025">[-]</label><label class="expand" for="c-39075025">[1 more]</label></div><br/><div class="children"><div class="content">&gt; <i>I guess the idea is that the model trainers are ignorant of this</i><p>Maybe they&#x27;re ignorant of it right up until you announce it, but then they&#x27;re no longer ignorant of it.</div><br/></div></div></div></div><div id="39071898" class="c"><input type="checkbox" id="c-39071898" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39070835">root</a><span>|</span><a href="#39071603">parent</a><span>|</span><a href="#39071907">prev</a><span>|</span><a href="#39076658">next</a><span>|</span><label class="collapse" for="c-39071898">[-]</label><label class="expand" for="c-39071898">[1 more]</label></div><br/><div class="children"><div class="content">&gt;  the entire point is that these are virtually undetectable from typical training set examples<p>I&#x27;ll repeat this point for clarity. After going over the paper again, denoising shouldn&#x27;t affect this attack, it&#x27;s the ability of plausible images to not be detected by human or AI discriminators (yet)</div><br/></div></div></div></div></div></div></div></div><div id="39076658" class="c"><input type="checkbox" id="c-39076658" checked=""/><div class="controls bullet"><span class="by">mattszaszko</span><span>|</span><a href="#39070835">prev</a><span>|</span><a href="#39068570">next</a><span>|</span><label class="collapse" for="c-39076658">[-]</label><label class="expand" for="c-39076658">[1 more]</label></div><br/><div class="children"><div class="content">This timeline is getting quite similar to the second season of Pantheon.</div><br/></div></div><div id="39068570" class="c"><input type="checkbox" id="c-39068570" checked=""/><div class="controls bullet"><span class="by">msp26</span><span>|</span><a href="#39076658">prev</a><span>|</span><a href="#39068368">next</a><span>|</span><label class="collapse" for="c-39068570">[-]</label><label class="expand" for="c-39068570">[2 more]</label></div><br/><div class="children"><div class="content">&gt;Like Glaze, Nightshade is computed as a multi-objective optimization that minimizes visible changes to the original image.<p>It&#x27;s still noticeably visible.</div><br/><div id="39068608" class="c"><input type="checkbox" id="c-39068608" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#39068570">parent</a><span>|</span><a href="#39068368">next</a><span>|</span><label class="collapse" for="c-39068608">[-]</label><label class="expand" for="c-39068608">[1 more]</label></div><br/><div class="children"><div class="content">Yeah, I&#x27;ve seen multiple artists complain about how glazing reduces image quality. It&#x27;s very noticeable. That seems like an unavoidable problem given how AI is trained on images right now.</div><br/></div></div></div></div><div id="39068368" class="c"><input type="checkbox" id="c-39068368" checked=""/><div class="controls bullet"><span class="by">eddd-ddde</span><span>|</span><a href="#39068570">prev</a><span>|</span><a href="#39075808">next</a><span>|</span><label class="collapse" for="c-39068368">[-]</label><label class="expand" for="c-39068368">[2 more]</label></div><br/><div class="children"><div class="content">Isn&#x27;t this just teaching the models how to better understand pictures as humans do? As long as you feed them content that looks good to a human, wouldn&#x27;t they improve in creating such content?</div><br/><div id="39074784" class="c"><input type="checkbox" id="c-39074784" checked=""/><div class="controls bullet"><span class="by">lern_too_spel</span><span>|</span><a href="#39068368">parent</a><span>|</span><a href="#39075808">next</a><span>|</span><label class="collapse" for="c-39074784">[-]</label><label class="expand" for="c-39074784">[1 more]</label></div><br/><div class="children"><div class="content">You would think the economists at UChicago would have told these researchers that their tool would achieve the opposite effect of what they intended, but here we are.<p>In this case, the mechanism for how it would work is effectively useless. It doesn&#x27;t affect OpenAI or other companies building foundation models. It only works on people fine-tuning these foundation models, and only if the image is glazed to affect the same foundation model.</div><br/></div></div></div></div><div id="39075808" class="c"><input type="checkbox" id="c-39075808" checked=""/><div class="controls bullet"><span class="by">ngneer</span><span>|</span><a href="#39068368">prev</a><span>|</span><a href="#39070808">next</a><span>|</span><label class="collapse" for="c-39075808">[-]</label><label class="expand" for="c-39075808">[1 more]</label></div><br/><div class="children"><div class="content">I love it. This undermines the notion of ground truth. What separates correct information from incorrect information? Maybe nothing! I love how they acknowledge the never ending attack versus defense game. In  stark contrast to &quot;our AI will solve all your problems&quot;.</div><br/></div></div><div id="39070808" class="c"><input type="checkbox" id="c-39070808" checked=""/><div class="controls bullet"><span class="by">garg</span><span>|</span><a href="#39075808">prev</a><span>|</span><a href="#39068339">next</a><span>|</span><label class="collapse" for="c-39070808">[-]</label><label class="expand" for="c-39070808">[1 more]</label></div><br/><div class="children"><div class="content">Each time there is an update to training algorithms and in response poisoning algorithms, artists will have to re-glaze, re-mist, and re-nightshade all their images?<p>Eventually I assume the poisoning artifacts introduced in the images will be very visible to humans as well.</div><br/></div></div><div id="39068339" class="c"><input type="checkbox" id="c-39068339" checked=""/><div class="controls bullet"><span class="by">popohauer</span><span>|</span><a href="#39070808">prev</a><span>|</span><a href="#39068302">next</a><span>|</span><label class="collapse" for="c-39068339">[-]</label><label class="expand" for="c-39068339">[4 more]</label></div><br/><div class="children"><div class="content">I&#x27;m glad to see tools like Nightshade starting to pop up to protect the real life creativity of artists. I like AI art, but I do feel conflicted about its potential long term effects towards a society that no longer values authentic creativity.</div><br/><div id="39070992" class="c"><input type="checkbox" id="c-39070992" checked=""/><div class="controls bullet"><span class="by">Minor49er</span><span>|</span><a href="#39068339">parent</a><span>|</span><a href="#39068302">next</a><span>|</span><label class="collapse" for="c-39070992">[-]</label><label class="expand" for="c-39070992">[3 more]</label></div><br/><div class="children"><div class="content">Is the existence of the AI tool not itself a product of authentic creativity? Does eliminating barriers to image generation not facilitate authentic creativity?</div><br/><div id="39072142" class="c"><input type="checkbox" id="c-39072142" checked=""/><div class="controls bullet"><span class="by">23B1</span><span>|</span><a href="#39068339">root</a><span>|</span><a href="#39070992">parent</a><span>|</span><a href="#39068302">next</a><span>|</span><label class="collapse" for="c-39072142">[-]</label><label class="expand" for="c-39072142">[2 more]</label></div><br/><div class="children"><div class="content">No, it facilitates commoditization. Art – real art – is fundamentally a human-to-human transaction. Once everyone can fire perfectly-rendered perfectly-unique pieces of &#x27;art&#x27; at each other, it&#x27;ll just become like the internet is today: filled with extremely low-value noise.<p>Enjoy the short term novelty while you can.</div><br/><div id="39073261" class="c"><input type="checkbox" id="c-39073261" checked=""/><div class="controls bullet"><span class="by">fulladder</span><span>|</span><a href="#39068339">root</a><span>|</span><a href="#39072142">parent</a><span>|</span><a href="#39068302">next</a><span>|</span><label class="collapse" for="c-39073261">[-]</label><label class="expand" for="c-39073261">[1 more]</label></div><br/><div class="children"><div class="content">This is the right prediction. Once machines can generate visual art, people will simply stop valuing it. We may see increased interest in other forms of art, e.g., live performance art like theater. It&#x27;s hard to predict exactly how it&#x27;ll play out, but once something becomes cheap to produce and widely available, it loses its luster for connoisseurs and then gradually loses its luster for everybody else too.</div><br/></div></div></div></div></div></div></div></div><div id="39068302" class="c"><input type="checkbox" id="c-39068302" checked=""/><div class="controls bullet"><span class="by">Quanttek</span><span>|</span><a href="#39068339">prev</a><span>|</span><a href="#39071095">next</a><span>|</span><label class="collapse" for="c-39068302">[-]</label><label class="expand" for="c-39068302">[25 more]</label></div><br/><div class="children"><div class="content">This is fantastic. If companies want to create AI models, they should license the content they use for the training data. As long as there are not sufficient legal protections and the EU&#x2F;Congress do not act, tools like these can serve as a stopgap and maybe help increase pressure on policymakers</div><br/><div id="39068494" class="c"><input type="checkbox" id="c-39068494" checked=""/><div class="controls bullet"><span class="by">popohauer</span><span>|</span><a href="#39068302">parent</a><span>|</span><a href="#39068328">next</a><span>|</span><label class="collapse" for="c-39068494">[-]</label><label class="expand" for="c-39068494">[6 more]</label></div><br/><div class="children"><div class="content">It&#x27;s going to be interesting to see how the lawsuits against OpenAI by content creators plays out. If the courts rule that AI generated content is a derivative work of all the content it was trained on it could really flip the entire gen AI movement on its head.</div><br/><div id="39068583" class="c"><input type="checkbox" id="c-39068583" checked=""/><div class="controls bullet"><span class="by">luma</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068494">parent</a><span>|</span><a href="#39068328">next</a><span>|</span><label class="collapse" for="c-39068583">[-]</label><label class="expand" for="c-39068583">[5 more]</label></div><br/><div class="children"><div class="content">If it were a derivative work[1] (and sufficiently transformational) then it&#x27;s allowed under current copyright law and might not be the slam dunk ruling you were hoping for.<p>[1] <a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Derivative_work" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Derivative_work</a></div><br/><div id="39071806" class="c"><input type="checkbox" id="c-39071806" checked=""/><div class="controls bullet"><span class="by">popohauer</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068583">parent</a><span>|</span><a href="#39071947">next</a><span>|</span><label class="collapse" for="c-39071806">[-]</label><label class="expand" for="c-39071806">[1 more]</label></div><br/><div class="children"><div class="content">Oh, interesting, I didn&#x27;t realize that&#x27;s how it worked. Thanks for the additional context around this. Guess it&#x27;s not as upending as I thought it could be.</div><br/></div></div><div id="39071947" class="c"><input type="checkbox" id="c-39071947" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068583">parent</a><span>|</span><a href="#39071806">prev</a><span>|</span><a href="#39068618">next</a><span>|</span><label class="collapse" for="c-39071947">[-]</label><label class="expand" for="c-39071947">[1 more]</label></div><br/><div class="children"><div class="content">Not if it is AI generated. So far only humans can be original enough to warrant copyrights, at least in the US .<p>BTW, the right to prepare derivative works belongs to the copyright holder of the reference work.<p>I doubt that many AI works are in fact derivative works. Sure, some bear enough similarity, but a gross majority likely doesn&#x27;t.</div><br/></div></div><div id="39068618" class="c"><input type="checkbox" id="c-39068618" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068583">parent</a><span>|</span><a href="#39071947">prev</a><span>|</span><a href="#39068328">next</a><span>|</span><label class="collapse" for="c-39068618">[-]</label><label class="expand" for="c-39068618">[2 more]</label></div><br/><div class="children"><div class="content">&quot;sufficiently transformational&quot; is carrying a lot of water here. At minimum it would cloud the issue and might expose anyone using AI to lawsuits where they&#x27;d potentially have to defend each generated image.</div><br/><div id="39071964" class="c"><input type="checkbox" id="c-39071964" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068618">parent</a><span>|</span><a href="#39068328">next</a><span>|</span><label class="collapse" for="c-39071964">[-]</label><label class="expand" for="c-39071964">[1 more]</label></div><br/><div class="children"><div class="content">Sufficiently transformational only applies to copyrightability, but AI works are not copyrightable under current US law, so it&#x27;s a non-issue.</div><br/></div></div></div></div></div></div></div></div><div id="39068328" class="c"><input type="checkbox" id="c-39068328" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#39068302">parent</a><span>|</span><a href="#39068494">prev</a><span>|</span><a href="#39071095">next</a><span>|</span><label class="collapse" for="c-39068328">[-]</label><label class="expand" for="c-39068328">[18 more]</label></div><br/><div class="children"><div class="content">&gt;  they should license the content they use for the training data<p>You mean like OpenAI and Adobe ?<p>Only the free and open source models didn&#x27;t licensed any content for the training data.</div><br/><div id="39068399" class="c"><input type="checkbox" id="c-39068399" checked=""/><div class="controls bullet"><span class="by">galleywest200</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068328">parent</a><span>|</span><a href="#39068452">next</a><span>|</span><label class="collapse" for="c-39068399">[-]</label><label class="expand" for="c-39068399">[15 more]</label></div><br/><div class="children"><div class="content">Adobe is training off of images stored in their cloud systems, per their Terms of Service.<p>OpenAI has provided no such documentation or legal guarantees, and it is still quite possible they scraped all sorts of copyright materials.</div><br/><div id="39068613" class="c"><input type="checkbox" id="c-39068613" checked=""/><div class="controls bullet"><span class="by">luma</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068399">parent</a><span>|</span><a href="#39075068">next</a><span>|</span><label class="collapse" for="c-39068613">[-]</label><label class="expand" for="c-39068613">[11 more]</label></div><br/><div class="children"><div class="content">Google scrapes copyrighted material every day and then presents that material to users in the form of excerpts, images, and entire book pages.  This has been ruled OK by the courts.  Scraping copyrighted information is not illegal or we couldn&#x27;t have search engines.</div><br/><div id="39071990" class="c"><input type="checkbox" id="c-39071990" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068613">parent</a><span>|</span><a href="#39068628">next</a><span>|</span><label class="collapse" for="c-39071990">[-]</label><label class="expand" for="c-39071990">[2 more]</label></div><br/><div class="children"><div class="content">Scraping is only legal if it&#x27;s temporary and transformational. If Google started selling the scrapped images it would be a different story.</div><br/><div id="39074032" class="c"><input type="checkbox" id="c-39074032" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39071990">parent</a><span>|</span><a href="#39068628">next</a><span>|</span><label class="collapse" for="c-39074032">[-]</label><label class="expand" for="c-39074032">[1 more]</label></div><br/><div class="children"><div class="content">What is not transformational for generative AI ?</div><br/></div></div></div></div><div id="39068628" class="c"><input type="checkbox" id="c-39068628" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068613">parent</a><span>|</span><a href="#39071990">prev</a><span>|</span><a href="#39075068">next</a><span>|</span><label class="collapse" for="c-39068628">[-]</label><label class="expand" for="c-39068628">[8 more]</label></div><br/><div class="children"><div class="content">Google is not presently selling &quot;we trained an AI on people&#x27;s art without permission, and you can type their name in along with a prompt to generate a knockoff of their art, and we charge you money for this&quot;. So it&#x27;s not really a 1:1 comparison, since there are companies selling the thing I described right now.</div><br/><div id="39070190" class="c"><input type="checkbox" id="c-39070190" checked=""/><div class="controls bullet"><span class="by">luma</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068628">parent</a><span>|</span><a href="#39075068">next</a><span>|</span><label class="collapse" for="c-39070190">[-]</label><label class="expand" for="c-39070190">[7 more]</label></div><br/><div class="children"><div class="content">That pretty clearly would fall under transformative work.  It is not illegal for a human to paint a painting in the style of, say, Banksy, and then sell the resulting painting.</div><br/><div id="39070426" class="c"><input type="checkbox" id="c-39070426" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070190">parent</a><span>|</span><a href="#39075068">next</a><span>|</span><label class="collapse" for="c-39070426">[-]</label><label class="expand" for="c-39070426">[6 more]</label></div><br/><div class="children"><div class="content">Humans and AI are not the same thing, legally or physically. The law does not currently grant AI rights of any kind.</div><br/><div id="39070751" class="c"><input type="checkbox" id="c-39070751" checked=""/><div class="controls bullet"><span class="by">luma</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070426">parent</a><span>|</span><a href="#39072003">next</a><span>|</span><label class="collapse" for="c-39070751">[-]</label><label class="expand" for="c-39070751">[4 more]</label></div><br/><div class="children"><div class="content">If a human isn&#x27;t violating the law when doing that thing, then how is the machine violating the law when it cannot even hold copyright itself?</div><br/><div id="39071341" class="c"><input type="checkbox" id="c-39071341" checked=""/><div class="controls bullet"><span class="by">estebank</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070751">parent</a><span>|</span><a href="#39070757">next</a><span>|</span><label class="collapse" for="c-39071341">[-]</label><label class="expand" for="c-39071341">[1 more]</label></div><br/><div class="children"><div class="content">In some locales sitting on the street writing down a list of people coming and going is legal, but leaving a camera pointed at the street isn&#x27;t. Legislation like that makes a distinction between an action by a person (which has bounds on scalability) and mechanized actions (that do not).</div><br/></div></div><div id="39070757" class="c"><input type="checkbox" id="c-39070757" checked=""/><div class="controls bullet"><span class="by">kevingadd</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070751">parent</a><span>|</span><a href="#39071341">prev</a><span>|</span><a href="#39072003">next</a><span>|</span><label class="collapse" for="c-39070757">[-]</label><label class="expand" for="c-39070757">[2 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not sure how to explain this any clearer: Humans and machines are legally distinct. Machines don&#x27;t have the rights that humans have.</div><br/><div id="39071609" class="c"><input type="checkbox" id="c-39071609" checked=""/><div class="controls bullet"><span class="by">Ukv</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070757">parent</a><span>|</span><a href="#39072003">next</a><span>|</span><label class="collapse" for="c-39071609">[-]</label><label class="expand" for="c-39071609">[1 more]</label></div><br/><div class="children"><div class="content">Fair Use is the relevant protection and is not specific to manual creation. Traditional algorithms (e.g: the snippets, caching, and thumbnailing done by search engines) are already covered by it.</div><br/></div></div></div></div></div></div><div id="39072003" class="c"><input type="checkbox" id="c-39072003" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39070426">parent</a><span>|</span><a href="#39070751">prev</a><span>|</span><a href="#39075068">next</a><span>|</span><label class="collapse" for="c-39072003">[-]</label><label class="expand" for="c-39072003">[1 more]</label></div><br/><div class="children"><div class="content">What&#x27;s not prohibited is allowed, at least in the US.</div><br/></div></div></div></div></div></div></div></div></div></div><div id="39075068" class="c"><input type="checkbox" id="c-39075068" checked=""/><div class="controls bullet"><span class="by">mesh</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068399">parent</a><span>|</span><a href="#39068613">prev</a><span>|</span><a href="#39068470">next</a><span>|</span><label class="collapse" for="c-39075068">[-]</label><label class="expand" for="c-39075068">[1 more]</label></div><br/><div class="children"><div class="content">No they are not. They train their models on Adobe Stock content. They do not train on user content.<p><a href="https:&#x2F;&#x2F;helpx.adobe.com&#x2F;manage-account&#x2F;using&#x2F;machine-learning-faq.html" rel="nofollow">https:&#x2F;&#x2F;helpx.adobe.com&#x2F;manage-account&#x2F;using&#x2F;machine-learnin...</a><p>&quot;The insights obtained through content analysis will not be used to re-create your content or lead to identifying any personal information.&quot;<p>&quot;For Adobe Firefly, the first model is trained on Adobe Stock images, openly licensed content, and public domain content where the copyright has expired.&quot;<p>(I work for Adobe)</div><br/></div></div><div id="39068470" class="c"><input type="checkbox" id="c-39068470" checked=""/><div class="controls bullet"><span class="by">Kuinox</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068399">parent</a><span>|</span><a href="#39075068">prev</a><span>|</span><a href="#39068434">next</a><span>|</span><label class="collapse" for="c-39068470">[-]</label><label class="expand" for="c-39068470">[1 more]</label></div><br/><div class="children"><div class="content">&gt; OpenAI has provided no such documentation<p>OpenAI and Shutterstocks publicly announced their collaboration, Shutterstocks sells AI generated images, generated with OpenAI models.</div><br/></div></div><div id="39068434" class="c"><input type="checkbox" id="c-39068434" checked=""/><div class="controls bullet"><span class="by">devmor</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068399">parent</a><span>|</span><a href="#39068470">prev</a><span>|</span><a href="#39068452">next</a><span>|</span><label class="collapse" for="c-39068434">[-]</label><label class="expand" for="c-39068434">[1 more]</label></div><br/><div class="children"><div class="content">There is in fact, an extreme amount of circumstantial evidence that they intentionally and knowingly violated copyright en mass. It’s been quite a popular subject in tech news the past couple weeks.</div><br/></div></div></div></div><div id="39068452" class="c"><input type="checkbox" id="c-39068452" checked=""/><div class="controls bullet"><span class="by">KeplerBoy</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068328">parent</a><span>|</span><a href="#39068399">prev</a><span>|</span><a href="#39068578">next</a><span>|</span><label class="collapse" for="c-39068452">[-]</label><label class="expand" for="c-39068452">[1 more]</label></div><br/><div class="children"><div class="content">There is a small difference between any and all. OpenAI certainly didn&#x27;t licence all of the image they use for training.</div><br/></div></div><div id="39068578" class="c"><input type="checkbox" id="c-39068578" checked=""/><div class="controls bullet"><span class="by">jazzyjackson</span><span>|</span><a href="#39068302">root</a><span>|</span><a href="#39068328">parent</a><span>|</span><a href="#39068452">prev</a><span>|</span><a href="#39071095">next</a><span>|</span><label class="collapse" for="c-39068578">[-]</label><label class="expand" for="c-39068578">[1 more]</label></div><br/><div class="children"><div class="content">source for OpenAI paying anyone a dime? don&#x27;t you think that would set a precedent that everyone else deserves their cut?</div><br/></div></div></div></div></div></div><div id="39071095" class="c"><input type="checkbox" id="c-39071095" checked=""/><div class="controls bullet"><span class="by">ang_cire</span><span>|</span><a href="#39068302">prev</a><span>|</span><a href="#39071067">next</a><span>|</span><label class="collapse" for="c-39071095">[-]</label><label class="expand" for="c-39071095">[12 more]</label></div><br/><div class="children"><div class="content">Setting aside the efficacy of this tool, I would be very interested in the legal implications of putting designs in your art that could corrupt ML models.<p>For instance, if I set traps in my home which hurt an intruder we are both guilty of crimes (traps are illegal and are never considered self defense, B&amp;E is illegal).<p>Would I be responsible for corrupting the AI operator&#x27;s data if I intentionally include adversarial artifacts to corrupt models, or is that just DRM to legally protect my art from infringement?<p>edit:<p>I replied to someone else, but this is probably good context:<p>DRM is legally allowed to disable or even corrupt the software or media that it is protecting, if it detects misuse.<p>If an adversarial-AI tool attacks the model, it then becomes a question of whether the model, having now incorporated my protected art, is now &quot;mine&quot; to disable&#x2F;corrupt, or whether it is in fact out of bounds of DRM.<p>So for instance, a court could say that the adversarial-AI methods could only actively prevent the training software from incorporating the protected media into a model, but could not corrupt the model itself.</div><br/><div id="39071133" class="c"><input type="checkbox" id="c-39071133" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39074455">next</a><span>|</span><label class="collapse" for="c-39071133">[-]</label><label class="expand" for="c-39071133">[4 more]</label></div><br/><div class="children"><div class="content">None whatsoever. There is no right to good data for model training, nor does any contractual relationship exist between you and and a model builder who scrapes your website.</div><br/><div id="39071597" class="c"><input type="checkbox" id="c-39071597" checked=""/><div class="controls bullet"><span class="by">ang_cire</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39071133">parent</a><span>|</span><a href="#39074455">next</a><span>|</span><label class="collapse" for="c-39071597">[-]</label><label class="expand" for="c-39071597">[3 more]</label></div><br/><div class="children"><div class="content">If you&#x27;re assuming this is open-shut, you&#x27;re wrong. I asked this specifically as someone who works in security. A court is going to have to decide where the line is between DRM and malware in adversarial-AI tools.</div><br/><div id="39072770" class="c"><input type="checkbox" id="c-39072770" checked=""/><div class="controls bullet"><span class="by">anigbrowl</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39071597">parent</a><span>|</span><a href="#39071850">next</a><span>|</span><label class="collapse" for="c-39072770">[-]</label><label class="expand" for="c-39072770">[1 more]</label></div><br/><div class="children"><div class="content">I&#x27;m not. Malware is one thin, passive data poisoning is another. Mapmakers have long used such devices to detect&#x2F;deter unwanted copying. In the US such &#x27;trap streets&#x27; are not protected by copyright, but nor do they generate liability.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trap_street" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trap_street</a></div><br/></div></div><div id="39071850" class="c"><input type="checkbox" id="c-39071850" checked=""/><div class="controls bullet"><span class="by">ufocia</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39071597">parent</a><span>|</span><a href="#39072770">prev</a><span>|</span><a href="#39074455">next</a><span>|</span><label class="collapse" for="c-39071850">[-]</label><label class="expand" for="c-39071850">[1 more]</label></div><br/><div class="children"><div class="content">Worth trying but I doubt it unless we establish a right to train.</div><br/></div></div></div></div></div></div><div id="39074455" class="c"><input type="checkbox" id="c-39074455" checked=""/><div class="controls bullet"><span class="by">danShumway</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39071133">prev</a><span>|</span><a href="#39071261">next</a><span>|</span><label class="collapse" for="c-39074455">[-]</label><label class="expand" for="c-39074455">[1 more]</label></div><br/><div class="children"><div class="content">The way Nightshade works (assuming it does work) is by confusing the features of different tags with each other. To argue that this is illegal would be to argue that mistagging a piece of artwork on a gallery is illegal.<p>If you upload a picture of a dog to DeviantArt and you label it as a cat, and a model ingests that image and starts to think that cats look like dogs, would anybody claim that you are breaking a law? If you upload bad code to Github that has bugs, and an AI model consumes that code and then reproduces the bugs, would anyone argue that uploading badly written code to Github is a crime?<p>What if you uploaded some bad code to Github and then wrote a comment at the top of the code explaining what the error was, because you knew that the model would ignore that comment and would still look at the bad code. Then would you be committing a crime by putting that code on Github?<p>Even if it could be proven that your <i>intention</i> was for that code or that mistagged image to be unhelpful to training, it would still be a huge leap to say that either of those activities were criminal -- I would hope that the majority of HN would see that as a dangerous legal road to travel down.</div><br/></div></div><div id="39071261" class="c"><input type="checkbox" id="c-39071261" checked=""/><div class="controls bullet"><span class="by">kortilla</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39074455">prev</a><span>|</span><a href="#39073650">next</a><span>|</span><label class="collapse" for="c-39071261">[-]</label><label class="expand" for="c-39071261">[3 more]</label></div><br/><div class="children"><div class="content">That’s like asking if lying on a forum is illegal</div><br/><div id="39071583" class="c"><input type="checkbox" id="c-39071583" checked=""/><div class="controls bullet"><span class="by">ang_cire</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39071261">parent</a><span>|</span><a href="#39073650">next</a><span>|</span><label class="collapse" for="c-39071583">[-]</label><label class="expand" for="c-39071583">[2 more]</label></div><br/><div class="children"><div class="content">No, it&#x27;s much closer to (in fact, it is simply) asking if adversarial AI tools count as DRM or as malware. And a court is going to have to decide whether the model and or its output counts as separate software, which it is illegal for DRM to intentionally attack.<p>DRM can, for instance, disable its own parent tool (e.g. a video game) if it detects misuse, but it can&#x27;t attack the host computer or other software on that computer.<p>So is the model or its output, having been trained on my art, a byproduct of my art, in which case I have a legal right to &#x27;disable&#x27; it, or is it separate software that I don&#x27;t have a right to corrupt?</div><br/><div id="39074545" class="c"><input type="checkbox" id="c-39074545" checked=""/><div class="controls bullet"><span class="by">danShumway</span><span>|</span><a href="#39071095">root</a><span>|</span><a href="#39071583">parent</a><span>|</span><a href="#39073650">next</a><span>|</span><label class="collapse" for="c-39074545">[-]</label><label class="expand" for="c-39074545">[1 more]</label></div><br/><div class="children"><div class="content">&gt; asking if adversarial AI tools count as DRM or as malware<p>Neither. Nightshade is not DRM or malware, it&#x27;s &quot;lying&quot; about the contents of an image.<p>Arguably, Nightshade does not corrupt or disable the model at all. It feeds it bad data that leads the model to generate incorrect conclusions or patterns about how to generate images. This is assuming it works, which we&#x27;ll have to wait and see, I&#x27;m not taking that as a given.<p>But the only &quot;corruption&quot; happening here is that the model is being fed data that it &quot;trusts&quot; without verifying that what the data is &quot;telling&quot; it is correct. It&#x27;s not disabling the model or crashing it, the model is forming incorrect conclusions and patterns about how to generate the image. If Google translate asked you to rate its performance on a task, and you gave it an incorrect rating from what you actually thought its performance was, is that DRM? Malware? Have you disabled Google translate by giving it bad feedback?<p>I don&#x27;t think the framing of this as either DRM or malware is correct. This is bad training data. Assuming it works, it works because it&#x27;s bad training data -- that&#x27;s why ingesting one or two images doesn&#x27;t affect models but ingesting a lot of images does, because training a model on bad data leads the model to perform worse if and only if there is enough of that bad data. And so what we&#x27;re really talking about here is not a question of DRM or malware, it&#x27;s a question of whether or not artists have a legal obligation to make their data useful for training -- and of course they don&#x27;t. The implications of saying that they did would be enormous, it would imply that any time you knowingly lied about a question that was being fed into an AI training set that doing so was illegal.</div><br/></div></div></div></div></div></div><div id="39073650" class="c"><input type="checkbox" id="c-39073650" checked=""/><div class="controls bullet"><span class="by">npteljes</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39071261">prev</a><span>|</span><a href="#39072593">next</a><span>|</span><label class="collapse" for="c-39073650">[-]</label><label class="expand" for="c-39073650">[1 more]</label></div><br/><div class="children"><div class="content">I see it as no different than mapmakers inventing a nonexistent alley, to check who copies their maps verbatim (&quot;trap street&quot;). Even if this caused, for example, a car crash because of an autonomous driver, the onus I think would be on the one that made the car and used the stolen map for navigation, and not on the one that created the original map.<p><a href="https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trap_street" rel="nofollow">https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Trap_street</a></div><br/></div></div><div id="39072593" class="c"><input type="checkbox" id="c-39072593" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39073650">prev</a><span>|</span><a href="#39071279">next</a><span>|</span><label class="collapse" for="c-39072593">[-]</label><label class="expand" for="c-39072593">[1 more]</label></div><br/><div class="children"><div class="content">Japan is considering it, I think? <a href="https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38615280">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38615280</a></div><br/></div></div><div id="39071279" class="c"><input type="checkbox" id="c-39071279" checked=""/><div class="controls bullet"><span class="by">GaryNumanVevo</span><span>|</span><a href="#39071095">parent</a><span>|</span><a href="#39072593">prev</a><span>|</span><a href="#39071067">next</a><span>|</span><label class="collapse" for="c-39071279">[-]</label><label class="expand" for="c-39071279">[1 more]</label></div><br/><div class="children"><div class="content">How would that situation be remotely related?</div><br/></div></div></div></div><div id="39071067" class="c"><input type="checkbox" id="c-39071067" checked=""/><div class="controls bullet"><span class="by">gweinberg</span><span>|</span><a href="#39071095">prev</a><span>|</span><a href="#39076214">next</a><span>|</span><label class="collapse" for="c-39071067">[-]</label><label class="expand" for="c-39071067">[1 more]</label></div><br/><div class="children"><div class="content">For this to work, wouldn&#x27;t you have to have an enormous number of artists collaborating on &quot;poisoning&quot; their images the same way (cow to handbag) while somehow keeping it secret form ai trainers that they were doing this?
It seems to me that even if the technology works perfectly as intended, you&#x27;re effectively just mislabeling a tiny fraction of the training data.</div><br/></div></div><div id="39076214" class="c"><input type="checkbox" id="c-39076214" checked=""/><div class="controls bullet"><span class="by">24karrotts_</span><span>|</span><a href="#39071067">prev</a><span>|</span><a href="#39071766">next</a><span>|</span><label class="collapse" for="c-39076214">[-]</label><label class="expand" for="c-39076214">[1 more]</label></div><br/><div class="children"><div class="content">If you decrease quality of art, you give AI all the advantage in the market.</div><br/></div></div><div id="39071766" class="c"><input type="checkbox" id="c-39071766" checked=""/><div class="controls bullet"><span class="by">squidbeak</span><span>|</span><a href="#39076214">prev</a><span>|</span><a href="#39070921">next</a><span>|</span><label class="collapse" for="c-39071766">[-]</label><label class="expand" for="c-39071766">[9 more]</label></div><br/><div class="children"><div class="content">I really don&#x27;t understand the anxiety of artists towards AI - as if creatives haven&#x27;t always borrowed and imitated. Every leading artist has had acolytes, and while it&#x27;s true no artist ever had an acolyte as prodigiously productive as AI will be, I don&#x27;t see anything different between a young artist looking to Picasso for cues and Stable Diffusion or DALL-E doing the same. Styles and methods haven&#x27;t ever been subject to copyright - and art would die the moment that changed.<p>The only explanation I can find for this backlash is that artists are actually worried just like the rest of us that pretty soon AI will produce higher quality more inventive work faster and more imaginatively than they can - which is very natural, but not a reason to inhibit an AI&#x27;s creative education.</div><br/><div id="39071892" class="c"><input type="checkbox" id="c-39071892" checked=""/><div class="controls bullet"><span class="by">beepbooptheory</span><span>|</span><a href="#39071766">parent</a><span>|</span><a href="#39072185">next</a><span>|</span><label class="collapse" for="c-39071892">[-]</label><label class="expand" for="c-39071892">[1 more]</label></div><br/><div class="children"><div class="content">This has been litigated over and over again, and there have been plenty of good points made and concerns raised over it by those who it actually affects.  It seems a little bit disingenuous (especially in this forum) to say that that conclusion is the &quot;only explanation&quot; you can come up with.  And just to avoid prompting you too much: trust me, we all know or can guess why you think AI art is a good thing regardless of any concerns one might bring up.</div><br/></div></div><div id="39072132" class="c"><input type="checkbox" id="c-39072132" checked=""/><div class="controls bullet"><span class="by">jwells89</span><span>|</span><a href="#39071766">parent</a><span>|</span><a href="#39072185">prev</a><span>|</span><a href="#39070921">next</a><span>|</span><label class="collapse" for="c-39072132">[-]</label><label class="expand" for="c-39072132">[1 more]</label></div><br/><div class="children"><div class="content">Imitation isn’t the problem so much as it is that ML generated images are composed of a mush of the images it was trained on. A human artist can abstract the concepts underpinning a style and mimic it by drawing all-new lineart, coloration, shading, composition, etc, while the ML model has to lean on blending training imagery together.<p>Furthermore there’s a sort of unavoidable “jitter” in human-produced art that varies between individuals that stems from vastly different ways of thinking, perception of the world, mental abstraction processes, life experiences, etc. This is why artists who start out imitating other artists almost always develop their imitations into a style all their own — the imitations were already appreciably different from the original due to the aforementioned biases and those distinctions only grow with time and experimentation.<p>There would be greatly reduced moral controversy surrounding ML models if they lacked that mincemeat&#x2F;pink slime aspect.</div><br/></div></div></div></div><div id="39070921" class="c"><input type="checkbox" id="c-39070921" checked=""/><div class="controls bullet"><span class="by">enord</span><span>|</span><a href="#39071766">prev</a><span>|</span><a href="#39068487">next</a><span>|</span><label class="collapse" for="c-39070921">[-]</label><label class="expand" for="c-39070921">[6 more]</label></div><br/><div class="children"><div class="content">I’m completely flabbergasted by the number of comments implying copyright concepts such as “fair use” or “derivative work” apply to trained ML models. Copyright is for _people_, as are the entailing rights, responsibilities and exemptions.
This has gone far beyond anthropomorphising and we need to like get it together, man!</div><br/><div id="39071386" class="c"><input type="checkbox" id="c-39071386" checked=""/><div class="controls bullet"><span class="by">ronsor</span><span>|</span><a href="#39070921">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39071386">[-]</label><label class="expand" for="c-39071386">[3 more]</label></div><br/><div class="children"><div class="content">You act like computers and ML models aren&#x27;t just tools used by people.</div><br/><div id="39074156" class="c"><input type="checkbox" id="c-39074156" checked=""/><div class="controls bullet"><span class="by">enord</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39071386">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39074156">[-]</label><label class="expand" for="c-39074156">[2 more]</label></div><br/><div class="children"><div class="content">What did I write to give you that impression?</div><br/><div id="39075051" class="c"><input type="checkbox" id="c-39075051" checked=""/><div class="controls bullet"><span class="by">Ukv</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39074156">parent</a><span>|</span><a href="#39072640">next</a><span>|</span><label class="collapse" for="c-39075051">[-]</label><label class="expand" for="c-39075051">[1 more]</label></div><br/><div class="children"><div class="content">My initial interpretation was that you&#x27;re saying fair use is irrelevant to the situation because machine learning models aren&#x27;t themselves legal persons. But, fair use doesn&#x27;t solely apply to manual creation - use of traditional algorithms (e.g: the snippets, caching, and thumbnailing done by search engines) is still covered by fair use. To my understanding, that&#x27;s why ronsor pointed out that ML models are tools used by people (and those people can give a fair use defense).<p>Possibly you instead meant that fair use is relevant, but people are wording remarks in a way that suggests the model itself is giving a fair use defence to copyright infringement, rather than the persons training or using it?</div><br/></div></div></div></div></div></div><div id="39072640" class="c"><input type="checkbox" id="c-39072640" checked=""/><div class="controls bullet"><span class="by">CaptainFever</span><span>|</span><a href="#39070921">parent</a><span>|</span><a href="#39071386">prev</a><span>|</span><a href="#39068487">next</a><span>|</span><label class="collapse" for="c-39072640">[-]</label><label class="expand" for="c-39072640">[2 more]</label></div><br/><div class="children"><div class="content">No one is saying a model is the legal entity. The legal entities are still people and corporations.</div><br/><div id="39074131" class="c"><input type="checkbox" id="c-39074131" checked=""/><div class="controls bullet"><span class="by">enord</span><span>|</span><a href="#39070921">root</a><span>|</span><a href="#39072640">parent</a><span>|</span><a href="#39068487">next</a><span>|</span><label class="collapse" for="c-39074131">[-]</label><label class="expand" for="c-39074131">[1 more]</label></div><br/><div class="children"><div class="content">Oh come on, you’re being insincere. Wether or not the model is learning from the work just like people is hotly debated <i>as if it would make a difference</i>. Fair use is even brought up. Fair use! Even if it applied, these training sets collate <i>all of everything</i><p>I feel like I’m taking crazy pills TBQH</div><br/></div></div></div></div></div></div><div id="39068487" class="c"><input type="checkbox" id="c-39068487" checked=""/><div class="controls bullet"><span class="by">ultimoo</span><span>|</span><a href="#39070921">prev</a><span>|</span><a href="#39068272">next</a><span>|</span><label class="collapse" for="c-39068487">[-]</label><label class="expand" for="c-39068487">[1 more]</label></div><br/><div class="children"><div class="content">would it have been that hard to include a sample photo and how it looks with the nightshade filter side by side in a 3 page document describing how it would look in great detail</div><br/></div></div><div id="39068272" class="c"><input type="checkbox" id="c-39068272" checked=""/><div class="controls bullet"><span class="by">gmerc</span><span>|</span><a href="#39068487">prev</a><span>|</span><a href="#39075230">next</a><span>|</span><label class="collapse" for="c-39068272">[-]</label><label class="expand" for="c-39068272">[6 more]</label></div><br/><div class="children"><div class="content">Doing the work to increase OpenAIs moat</div><br/><div id="39068317" class="c"><input type="checkbox" id="c-39068317" checked=""/><div class="controls bullet"><span class="by">Drakim</span><span>|</span><a href="#39068272">parent</a><span>|</span><a href="#39075230">next</a><span>|</span><label class="collapse" for="c-39068317">[-]</label><label class="expand" for="c-39068317">[5 more]</label></div><br/><div class="children"><div class="content">Obviously AIs can just train on images that aren&#x27;t poisoned.</div><br/><div id="39068442" class="c"><input type="checkbox" id="c-39068442" checked=""/><div class="controls bullet"><span class="by">jsheard</span><span>|</span><a href="#39068272">root</a><span>|</span><a href="#39068317">parent</a><span>|</span><a href="#39075230">next</a><span>|</span><label class="collapse" for="c-39068442">[-]</label><label class="expand" for="c-39068442">[4 more]</label></div><br/><div class="children"><div class="content">Is it possible to reliably detect whether an image is poisoned? If not then it achieves the goal of punishing entities which indiscriminately harvest data.</div><br/><div id="39068625" class="c"><input type="checkbox" id="c-39068625" checked=""/><div class="controls bullet"><span class="by">Kalium</span><span>|</span><a href="#39068272">root</a><span>|</span><a href="#39068442">parent</a><span>|</span><a href="#39068615">next</a><span>|</span><label class="collapse" for="c-39068625">[-]</label><label class="expand" for="c-39068625">[1 more]</label></div><br/><div class="children"><div class="content">You can use older images, collected from before the &quot;poisoning&quot; software was released. Then you don&#x27;t have to.<p>This, of course, assumes that &quot;poisoning&quot; actually works. Glaze and Nightshade and similar are very much akin to the various documented attacks on facial recognition systems. The attack does not exploit some fundamental flaw in how the systems work, but specific characteristics in a given implementation and version.<p>This matters because it means that later versions and models will inevitably not have the same vulnerabilities. The result is that any given defensive transformation should be expected to be only narrowly effective.</div><br/></div></div><div id="39068615" class="c"><input type="checkbox" id="c-39068615" checked=""/><div class="controls bullet"><span class="by">Drakim</span><span>|</span><a href="#39068272">root</a><span>|</span><a href="#39068442">parent</a><span>|</span><a href="#39068625">prev</a><span>|</span><a href="#39068664">next</a><span>|</span><label class="collapse" for="c-39068615">[-]</label><label class="expand" for="c-39068615">[1 more]</label></div><br/><div class="children"><div class="content">It&#x27;s roughly in the same spot as reliably detecting if you have permission to use the image for your data training set in the first place.<p>If it doesn&#x27;t matter, then neither does the poisoning matter.</div><br/></div></div><div id="39068664" class="c"><input type="checkbox" id="c-39068664" checked=""/><div class="controls bullet"><span class="by">dist-epoch</span><span>|</span><a href="#39068272">root</a><span>|</span><a href="#39068442">parent</a><span>|</span><a href="#39068615">prev</a><span>|</span><a href="#39075230">next</a><span>|</span><label class="collapse" for="c-39068664">[-]</label><label class="expand" for="c-39068664">[1 more]</label></div><br/><div class="children"><div class="content">AI&#x27;s have learned much tougher things. You just need a small data set of poisoned images to learn it&#x27;s features.</div><br/></div></div></div></div></div></div></div></div><div id="39075230" class="c"><input type="checkbox" id="c-39075230" checked=""/><div class="controls bullet"><span class="by">aussieguy1234</span><span>|</span><a href="#39068272">prev</a><span>|</span><a href="#39074414">next</a><span>|</span><label class="collapse" for="c-39075230">[-]</label><label class="expand" for="c-39075230">[1 more]</label></div><br/><div class="children"><div class="content">The image generation models now are at the point where they can produce their own synthetic training images. So I&#x27;m not sure how big of an impact something like this would have.</div><br/></div></div><div id="39075293" class="c"><input type="checkbox" id="c-39075293" checked=""/><div class="controls bullet"><span class="by">matt3210</span><span>|</span><a href="#39074414">prev</a><span>|</span><label class="collapse" for="c-39075293">[-]</label><label class="expand" for="c-39075293">[2 more]</label></div><br/><div class="children"><div class="content">Put a TOC on all your  content that says “by using my content for AI you agree to pay X per image” and then send them a bill once you see it in an AI.</div><br/><div id="39075419" class="c"><input type="checkbox" id="c-39075419" checked=""/><div class="controls bullet"><span class="by">wruza</span><span>|</span><a href="#39075293">parent</a><span>|</span><label class="collapse" for="c-39075419">[-]</label><label class="expand" for="c-39075419">[1 more]</label></div><br/><div class="children"><div class="content">Once you see what exactly? “AI” isn’t some image filter from the early 2000s.</div><br/></div></div></div></div></div></div></div></div></div></body></html>